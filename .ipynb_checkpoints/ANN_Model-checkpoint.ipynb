{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.config import Config_f\n",
    "from lib.data_set import Features\n",
    "from lib.model import SimpleModel\n",
    "from lib import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctypes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pywt\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest,f_classif,chi2,mutual_info_classif,VarianceThreshold,RFE,SelectFromModel\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,f1_score\n",
    "\n",
    "from tensorflow.keras import layers as KL\n",
    "from tensorflow.keras import models as KM\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File name read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file name of data with various Labels\n",
    "df = pd.read_csv('./useful_data_label.csv',index_col=0) \n",
    "# read file name of data with only label 0\n",
    "df2 = pd.read_csv('./unuseful_data_label.csv',index_col=0)\n",
    "# read some of the data with only label 0\n",
    "df3 = pd.read_csv('./data/file_name.txt',header=None)\n",
    "player = ctypes.windll.kernel32\n",
    "\n",
    "ind = df2.iloc[1].isna()\n",
    "files = np.concatenate([np.array(df.columns),np.array('normal/'+df2.columns[ind])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Override the base class of Config and Features for ANN Model\n",
    "class ANN_Config(Config_f):\n",
    "    NAME = 'ANN'\n",
    "    NUM_CLASSES = 2\n",
    "    EPOCHS = 300\n",
    "    BATCH_SIZE = 32\n",
    "    CLASS_WEIGHTS = None\n",
    "    COST_SENSITIVE = False\n",
    "    \n",
    "    FN_LP = 300\n",
    "    DETREND_LAMBDA = 50\n",
    "    TEST_FILES = files[[5,30,31,32,33,34,35]]\n",
    "    \n",
    "    \n",
    "class ANN_dataset(Features):\n",
    "    \n",
    "    def __init__(self,config):\n",
    "        super(ANN_dataset,self).__init__(config)\n",
    "        self.config = config\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BATCH_SIZE                     32\n",
      "BINS                           3\n",
      "CHANNELS                       ['LEFT_TA', 'LEFT_TS', 'LEFT_BF', 'LEFT_RF', 'RIGHT_TA', 'RIGHT_TS', 'RIGHT_BF', 'RIGHT_RF']\n",
      "CLASS_WEIGHTS                  None\n",
      "COST_SENSITIVE                 False\n",
      "DETREND_LAMBDA                 50\n",
      "DROP_WITH_ZSCORE               None\n",
      "EPOCHS                         300\n",
      "FEATURES_LIST                  ['IEMG', 'SSI', 'WL', 'ZC', 'ku', 'SSC', 'skew', 'Acti', 'AR', 'HIST', 'MDF', 'MNF', 'mDWT']\n",
      "FN_HP                          None\n",
      "FN_IR                          False\n",
      "FN_LP                          300\n",
      "LEVEL_DWT                      3\n",
      "NAME                           ANN\n",
      "NUM_CLASSES                    2\n",
      "NUM_MF                         3\n",
      "N_ENV                          20\n",
      "RANGES                         (-3, 3)\n",
      "RECT                           False\n",
      "REMOVE_FREQS                   True\n",
      "SAME_LABEL                     True\n",
      "SAVE                           False\n",
      "SCALE                          True\n",
      "SHUFFLE                        True\n",
      "STEP_SIZE                      512\n",
      "TEST_FILES                     ['G07_Freezing_Trial1_trial_1_emg.csv'\n",
      " 'normal/G09_Walking_trial_2_emg.csv' 'normal/G09_Walking_trial_4_emg.csv'\n",
      " 'normal/G09_Walking_trial_6_emg.csv' 'normal/G11_Walking_trial_2_emg.csv'\n",
      " 'normal/G11_Walking_trial_4_emg.csv'\n",
      " 'normal/P231_M050_A_Walking_trial_2_emg.csv']\n",
      "THRESHOLD_SSC                  0.01\n",
      "THRESHOLD_WAMP                 1\n",
      "THRESHOLD_ZC                   0.0\n",
      "TRAIN_SET_RATIO                0.8\n",
      "WAVELET_DWT                    db7\n",
      "WINDOW_SIZE                    1024\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate ANN configuration\n",
    "config = ANN_Config()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ANN_dataset(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip\n",
      "skip\n",
      "3/174: G06_FoG_trial_1_emg.csv\n",
      "4/174: G06_FoG_trial_2_emg.csv\n",
      "5/174: G06_FoG_trial_3_emg.csv\n",
      "6/174: G07_Freezing_Trial1_trial_1_emg.csv\n",
      "7/174: G08_FoG_1_trial_1_emg.csv\n",
      "8/174: G08_FoG_2_trial_1_emg.csv\n",
      "9/174: G11_FoG_trial_1_emg.csv\n",
      "10/174: G11_FoG_trial_2_emg.csv\n",
      "11/174: P379_M050_2_OFF_A_FoG_trial_1_emg.csv\n",
      "12/174: P379_M050_2_OFF_A_FoG_trial_2_emg.csv\n",
      "13/174: P379_M050_2_OFF_A_FoG_trial_3_emg.csv\n",
      "14/174: P379_M050_2_OFF_B_FoG_trial_1_emg.csv\n",
      "15/174: P379_M050_2_OFF_B_FoG_trial_2_emg.csv\n",
      "16/174: P379_M050_2_OFF_B_FoG_trial_3_emg.csv\n",
      "17/174: P551_M050_2_A_FoG_trial_1_emg.csv\n",
      "18/174: P551_M050_2_B_FoG_trial_1_emg.csv\n",
      "19/174: P551_M050_2_B_FoG_trial_2_emg.csv\n",
      "20/174: P812_M050_2_B_FoG_trial_1_emg.csv\n",
      "21/174: P812_M050_2_B_FoG_trial_2_emg.csv\n",
      "22/174: normal/G02_Walking_trial_1_emg.csv\n",
      "23/174: normal/G03_Walking_trial_1_emg.csv\n",
      "24/174: normal/G03_Walking_trial_2_emg.csv\n",
      "25/174: normal/G05_Walking_struct_fixed_trial_1_emg.csv\n",
      "26/174: normal/G05_Walking_struct_fixed_trial_2_emg.csv\n",
      "27/174: normal/G05_Walking_struct_fixed_trial_3_emg.csv\n",
      "28/174: normal/G09_FoG_trial_1_emg.csv\n",
      "29/174: normal/G09_FoG_trial_2_emg.csv\n",
      "30/174: normal/G09_FoG_trial_3_emg.csv\n",
      "31/174: normal/G09_Walking_trial_2_emg.csv\n",
      "32/174: normal/G09_Walking_trial_4_emg.csv\n",
      "33/174: normal/G09_Walking_trial_6_emg.csv\n",
      "34/174: normal/G11_Walking_trial_2_emg.csv\n",
      "35/174: normal/G11_Walking_trial_4_emg.csv\n",
      "36/174: normal/P231_M050_A_Walking_trial_2_emg.csv\n",
      "37/174: normal/P231_M050_A_Walking_trial_4_emg.csv\n",
      "38/174: normal/P231_M050_A_Walking_trial_6_emg.csv\n",
      "39/174: normal/P231_M050_B_Walking_trial_2_emg.csv\n",
      "40/174: normal/P231_M050_B_Walking_trial_4_emg.csv\n",
      "41/174: normal/P231_M050_B_Walking_trial_6_emg.csv\n",
      "42/174: normal/P231_M100_2_A_FoG_trial_3_emg.csv\n",
      "43/174: normal/P231_M100_2_A_Walking_trial_4_emg.csv\n",
      "44/174: normal/P231_M100_2_A_Walking_trial_6_emg.csv\n",
      "45/174: normal/P231_M100_ON_A_Walking_trial_2_emg.csv\n",
      "46/174: normal/P231_M100_ON_A_Walking_trial_4_emg.csv\n",
      "47/174: normal/P231_M100_ON_A_Walking_trial_6_emg.csv\n",
      "48/174: normal/P231_Msham_A_Walking_trial_2_emg.csv\n",
      "49/174: normal/P231_Msham_A_Walking_trial_6_emg.csv\n",
      "50/174: normal/P231_Msham_B_Walking_trial_2_emg.csv\n",
      "51/174: normal/P351_M050_2_A_FoG_trial_1_emg.csv\n",
      "52/174: normal/P351_M050_2_A_FoG_trial_2_emg.csv\n",
      "53/174: normal/P351_M050_2_A_FoG_trial_3_emg.csv\n",
      "54/174: normal/P351_M050_2_A_Walking_trial_2_emg.csv\n",
      "55/174: normal/P351_M050_2_A_Walking_trial_4_emg.csv\n",
      "56/174: normal/P351_M050_2_A_Walking_trial_6_emg.csv\n",
      "57/174: normal/P351_M050_2_B_FoG_trial_1_emg.csv\n",
      "58/174: normal/P351_M050_2_B_FoG_trial_2_emg.csv\n",
      "59/174: normal/P351_M050_2_B_FoG_trial_3_emg.csv\n",
      "60/174: normal/P351_M050_2_B_Walking_trial_2_emg.csv\n",
      "61/174: normal/P351_M050_2_B_Walking_trial_4_emg.csv\n",
      "62/174: normal/P351_M050_2_B_Walking_trial_6_emg.csv\n",
      "63/174: normal/P351_M050_A_FoG_trial_1_emg.csv\n",
      "64/174: normal/P351_M050_A_FoG_trial_2_emg.csv\n",
      "65/174: normal/P351_M050_A_FoG_trial_3_emg.csv\n",
      "66/174: normal/P351_M050_A_Walking_trial_2_emg.csv\n",
      "67/174: normal/P351_M050_A_Walking_trial_4_emg.csv\n",
      "68/174: normal/P351_M050_B_FoG_trial_1_emg.csv\n",
      "69/174: normal/P351_M050_B_FoG_trial_2_emg.csv\n",
      "70/174: normal/P351_M050_B_FoG_trial_3_emg.csv\n",
      "71/174: normal/P351_M050_B_Walking_trial_2_emg.csv\n",
      "72/174: normal/P351_M050_B_Walking_trial_4_emg.csv\n",
      "73/174: normal/P351_M050_B_Walking_trial_6_emg.csv\n",
      "74/174: normal/P351_Msham_A_FoG_trial_1_emg.csv\n",
      "75/174: normal/P351_Msham_A_FoG_trial_2_emg.csv\n",
      "76/174: normal/P351_Msham_A_FoG_trial_3_emg.csv\n",
      "77/174: normal/P351_Msham_A_Walking_trial_2_emg.csv\n",
      "78/174: normal/P351_Msham_A_Walking_trial_4_emg.csv\n",
      "79/174: normal/P351_Msham_A_Walking_trial_6_emg.csv\n",
      "80/174: normal/P351_Msham_B_FoG_trial_1_emg.csv\n",
      "81/174: normal/P351_Msham_B_FoG_trial_2_emg.csv\n",
      "82/174: normal/P351_Msham_B_FoG_trial_3_emg.csv\n",
      "83/174: normal/P351_Msham_B_Walking_trial_2_emg.csv\n",
      "84/174: normal/P351_Msham_B_Walking_trial_4_emg.csv\n",
      "85/174: normal/P351_Msham_B_Walking_trial_6_emg.csv\n",
      "86/174: normal/P379_M050_A_Walking_trial_2_emg.csv\n",
      "87/174: normal/P379_M050_A_Walking_trial_3_emg.csv\n",
      "88/174: normal/P379_M050_B_Walking_trial_2_emg.csv\n",
      "89/174: normal/P379_Msham_B_Walking_trial_6_emg.csv\n",
      "90/174: normal/P533_M050_A_Walking_trial_1_emg.csv\n",
      "91/174: normal/P533_M050_A_Walking_trial_2_emg.csv\n",
      "92/174: normal/P533_M050_B_Walking_trial_2_emg.csv\n",
      "93/174: normal/P533_M050_B_Walking_trial_3_emg.csv\n",
      "94/174: normal/P533_M100_A_Walking_trial_2_emg.csv\n",
      "95/174: normal/P533_M100_B_Walking_trial_4_emg.csv\n",
      "96/174: normal/P551_M50_B_Walking_trial_6_emg.csv\n",
      "97/174: normal/P623_M050_2_A_Walking_trial_2_emg.csv\n",
      "98/174: normal/P623_M050_2_A_Walking_trial_4_emg.csv\n",
      "skip\n",
      "100/174: normal/P623_M050_2_B_Walking_trial_2_emg.csv\n",
      "101/174: normal/P623_M050_2_B_Walking_trial_6_emg.csv\n",
      "102/174: normal/P623_M050_A_Walking_trial_4_emg.csv\n",
      "103/174: normal/P623_M100_A_Walking_trial_4_emg.csv\n",
      "104/174: normal/P623_M100_B_Walking_trial_4_emg.csv\n",
      "105/174: normal/P623_Msham_A_Walking_trial_4_emg.csv\n",
      "106/174: normal/P623_Msham_A_Walking_trial_6_emg.csv\n",
      "107/174: normal/P623_Msham_B_Walking_trial_2_emg.csv\n",
      "108/174: normal/P623_Msham_B_Walking_trial_4_emg.csv\n",
      "109/174: normal/P645_M050_A_Walking_trial_2_emg.csv\n",
      "110/174: normal/P645_M050_A_Walking_trial_3_emg.csv\n",
      "111/174: normal/P645_M050_B_Walking_trial_2_emg.csv\n",
      "112/174: normal/P645_M050_B_Walking_trial_3_emg.csv\n",
      "113/174: normal/P812_M050_2_A_FoG_trial_1_emg.csv\n",
      "114/174: normal/P812_M050_2_A_FoG_trial_3_emg.csv\n",
      "115/174: normal/P812_M050_2_A_Walking_trial_2_emg.csv\n",
      "116/174: normal/P812_M050_2_A_Walking_trial_3_emg.csv\n",
      "117/174: normal/P812_M050_2_B_Walking_1_trial_4_emg.csv\n",
      "118/174: normal/P812_M050_A_FoG_trial_1_emg.csv\n",
      "119/174: normal/P812_M050_A_FoG_trial_2_emg.csv\n",
      "120/174: normal/P812_M050_A_FoG_trial_3_emg.csv\n",
      "121/174: normal/P812_M050_A_Walking_trial_1_emg.csv\n",
      "122/174: normal/P812_M050_A_Walking_trial_2_emg.csv\n",
      "123/174: normal/P812_M050_B_FoG_trial_1_emg.csv\n",
      "124/174: normal/P812_M050_B_FoG_trial_2_emg.csv\n",
      "125/174: normal/P812_M050_B_FoG_trial_3_emg.csv\n",
      "126/174: normal/P812_M050_B_Walking_trial_1_emg.csv\n",
      "127/174: normal/P812_M050_B_Walking_trial_2_emg.csv\n",
      "128/174: normal/P812_M100_A_FoG_trial_1_emg.csv\n",
      "129/174: normal/P812_M100_A_Walking_trial_3_emg.csv\n",
      "130/174: normal/P812_M100_B_FoG_trial_1_emg.csv\n",
      "131/174: normal/P812_M100_B_FoG_trial_3_emg.csv\n",
      "132/174: normal/P812_M100_B_Walking2_trial_1_emg.csv\n",
      "133/174: normal/P812_M100_B_Walking2_trial_2_emg.csv\n",
      "134/174: normal/P876_M100_B_FoG_trial_1_emg.csv\n",
      "135/174: normal/P876_M100_B_FoG_trial_2_emg.csv\n",
      "136/174: normal/P876_M100_B_FoG_trial_3_emg.csv\n",
      "137/174: normal/P876_M100_B_Walking_trial_4_emg.csv\n",
      "138/174: normal/P876_M100_B_Walking_trial_6_emg.csv\n",
      "139/174: normal/P940_M050_2_A_FoG_trial_3_emg.csv\n",
      "140/174: normal/P940_M050_2_A_FoG_trial_4_emg.csv\n",
      "141/174: normal/P940_M050_2_A_Walking_trial_2_emg.csv\n",
      "142/174: normal/P940_M050_2_B_FoG_trial_1_emg.csv\n",
      "143/174: normal/P940_M050_2_B_Walking_trial_2_emg.csv\n",
      "144/174: normal/P940_M050_2_B_Walking_trial_4_emg.csv\n",
      "145/174: normal/P940_M050_2_B_Walking_trial_6_emg.csv\n",
      "146/174: normal/P940_M050_A_FoG_trial_2_emg.csv\n",
      "147/174: normal/P940_M050_A_FoG_trial_3_emg.csv\n",
      "148/174: normal/P940_M050_A_Walking_trial_2_emg.csv\n",
      "149/174: normal/P940_M050_A_Walking_trial_4_emg.csv\n",
      "150/174: normal/P940_M050_A_Walking_trial_6_emg.csv\n",
      "151/174: normal/P940_M050_B_FoG_trial_1_emg.csv\n",
      "152/174: normal/P940_M050_B_FoG_trial_2_emg.csv\n",
      "153/174: normal/P940_M050_B_FoG_trial_3_emg.csv\n",
      "154/174: normal/P940_M050_B_Walking_trial_2_emg.csv\n",
      "155/174: normal/P940_M050_B_Walking_trial_4_emg.csv\n",
      "156/174: normal/P940_M050_B_Walking_trial_6_emg.csv\n",
      "157/174: normal/P940_M100_A_FoG_trial_1_emg.csv\n",
      "158/174: normal/P940_M100_A_FoG_trial_2_emg.csv\n",
      "159/174: normal/P940_M100_A_FoG_trial_3_emg.csv\n",
      "160/174: normal/P940_M100_A_Walking_trial_2_emg.csv\n",
      "161/174: normal/P940_M100_A_Walking_trial_4_emg.csv\n",
      "162/174: normal/P940_M100_A_Walking_trial_6_emg.csv\n",
      "163/174: normal/P940_M100_B_FoG_trial_2_emg.csv\n",
      "164/174: normal/P940_M100_B_FoG_trial_3_emg.csv\n",
      "165/174: normal/P940_M100_B_Walking_2_trial_2_emg.csv\n",
      "166/174: normal/P940_M100_B_Walking_2_trial_6_emg.csv\n",
      "167/174: normal/P940_MSham_A_FoG_trial_1_emg.csv\n",
      "168/174: normal/P940_MSham_A_FoG_trial_3_emg.csv\n",
      "169/174: normal/P940_MSham_A_Walking_trial_2_emg.csv\n",
      "170/174: normal/P940_MSham_A_Walking_trial_4_emg.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/174: normal/P940_MSham_A_Walking_trial_6_emg.csv\n",
      "172/174: normal/P940_MSham_B_Walking_trial_2_emg.csv\n",
      "173/174: normal/P940_MSham_B_Walking_trial_4_emg.csv\n",
      "174/174: normal/P940_MSham_B_Walking_trial_6_emg.csv\n",
      "threshold_WAMP:1.0, threshold_ZC:0.0, threshold_SSC:0.0, bins:3, ranges:(-3,3), num_mf:3, wavelet: db7, level: 3\n",
      "['IEMG', 'SSI', 'WL', 'ZC', 'ku', 'SSC', 'skew', 'Acti', 'AR', 'HIST', 'MDF', 'MNF', 'mDWT']\n",
      "threshold_WAMP:1.0, threshold_ZC:0.0, threshold_SSC:0.0, bins:3, ranges:(-3,3), num_mf:3, wavelet: db7, level: 3\n",
      "['IEMG', 'SSI', 'WL', 'ZC', 'ku', 'SSC', 'skew', 'Acti', 'AR', 'HIST', 'MDF', 'MNF', 'mDWT']\n",
      "threshold_WAMP:1.0, threshold_ZC:0.0, threshold_SSC:0.0, bins:3, ranges:(-3,3), num_mf:3, wavelet: db7, level: 3\n",
      "['IEMG', 'SSI', 'WL', 'ZC', 'ku', 'SSC', 'skew', 'Acti', 'AR', 'HIST', 'MDF', 'MNF', 'mDWT']\n"
     ]
    }
   ],
   "source": [
    "# Choose features to use\n",
    "data.feature_list = ['IEMG', 'SSI', 'WL', 'ZC', 'ku', 'SSC', 'skew', 'Acti', 'AR', 'HIST', 'MDF', 'MNF', 'mDWT']\n",
    "\n",
    "# Load data from files\n",
    "data.load_data(files)\n",
    "\n",
    "# Extract features from data\n",
    "data.extract_features()\n",
    "\n",
    "X_train,Y_train,_ = data.train_set\n",
    "X_valid,Y_valid,_ = data.valid_set\n",
    "X_test, Y_test, _ = data.test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Override base class of SimpleMode for ANN\n",
    "class ANN_Model(SimpleModel):\n",
    "    \n",
    "    def build(self,config):\n",
    "        \n",
    "        reg = keras.regularizers.l1(0)\n",
    "        acti = 'elu'\n",
    "        drop = 0.2\n",
    "        init = 'glorot_normal'\n",
    "\n",
    "        model = KM.Sequential()\n",
    "        model.add(KL.Dense(128,\n",
    "                               kernel_initializer=init,\n",
    "                               kernel_regularizer = reg,\n",
    "                               #use_bias=False\n",
    "                         ))\n",
    "        model.add(KL.Activation(acti))\n",
    "        model.add(KL.Dropout(drop))\n",
    "\n",
    "        model.add(KL.Dense(64,\n",
    "                               kernel_initializer=init,\n",
    "                               kernel_regularizer = reg,\n",
    "                              # use_bias=False\n",
    "                         ))\n",
    "        model.add(KL.Activation(acti))\n",
    "        model.add(KL.Dropout(drop))\n",
    "\n",
    "        model.add(KL.Dense(32,\n",
    "                               kernel_initializer=init,\n",
    "                               kernel_regularizer = reg,\n",
    "                               #use_bias=False\n",
    "                         ))\n",
    "        model.add(KL.Activation(acti))\n",
    "        model.add(KL.Dropout(drop))\n",
    "\n",
    "        model.add(KL.Dense(16,\n",
    "                               kernel_initializer=init,\n",
    "                               kernel_regularizer = reg,\n",
    "                               #use_bias=False\n",
    "                         ))\n",
    "        model.add(KL.Activation(acti))\n",
    "        model.add(KL.Dropout(drop))\n",
    "\n",
    "        model.add(KL.Dense(config.NUM_CLASSES,activation='softmax'))\n",
    "\n",
    "        \n",
    "        if config.COST_SENSITIVE:\n",
    "            self.cost_matrix = config.COST_MATRIX\n",
    "            model.compile(loss=self.sparse_cost_sensitive_loss, optimizer=\"adam\", metrics=['accuracy'])\n",
    "            print('Using cost sensitive with cost matrix:\\n',np.array(self.cost_matrix))\n",
    "        else:\n",
    "            model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "            if config.CLASS_WEIGHTS != None:\n",
    "                print('Using categorical crossentropy with class weights:\\n',config.CLASS_WEIGHTS)\n",
    "            else:\n",
    "                print('Using categorical crossentropy without class weights.')\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train(self, train_dataset, val_dataset, oh, transformer=None, callbacks=None):\n",
    "        \n",
    "        self.X_train = train_dataset[0]\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train = scaler.fit_transform(train_dataset[0])\n",
    "        \n",
    "        scaler.fit(np.concatenate([train_dataset[0],val_dataset[0]]))\n",
    "        X_val = scaler.transform(val_dataset[0])\n",
    "        \n",
    "        if transformer != None:\n",
    "            self.transformer = transformer\n",
    "            self.transformer.fit(X_train,np.ravel(oh.inverse_transform(train_dataset[1])))\n",
    "            X_train = self.transformer.transform(X_train)\n",
    "            X_val = self.transformer.transform(X_val)\n",
    "        else:\n",
    "            self.transformer = None\n",
    "\n",
    "        self.simple_model.fit(X_train,\n",
    "                              train_dataset[1],\n",
    "                              validation_data=(X_val,val_dataset[1]),\n",
    "                              epochs=self.config.EPOCHS,\n",
    "                              batch_size=self.config.BATCH_SIZE,\n",
    "                              class_weight=self.config.CLASS_WEIGHTS,\n",
    "                              callbacks=callbacks,\n",
    "                              shuffle=True)\n",
    "\n",
    "    def sparse_cost_sensitive_loss (self,y_true,y_pred):\n",
    "        cost_matrix = self.cost_matrix\n",
    "        batch_cost_matrix = tf.nn.embedding_lookup(cost_matrix, tf.argmax(y_true,axis=1))\n",
    "        eps = 1e-6\n",
    "        probability = tf.clip_by_value(y_pred, eps, 1-eps)\n",
    "        cost_values = tf.math.log(1-probability)*batch_cost_matrix\n",
    "        loss = tf.reduce_mean(-tf.reduce_sum(cost_values, axis=1))\n",
    "        return loss\n",
    "    \n",
    "    def model_metrics(self,data,label):\n",
    "        pred = self.predict(data)\n",
    "        acc = accuracy_score(np.argmax(label,axis=1),np.argmax(pred,axis=1))\n",
    "        cm = confusion_matrix(np.argmax(label,axis=1),np.argmax(pred,axis=1))\n",
    "        f1 = f1_score(np.argmax(label,axis=1),np.argmax(pred,axis=1),average='macro')\n",
    "        return acc,cm,f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data split and processing for model\n",
    "class_id = [1,2,6]\n",
    "binary = True\n",
    "x_train,y_train,x_valid,y_valid,x_test,y_test,oh = utils.data_split_oh((X_train,X_valid,X_test),\n",
    "                                                                    (Y_train,Y_valid,Y_test),\n",
    "                                                                    class_id,\n",
    "                                                                    binary,\n",
    "                                                                    random_state = 555)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cost sensitive with cost matrix:\n",
      " [[ 0.  1.]\n",
      " [10.  0.]]\n"
     ]
    }
   ],
   "source": [
    "config.EPOCHS = 300\n",
    "config.NUM_CLASSES = 2\n",
    "config.CLASS_WEIGHTS = None#{0:1,1:5}\n",
    "\n",
    "config.COST_MATRIX = tf.constant([[0,1.],\n",
    "              [5,0]])\n",
    "\n",
    "pca = PCA(n_components=80,copy=True)\n",
    "sfm = SelectFromModel(GradientBoostingClassifier(),max_features=80)\n",
    "rfe = RFE(estimator=LogisticRegression(max_iter=10000), n_features_to_select=80)\n",
    "vt = VarianceThreshold(threshold=0.01)\n",
    "\n",
    "if binary:\n",
    "    config.COST_SENSITIVE = True\n",
    "    config.NUM_CLASSES = 2\n",
    "    transformer=rfe\n",
    "else:\n",
    "    config.COST_SENSITIVE = False\n",
    "    config.NUM_CLASSES = len(class_id)\n",
    "    transformer=pca\n",
    "\n",
    "# Generate ANN Model\n",
    "ANN_model = ANN_Model('ANN',config,'./model/ANN/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "173/173 [==============================] - 2s 5ms/step - loss: 1.1599 - accuracy: 0.6642 - val_loss: 0.6068 - val_accuracy: 0.7518\n",
      "Epoch 2/300\n",
      "173/173 [==============================] - 0s 3ms/step - loss: 0.5240 - accuracy: 0.8730 - val_loss: 0.3870 - val_accuracy: 0.8737\n",
      "Epoch 3/300\n",
      "173/173 [==============================] - 1s 3ms/step - loss: 0.4406 - accuracy: 0.8936 - val_loss: 0.4519 - val_accuracy: 0.8133\n",
      "Epoch 4/300\n",
      "173/173 [==============================] - 1s 4ms/step - loss: 0.4073 - accuracy: 0.8958 - val_loss: 0.3661 - val_accuracy: 0.8606\n",
      "Epoch 5/300\n",
      "173/173 [==============================] - 1s 5ms/step - loss: 0.3728 - accuracy: 0.9107 - val_loss: 0.2736 - val_accuracy: 0.9477\n",
      "Epoch 6/300\n",
      "173/173 [==============================] - 1s 4ms/step - loss: 0.3769 - accuracy: 0.9105 - val_loss: 0.2709 - val_accuracy: 0.9554\n",
      "Epoch 7/300\n",
      "173/173 [==============================] - 0s 3ms/step - loss: 0.3725 - accuracy: 0.9166 - val_loss: 0.3225 - val_accuracy: 0.8759\n",
      "Epoch 8/300\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.3280 - accuracy: 0.9109 - val_loss: 0.3180 - val_accuracy: 0.8775\n",
      "Epoch 9/300\n",
      "173/173 [==============================] - 1s 3ms/step - loss: 0.3676 - accuracy: 0.9016 - val_loss: 0.2540 - val_accuracy: 0.9178\n",
      "Epoch 10/300\n",
      "173/173 [==============================] - 1s 5ms/step - loss: 0.3033 - accuracy: 0.9243 - val_loss: 0.2297 - val_accuracy: 0.9456\n",
      "Epoch 11/300\n",
      "173/173 [==============================] - 1s 3ms/step - loss: 0.2741 - accuracy: 0.9336 - val_loss: 0.4869 - val_accuracy: 0.8035\n",
      "Epoch 12/300\n",
      "173/173 [==============================] - 1s 4ms/step - loss: 0.3224 - accuracy: 0.9138 - val_loss: 0.2593 - val_accuracy: 0.9630\n",
      "Epoch 13/300\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.3135 - accuracy: 0.9227 - val_loss: 0.2504 - val_accuracy: 0.9145\n",
      "Epoch 14/300\n",
      "173/173 [==============================] - 1s 5ms/step - loss: 0.2483 - accuracy: 0.9297 - val_loss: 0.2209 - val_accuracy: 0.9428\n",
      "Epoch 15/300\n",
      "173/173 [==============================] - 1s 5ms/step - loss: 0.2964 - accuracy: 0.9339 - val_loss: 0.2360 - val_accuracy: 0.9194\n",
      "Epoch 16/300\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.3179 - accuracy: 0.9220 - val_loss: 0.3608 - val_accuracy: 0.9733\n",
      "Epoch 17/300\n",
      "173/173 [==============================] - 1s 7ms/step - loss: 0.2429 - accuracy: 0.9404 - val_loss: 0.2367 - val_accuracy: 0.9570\n",
      "Epoch 18/300\n",
      "173/173 [==============================] - 1s 7ms/step - loss: 0.2727 - accuracy: 0.9232 - val_loss: 0.2134 - val_accuracy: 0.9456\n",
      "Epoch 19/300\n",
      "173/173 [==============================] - 1s 5ms/step - loss: 0.2729 - accuracy: 0.9319 - val_loss: 0.2115 - val_accuracy: 0.9385\n",
      "Epoch 20/300\n",
      "173/173 [==============================] - 1s 5ms/step - loss: 0.2808 - accuracy: 0.9368 - val_loss: 0.2153 - val_accuracy: 0.9298\n",
      "Epoch 21/300\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.2632 - accuracy: 0.9369 - val_loss: 0.2038 - val_accuracy: 0.9407\n",
      "Epoch 22/300\n",
      "173/173 [==============================] - 1s 5ms/step - loss: 0.2980 - accuracy: 0.9294 - val_loss: 0.2290 - val_accuracy: 0.9243\n",
      "Epoch 23/300\n",
      "173/173 [==============================] - 1s 4ms/step - loss: 0.2583 - accuracy: 0.9350 - val_loss: 0.2881 - val_accuracy: 0.8895\n",
      "Epoch 24/300\n",
      "173/173 [==============================] - 1s 4ms/step - loss: 0.2266 - accuracy: 0.9413 - val_loss: 0.2144 - val_accuracy: 0.9287\n",
      "Epoch 25/300\n",
      "173/173 [==============================] - 1s 3ms/step - loss: 0.2474 - accuracy: 0.9393 - val_loss: 0.2081 - val_accuracy: 0.9314\n",
      "Epoch 26/300\n",
      "173/173 [==============================] - 1s 4ms/step - loss: 0.2350 - accuracy: 0.9343 - val_loss: 0.2624 - val_accuracy: 0.9036\n",
      "Epoch 27/300\n",
      "173/173 [==============================] - 1s 4ms/step - loss: 0.2373 - accuracy: 0.9406 - val_loss: 0.2532 - val_accuracy: 0.9145\n",
      "Epoch 28/300\n",
      "173/173 [==============================] - 1s 3ms/step - loss: 0.2107 - accuracy: 0.9469 - val_loss: 0.2060 - val_accuracy: 0.9341\n",
      "Epoch 29/300\n",
      "173/173 [==============================] - 1s 3ms/step - loss: 0.2183 - accuracy: 0.9435 - val_loss: 0.2247 - val_accuracy: 0.9238\n",
      "Epoch 30/300\n",
      "173/173 [==============================] - 1s 3ms/step - loss: 0.2292 - accuracy: 0.9452 - val_loss: 0.2907 - val_accuracy: 0.9036\n",
      "Epoch 31/300\n",
      "173/173 [==============================] - 1s 3ms/step - loss: 0.2818 - accuracy: 0.9202 - val_loss: 0.2194 - val_accuracy: 0.9586\n",
      "Epoch 32/300\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.2346 - accuracy: 0.9435 - val_loss: 0.2324 - val_accuracy: 0.9679\n",
      "Epoch 33/300\n",
      "173/173 [==============================] - 0s 3ms/step - loss: 0.1743 - accuracy: 0.9561 - val_loss: 0.3558 - val_accuracy: 0.8394\n",
      "Epoch 34/300\n",
      "173/173 [==============================] - 1s 3ms/step - loss: 0.2142 - accuracy: 0.9368 - val_loss: 0.2117 - val_accuracy: 0.9679\n",
      "Epoch 35/300\n",
      "173/173 [==============================] - 1s 4ms/step - loss: 0.2009 - accuracy: 0.9481 - val_loss: 0.2617 - val_accuracy: 0.9162\n",
      "Epoch 36/300\n",
      "173/173 [==============================] - 1s 3ms/step - loss: 0.2099 - accuracy: 0.9440 - val_loss: 0.3268 - val_accuracy: 0.8683\n",
      "Epoch 37/300\n",
      "173/173 [==============================] - 1s 3ms/step - loss: 0.2274 - accuracy: 0.9401 - val_loss: 0.1978 - val_accuracy: 0.9652\n",
      "Epoch 38/300\n",
      "173/173 [==============================] - 1s 4ms/step - loss: 0.1736 - accuracy: 0.9553 - val_loss: 0.1888 - val_accuracy: 0.9554\n",
      "Epoch 39/300\n",
      "173/173 [==============================] - 1s 4ms/step - loss: 0.1966 - accuracy: 0.9468 - val_loss: 0.2072 - val_accuracy: 0.9401\n",
      "Epoch 40/300\n",
      "173/173 [==============================] - 1s 3ms/step - loss: 0.2199 - accuracy: 0.9481 - val_loss: 0.2918 - val_accuracy: 0.9760\n",
      "Epoch 41/300\n",
      "173/173 [==============================] - 1s 4ms/step - loss: 0.1775 - accuracy: 0.9540 - val_loss: 0.2747 - val_accuracy: 0.8944\n",
      "Epoch 42/300\n",
      "173/173 [==============================] - 1s 3ms/step - loss: 0.2456 - accuracy: 0.9300 - val_loss: 0.2403 - val_accuracy: 0.9107\n",
      "Epoch 43/300\n",
      "173/173 [==============================] - 1s 4ms/step - loss: 0.2101 - accuracy: 0.9527 - val_loss: 0.1878 - val_accuracy: 0.9483\n",
      "Epoch 44/300\n",
      "173/173 [==============================] - 1s 4ms/step - loss: 0.2428 - accuracy: 0.9407 - val_loss: 0.2034 - val_accuracy: 0.9369\n",
      "Epoch 45/300\n",
      "173/173 [==============================] - 1s 4ms/step - loss: 0.1855 - accuracy: 0.9525 - val_loss: 0.1939 - val_accuracy: 0.9330\n",
      "Epoch 46/300\n",
      "173/173 [==============================] - 1s 4ms/step - loss: 0.1976 - accuracy: 0.9487 - val_loss: 0.2545 - val_accuracy: 0.9102\n",
      "Epoch 47/300\n",
      "173/173 [==============================] - 1s 3ms/step - loss: 0.2949 - accuracy: 0.9172 - val_loss: 0.2154 - val_accuracy: 0.9243\n",
      "Epoch 48/300\n",
      "173/173 [==============================] - 1s 3ms/step - loss: 0.2164 - accuracy: 0.9415 - val_loss: 0.1915 - val_accuracy: 0.9407\n",
      "Epoch 49/300\n",
      "173/173 [==============================] - 1s 3ms/step - loss: 0.1624 - accuracy: 0.9561 - val_loss: 0.2057 - val_accuracy: 0.9673\n",
      "Epoch 50/300\n",
      "173/173 [==============================] - 1s 3ms/step - loss: 0.2005 - accuracy: 0.9494 - val_loss: 0.1809 - val_accuracy: 0.9477\n",
      "Epoch 51/300\n",
      "173/173 [==============================] - 1s 4ms/step - loss: 0.1804 - accuracy: 0.9544 - val_loss: 0.2434 - val_accuracy: 0.9085\n",
      "Epoch 52/300\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.2543 - accuracy: 0.9230 - val_loss: 0.1759 - val_accuracy: 0.9559\n",
      "Epoch 53/300\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.1741 - accuracy: 0.9544 - val_loss: 0.1663 - val_accuracy: 0.9554\n",
      "Epoch 54/300\n",
      "173/173 [==============================] - 0s 3ms/step - loss: 0.1830 - accuracy: 0.9569 - val_loss: 0.3974 - val_accuracy: 0.9766\n",
      "Epoch 55/300\n",
      "173/173 [==============================] - 1s 3ms/step - loss: 0.3002 - accuracy: 0.9140 - val_loss: 0.2882 - val_accuracy: 0.9777\n",
      "Epoch 56/300\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.1844 - accuracy: 0.9607 - val_loss: 0.2340 - val_accuracy: 0.9717\n",
      "Epoch 57/300\n",
      "173/173 [==============================] - 0s 3ms/step - loss: 0.2046 - accuracy: 0.9543 - val_loss: 0.2346 - val_accuracy: 0.9739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/300\n",
      "173/173 [==============================] - 1s 3ms/step - loss: 0.1840 - accuracy: 0.9541 - val_loss: 0.2246 - val_accuracy: 0.9744\n",
      "Epoch 59/300\n",
      "173/173 [==============================] - 1s 4ms/step - loss: 0.2452 - accuracy: 0.9417 - val_loss: 0.4910 - val_accuracy: 0.8323\n",
      "Epoch 60/300\n",
      "173/173 [==============================] - 0s 3ms/step - loss: 0.2051 - accuracy: 0.9424 - val_loss: 0.1721 - val_accuracy: 0.9499\n",
      "Epoch 61/300\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.1873 - accuracy: 0.9485 - val_loss: 0.5071 - val_accuracy: 0.8084\n",
      "Epoch 62/300\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.2029 - accuracy: 0.9521 - val_loss: 0.2105 - val_accuracy: 0.9369\n",
      "Epoch 63/300\n",
      "173/173 [==============================] - 1s 3ms/step - loss: 0.2130 - accuracy: 0.9493 - val_loss: 0.1597 - val_accuracy: 0.9608\n",
      "Epoch 64/300\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.1669 - accuracy: 0.9603 - val_loss: 0.1647 - val_accuracy: 0.9477\n",
      "Epoch 65/300\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.1581 - accuracy: 0.9571 - val_loss: 0.1717 - val_accuracy: 0.9711\n",
      "Epoch 66/300\n",
      "173/173 [==============================] - 1s 3ms/step - loss: 0.1977 - accuracy: 0.9525 - val_loss: 0.1767 - val_accuracy: 0.9722\n",
      "Epoch 67/300\n",
      "173/173 [==============================] - 0s 3ms/step - loss: 0.1426 - accuracy: 0.9636 - val_loss: 0.2558 - val_accuracy: 0.9760\n",
      "Epoch 68/300\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.1710 - accuracy: 0.9566 - val_loss: 0.1928 - val_accuracy: 0.9314\n",
      "Epoch 69/300\n",
      "173/173 [==============================] - 1s 3ms/step - loss: 0.1809 - accuracy: 0.9562 - val_loss: 0.1761 - val_accuracy: 0.9537\n",
      "Epoch 70/300\n",
      "173/173 [==============================] - 1s 3ms/step - loss: 0.1391 - accuracy: 0.9675 - val_loss: 0.1692 - val_accuracy: 0.9679\n",
      "Epoch 71/300\n",
      "173/173 [==============================] - 1s 3ms/step - loss: 0.1367 - accuracy: 0.9677 - val_loss: 0.1631 - val_accuracy: 0.9483\n",
      "Epoch 72/300\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.1714 - accuracy: 0.9540 - val_loss: 0.1723 - val_accuracy: 0.9679\n",
      "Epoch 73/300\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.1594 - accuracy: 0.9582 - val_loss: 0.1597 - val_accuracy: 0.9603\n",
      "Epoch 74/300\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.1667 - accuracy: 0.9561 - val_loss: 0.1813 - val_accuracy: 0.9428\n",
      "Epoch 75/300\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.2212 - accuracy: 0.9432 - val_loss: 0.1623 - val_accuracy: 0.9532\n",
      "Epoch 76/300\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.1654 - accuracy: 0.9620 - val_loss: 0.1831 - val_accuracy: 0.9695\n",
      "Epoch 77/300\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.1696 - accuracy: 0.9592 - val_loss: 0.1580 - val_accuracy: 0.9537\n",
      "Epoch 78/300\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.1465 - accuracy: 0.9655 - val_loss: 0.1816 - val_accuracy: 0.9717\n",
      "Epoch 79/300\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.2334 - accuracy: 0.9349 - val_loss: 0.1960 - val_accuracy: 0.9766\n",
      "Epoch 80/300\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.1471 - accuracy: 0.9667 - val_loss: 0.1715 - val_accuracy: 0.9483\n",
      "Epoch 81/300\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.1631 - accuracy: 0.9600 - val_loss: 0.3082 - val_accuracy: 0.9777\n",
      "Epoch 82/300\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.1660 - accuracy: 0.9653 - val_loss: 0.1817 - val_accuracy: 0.9456\n",
      "Epoch 83/300\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.1946 - accuracy: 0.9397 - val_loss: 0.2578 - val_accuracy: 0.8982\n",
      "Epoch 84/300\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.1864 - accuracy: 0.9452 - val_loss: 0.1926 - val_accuracy: 0.9750\n",
      "Epoch 85/300\n",
      "173/173 [==============================] - 1s 3ms/step - loss: 0.1255 - accuracy: 0.9697 - val_loss: 0.1778 - val_accuracy: 0.9396\n",
      "Epoch 86/300\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.1854 - accuracy: 0.9545 - val_loss: 0.1791 - val_accuracy: 0.9445\n",
      "Epoch 87/300\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.1515 - accuracy: 0.9634 - val_loss: 0.2683 - val_accuracy: 0.9091\n",
      "Epoch 88/300\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.1606 - accuracy: 0.9582 - val_loss: 0.2948 - val_accuracy: 0.8900\n",
      "Epoch 89/300\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.1522 - accuracy: 0.9557 - val_loss: 0.1798 - val_accuracy: 0.9733\n",
      "Epoch 90/300\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.1845 - accuracy: 0.9507 - val_loss: 0.2458 - val_accuracy: 0.9750\n",
      "Epoch 91/300\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.1630 - accuracy: 0.9646 - val_loss: 0.1725 - val_accuracy: 0.9434\n",
      "Epoch 92/300\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.1607 - accuracy: 0.9660 - val_loss: 0.2232 - val_accuracy: 0.9124\n",
      "Epoch 93/300\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.1539 - accuracy: 0.9573 - val_loss: 0.1640 - val_accuracy: 0.9695\n",
      "Epoch 94/300\n",
      "173/173 [==============================] - 0s 3ms/step - loss: 0.1419 - accuracy: 0.9667 - val_loss: 0.1912 - val_accuracy: 0.9548\n",
      "Epoch 95/300\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.2128 - accuracy: 0.9414 - val_loss: 0.1940 - val_accuracy: 0.9744\n",
      "Epoch 96/300\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.1747 - accuracy: 0.9571 - val_loss: 0.1780 - val_accuracy: 0.9695\n",
      "Epoch 97/300\n",
      "173/173 [==============================] - 1s 4ms/step - loss: 0.1749 - accuracy: 0.9548 - val_loss: 0.1816 - val_accuracy: 0.9739\n"
     ]
    }
   ],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(patience = 20,\n",
    "                                             monitor = 'val_loss', \n",
    "                                             #baseline = 0.9,\n",
    "                                             restore_best_weights=True)\n",
    "\n",
    "ANN_model.train((x_train,y_train),\n",
    "                (x_valid,y_valid),\n",
    "                oh,\n",
    "                transformer,\n",
    "                [early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_train: 0.964240\n",
      "f1_train: 0.903098\n",
      "confusion_matrix:\n",
      " [[4844  197]\n",
      " [   0  468]] \n",
      "\n",
      "acc_valid: 0.953729\n",
      "f1_valid: 0.887379\n",
      "confusion_matrix:\n",
      " [[1581   83]\n",
      " [   2  171]] \n",
      "\n",
      "acc_test: 0.949735\n",
      "f1_test: 0.935619\n",
      "confusion_matrix:\n",
      " [[268  17]\n",
      " [  2  91]]\n"
     ]
    }
   ],
   "source": [
    "acc_train,cm_train,f1_train = ANN_model.model_metrics(x_train,y_train)\n",
    "acc_valid,cm_valid,f1_valid = ANN_model.model_metrics(x_valid,y_valid)\n",
    "acc_test,cm_test,f1_test = ANN_model.model_metrics(x_test,y_test)\n",
    "print('acc_train: %f\\nf1_train: %f\\nconfusion_matrix:\\n'%(acc_train,f1_train),cm_train,'\\n')\n",
    "print('acc_valid: %f\\nf1_valid: %f\\nconfusion_matrix:\\n'%(acc_valid,f1_valid),cm_valid,'\\n')\n",
    "print('acc_test: %f\\nf1_test: %f\\nconfusion_matrix:\\n'%(acc_test,f1_test),cm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['G08_FoG_2_trial_1_emg.csv',\n",
       "       'normal/P231_M050_B_Walking_trial_6_emg.csv',\n",
       "       'normal/P231_M100_2_A_FoG_trial_3_emg.csv',\n",
       "       'normal/P231_M100_2_A_Walking_trial_4_emg.csv',\n",
       "       'normal/P231_M100_2_A_Walking_trial_6_emg.csv',\n",
       "       'normal/P231_M100_ON_A_Walking_trial_2_emg.csv',\n",
       "       'normal/P231_M100_ON_A_Walking_trial_4_emg.csv'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[[7,40,41,42,43,44,45]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
