{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import data_processing as dp\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "import h5py\n",
    "from itertools import permutations,combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize labels in each file and save them to csv file\n",
    "\n",
    "df = pd.DataFrame(index=[0,1,2,3,4,5,6])\n",
    "for dirname,_,filenames in os.walk('E:\\Document\\教材\\Master thesis\\data'):\n",
    "    for filename in filenames:\n",
    "        dir_depth = len(dirname.split(os.path.sep))\n",
    "        if dir_depth == 5:\n",
    "            if filename.endswith('.csv'):\n",
    "                file = os.path.join(dirname,filename)\n",
    "                emg_data = pd.read_csv(file)\n",
    "                try:\n",
    "                    emg_data.Label2\n",
    "                except AttributeError:\n",
    "                    continue\n",
    "                else:\n",
    "                    info = emg_data.Label2.value_counts()\n",
    "                    df[filename] = info\n",
    "                print(info)\n",
    "            #print(os.path.join(dirname,filename))\n",
    "df.to_csv('whole_data_info.csv',index=True)\n",
    "#df.to_csv('whole_data_info.txt',sep='\\t',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "emg_data = pd.read_csv('.\\data\\P812_M050_2_B_FoG_trial_2_emg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file name of data with various Labels\n",
    "df = pd.read_csv('./useful_data_label.csv',index_col=0) \n",
    "# read file name of data with only label 0\n",
    "df2 = pd.read_csv('./unuseful_data_label.csv',index_col=0)\n",
    "# read some of the data with only label 0\n",
    "df3 = pd.read_csv('./data/file_name.txt',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 256\n",
    "stride = 64\n",
    "threshold_WAMP = 30\n",
    "threshold_ZC = 0\n",
    "threshold_SSC = 1\n",
    "bins=9\n",
    "bound = 70\n",
    "HIST_range = (-bound,bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data_processing' from 'E:\\\\Document\\\\jupyter\\\\Master Thesis\\\\data_processing.py'>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imp\n",
    "imp.reload(dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save...\n",
      "128\n",
      "save finished.\n"
     ]
    }
   ],
   "source": [
    "#generate features\n",
    "files = np.concatenate([np.array(df.columns),np.array('正常/'+df3.loc[:,0])])\n",
    "widths = [512]\n",
    "\n",
    "for width in widths:\n",
    "    features = []\n",
    "    labels = []\n",
    "    stride = width//4\n",
    "    for file in files:\n",
    "        feature,label = dp.pipeline_feature('./data/'+file,width = width, \n",
    "                                           stride=stride,\n",
    "                                           threshold_WAMP = threshold_WAMP,\n",
    "                                           threshold_SSC = threshold_SSC,\n",
    "                                           bins=bins,\n",
    "                                           ranges=HIST_range,\n",
    "                                           show_para=False)\n",
    "        features += feature.tolist()\n",
    "        labels += label.tolist()\n",
    "    print('save...')\n",
    "    print(stride)\n",
    "    save_file = './processed data/features_W%d_S%d.hdf5'%(width,stride)\n",
    "    with h5py.File(save_file,'w') as f:\n",
    "        f.create_dataset('features',data=np.array(features),\n",
    "                         chunks = True,dtype = np.float32)\n",
    "        f.create_dataset('labels',data=np.array(labels), dtype = np.int8)\n",
    "    print('save finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip\n",
      "skip\n",
      "skip\n",
      "skip\n",
      "G05_Walking_struct_fixed_trial_2_emg.csv\n",
      "skip\n",
      "skip\n",
      "G09_FoG_trial_2_emg.csv\n",
      "skip\n",
      "G09_Walking_trial_2_emg.csv\n",
      "G09_Walking_trial_4_emg.csv\n",
      "G09_Walking_trial_6_emg.csv\n",
      "skip\n",
      "G11_Walking_trial_4_emg.csv\n",
      "skip\n",
      "skip\n",
      "P231_M050_A_Walking_trial_6_emg.csv\n",
      "P231_M050_B_Walking_trial_2_emg.csv\n",
      "P231_M050_B_Walking_trial_4_emg.csv\n",
      "P231_M050_B_Walking_trial_6_emg.csv\n",
      "P231_M100_2_A_FoG_trial_3_emg.csv\n",
      "P231_M100_2_A_Walking_trial_4_emg.csv\n",
      "P231_M100_2_A_Walking_trial_6_emg.csv\n",
      "P231_M100_ON_A_Walking_trial_2_emg.csv\n",
      "P231_M100_ON_A_Walking_trial_4_emg.csv\n",
      "P231_M100_ON_A_Walking_trial_6_emg.csv\n",
      "P231_Msham_A_Walking_trial_2_emg.csv\n",
      "P231_Msham_A_Walking_trial_6_emg.csv\n",
      "P231_Msham_B_Walking_trial_2_emg.csv\n",
      "skip\n",
      "P351_M050_2_A_FoG_trial_2_emg.csv\n",
      "P351_M050_2_A_FoG_trial_3_emg.csv\n",
      "skip\n",
      "P351_M050_2_A_Walking_trial_4_emg.csv\n",
      "P351_M050_2_A_Walking_trial_6_emg.csv\n",
      "P351_M050_2_B_FoG_trial_1_emg.csv\n",
      "P351_M050_2_B_FoG_trial_2_emg.csv\n",
      "P351_M050_2_B_FoG_trial_3_emg.csv\n",
      "P351_M050_2_B_Walking_trial_2_emg.csv\n",
      "P351_M050_2_B_Walking_trial_4_emg.csv\n",
      "P351_M050_2_B_Walking_trial_6_emg.csv\n",
      "P351_M050_A_FoG_trial_1_emg.csv\n",
      "P351_M050_A_FoG_trial_2_emg.csv\n",
      "P351_M050_A_FoG_trial_3_emg.csv\n",
      "P351_M050_A_Walking_trial_2_emg.csv\n",
      "P351_M050_A_Walking_trial_4_emg.csv\n",
      "P351_M050_B_FoG_trial_1_emg.csv\n",
      "P351_M050_B_FoG_trial_2_emg.csv\n",
      "P351_M050_B_FoG_trial_3_emg.csv\n",
      "P351_M050_B_Walking_trial_2_emg.csv\n",
      "P351_M050_B_Walking_trial_4_emg.csv\n",
      "P351_M050_B_Walking_trial_6_emg.csv\n",
      "P351_Msham_A_FoG_trial_1_emg.csv\n",
      "P351_Msham_A_FoG_trial_2_emg.csv\n",
      "P351_Msham_A_FoG_trial_3_emg.csv\n",
      "P351_Msham_A_Walking_trial_2_emg.csv\n",
      "P351_Msham_A_Walking_trial_4_emg.csv\n",
      "P351_Msham_A_Walking_trial_6_emg.csv\n",
      "P351_Msham_B_FoG_trial_1_emg.csv\n",
      "P351_Msham_B_FoG_trial_2_emg.csv\n",
      "P351_Msham_B_FoG_trial_3_emg.csv\n",
      "P351_Msham_B_Walking_trial_2_emg.csv\n",
      "P351_Msham_B_Walking_trial_4_emg.csv\n",
      "skip\n",
      "skip\n",
      "P379_M050_A_Walking_trial_3_emg.csv\n",
      "P379_M050_B_Walking_trial_2_emg.csv\n",
      "skip\n",
      "P533_M050_A_Walking_trial_1_emg.csv\n",
      "skip\n",
      "P533_M050_B_Walking_trial_2_emg.csv\n",
      "skip\n",
      "P533_M100_A_Walking_trial_2_emg.csv\n",
      "P533_M100_B_Walking_trial_4_emg.csv\n",
      "P551_M50_B_Walking_trial_6_emg.csv\n",
      "skip\n",
      "P623_M050_2_A_Walking_trial_4_emg.csv\n",
      "P623_M050_2_A_Walking_trial_6_emg.csv\n",
      "P623_M050_2_B_Walking_trial_2_emg.csv\n",
      "P623_M050_2_B_Walking_trial_6_emg.csv\n",
      "P623_M050_A_Walking_trial_4_emg.csv\n",
      "skip\n",
      "P623_M100_B_Walking_trial_4_emg.csv\n",
      "P623_Msham_A_Walking_trial_4_emg.csv\n",
      "P623_Msham_A_Walking_trial_6_emg.csv\n",
      "P623_Msham_B_Walking_trial_2_emg.csv\n",
      "P623_Msham_B_Walking_trial_4_emg.csv\n",
      "skip\n",
      "P645_M050_A_Walking_trial_3_emg.csv\n",
      "skip\n",
      "P645_M050_B_Walking_trial_3_emg.csv\n",
      "skip\n",
      "P812_M050_2_A_FoG_trial_3_emg.csv\n",
      "P812_M050_2_A_Walking_trial_2_emg.csv\n",
      "P812_M050_2_A_Walking_trial_3_emg.csv\n",
      "P812_M050_2_B_Walking_1_trial_4_emg.csv\n",
      "P812_M050_A_FoG_trial_1_emg.csv\n",
      "P812_M050_A_FoG_trial_2_emg.csv\n",
      "P812_M050_A_FoG_trial_3_emg.csv\n",
      "P812_M050_A_Walking_trial_1_emg.csv\n",
      "P812_M050_A_Walking_trial_2_emg.csv\n",
      "P812_M050_B_FoG_trial_1_emg.csv\n",
      "P812_M050_B_FoG_trial_2_emg.csv\n",
      "P812_M050_B_FoG_trial_3_emg.csv\n",
      "P812_M050_B_Walking_trial_1_emg.csv\n",
      "P812_M050_B_Walking_trial_2_emg.csv\n",
      "P812_M100_A_FoG_trial_1_emg.csv\n",
      "P812_M100_A_Walking_trial_3_emg.csv\n",
      "P812_M100_B_FoG_trial_1_emg.csv\n",
      "P812_M100_B_FoG_trial_3_emg.csv\n",
      "P812_M100_B_Walking2_trial_1_emg.csv\n",
      "P812_M100_B_Walking2_trial_2_emg.csv\n",
      "skip\n",
      "P876_M100_B_FoG_trial_2_emg.csv\n",
      "P876_M100_B_FoG_trial_3_emg.csv\n",
      "skip\n",
      "P876_M100_B_Walking_trial_6_emg.csv\n",
      "skip\n",
      "P940_M050_2_A_FoG_trial_4_emg.csv\n",
      "P940_M050_2_A_Walking_trial_2_emg.csv\n",
      "P940_M050_2_B_FoG_trial_1_emg.csv\n",
      "P940_M050_2_B_Walking_trial_2_emg.csv\n",
      "P940_M050_2_B_Walking_trial_4_emg.csv\n",
      "P940_M050_2_B_Walking_trial_6_emg.csv\n",
      "P940_M050_A_FoG_trial_2_emg.csv\n",
      "P940_M050_A_FoG_trial_3_emg.csv\n",
      "P940_M050_A_Walking_trial_2_emg.csv\n",
      "P940_M050_A_Walking_trial_4_emg.csv\n",
      "P940_M050_A_Walking_trial_6_emg.csv\n",
      "P940_M050_B_FoG_trial_1_emg.csv\n",
      "P940_M050_B_FoG_trial_2_emg.csv\n",
      "P940_M050_B_FoG_trial_3_emg.csv\n",
      "P940_M050_B_Walking_trial_2_emg.csv\n",
      "P940_M050_B_Walking_trial_4_emg.csv\n",
      "P940_M050_B_Walking_trial_6_emg.csv\n",
      "P940_M100_A_FoG_trial_1_emg.csv\n",
      "skip\n",
      "P940_M100_A_FoG_trial_3_emg.csv\n",
      "P940_M100_A_Walking_trial_2_emg.csv\n",
      "P940_M100_A_Walking_trial_4_emg.csv\n",
      "P940_M100_A_Walking_trial_6_emg.csv\n",
      "P940_M100_B_FoG_trial_2_emg.csv\n",
      "P940_M100_B_FoG_trial_3_emg.csv\n",
      "P940_M100_B_Walking_2_trial_2_emg.csv\n",
      "P940_M100_B_Walking_2_trial_6_emg.csv\n",
      "P940_MSham_A_FoG_trial_1_emg.csv\n",
      "P940_MSham_A_FoG_trial_3_emg.csv\n",
      "P940_MSham_A_Walking_trial_2_emg.csv\n",
      "P940_MSham_A_Walking_trial_4_emg.csv\n",
      "P940_MSham_A_Walking_trial_6_emg.csv\n",
      "P940_MSham_B_Walking_trial_2_emg.csv\n",
      "P940_MSham_B_Walking_trial_4_emg.csv\n",
      "P940_MSham_B_Walking_trial_6_emg.csv\n",
      "save...\n",
      "16\n",
      "save finished.\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "#generate features of the rest data\n",
    "ind = df2.iloc[1].isna()\n",
    "files = df2.columns[ind]\n",
    "widths = [64]\n",
    "i = 0\n",
    "cols = [ 'LEFT_TA','LEFT_TS','LEFT_BF', 'LEFT_RF',\n",
    "        'RIGHT_TA','RIGHT_TS','RIGHT_BF', 'RIGHT_RF']\n",
    "cols = {'Left':cols[:4],'Right':cols[4:]}\n",
    "for width in widths:\n",
    "    features = []\n",
    "    labels = []\n",
    "    stride = width//4\n",
    "    for file in files:\n",
    "        if file in np.array(df3):\n",
    "            i += 1\n",
    "            print('skip')\n",
    "            continue\n",
    "        print(file)\n",
    "        feature,label = dp.pipeline_feature('./data/正常/'+file,\n",
    "                                           #columns = cols['Right'],\n",
    "                                           width = width, \n",
    "                                           stride=stride,\n",
    "                                           threshold_WAMP = threshold_WAMP,\n",
    "                                           threshold_SSC = threshold_SSC,\n",
    "                                           bins=bins,\n",
    "                                           ranges=HIST_range,\n",
    "                                           show_para=False)\n",
    "        features += feature.tolist()\n",
    "        labels += label.tolist()\n",
    "    print('save...')\n",
    "    print(stride)\n",
    "    save_file = './processed data/features_rest_W%d_S%d.hdf5'%(width,stride)\n",
    "    with h5py.File(save_file,'w') as f:\n",
    "        f.create_dataset('features',data=np.array(features),\n",
    "                         chunks = True,dtype = np.float32)\n",
    "        f.create_dataset('labels',data=np.array(labels), dtype = np.int8)\n",
    "    print('save finished.')\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53005, 84)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(features).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save...\n",
      "64\n",
      "save finished.\n",
      "save...\n",
      "64\n",
      "save finished.\n"
     ]
    }
   ],
   "source": [
    "#generate features from Left or Right\n",
    "files = np.concatenate([np.array(df.columns),np.array('正常/'+df3.loc[:,0])])\n",
    "widths = [256]\n",
    "#drop_cols = [ 'RIGHT_TA','RIGHT_TS','RIGHT_BF', 'RIGHT_RF']\n",
    "cols = [ 'LEFT_TA','LEFT_TS','LEFT_BF', 'LEFT_RF',\n",
    "        'RIGHT_TA','RIGHT_TS','RIGHT_BF', 'RIGHT_RF']\n",
    "cols = {'Left':cols[:4],'Right':cols[4:]}\n",
    "for col in cols:\n",
    "    features = []\n",
    "    labels = []\n",
    "    stride = width//4\n",
    "    for file in files:\n",
    "        feature,label = dp.pipeline_selected_feature('./data/'+file,\n",
    "                                                     columns=cols[col],\n",
    "                                            width = width, \n",
    "                                           stride=stride,\n",
    "                                           threshold_WAMP = threshold_WAMP,\n",
    "                                           threshold_SSC = threshold_SSC,\n",
    "                                           bins=bins,\n",
    "                                           ranges=HIST_range,\n",
    "                                           show_para=False)\n",
    "        features += feature.tolist()\n",
    "        labels += label.tolist()\n",
    "    print('save...')\n",
    "    print(stride)\n",
    "    save_file = './processed data/'+col+'_features_W%d_S%d.hdf5'%(width,stride)\n",
    "    with h5py.File(save_file,'w') as f:\n",
    "        f.create_dataset('features',data=np.array(features),\n",
    "                         chunks = True,dtype = np.float32)\n",
    "        f.create_dataset('labels',data=np.array(labels), dtype = np.int8)\n",
    "    print('save finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save...\n",
      "64\n",
      "save finished.\n",
      "save...\n",
      "64\n",
      "save finished.\n",
      "save...\n",
      "64\n",
      "save finished.\n",
      "save...\n",
      "64\n",
      "save finished.\n",
      "save...\n",
      "64\n",
      "save finished.\n",
      "save...\n",
      "64\n",
      "save finished.\n",
      "save...\n",
      "64\n",
      "save finished.\n",
      "save...\n",
      "64\n",
      "save finished.\n"
     ]
    }
   ],
   "source": [
    "#generate selected features\n",
    "files = np.concatenate([np.array(df.columns),np.array('正常/'+df3.loc[:,0])])\n",
    "widths = [256]\n",
    "cols = ['LTA','LTS','LBF','LRF','RTA','RTS','RBF','RRF']\n",
    "#drop_cols = [ 'RIGHT_TA','RIGHT_TS','RIGHT_BF', 'RIGHT_RF']\n",
    "cols = [ 'LEFT_TA','LEFT_TS','LEFT_BF', 'LEFT_RF',\n",
    "        'RIGHT_TA','RIGHT_TS','RIGHT_BF', 'RIGHT_RF']\n",
    "#for p in combinations(cols,2):\n",
    "for col in cols:\n",
    "    features = []\n",
    "    labels = []\n",
    "    width = 256\n",
    "    stride = width//4\n",
    "    #col = [p[0],p[1]]\n",
    "    for file in files:\n",
    "        feature,label = dp.pipeline_selected_feature('./data/'+file,\n",
    "                                                     #columns=col,\n",
    "                                                     drop_cols = [col],\n",
    "                                            width = width, \n",
    "                                           stride=stride,\n",
    "                                           threshold_WAMP = threshold_WAMP,\n",
    "                                           threshold_SSC = threshold_SSC,\n",
    "                                           bins=bins,\n",
    "                                           ranges=HIST_range,\n",
    "                                           show_para=False)\n",
    "        features += feature.tolist()\n",
    "        labels += label.tolist()\n",
    "    print('save...')\n",
    "    print(stride)\n",
    "    #save_file = './processed data/'+p[0]+p[1]+'_features_W%d_S%d.hdf5'%(width,stride)\n",
    "    save_file = './processed data/drop_'+col+'_features_W%d_S%d.hdf5'%(width,stride)\n",
    "    with h5py.File(save_file,'w') as f:\n",
    "        f.create_dataset('features',data=np.array(features),\n",
    "                         chunks = True,dtype = np.float32)\n",
    "        f.create_dataset('labels',data=np.array(labels), dtype = np.int8)\n",
    "    print('save finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34360, 42)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(features).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LTA', 'LTS', 'LBF', 'LRF']\n",
      "['RTA', 'RTS', 'RBF', 'RRF']\n"
     ]
    }
   ],
   "source": [
    "cols = ['LTA','LTS','LBF','LRF','RTA','RTS','RBF','RRF']\n",
    "cols = {'Left':cols[:4],'Right':cols[4:]}\n",
    "for col in cols:\n",
    "    print(cols[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    14576.34375\n",
       "1     9322.81250\n",
       "2    15632.78125\n",
       "3     1228.59375\n",
       "4       65.81250\n",
       "5       -8.00000\n",
       "6     7140.87500\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(num-256)/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 256\n",
    "stride = 64\n",
    "threshold_WAMP = 30\n",
    "threshold_ZC = 0\n",
    "threshold_SSC = 1\n",
    "bins=9\n",
    "bound = 70\n",
    "HIST_range = (-bound,bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:1 (1072, 256, 8)\n",
      "i:2 (1088, 256, 8)\n",
      "i:3 (530, 256, 8)\n",
      "i:4 (474, 256, 8)\n",
      "i:5 (470, 256, 8)\n",
      "i:6 (2334, 256, 8)\n",
      "i:7 (3253, 256, 8)\n",
      "i:8 (5280, 256, 8)\n",
      "i:9 (425, 256, 8)\n",
      "i:10 (310, 256, 8)\n",
      "i:11 (363, 256, 8)\n",
      "i:12 (362, 256, 8)\n",
      "i:13 (316, 256, 8)\n",
      "i:14 (409, 256, 8)\n",
      "i:15 (379, 256, 8)\n",
      "i:16 (374, 256, 8)\n",
      "i:17 (390, 256, 8)\n",
      "i:18 (1309, 256, 8)\n",
      "i:19 (1023, 256, 8)\n",
      "i:20 (1097, 256, 8)\n",
      "i:21 (1016, 256, 8)\n",
      "Duration: 25.108637\n"
     ]
    }
   ],
   "source": [
    "# read the data and labels of df\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "#sc = StandardScaler(with_mean=False)\n",
    "i = 0\n",
    "start = time.time()\n",
    "for file in df.columns:\n",
    "    emg_data = pd.read_csv('./data/'+file)\n",
    "    emg_data = emg_data.fillna({'LEFT_TA':emg_data.LEFT_TA.mean(),\n",
    "                                'LEFT_TS':emg_data.LEFT_TS.mean(),\n",
    "                                'LEFT_BF':emg_data.LEFT_BF.mean(),\n",
    "                                'LEFT_RF':emg_data.LEFT_RF.mean(),\n",
    "                                'RIGHT_TA':emg_data.RIGHT_TA.mean(),\n",
    "                                'RIGHT_TS':emg_data.RIGHT_TS.mean(),\n",
    "                                'RIGHT_BF':emg_data.RIGHT_BF.mean(),\n",
    "                                'RIGHT_RF':emg_data.RIGHT_RF.mean()})\n",
    "    #emg_data = emg_data[emg_data.Label1 == emg_data.Label2].reset_index(drop=True)\n",
    "    x,y = dp.generate_window_slide_data(emg_data,width=width,stride=stride,scaler=False)\n",
    "    X += x.tolist()\n",
    "    Y += y.tolist()\n",
    "    i += 1\n",
    "    print('i:%d'%i,x.shape)\n",
    "end = time.time()\n",
    "duration = end-start\n",
    "print('Duration: %f'%(duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:1 (506, 256, 8)\n",
      "i:2 (703, 256, 8)\n",
      "i:3 (588, 256, 8)\n",
      "i:4 (1040, 256, 8)\n",
      "i:5 (699, 256, 8)\n",
      "i:6 (1335, 256, 8)\n",
      "i:7 (895, 256, 8)\n",
      "i:8 (958, 256, 8)\n",
      "i:9 (844, 256, 8)\n",
      "i:10 (727, 256, 8)\n",
      "i:11 (768, 256, 8)\n",
      "i:12 (814, 256, 8)\n",
      "i:13 (833, 256, 8)\n",
      "i:14 (690, 256, 8)\n",
      "i:15 (761, 256, 8)\n",
      "i:16 (1198, 256, 8)\n",
      "i:17 (1330, 256, 8)\n",
      "i:18 (1028, 256, 8)\n",
      "i:19 (803, 256, 8)\n",
      "i:20 (1021, 256, 8)\n",
      "i:21 (1935, 256, 8)\n",
      "i:22 (1128, 256, 8)\n",
      "i:23 (818, 256, 8)\n",
      "i:24 (1299, 256, 8)\n",
      "i:25 (707, 256, 8)\n",
      "i:26 (732, 256, 8)\n",
      "Duration: 26.938807\n"
     ]
    }
   ],
   "source": [
    "# read the data and labels of df2 or df3\n",
    "\n",
    "ind = df2.iloc[1].isna()\n",
    "features = []\n",
    "#sc = StandardScaler(with_mean=False)\n",
    "#width = 256\n",
    "#stride = 32\n",
    "start = time.time()\n",
    "i = 0\n",
    "for file in np.array(df3.loc[:,0]):\n",
    "    #if file in np.array(df3.loc[:,0]):\n",
    "    #    continue\n",
    "    emg_data = pd.read_csv('./data/正常/'+file)\n",
    "    emg_data = emg_data.fillna({'LEFT_TA':emg_data.LEFT_TA.mean(),\n",
    "                                'LEFT_TS':emg_data.LEFT_TS.mean(),\n",
    "                                'LEFT_BF':emg_data.LEFT_BF.mean(),\n",
    "                                'LEFT_RF':emg_data.LEFT_RF.mean(),\n",
    "                                'RIGHT_TA':emg_data.RIGHT_TA.mean(),\n",
    "                                'RIGHT_TS':emg_data.RIGHT_TS.mean(),\n",
    "                                'RIGHT_BF':emg_data.RIGHT_BF.mean(),\n",
    "                                'RIGHT_RF':emg_data.RIGHT_RF.mean()})\n",
    "    #emg_data = emg_data[emg_data.Label1 == emg_data.Label2].reset_index(drop=True)\n",
    "    x,y = dp.generate_window_slide_data(emg_data,width=width,stride=stride,scaler=False)\n",
    "    #feature = dp.generate_feature(x,threshold_WAMP=threshold_WAMP,\n",
    "    #                          threshold_ZC=threshold_ZC,\n",
    "    #                          threshold_SSC=threshold_SSC,\n",
    "    #                          bins=bins,ranges=HIST_range)\n",
    "    #features += feature.tolist()\n",
    "    X += x.tolist()\n",
    "    Y += y.tolist()\n",
    "    i += 1\n",
    "    print('i:%d'%i,x.shape)\n",
    "    \n",
    "end = time.time()\n",
    "duration = end-start\n",
    "print('Duration: %f'%(duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G02_Walking_trial_1_emg.csv\n",
      "G03_Walking_trial_1_emg.csv\n",
      "G03_Walking_trial_2_emg.csv\n",
      "G05_Walking_struct_fixed_trial_1_emg.csv\n",
      "G05_Walking_struct_fixed_trial_2_emg.csv\n",
      "G05_Walking_struct_fixed_trial_3_emg.csv\n",
      "G09_FoG_trial_1_emg.csv\n",
      "G09_FoG_trial_2_emg.csv\n",
      "G09_FoG_trial_3_emg.csv\n",
      "G09_Walking_trial_2_emg.csv\n",
      "G09_Walking_trial_4_emg.csv\n",
      "G09_Walking_trial_6_emg.csv\n",
      "G11_Walking_trial_2_emg.csv\n",
      "G11_Walking_trial_4_emg.csv\n",
      "P231_M050_A_Walking_trial_2_emg.csv\n",
      "P231_M050_A_Walking_trial_4_emg.csv\n",
      "P231_M050_A_Walking_trial_6_emg.csv\n",
      "P231_M050_B_Walking_trial_2_emg.csv\n",
      "P231_M050_B_Walking_trial_4_emg.csv\n",
      "P231_M050_B_Walking_trial_6_emg.csv\n",
      "P231_M100_2_A_FoG_trial_3_emg.csv\n",
      "P231_M100_2_A_Walking_trial_4_emg.csv\n",
      "P231_M100_2_A_Walking_trial_6_emg.csv\n",
      "P231_M100_ON_A_Walking_trial_2_emg.csv\n",
      "P231_M100_ON_A_Walking_trial_4_emg.csv\n",
      "P231_M100_ON_A_Walking_trial_6_emg.csv\n",
      "P231_Msham_A_Walking_trial_2_emg.csv\n",
      "P231_Msham_A_Walking_trial_6_emg.csv\n",
      "P231_Msham_B_Walking_trial_2_emg.csv\n",
      "P351_M050_2_A_FoG_trial_1_emg.csv\n",
      "P351_M050_2_A_FoG_trial_2_emg.csv\n",
      "P351_M050_2_A_FoG_trial_3_emg.csv\n",
      "P351_M050_2_A_Walking_trial_2_emg.csv\n",
      "P351_M050_2_A_Walking_trial_4_emg.csv\n",
      "P351_M050_2_A_Walking_trial_6_emg.csv\n",
      "P351_M050_2_B_FoG_trial_1_emg.csv\n",
      "P351_M050_2_B_FoG_trial_2_emg.csv\n",
      "P351_M050_2_B_FoG_trial_3_emg.csv\n",
      "P351_M050_2_B_Walking_trial_2_emg.csv\n",
      "P351_M050_2_B_Walking_trial_4_emg.csv\n",
      "P351_M050_2_B_Walking_trial_6_emg.csv\n",
      "P351_M050_A_FoG_trial_1_emg.csv\n",
      "P351_M050_A_FoG_trial_2_emg.csv\n",
      "P351_M050_A_FoG_trial_3_emg.csv\n",
      "P351_M050_A_Walking_trial_2_emg.csv\n",
      "P351_M050_A_Walking_trial_4_emg.csv\n",
      "P351_M050_B_FoG_trial_1_emg.csv\n",
      "P351_M050_B_FoG_trial_2_emg.csv\n",
      "P351_M050_B_FoG_trial_3_emg.csv\n",
      "P351_M050_B_Walking_trial_2_emg.csv\n",
      "P351_M050_B_Walking_trial_4_emg.csv\n",
      "P351_M050_B_Walking_trial_6_emg.csv\n",
      "P351_Msham_A_FoG_trial_1_emg.csv\n",
      "P351_Msham_A_FoG_trial_2_emg.csv\n",
      "P351_Msham_A_FoG_trial_3_emg.csv\n",
      "P351_Msham_A_Walking_trial_2_emg.csv\n",
      "P351_Msham_A_Walking_trial_4_emg.csv\n",
      "P351_Msham_A_Walking_trial_6_emg.csv\n",
      "P351_Msham_B_FoG_trial_1_emg.csv\n",
      "P351_Msham_B_FoG_trial_2_emg.csv\n",
      "P351_Msham_B_FoG_trial_3_emg.csv\n",
      "P351_Msham_B_Walking_trial_2_emg.csv\n",
      "P351_Msham_B_Walking_trial_4_emg.csv\n",
      "P351_Msham_B_Walking_trial_6_emg.csv\n",
      "P379_M050_A_Walking_trial_2_emg.csv\n",
      "P379_M050_A_Walking_trial_3_emg.csv\n",
      "P379_M050_B_Walking_trial_2_emg.csv\n",
      "P379_Msham_B_Walking_trial_6_emg.csv\n",
      "P533_M050_A_Walking_trial_1_emg.csv\n",
      "P533_M050_A_Walking_trial_2_emg.csv\n",
      "P533_M050_B_Walking_trial_2_emg.csv\n",
      "P533_M050_B_Walking_trial_3_emg.csv\n",
      "P533_M100_A_Walking_trial_2_emg.csv\n",
      "P533_M100_B_Walking_trial_4_emg.csv\n",
      "P551_M50_B_Walking_trial_6_emg.csv\n",
      "P623_M050_2_A_Walking_trial_2_emg.csv\n",
      "P623_M050_2_A_Walking_trial_4_emg.csv\n",
      "P623_M050_2_A_Walking_trial_6_emg.csv\n",
      "P623_M050_2_B_Walking_trial_2_emg.csv\n",
      "P623_M050_2_B_Walking_trial_6_emg.csv\n",
      "P623_M050_A_Walking_trial_4_emg.csv\n",
      "P623_M100_A_Walking_trial_4_emg.csv\n",
      "P623_M100_B_Walking_trial_4_emg.csv\n",
      "P623_Msham_A_Walking_trial_4_emg.csv\n",
      "P623_Msham_A_Walking_trial_6_emg.csv\n",
      "P623_Msham_B_Walking_trial_2_emg.csv\n",
      "P623_Msham_B_Walking_trial_4_emg.csv\n",
      "P645_M050_A_Walking_trial_2_emg.csv\n",
      "P645_M050_A_Walking_trial_3_emg.csv\n",
      "P645_M050_B_Walking_trial_2_emg.csv\n",
      "P645_M050_B_Walking_trial_3_emg.csv\n",
      "P812_M050_2_A_FoG_trial_1_emg.csv\n",
      "P812_M050_2_A_FoG_trial_3_emg.csv\n",
      "P812_M050_2_A_Walking_trial_2_emg.csv\n",
      "P812_M050_2_A_Walking_trial_3_emg.csv\n",
      "P812_M050_2_B_Walking_1_trial_4_emg.csv\n",
      "P812_M050_A_FoG_trial_1_emg.csv\n",
      "P812_M050_A_FoG_trial_2_emg.csv\n",
      "P812_M050_A_FoG_trial_3_emg.csv\n",
      "P812_M050_A_Walking_trial_1_emg.csv\n",
      "P812_M050_A_Walking_trial_2_emg.csv\n",
      "P812_M050_B_FoG_trial_1_emg.csv\n",
      "P812_M050_B_FoG_trial_2_emg.csv\n",
      "P812_M050_B_FoG_trial_3_emg.csv\n",
      "P812_M050_B_Walking_trial_1_emg.csv\n",
      "P812_M050_B_Walking_trial_2_emg.csv\n",
      "P812_M100_A_FoG_trial_1_emg.csv\n",
      "P812_M100_A_Walking_trial_3_emg.csv\n",
      "P812_M100_B_FoG_trial_1_emg.csv\n",
      "P812_M100_B_FoG_trial_3_emg.csv\n",
      "P812_M100_B_Walking2_trial_1_emg.csv\n",
      "P812_M100_B_Walking2_trial_2_emg.csv\n",
      "P876_M100_B_FoG_trial_1_emg.csv\n",
      "P876_M100_B_FoG_trial_2_emg.csv\n",
      "P876_M100_B_FoG_trial_3_emg.csv\n",
      "P876_M100_B_Walking_trial_4_emg.csv\n",
      "P876_M100_B_Walking_trial_6_emg.csv\n",
      "P940_M050_2_A_FoG_trial_3_emg.csv\n",
      "P940_M050_2_A_FoG_trial_4_emg.csv\n",
      "P940_M050_2_A_Walking_trial_2_emg.csv\n",
      "P940_M050_2_B_FoG_trial_1_emg.csv\n",
      "P940_M050_2_B_Walking_trial_2_emg.csv\n",
      "P940_M050_2_B_Walking_trial_4_emg.csv\n",
      "P940_M050_2_B_Walking_trial_6_emg.csv\n",
      "P940_M050_A_FoG_trial_2_emg.csv\n",
      "P940_M050_A_FoG_trial_3_emg.csv\n",
      "P940_M050_A_Walking_trial_2_emg.csv\n",
      "P940_M050_A_Walking_trial_4_emg.csv\n",
      "P940_M050_A_Walking_trial_6_emg.csv\n",
      "P940_M050_B_FoG_trial_1_emg.csv\n",
      "P940_M050_B_FoG_trial_2_emg.csv\n",
      "P940_M050_B_FoG_trial_3_emg.csv\n",
      "P940_M050_B_Walking_trial_2_emg.csv\n",
      "P940_M050_B_Walking_trial_4_emg.csv\n",
      "P940_M050_B_Walking_trial_6_emg.csv\n",
      "P940_M100_A_FoG_trial_1_emg.csv\n",
      "P940_M100_A_FoG_trial_2_emg.csv\n",
      "P940_M100_A_FoG_trial_3_emg.csv\n",
      "P940_M100_A_Walking_trial_2_emg.csv\n",
      "P940_M100_A_Walking_trial_4_emg.csv\n",
      "P940_M100_A_Walking_trial_6_emg.csv\n",
      "P940_M100_B_FoG_trial_2_emg.csv\n",
      "P940_M100_B_FoG_trial_3_emg.csv\n",
      "P940_M100_B_Walking_2_trial_2_emg.csv\n",
      "P940_M100_B_Walking_2_trial_6_emg.csv\n",
      "P940_MSham_A_FoG_trial_1_emg.csv\n",
      "P940_MSham_A_FoG_trial_3_emg.csv\n",
      "P940_MSham_A_Walking_trial_2_emg.csv\n",
      "P940_MSham_A_Walking_trial_4_emg.csv\n",
      "P940_MSham_A_Walking_trial_6_emg.csv\n",
      "P940_MSham_B_Walking_trial_2_emg.csv\n",
      "P940_MSham_B_Walking_trial_4_emg.csv\n",
      "P940_MSham_B_Walking_trial_6_emg.csv\n"
     ]
    }
   ],
   "source": [
    "ind = df2.iloc[1].isna()\n",
    "for file in df2.columns[ind]:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    30980\n",
       "2     7223\n",
       "1     4278\n",
       "6     3401\n",
       "3      524\n",
       "4       28\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(Y).value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46434,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(Y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = './processed data/data_set_after_window_S64_withoutSC_allPa.hdf5'\n",
    "with h5py.File(file,'w') as f:\n",
    "    f.create_dataset('cwt_data',data=np.array(X),\n",
    "                     chunks = True,dtype = np.float32)\n",
    "    f.create_dataset('label2',data=np.array(Y), dtype = np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = './processed data/feature_restdata.hdf5'\n",
    "with h5py.File(file,'w') as f:\n",
    "    f.create_dataset('features',data=np.array(features),\n",
    "                     chunks = True,dtype = np.float32)\n",
    "    f.create_dataset('labels',data=np.array(Y), dtype = np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    26775\n",
       "2    22889\n",
       "1     2842\n",
       "3      761\n",
       "Name: Label1, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emg_data[emg_data.Label1 == emg_data.Label2].Label1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                  G02_Walking_trial_1_emg.csv\n",
       "1                  G03_Walking_trial_1_emg.csv\n",
       "2                  G03_Walking_trial_2_emg.csv\n",
       "3     G05_Walking_struct_fixed_trial_1_emg.csv\n",
       "4     G05_Walking_struct_fixed_trial_3_emg.csv\n",
       "5                      G09_FoG_trial_1_emg.csv\n",
       "6                      G09_FoG_trial_3_emg.csv\n",
       "7                  G11_Walking_trial_2_emg.csv\n",
       "8          P231_M050_A_Walking_trial_2_emg.csv\n",
       "9          P231_M050_A_Walking_trial_4_emg.csv\n",
       "10           P351_M050_2_A_FoG_trial_1_emg.csv\n",
       "11       P351_M050_2_A_Walking_trial_2_emg.csv\n",
       "12        P351_Msham_B_Walking_trial_6_emg.csv\n",
       "13         P379_M050_A_Walking_trial_2_emg.csv\n",
       "14        P379_Msham_B_Walking_trial_6_emg.csv\n",
       "15         P533_M050_A_Walking_trial_2_emg.csv\n",
       "16         P533_M050_B_Walking_trial_3_emg.csv\n",
       "17       P623_M050_2_A_Walking_trial_2_emg.csv\n",
       "18         P623_M100_A_Walking_trial_4_emg.csv\n",
       "19         P645_M050_A_Walking_trial_2_emg.csv\n",
       "20         P645_M050_B_Walking_trial_2_emg.csv\n",
       "21           P812_M050_2_A_FoG_trial_1_emg.csv\n",
       "22         P876_M100_B_Walking_trial_4_emg.csv\n",
       "23             P876_M100_B_FoG_trial_1_emg.csv\n",
       "24           P940_M050_2_A_FoG_trial_3_emg.csv\n",
       "25             P940_M100_A_FoG_trial_2_emg.csv\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if file in np.array(df3):\n",
    "    print('yes')\n",
    "file\n",
    "df3.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './processed data/data_set_after_window_label12.hdf5'\n",
    "with h5py.File(path,'r') as f:\n",
    "    x = f['cwt_data'][...]\n",
    "    y = f['label2'][...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    11903\n",
       "0    11711\n",
       "6     5887\n",
       "1     5405\n",
       "3       92\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G02_Walking_trial_1_emg.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G03_Walking_trial_1_emg.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G03_Walking_trial_2_emg.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G05_Walking_struct_fixed_trial_1_emg.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G05_Walking_struct_fixed_trial_3_emg.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>G09_FoG_trial_1_emg.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>G09_FoG_trial_3_emg.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>G11_Walking_trial_2_emg.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>P231_M050_A_Walking_trial_2_emg.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>P231_M050_A_Walking_trial_4_emg.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>P351_M050_2_A_FoG_trial_1_emg.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>P351_M050_2_A_Walking_trial_2_emg.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>P351_Msham_B_Walking_trial_6_emg.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>P379_M050_A_Walking_trial_2_emg.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>P379_Msham_B_Walking_trial_6_emg.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>P533_M050_A_Walking_trial_2_emg.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>P533_M050_B_Walking_trial_3_emg.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>P623_M050_2_A_Walking_trial_2_emg.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>P623_M100_A_Walking_trial_4_emg.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>P645_M050_A_Walking_trial_2_emg.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>P645_M050_B_Walking_trial_2_emg.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>P812_M050_2_A_FoG_trial_1_emg.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>P876_M100_B_Walking_trial_4_emg.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>P876_M100_B_FoG_trial_1_emg.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>P940_M050_2_A_FoG_trial_3_emg.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>P940_M100_A_FoG_trial_2_emg.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           0\n",
       "0                G02_Walking_trial_1_emg.csv\n",
       "1                G03_Walking_trial_1_emg.csv\n",
       "2                G03_Walking_trial_2_emg.csv\n",
       "3   G05_Walking_struct_fixed_trial_1_emg.csv\n",
       "4   G05_Walking_struct_fixed_trial_3_emg.csv\n",
       "5                    G09_FoG_trial_1_emg.csv\n",
       "6                    G09_FoG_trial_3_emg.csv\n",
       "7                G11_Walking_trial_2_emg.csv\n",
       "8        P231_M050_A_Walking_trial_2_emg.csv\n",
       "9        P231_M050_A_Walking_trial_4_emg.csv\n",
       "10         P351_M050_2_A_FoG_trial_1_emg.csv\n",
       "11     P351_M050_2_A_Walking_trial_2_emg.csv\n",
       "12      P351_Msham_B_Walking_trial_6_emg.csv\n",
       "13       P379_M050_A_Walking_trial_2_emg.csv\n",
       "14      P379_Msham_B_Walking_trial_6_emg.csv\n",
       "15       P533_M050_A_Walking_trial_2_emg.csv\n",
       "16       P533_M050_B_Walking_trial_3_emg.csv\n",
       "17     P623_M050_2_A_Walking_trial_2_emg.csv\n",
       "18       P623_M100_A_Walking_trial_4_emg.csv\n",
       "19       P645_M050_A_Walking_trial_2_emg.csv\n",
       "20       P645_M050_B_Walking_trial_2_emg.csv\n",
       "21         P812_M050_2_A_FoG_trial_1_emg.csv\n",
       "22       P876_M100_B_Walking_trial_4_emg.csv\n",
       "23           P876_M100_B_FoG_trial_1_emg.csv\n",
       "24         P940_M050_2_A_FoG_trial_3_emg.csv\n",
       "25           P940_M100_A_FoG_trial_2_emg.csv"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('./data/file_name.txt',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx,yy=dp.generate_window_slide_data(emg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
