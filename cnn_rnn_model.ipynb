{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.config import Config\n",
    "from lib.data_set import Dataset\n",
    "from lib.model import NNModel\n",
    "from lib import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctypes\n",
    "import data_processing as dp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers as KL\n",
    "from tensorflow.keras import models as KM\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'model' from 'E:\\\\Document\\\\jupyter\\\\Master Thesis\\\\model.py'>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imp\n",
    "imp.reload(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File name read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file name of data with various Labels\n",
    "df = pd.read_csv('./useful_data_label.csv',index_col=0) \n",
    "# read file name of data with only label 0\n",
    "df2 = pd.read_csv('./unuseful_data_label.csv',index_col=0)\n",
    "# read some of the data with only label 0\n",
    "df3 = pd.read_csv('./data/file_name.txt',header=None)\n",
    "player = ctypes.windll.kernel32\n",
    "\n",
    "ind = df2.iloc[1].isna()\n",
    "files = np.concatenate([np.array(df.columns),np.array('normal/'+df2.columns[ind])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Override the base class of Config and Features for RNN_CNN Model\n",
    "class RCNN_Config(Config):\n",
    "    \n",
    "    NAME = 'RNN_CNN'\n",
    "    NUM_CLASSES = 2\n",
    "    EPOCHS = 300\n",
    "    BATCH_SIZE = 32\n",
    "    COST_SENSITIVE = False\n",
    "    CLASS_WEIGHTS = None\n",
    "    TEST_FILES = files[[6,30,31,32,33,34,35]]\n",
    "    \n",
    "class Rect_dataset(Dataset):\n",
    "    \n",
    "    def __init__(self,config):\n",
    "        super(Rect_dataset,self).__init__(config)\n",
    "        self.n_env = config.N_ENV\n",
    "    \n",
    "    def rectify_data(self):\n",
    "        \n",
    "        self.Xr = dp.rectify_emg_moving_average(self.X,self.n_env)\n",
    "        self.Xr2 = dp.rectify_emg_moving_average(self.X2,self.n_env)\n",
    "        self.Xr3 = dp.rectify_emg_moving_average(self.X3,self.n_env)\n",
    "    \n",
    "    @property\n",
    "    def train_set(self):\n",
    "        return self.Xr,self.Y,self.F\n",
    "    \n",
    "    @property\n",
    "    def valid_set(self):\n",
    "        return self.Xr2,self.Y2,self.F2\n",
    "    \n",
    "    @property\n",
    "    def test_set(self):\n",
    "        return self.Xr3,self.Y3,self.F3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate CWT-CNN configuration\n",
    "config = RCNN_Config()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Rect_dataset(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip\n",
      "skip\n",
      "3/174: G06_FoG_trial_1_emg.csv\n",
      "4/174: G06_FoG_trial_2_emg.csv\n",
      "5/174: G06_FoG_trial_3_emg.csv\n",
      "6/174: G07_Freezing_Trial1_trial_1_emg.csv\n",
      "7/174: G08_FoG_1_trial_1_emg.csv\n",
      "8/174: G08_FoG_2_trial_1_emg.csv\n",
      "9/174: G11_FoG_trial_1_emg.csv\n",
      "10/174: G11_FoG_trial_2_emg.csv\n",
      "11/174: P379_M050_2_OFF_A_FoG_trial_1_emg.csv\n",
      "12/174: P379_M050_2_OFF_A_FoG_trial_2_emg.csv\n",
      "13/174: P379_M050_2_OFF_A_FoG_trial_3_emg.csv\n",
      "14/174: P379_M050_2_OFF_B_FoG_trial_1_emg.csv\n",
      "15/174: P379_M050_2_OFF_B_FoG_trial_2_emg.csv\n",
      "16/174: P379_M050_2_OFF_B_FoG_trial_3_emg.csv\n",
      "17/174: P551_M050_2_A_FoG_trial_1_emg.csv\n",
      "18/174: P551_M050_2_B_FoG_trial_1_emg.csv\n",
      "19/174: P551_M050_2_B_FoG_trial_2_emg.csv\n",
      "20/174: P812_M050_2_B_FoG_trial_1_emg.csv\n",
      "21/174: P812_M050_2_B_FoG_trial_2_emg.csv\n",
      "22/174: normal/G02_Walking_trial_1_emg.csv\n",
      "23/174: normal/G03_Walking_trial_1_emg.csv\n",
      "24/174: normal/G03_Walking_trial_2_emg.csv\n",
      "25/174: normal/G05_Walking_struct_fixed_trial_1_emg.csv\n",
      "26/174: normal/G05_Walking_struct_fixed_trial_2_emg.csv\n",
      "27/174: normal/G05_Walking_struct_fixed_trial_3_emg.csv\n",
      "28/174: normal/G09_FoG_trial_1_emg.csv\n",
      "29/174: normal/G09_FoG_trial_2_emg.csv\n",
      "30/174: normal/G09_FoG_trial_3_emg.csv\n",
      "31/174: normal/G09_Walking_trial_2_emg.csv\n",
      "32/174: normal/G09_Walking_trial_4_emg.csv\n",
      "33/174: normal/G09_Walking_trial_6_emg.csv\n",
      "34/174: normal/G11_Walking_trial_2_emg.csv\n",
      "35/174: normal/G11_Walking_trial_4_emg.csv\n",
      "36/174: normal/P231_M050_A_Walking_trial_2_emg.csv\n",
      "37/174: normal/P231_M050_A_Walking_trial_4_emg.csv\n",
      "38/174: normal/P231_M050_A_Walking_trial_6_emg.csv\n",
      "39/174: normal/P231_M050_B_Walking_trial_2_emg.csv\n",
      "40/174: normal/P231_M050_B_Walking_trial_4_emg.csv\n",
      "41/174: normal/P231_M050_B_Walking_trial_6_emg.csv\n",
      "42/174: normal/P231_M100_2_A_FoG_trial_3_emg.csv\n",
      "43/174: normal/P231_M100_2_A_Walking_trial_4_emg.csv\n",
      "44/174: normal/P231_M100_2_A_Walking_trial_6_emg.csv\n",
      "45/174: normal/P231_M100_ON_A_Walking_trial_2_emg.csv\n",
      "46/174: normal/P231_M100_ON_A_Walking_trial_4_emg.csv\n",
      "47/174: normal/P231_M100_ON_A_Walking_trial_6_emg.csv\n",
      "48/174: normal/P231_Msham_A_Walking_trial_2_emg.csv\n",
      "49/174: normal/P231_Msham_A_Walking_trial_6_emg.csv\n",
      "50/174: normal/P231_Msham_B_Walking_trial_2_emg.csv\n",
      "51/174: normal/P351_M050_2_A_FoG_trial_1_emg.csv\n",
      "52/174: normal/P351_M050_2_A_FoG_trial_2_emg.csv\n",
      "53/174: normal/P351_M050_2_A_FoG_trial_3_emg.csv\n",
      "54/174: normal/P351_M050_2_A_Walking_trial_2_emg.csv\n",
      "55/174: normal/P351_M050_2_A_Walking_trial_4_emg.csv\n",
      "56/174: normal/P351_M050_2_A_Walking_trial_6_emg.csv\n",
      "57/174: normal/P351_M050_2_B_FoG_trial_1_emg.csv\n",
      "58/174: normal/P351_M050_2_B_FoG_trial_2_emg.csv\n",
      "59/174: normal/P351_M050_2_B_FoG_trial_3_emg.csv\n",
      "60/174: normal/P351_M050_2_B_Walking_trial_2_emg.csv\n",
      "61/174: normal/P351_M050_2_B_Walking_trial_4_emg.csv\n",
      "62/174: normal/P351_M050_2_B_Walking_trial_6_emg.csv\n",
      "63/174: normal/P351_M050_A_FoG_trial_1_emg.csv\n",
      "64/174: normal/P351_M050_A_FoG_trial_2_emg.csv\n",
      "65/174: normal/P351_M050_A_FoG_trial_3_emg.csv\n",
      "66/174: normal/P351_M050_A_Walking_trial_2_emg.csv\n",
      "67/174: normal/P351_M050_A_Walking_trial_4_emg.csv\n",
      "68/174: normal/P351_M050_B_FoG_trial_1_emg.csv\n",
      "69/174: normal/P351_M050_B_FoG_trial_2_emg.csv\n",
      "70/174: normal/P351_M050_B_FoG_trial_3_emg.csv\n",
      "71/174: normal/P351_M050_B_Walking_trial_2_emg.csv\n",
      "72/174: normal/P351_M050_B_Walking_trial_4_emg.csv\n",
      "73/174: normal/P351_M050_B_Walking_trial_6_emg.csv\n",
      "74/174: normal/P351_Msham_A_FoG_trial_1_emg.csv\n",
      "75/174: normal/P351_Msham_A_FoG_trial_2_emg.csv\n",
      "76/174: normal/P351_Msham_A_FoG_trial_3_emg.csv\n",
      "77/174: normal/P351_Msham_A_Walking_trial_2_emg.csv\n",
      "78/174: normal/P351_Msham_A_Walking_trial_4_emg.csv\n",
      "79/174: normal/P351_Msham_A_Walking_trial_6_emg.csv\n",
      "80/174: normal/P351_Msham_B_FoG_trial_1_emg.csv\n",
      "81/174: normal/P351_Msham_B_FoG_trial_2_emg.csv\n",
      "82/174: normal/P351_Msham_B_FoG_trial_3_emg.csv\n",
      "83/174: normal/P351_Msham_B_Walking_trial_2_emg.csv\n",
      "84/174: normal/P351_Msham_B_Walking_trial_4_emg.csv\n",
      "85/174: normal/P351_Msham_B_Walking_trial_6_emg.csv\n",
      "86/174: normal/P379_M050_A_Walking_trial_2_emg.csv\n",
      "87/174: normal/P379_M050_A_Walking_trial_3_emg.csv\n",
      "88/174: normal/P379_M050_B_Walking_trial_2_emg.csv\n",
      "89/174: normal/P379_Msham_B_Walking_trial_6_emg.csv\n",
      "90/174: normal/P533_M050_A_Walking_trial_1_emg.csv\n",
      "91/174: normal/P533_M050_A_Walking_trial_2_emg.csv\n",
      "92/174: normal/P533_M050_B_Walking_trial_2_emg.csv\n",
      "93/174: normal/P533_M050_B_Walking_trial_3_emg.csv\n",
      "94/174: normal/P533_M100_A_Walking_trial_2_emg.csv\n",
      "95/174: normal/P533_M100_B_Walking_trial_4_emg.csv\n",
      "96/174: normal/P551_M50_B_Walking_trial_6_emg.csv\n",
      "97/174: normal/P623_M050_2_A_Walking_trial_2_emg.csv\n",
      "98/174: normal/P623_M050_2_A_Walking_trial_4_emg.csv\n",
      "skip\n",
      "100/174: normal/P623_M050_2_B_Walking_trial_2_emg.csv\n",
      "101/174: normal/P623_M050_2_B_Walking_trial_6_emg.csv\n",
      "102/174: normal/P623_M050_A_Walking_trial_4_emg.csv\n",
      "103/174: normal/P623_M100_A_Walking_trial_4_emg.csv\n",
      "104/174: normal/P623_M100_B_Walking_trial_4_emg.csv\n",
      "105/174: normal/P623_Msham_A_Walking_trial_4_emg.csv\n",
      "106/174: normal/P623_Msham_A_Walking_trial_6_emg.csv\n",
      "107/174: normal/P623_Msham_B_Walking_trial_2_emg.csv\n",
      "108/174: normal/P623_Msham_B_Walking_trial_4_emg.csv\n",
      "109/174: normal/P645_M050_A_Walking_trial_2_emg.csv\n",
      "110/174: normal/P645_M050_A_Walking_trial_3_emg.csv\n",
      "111/174: normal/P645_M050_B_Walking_trial_2_emg.csv\n",
      "112/174: normal/P645_M050_B_Walking_trial_3_emg.csv\n",
      "113/174: normal/P812_M050_2_A_FoG_trial_1_emg.csv\n",
      "114/174: normal/P812_M050_2_A_FoG_trial_3_emg.csv\n",
      "115/174: normal/P812_M050_2_A_Walking_trial_2_emg.csv\n",
      "116/174: normal/P812_M050_2_A_Walking_trial_3_emg.csv\n",
      "117/174: normal/P812_M050_2_B_Walking_1_trial_4_emg.csv\n",
      "118/174: normal/P812_M050_A_FoG_trial_1_emg.csv\n",
      "119/174: normal/P812_M050_A_FoG_trial_2_emg.csv\n",
      "120/174: normal/P812_M050_A_FoG_trial_3_emg.csv\n",
      "121/174: normal/P812_M050_A_Walking_trial_1_emg.csv\n",
      "122/174: normal/P812_M050_A_Walking_trial_2_emg.csv\n",
      "123/174: normal/P812_M050_B_FoG_trial_1_emg.csv\n",
      "124/174: normal/P812_M050_B_FoG_trial_2_emg.csv\n",
      "125/174: normal/P812_M050_B_FoG_trial_3_emg.csv\n",
      "126/174: normal/P812_M050_B_Walking_trial_1_emg.csv\n",
      "127/174: normal/P812_M050_B_Walking_trial_2_emg.csv\n",
      "128/174: normal/P812_M100_A_FoG_trial_1_emg.csv\n",
      "129/174: normal/P812_M100_A_Walking_trial_3_emg.csv\n",
      "130/174: normal/P812_M100_B_FoG_trial_1_emg.csv\n",
      "131/174: normal/P812_M100_B_FoG_trial_3_emg.csv\n",
      "132/174: normal/P812_M100_B_Walking2_trial_1_emg.csv\n",
      "133/174: normal/P812_M100_B_Walking2_trial_2_emg.csv\n",
      "134/174: normal/P876_M100_B_FoG_trial_1_emg.csv\n",
      "135/174: normal/P876_M100_B_FoG_trial_2_emg.csv\n",
      "136/174: normal/P876_M100_B_FoG_trial_3_emg.csv\n",
      "137/174: normal/P876_M100_B_Walking_trial_4_emg.csv\n",
      "138/174: normal/P876_M100_B_Walking_trial_6_emg.csv\n",
      "139/174: normal/P940_M050_2_A_FoG_trial_3_emg.csv\n",
      "140/174: normal/P940_M050_2_A_FoG_trial_4_emg.csv\n",
      "141/174: normal/P940_M050_2_A_Walking_trial_2_emg.csv\n",
      "142/174: normal/P940_M050_2_B_FoG_trial_1_emg.csv\n",
      "143/174: normal/P940_M050_2_B_Walking_trial_2_emg.csv\n",
      "144/174: normal/P940_M050_2_B_Walking_trial_4_emg.csv\n",
      "145/174: normal/P940_M050_2_B_Walking_trial_6_emg.csv\n",
      "146/174: normal/P940_M050_A_FoG_trial_2_emg.csv\n",
      "147/174: normal/P940_M050_A_FoG_trial_3_emg.csv\n",
      "148/174: normal/P940_M050_A_Walking_trial_2_emg.csv\n",
      "149/174: normal/P940_M050_A_Walking_trial_4_emg.csv\n",
      "150/174: normal/P940_M050_A_Walking_trial_6_emg.csv\n",
      "151/174: normal/P940_M050_B_FoG_trial_1_emg.csv\n",
      "152/174: normal/P940_M050_B_FoG_trial_2_emg.csv\n",
      "153/174: normal/P940_M050_B_FoG_trial_3_emg.csv\n",
      "154/174: normal/P940_M050_B_Walking_trial_2_emg.csv\n",
      "155/174: normal/P940_M050_B_Walking_trial_4_emg.csv\n",
      "156/174: normal/P940_M050_B_Walking_trial_6_emg.csv\n",
      "157/174: normal/P940_M100_A_FoG_trial_1_emg.csv\n",
      "158/174: normal/P940_M100_A_FoG_trial_2_emg.csv\n",
      "159/174: normal/P940_M100_A_FoG_trial_3_emg.csv\n",
      "160/174: normal/P940_M100_A_Walking_trial_2_emg.csv\n",
      "161/174: normal/P940_M100_A_Walking_trial_4_emg.csv\n",
      "162/174: normal/P940_M100_A_Walking_trial_6_emg.csv\n",
      "163/174: normal/P940_M100_B_FoG_trial_2_emg.csv\n",
      "164/174: normal/P940_M100_B_FoG_trial_3_emg.csv\n",
      "165/174: normal/P940_M100_B_Walking_2_trial_2_emg.csv\n",
      "166/174: normal/P940_M100_B_Walking_2_trial_6_emg.csv\n",
      "167/174: normal/P940_MSham_A_FoG_trial_1_emg.csv\n",
      "168/174: normal/P940_MSham_A_FoG_trial_3_emg.csv\n",
      "169/174: normal/P940_MSham_A_Walking_trial_2_emg.csv\n",
      "170/174: normal/P940_MSham_A_Walking_trial_4_emg.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/174: normal/P940_MSham_A_Walking_trial_6_emg.csv\n",
      "172/174: normal/P940_MSham_B_Walking_trial_2_emg.csv\n",
      "173/174: normal/P940_MSham_B_Walking_trial_4_emg.csv\n",
      "174/174: normal/P940_MSham_B_Walking_trial_6_emg.csv\n"
     ]
    }
   ],
   "source": [
    "# Load data from files\n",
    "data.load_data(files)\n",
    "\n",
    "# Rectify the data to get envelope\n",
    "data.rectify_data()\n",
    "\n",
    "X_train,Y_train,_ = data.train_set\n",
    "X_valid,Y_valid,_ = data.valid_set\n",
    "X_test, Y_test, _ = data.test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Override base class of SimpleMode for RNN_CNN\n",
    "class RNN_CNN_Model(NNModel):\n",
    "    \n",
    "    def build(self, mode,config):\n",
    "        self.input_shape = [config.WINDOW_SIZE, len(config.CHANNELS)]\n",
    "        kernel_size=3\n",
    "        reg=keras.regularizers.l2(1e-4)\n",
    "        drop_rate = 0.\n",
    "        kernel_initializer = 'glorot_normal'\n",
    "        mo = 0.8\n",
    "        st = 1\n",
    "        axis = 2\n",
    "        model = KM.Sequential()\n",
    "        model.add(KL.InputLayer(input_shape=self.input_shape))\n",
    "\n",
    "        model.add(KL.Bidirectional(KL.LSTM(32,return_sequences=True,\n",
    "                                                   recurrent_regularizer=reg)))\n",
    "\n",
    "        model.add(KL.Conv1D(filters=32, kernel_size=kernel_size,strides=st,\n",
    "                                padding='same',\n",
    "                                kernel_regularizer=reg,\n",
    "                               ))\n",
    "        model.add(KL.BatchNormalization(momentum=mo))\n",
    "\n",
    "        model.add(KL.LeakyReLU(0.1))\n",
    "        model.add(KL.MaxPooling1D(2))\n",
    "        model.add(KL.Dropout(drop_rate))\n",
    "        model.add(KL.Conv1D(filters=16, kernel_size=kernel_size,strides=st,\n",
    "                                padding='same',\n",
    "                                kernel_regularizer=reg,\n",
    "                               ))\n",
    "        model.add(KL.BatchNormalization(momentum=mo))\n",
    "\n",
    "        model.add(KL.LeakyReLU(0.1))\n",
    "        model.add(KL.MaxPooling1D(2))\n",
    "        model.add(KL.Dropout(drop_rate))\n",
    "        model.add(KL.Conv1D(filters=8, kernel_size=kernel_size,strides=st,\n",
    "                                padding='same',\n",
    "                                kernel_regularizer=reg,\n",
    "                               ))\n",
    "        model.add(KL.BatchNormalization(momentum=mo))\n",
    "\n",
    "        model.add(KL.LeakyReLU(0.1))\n",
    "        model.add(KL.MaxPooling1D(2))\n",
    "        model.add(KL.Dropout(drop_rate))\n",
    "        model.add(KL.Conv1D(filters=4, kernel_size=kernel_size,strides=st,\n",
    "                                padding='same',\n",
    "                                kernel_regularizer=reg,\n",
    "                               ))\n",
    "        model.add(KL.BatchNormalization(momentum=mo))\n",
    "\n",
    "        model.add(KL.LeakyReLU(0.1))\n",
    "        model.add(KL.MaxPooling1D(2))\n",
    "\n",
    "        model.add(KL.GlobalAveragePooling1D())\n",
    "        model.add(KL.Dropout(drop_rate))\n",
    "        model.add(KL.Dense(config.NUM_CLASSES,activation='softmax',kernel_regularizer=reg))\n",
    "        \n",
    "        model.summary()\n",
    "        if config.COST_SENSITIVE:\n",
    "            self.cost_matrix = config.COST_MATRIX\n",
    "            model.compile(loss=self.sparse_cost_sensitive_loss, optimizer=\"adam\", metrics=['accuracy'])\n",
    "            print('Using cost sensitive with cost matrix:\\n',np.array(self.cost_matrix))\n",
    "        else:\n",
    "            model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "            if config.CLASS_WEIGHTS != None:\n",
    "                print('Using categorical crossentropy with class weights:\\n',config.CLASS_WEIGHTS)\n",
    "            else:\n",
    "                print('Using categorical crossentropy without class weights.')\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def sparse_cost_sensitive_loss (self,y_true,y_pred):\n",
    "        cost_matrix = self.cost_matrix\n",
    "        batch_cost_matrix = tf.nn.embedding_lookup(cost_matrix, tf.argmax(y_true,axis=1))\n",
    "        eps = 1e-6\n",
    "        probability = tf.clip_by_value(y_pred, eps, 1-eps)\n",
    "        cost_values = tf.math.log(1-probability)*batch_cost_matrix\n",
    "        loss = tf.reduce_mean(-tf.reduce_sum(cost_values, axis=1))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data split and processing for model\n",
    "class_id = [2,6]\n",
    "binary = True\n",
    "x_train,y_train,x_valid,y_valid,x_test,y_test = utils.data_split_oh((X_train,X_valid,X_test),\n",
    "                                                                    (Y_train,Y_valid,Y_test),\n",
    "                                                                    class_id,\n",
    "                                                                    binary,\n",
    "                                                                    random_state = 555)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_6 (Bidirection (None, 1024, 64)          10496     \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 1024, 32)          6176      \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 1024, 32)          128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)   (None, 1024, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 512, 32)           0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 512, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 512, 16)           1552      \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 512, 16)           64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)   (None, 512, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 256, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 256, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 256, 8)            392       \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 256, 8)            32        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)   (None, 256, 8)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 128, 8)            0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 128, 8)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 128, 4)            100       \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 128, 4)            16        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)   (None, 128, 4)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 64, 4)             0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_6 ( (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 18,966\n",
      "Trainable params: 18,846\n",
      "Non-trainable params: 120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#cost_matrix = tf.constant([[0,1.5,1,1.2],\n",
    "#              [1,0,1,1],\n",
    "#              [5,10,0,5],\n",
    "#              [1.,1.,1,0]])\n",
    "#cost_matrix = tf.constant([[0.,1.,1.],\n",
    "#              [10.,0.,1.],\n",
    "#              [10.,4.,0.]])\n",
    "config.COST_MATRIX = tf.constant([[0,1.],\n",
    "              [10,0]])\n",
    "\n",
    "if binary:\n",
    "    config.COST_SENSITIVE = True\n",
    "    config.NUM_CLASSES = 2\n",
    "else:\n",
    "    config.COST_SENSITIVE = False\n",
    "    config.NUM_CLASSES = len(class_id)\n",
    "\n",
    "rcnn_model = RNN_CNN_Model('RNN_CNN','training',config,'./model/RNN_CNN/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 0.\n",
      "\n",
      "Checkpoint Path: ./model/RNN_CNN/rnn_cnn20210117T0120\\RNN_CNN_rnn_cnn_{epoch:04d}.h5\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 14s 630ms/step - loss: 0.6453 - accuracy: 0.6852 - val_loss: 0.7599 - val_accuracy: 0.2697\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 7s 454ms/step - loss: 0.5171 - accuracy: 0.8677 - val_loss: 0.4277 - val_accuracy: 0.9671\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 7s 454ms/step - loss: 0.4600 - accuracy: 0.9151 - val_loss: 0.4783 - val_accuracy: 0.9145\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 7s 448ms/step - loss: 0.4147 - accuracy: 0.9466 - val_loss: 0.4066 - val_accuracy: 0.9671\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 7s 454ms/step - loss: 0.3731 - accuracy: 0.9689 - val_loss: 0.3738 - val_accuracy: 0.9474\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 7s 477ms/step - loss: 0.3478 - accuracy: 0.9530 - val_loss: 0.3122 - val_accuracy: 0.9737\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 8s 501ms/step - loss: 0.3217 - accuracy: 0.9492 - val_loss: 0.3132 - val_accuracy: 0.9803\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 7s 482ms/step - loss: 0.2945 - accuracy: 0.9700 - val_loss: 0.2989 - val_accuracy: 0.9539\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 7s 471ms/step - loss: 0.2827 - accuracy: 0.9630 - val_loss: 0.2696 - val_accuracy: 0.9342\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 7s 473ms/step - loss: 0.2629 - accuracy: 0.9592 - val_loss: 0.2346 - val_accuracy: 0.9803\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 7s 461ms/step - loss: 0.2468 - accuracy: 0.9669 - val_loss: 0.2073 - val_accuracy: 0.9737\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 7s 452ms/step - loss: 0.2312 - accuracy: 0.9677 - val_loss: 0.2190 - val_accuracy: 0.9605\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 7s 448ms/step - loss: 0.2184 - accuracy: 0.9598 - val_loss: 0.1889 - val_accuracy: 0.9737\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 7s 447ms/step - loss: 0.1898 - accuracy: 0.9811 - val_loss: 0.1989 - val_accuracy: 0.9539\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 7s 448ms/step - loss: 0.1934 - accuracy: 0.9572 - val_loss: 0.1608 - val_accuracy: 0.9803\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 7s 487ms/step - loss: 0.1817 - accuracy: 0.9683 - val_loss: 0.1614 - val_accuracy: 0.9803\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 8s 574ms/step - loss: 0.1740 - accuracy: 0.9613 - val_loss: 0.6301 - val_accuracy: 0.7303\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 7s 495ms/step - loss: 0.2611 - accuracy: 0.9428 - val_loss: 0.2600 - val_accuracy: 0.9342\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 7s 502ms/step - loss: 0.1693 - accuracy: 0.9716 - val_loss: 0.1393 - val_accuracy: 0.9671\n",
      "Epoch 20/300\n",
      "15/15 [==============================] - 7s 464ms/step - loss: 0.1618 - accuracy: 0.9636 - val_loss: 0.1834 - val_accuracy: 0.9737\n",
      "Epoch 21/300\n",
      "15/15 [==============================] - 7s 476ms/step - loss: 0.1761 - accuracy: 0.9682 - val_loss: 0.1644 - val_accuracy: 0.9539\n",
      "Epoch 22/300\n",
      "15/15 [==============================] - 7s 445ms/step - loss: 0.1575 - accuracy: 0.9603 - val_loss: 0.1317 - val_accuracy: 0.9868\n",
      "Epoch 23/300\n",
      "15/15 [==============================] - 7s 444ms/step - loss: 0.1393 - accuracy: 0.9708 - val_loss: 0.1408 - val_accuracy: 0.9803\n",
      "Epoch 24/300\n",
      "15/15 [==============================] - 7s 444ms/step - loss: 0.1662 - accuracy: 0.9728 - val_loss: 0.1220 - val_accuracy: 0.9737\n",
      "Epoch 25/300\n",
      "15/15 [==============================] - 7s 443ms/step - loss: 0.1180 - accuracy: 0.9762 - val_loss: 0.1204 - val_accuracy: 0.9539\n",
      "Epoch 26/300\n",
      "15/15 [==============================] - 7s 449ms/step - loss: 0.1166 - accuracy: 0.9798 - val_loss: 0.1255 - val_accuracy: 0.9737\n",
      "Epoch 27/300\n",
      "15/15 [==============================] - 7s 453ms/step - loss: 0.1301 - accuracy: 0.9635 - val_loss: 0.0980 - val_accuracy: 0.9803\n",
      "Epoch 28/300\n",
      "15/15 [==============================] - 7s 446ms/step - loss: 0.1178 - accuracy: 0.9688 - val_loss: 0.0970 - val_accuracy: 0.9868\n",
      "Epoch 29/300\n",
      "15/15 [==============================] - 7s 444ms/step - loss: 0.1079 - accuracy: 0.9683 - val_loss: 0.1432 - val_accuracy: 0.9408\n",
      "Epoch 30/300\n",
      "15/15 [==============================] - 7s 446ms/step - loss: 0.1077 - accuracy: 0.9575 - val_loss: 0.1543 - val_accuracy: 0.9671\n",
      "Epoch 31/300\n",
      "15/15 [==============================] - 7s 445ms/step - loss: 0.1009 - accuracy: 0.9801 - val_loss: 0.3276 - val_accuracy: 0.8421\n",
      "Epoch 32/300\n",
      "15/15 [==============================] - 7s 446ms/step - loss: 0.0931 - accuracy: 0.9918 - val_loss: 0.1486 - val_accuracy: 0.9671\n",
      "Epoch 33/300\n",
      "15/15 [==============================] - 7s 444ms/step - loss: 0.1089 - accuracy: 0.9732 - val_loss: 0.1029 - val_accuracy: 0.9803\n",
      "Epoch 34/300\n",
      "15/15 [==============================] - 7s 450ms/step - loss: 0.0925 - accuracy: 0.9814 - val_loss: 0.0867 - val_accuracy: 0.9868\n",
      "Epoch 35/300\n",
      "15/15 [==============================] - 7s 450ms/step - loss: 0.0998 - accuracy: 0.9738 - val_loss: 0.1174 - val_accuracy: 0.9408\n",
      "Epoch 36/300\n",
      "15/15 [==============================] - 7s 442ms/step - loss: 0.0860 - accuracy: 0.9828 - val_loss: 0.0781 - val_accuracy: 0.9868\n",
      "Epoch 37/300\n",
      "15/15 [==============================] - 7s 443ms/step - loss: 0.0775 - accuracy: 0.9869 - val_loss: 0.2071 - val_accuracy: 0.9342\n",
      "Epoch 38/300\n",
      "15/15 [==============================] - 7s 441ms/step - loss: 0.1154 - accuracy: 0.9622 - val_loss: 0.1801 - val_accuracy: 0.9539\n",
      "Epoch 39/300\n",
      "15/15 [==============================] - 7s 442ms/step - loss: 0.0877 - accuracy: 0.9887 - val_loss: 0.0902 - val_accuracy: 0.9803\n",
      "Epoch 40/300\n",
      "15/15 [==============================] - 7s 444ms/step - loss: 0.1014 - accuracy: 0.9749 - val_loss: 0.1006 - val_accuracy: 0.9803\n",
      "Epoch 41/300\n",
      "15/15 [==============================] - 7s 442ms/step - loss: 0.0836 - accuracy: 0.9900 - val_loss: 0.3034 - val_accuracy: 0.8487\n",
      "Epoch 42/300\n",
      "15/15 [==============================] - 7s 443ms/step - loss: 0.1055 - accuracy: 0.9719 - val_loss: 0.1429 - val_accuracy: 0.9671\n",
      "Epoch 43/300\n",
      "15/15 [==============================] - 7s 444ms/step - loss: 0.1231 - accuracy: 0.9672 - val_loss: 0.0754 - val_accuracy: 0.9803\n",
      "Epoch 44/300\n",
      "15/15 [==============================] - 7s 452ms/step - loss: 0.0837 - accuracy: 0.9747 - val_loss: 0.1104 - val_accuracy: 0.9803\n",
      "Epoch 45/300\n",
      "15/15 [==============================] - 7s 443ms/step - loss: 0.0988 - accuracy: 0.9759 - val_loss: 0.1646 - val_accuracy: 0.9145\n",
      "Epoch 46/300\n",
      "15/15 [==============================] - 7s 479ms/step - loss: 0.0778 - accuracy: 0.9847 - val_loss: 0.1481 - val_accuracy: 0.9671\n",
      "Epoch 47/300\n",
      "15/15 [==============================] - 7s 451ms/step - loss: 0.0925 - accuracy: 0.9863 - val_loss: 0.1111 - val_accuracy: 0.9539\n",
      "Epoch 48/300\n",
      "15/15 [==============================] - 7s 445ms/step - loss: 0.0854 - accuracy: 0.9761 - val_loss: 0.0965 - val_accuracy: 0.9803\n",
      "Epoch 49/300\n",
      "15/15 [==============================] - 7s 445ms/step - loss: 0.0869 - accuracy: 0.9853 - val_loss: 0.0935 - val_accuracy: 0.9539\n",
      "Epoch 50/300\n",
      "15/15 [==============================] - 7s 456ms/step - loss: 0.0658 - accuracy: 0.9924 - val_loss: 0.2637 - val_accuracy: 0.9276\n",
      "Epoch 51/300\n",
      "15/15 [==============================] - 7s 448ms/step - loss: 0.1166 - accuracy: 0.9720 - val_loss: 0.1478 - val_accuracy: 0.9671\n",
      "Epoch 52/300\n",
      "15/15 [==============================] - 7s 465ms/step - loss: 0.0835 - accuracy: 0.9770 - val_loss: 0.1184 - val_accuracy: 0.9671\n",
      "Epoch 53/300\n",
      "15/15 [==============================] - 7s 476ms/step - loss: 0.0764 - accuracy: 0.9854 - val_loss: 0.1111 - val_accuracy: 0.9605\n"
     ]
    }
   ],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(patience = 10,\n",
    "                                             monitor = 'val_loss', \n",
    "                                             #baseline = 0.9,\n",
    "                                             restore_best_weights=True)\n",
    "rcnn_model.train((x_train,y_train),(x_valid,y_valid),config.EPOCHS,config.BATCH_SIZE,[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_train: 0.982418\n",
      "confusion_matrix:\n",
      " [[285   7]\n",
      " [  1 162]]\n",
      "acc_valid: 0.980263\n",
      "confusion_matrix:\n",
      " [[108   3]\n",
      " [  0  41]]\n",
      "acc_test: 0.611650\n",
      "confusion_matrix:\n",
      " [[ 8  1]\n",
      " [39 55]]\n"
     ]
    }
   ],
   "source": [
    "acc_train,cm_train = rcnn_model.model_metrics(x_train,y_train)\n",
    "acc_valid,cm_valid = rcnn_model.model_metrics(x_valid,y_valid)\n",
    "acc_test,cm_test = rcnn_model.model_metrics(x_test,y_test)\n",
    "print('acc_train: %f\\nconfusion_matrix:\\n'%acc_train,cm_train)\n",
    "print('acc_valid: %f\\nconfusion_matrix:\\n'%acc_valid,cm_valid)\n",
    "print('acc_test: %f\\nconfusion_matrix:\\n'%acc_test,cm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
