{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import data_processing as dp\n",
    "from scipy import signal\n",
    "from scipy.stats import skew\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "import os\n",
    "import time\n",
    "import h5py\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for dirname, _, filenames in os.walk('.\\data'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2 = '.\\data\\正常\\G11_Walking_trial_4_emg.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.read_csv('./processed data/dataframe_W256_S64_R180_DWTLmax_dropna_samelabel_MF3.csv')\n",
    "\n",
    "# read file name of data with various Labels\n",
    "df = pd.read_csv('./useful_data_label.csv',index_col=0) \n",
    "drop = 'P379_M050_2_OFF_A_FoG_trial_2_emg.csv'\n",
    "drop2= 'P812_M050_2_B_FoG_trial_2_emg.csv'\n",
    "ind_drop = (df.columns!=drop) | (df.columns!=drop2)\n",
    "# read file name of data with only label 0\n",
    "df2 = pd.read_csv('./unuseful_data_label.csv',index_col=0)\n",
    "# read some of the data with only label 0\n",
    "df3 = pd.read_csv('./data/file_name.txt',header=None)\n",
    "\n",
    "files = np.concatenate([np.array(df.columns[ind_drop]),np.array(df3.loc[:,0])])\n",
    "ind = Data.File.isin(files)\n",
    "#ind = (Data.File != drop) & (Data.File != drop2)\n",
    "Data_sel = Data[ind]\n",
    "Data_rest = Data[~ind]\n",
    "#ind2 = Data_rest.File == drop\n",
    "#Data_rest = Data_rest[ind2]\n",
    "#Data_rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_col = ['_IEMG','_MAV','_SSI','_VAR','_RMS',\n",
    "               '_WL','_ZC','_SSC','_WAMP','_skew','_Acti','_AR','_HIST','_MDF']\n",
    "\n",
    "feature_all = Data_sel.iloc[:,1:-1]\n",
    "#ind_temp1 = feature_all.columns.str.contains('_mDWT')\n",
    "#ind_temp2 = feature_all.columns.str.contains('_Coe')\n",
    "#ind_temp3 = feature_all.columns.str.contains('_Scale')\n",
    "#ind_temp4 = feature_all.columns.str.contains('_HIST')\n",
    "#ind_temp = ind_temp1|ind_temp2|ind_temp3|ind_temp4\n",
    "ind_temp = feature_all.columns.str.contains('_MF')\n",
    "feature = feature_all.loc[:,~ind_temp]\n",
    "#feature = Data_sel.iloc[:,1:-1]\n",
    "#feature = Data_sel.iloc[:,:-2]\n",
    "y = Data_sel.Label\n",
    "#feature2_all = Data_rest.iloc[:,1:-1]\n",
    "#feature2 = feature2_all.loc[:,ind_temp]\n",
    "feature2 = Data_rest.iloc[:,1:-1]\n",
    "#feature2 = Data_rest.iloc[:,:-2]\n",
    "y2 = Data_rest.Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './processed data/data_set_after_window_withoutSC.hdf5'\n",
    "with h5py.File(path,'r') as f:\n",
    "    x = f['cwt_data'][...]\n",
    "    y = f['label2'][...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data_processing' from 'E:\\\\Document\\\\jupyter\\\\Master Thesis\\\\data_processing.py'>"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imp\n",
    "imp.reload(dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ctypes\n",
    "player = ctypes.windll.kernel32\n",
    "player.Beep(1000,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LEFT_TA_IEMG</th>\n",
       "      <th>LEFT_TS_IEMG</th>\n",
       "      <th>LEFT_BF_IEMG</th>\n",
       "      <th>LEFT_RF_IEMG</th>\n",
       "      <th>RIGHT_TA_IEMG</th>\n",
       "      <th>RIGHT_TS_IEMG</th>\n",
       "      <th>RIGHT_BF_IEMG</th>\n",
       "      <th>RIGHT_RF_IEMG</th>\n",
       "      <th>LEFT_TA_SSI</th>\n",
       "      <th>LEFT_TS_SSI</th>\n",
       "      <th>...</th>\n",
       "      <th>RIGHT_BF_mDWT6</th>\n",
       "      <th>RIGHT_BF_mDWT7</th>\n",
       "      <th>RIGHT_RF_mDWT0</th>\n",
       "      <th>RIGHT_RF_mDWT1</th>\n",
       "      <th>RIGHT_RF_mDWT2</th>\n",
       "      <th>RIGHT_RF_mDWT3</th>\n",
       "      <th>RIGHT_RF_mDWT4</th>\n",
       "      <th>RIGHT_RF_mDWT5</th>\n",
       "      <th>RIGHT_RF_mDWT6</th>\n",
       "      <th>RIGHT_RF_mDWT7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>548.09960</td>\n",
       "      <td>497.49110</td>\n",
       "      <td>681.18840</td>\n",
       "      <td>598.77924</td>\n",
       "      <td>1313.22860</td>\n",
       "      <td>4442.02050</td>\n",
       "      <td>1284.18550</td>\n",
       "      <td>693.58180</td>\n",
       "      <td>2070.7683</td>\n",
       "      <td>1748.4358</td>\n",
       "      <td>...</td>\n",
       "      <td>9.377046</td>\n",
       "      <td>4.990916</td>\n",
       "      <td>556.434814</td>\n",
       "      <td>343.095306</td>\n",
       "      <td>207.635269</td>\n",
       "      <td>93.610168</td>\n",
       "      <td>53.094650</td>\n",
       "      <td>24.570675</td>\n",
       "      <td>12.060508</td>\n",
       "      <td>5.739622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>543.63100</td>\n",
       "      <td>484.05870</td>\n",
       "      <td>665.12604</td>\n",
       "      <td>638.29640</td>\n",
       "      <td>1035.78380</td>\n",
       "      <td>3225.43430</td>\n",
       "      <td>1263.43310</td>\n",
       "      <td>687.76100</td>\n",
       "      <td>2057.3930</td>\n",
       "      <td>1713.7683</td>\n",
       "      <td>...</td>\n",
       "      <td>26.621002</td>\n",
       "      <td>14.194582</td>\n",
       "      <td>505.209656</td>\n",
       "      <td>279.325409</td>\n",
       "      <td>165.125229</td>\n",
       "      <td>83.372551</td>\n",
       "      <td>43.600906</td>\n",
       "      <td>20.352535</td>\n",
       "      <td>9.021744</td>\n",
       "      <td>4.887817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>524.71530</td>\n",
       "      <td>491.95126</td>\n",
       "      <td>639.57263</td>\n",
       "      <td>603.66766</td>\n",
       "      <td>990.65460</td>\n",
       "      <td>3633.17200</td>\n",
       "      <td>1217.76420</td>\n",
       "      <td>628.88730</td>\n",
       "      <td>1964.1893</td>\n",
       "      <td>1775.8363</td>\n",
       "      <td>...</td>\n",
       "      <td>38.259026</td>\n",
       "      <td>19.512487</td>\n",
       "      <td>425.959656</td>\n",
       "      <td>226.959534</td>\n",
       "      <td>119.487320</td>\n",
       "      <td>45.126644</td>\n",
       "      <td>8.551785</td>\n",
       "      <td>4.179543</td>\n",
       "      <td>1.943067</td>\n",
       "      <td>0.781084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>547.05853</td>\n",
       "      <td>466.00555</td>\n",
       "      <td>628.01060</td>\n",
       "      <td>632.10790</td>\n",
       "      <td>985.55725</td>\n",
       "      <td>5042.98700</td>\n",
       "      <td>1205.29320</td>\n",
       "      <td>592.94604</td>\n",
       "      <td>2096.5870</td>\n",
       "      <td>1575.4939</td>\n",
       "      <td>...</td>\n",
       "      <td>25.216244</td>\n",
       "      <td>11.351563</td>\n",
       "      <td>395.746338</td>\n",
       "      <td>213.186203</td>\n",
       "      <td>88.206375</td>\n",
       "      <td>41.611679</td>\n",
       "      <td>4.594048</td>\n",
       "      <td>1.401577</td>\n",
       "      <td>0.310067</td>\n",
       "      <td>0.121287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>515.43780</td>\n",
       "      <td>446.27258</td>\n",
       "      <td>626.81300</td>\n",
       "      <td>581.82970</td>\n",
       "      <td>869.83300</td>\n",
       "      <td>3146.06740</td>\n",
       "      <td>1249.10460</td>\n",
       "      <td>610.60790</td>\n",
       "      <td>2019.2968</td>\n",
       "      <td>1537.0039</td>\n",
       "      <td>...</td>\n",
       "      <td>8.140111</td>\n",
       "      <td>4.368567</td>\n",
       "      <td>477.853790</td>\n",
       "      <td>305.213226</td>\n",
       "      <td>166.140747</td>\n",
       "      <td>106.498840</td>\n",
       "      <td>68.548775</td>\n",
       "      <td>30.848173</td>\n",
       "      <td>15.781103</td>\n",
       "      <td>7.525197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16101</th>\n",
       "      <td>2210.39600</td>\n",
       "      <td>2431.59250</td>\n",
       "      <td>2522.21500</td>\n",
       "      <td>651.74896</td>\n",
       "      <td>2351.49150</td>\n",
       "      <td>909.37680</td>\n",
       "      <td>583.51416</td>\n",
       "      <td>869.30070</td>\n",
       "      <td>65793.2400</td>\n",
       "      <td>61341.7580</td>\n",
       "      <td>...</td>\n",
       "      <td>16.480499</td>\n",
       "      <td>7.987933</td>\n",
       "      <td>679.553101</td>\n",
       "      <td>465.168945</td>\n",
       "      <td>255.410934</td>\n",
       "      <td>123.197403</td>\n",
       "      <td>71.788757</td>\n",
       "      <td>31.097105</td>\n",
       "      <td>16.020678</td>\n",
       "      <td>7.656378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16102</th>\n",
       "      <td>2862.80100</td>\n",
       "      <td>2530.60000</td>\n",
       "      <td>2776.12740</td>\n",
       "      <td>645.07587</td>\n",
       "      <td>2642.48320</td>\n",
       "      <td>1071.73520</td>\n",
       "      <td>589.38550</td>\n",
       "      <td>805.04430</td>\n",
       "      <td>117425.8700</td>\n",
       "      <td>66555.9400</td>\n",
       "      <td>...</td>\n",
       "      <td>15.043890</td>\n",
       "      <td>7.118279</td>\n",
       "      <td>611.477295</td>\n",
       "      <td>414.233459</td>\n",
       "      <td>235.653336</td>\n",
       "      <td>101.961647</td>\n",
       "      <td>48.022587</td>\n",
       "      <td>23.091249</td>\n",
       "      <td>9.786898</td>\n",
       "      <td>5.183936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16103</th>\n",
       "      <td>2109.35350</td>\n",
       "      <td>3724.72560</td>\n",
       "      <td>2676.46920</td>\n",
       "      <td>630.86170</td>\n",
       "      <td>2719.53600</td>\n",
       "      <td>976.24420</td>\n",
       "      <td>611.96580</td>\n",
       "      <td>830.08466</td>\n",
       "      <td>86317.1000</td>\n",
       "      <td>120090.4700</td>\n",
       "      <td>...</td>\n",
       "      <td>10.769453</td>\n",
       "      <td>4.862518</td>\n",
       "      <td>669.540161</td>\n",
       "      <td>473.558655</td>\n",
       "      <td>263.836212</td>\n",
       "      <td>112.255241</td>\n",
       "      <td>57.610939</td>\n",
       "      <td>24.506268</td>\n",
       "      <td>12.162224</td>\n",
       "      <td>5.727070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16104</th>\n",
       "      <td>3429.48580</td>\n",
       "      <td>2834.17070</td>\n",
       "      <td>3254.47530</td>\n",
       "      <td>676.47100</td>\n",
       "      <td>2421.15940</td>\n",
       "      <td>899.85250</td>\n",
       "      <td>590.83167</td>\n",
       "      <td>718.16504</td>\n",
       "      <td>170800.9500</td>\n",
       "      <td>86476.3500</td>\n",
       "      <td>...</td>\n",
       "      <td>25.024672</td>\n",
       "      <td>11.816714</td>\n",
       "      <td>493.144226</td>\n",
       "      <td>299.594940</td>\n",
       "      <td>163.800293</td>\n",
       "      <td>76.252205</td>\n",
       "      <td>42.552967</td>\n",
       "      <td>19.244778</td>\n",
       "      <td>9.842437</td>\n",
       "      <td>4.149382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16105</th>\n",
       "      <td>2822.04900</td>\n",
       "      <td>3227.47920</td>\n",
       "      <td>3279.13940</td>\n",
       "      <td>650.26650</td>\n",
       "      <td>2701.44200</td>\n",
       "      <td>910.82764</td>\n",
       "      <td>593.37384</td>\n",
       "      <td>729.27860</td>\n",
       "      <td>141586.1900</td>\n",
       "      <td>101605.3360</td>\n",
       "      <td>...</td>\n",
       "      <td>10.815989</td>\n",
       "      <td>5.440997</td>\n",
       "      <td>460.868286</td>\n",
       "      <td>265.758392</td>\n",
       "      <td>134.612289</td>\n",
       "      <td>61.771595</td>\n",
       "      <td>14.207958</td>\n",
       "      <td>6.292281</td>\n",
       "      <td>2.992795</td>\n",
       "      <td>1.795406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16106 rows × 280 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LEFT_TA_IEMG  LEFT_TS_IEMG  LEFT_BF_IEMG  LEFT_RF_IEMG  RIGHT_TA_IEMG  \\\n",
       "0         548.09960     497.49110     681.18840     598.77924     1313.22860   \n",
       "1         543.63100     484.05870     665.12604     638.29640     1035.78380   \n",
       "2         524.71530     491.95126     639.57263     603.66766      990.65460   \n",
       "3         547.05853     466.00555     628.01060     632.10790      985.55725   \n",
       "4         515.43780     446.27258     626.81300     581.82970      869.83300   \n",
       "...             ...           ...           ...           ...            ...   \n",
       "16101    2210.39600    2431.59250    2522.21500     651.74896     2351.49150   \n",
       "16102    2862.80100    2530.60000    2776.12740     645.07587     2642.48320   \n",
       "16103    2109.35350    3724.72560    2676.46920     630.86170     2719.53600   \n",
       "16104    3429.48580    2834.17070    3254.47530     676.47100     2421.15940   \n",
       "16105    2822.04900    3227.47920    3279.13940     650.26650     2701.44200   \n",
       "\n",
       "       RIGHT_TS_IEMG  RIGHT_BF_IEMG  RIGHT_RF_IEMG  LEFT_TA_SSI  LEFT_TS_SSI  \\\n",
       "0         4442.02050     1284.18550      693.58180    2070.7683    1748.4358   \n",
       "1         3225.43430     1263.43310      687.76100    2057.3930    1713.7683   \n",
       "2         3633.17200     1217.76420      628.88730    1964.1893    1775.8363   \n",
       "3         5042.98700     1205.29320      592.94604    2096.5870    1575.4939   \n",
       "4         3146.06740     1249.10460      610.60790    2019.2968    1537.0039   \n",
       "...              ...            ...            ...          ...          ...   \n",
       "16101      909.37680      583.51416      869.30070   65793.2400   61341.7580   \n",
       "16102     1071.73520      589.38550      805.04430  117425.8700   66555.9400   \n",
       "16103      976.24420      611.96580      830.08466   86317.1000  120090.4700   \n",
       "16104      899.85250      590.83167      718.16504  170800.9500   86476.3500   \n",
       "16105      910.82764      593.37384      729.27860  141586.1900  101605.3360   \n",
       "\n",
       "       ...  RIGHT_BF_mDWT6  RIGHT_BF_mDWT7  RIGHT_RF_mDWT0  RIGHT_RF_mDWT1  \\\n",
       "0      ...        9.377046        4.990916      556.434814      343.095306   \n",
       "1      ...       26.621002       14.194582      505.209656      279.325409   \n",
       "2      ...       38.259026       19.512487      425.959656      226.959534   \n",
       "3      ...       25.216244       11.351563      395.746338      213.186203   \n",
       "4      ...        8.140111        4.368567      477.853790      305.213226   \n",
       "...    ...             ...             ...             ...             ...   \n",
       "16101  ...       16.480499        7.987933      679.553101      465.168945   \n",
       "16102  ...       15.043890        7.118279      611.477295      414.233459   \n",
       "16103  ...       10.769453        4.862518      669.540161      473.558655   \n",
       "16104  ...       25.024672       11.816714      493.144226      299.594940   \n",
       "16105  ...       10.815989        5.440997      460.868286      265.758392   \n",
       "\n",
       "       RIGHT_RF_mDWT2  RIGHT_RF_mDWT3  RIGHT_RF_mDWT4  RIGHT_RF_mDWT5  \\\n",
       "0          207.635269       93.610168       53.094650       24.570675   \n",
       "1          165.125229       83.372551       43.600906       20.352535   \n",
       "2          119.487320       45.126644        8.551785        4.179543   \n",
       "3           88.206375       41.611679        4.594048        1.401577   \n",
       "4          166.140747      106.498840       68.548775       30.848173   \n",
       "...               ...             ...             ...             ...   \n",
       "16101      255.410934      123.197403       71.788757       31.097105   \n",
       "16102      235.653336      101.961647       48.022587       23.091249   \n",
       "16103      263.836212      112.255241       57.610939       24.506268   \n",
       "16104      163.800293       76.252205       42.552967       19.244778   \n",
       "16105      134.612289       61.771595       14.207958        6.292281   \n",
       "\n",
       "       RIGHT_RF_mDWT6  RIGHT_RF_mDWT7  \n",
       "0           12.060508        5.739622  \n",
       "1            9.021744        4.887817  \n",
       "2            1.943067        0.781084  \n",
       "3            0.310067        0.121287  \n",
       "4           15.781103        7.525197  \n",
       "...               ...             ...  \n",
       "16101       16.020678        7.656378  \n",
       "16102        9.786898        5.183936  \n",
       "16103       12.162224        5.727070  \n",
       "16104        9.842437        4.149382  \n",
       "16105        2.992795        1.795406  \n",
       "\n",
       "[16106 rows x 280 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 256\n",
    "threshold_WAMP = 30\n",
    "threshold_ZC = 0\n",
    "threshold_SSC = 1\n",
    "bins=9\n",
    "bound = 70\n",
    "HIST_range = (-bound,bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = './processed data/data_set_after_window_W128_S64_sameLabel_rect.hdf5'\n",
    "with h5py.File(path,'r') as f:\n",
    "    x = f['data'][...]\n",
    "    y = f['label2'][...]\n",
    "#feature = dp.generate_feature(x,threshold_WAMP=threshold_WAMP,\n",
    "#                              threshold_ZC=threshold_ZC,\n",
    "#                              threshold_SSC=threshold_SSC,\n",
    "#                              bins=bins,ranges=HIST_range)\n",
    "#feature2 = dp.generate_feature(x2)\n",
    "player.Beep(1000,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('./processed data/nfeatures_W256_S64_WAMP30.hdf5','r') as f:\n",
    "    feature = f['features'][...]\n",
    "    y = f['labels'][...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature2,y2 = dp.pipeline_feature(path2,width=256,stride=64,\n",
    "                                  scaler=False,\n",
    "                                  threshold_WAMP=threshold_WAMP,\n",
    "                                  threshold_ZC=threshold_ZC,\n",
    "                                  threshold_SSC=threshold_SSC,\n",
    "                                  bins=bins,ranges=HIST_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('./processed data/nfeatures_rest_W256_S64.hdf5','r') as f:\n",
    "    feature2 = f['features'][...]\n",
    "    y2 = f['labels'][...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler(with_mean=True)\n",
    "feature_sc = sc.fit_transform(feature)\n",
    "feature2_sc = sc.transform(feature2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,Model,callbacks,regularizers,models\n",
    "from sklearn.model_selection import train_test_split,cross_validate\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import OneHotEncoder,normalize,MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE,BorderlineSMOTE,ADASYN,SVMSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,feature,y,binary=True,file=None):\n",
    "    if binary:\n",
    "        ind = ((y==0)|(y==1)|(y==2)|(y==3)|(y==4)|(y==6))\n",
    "        ind1 = ((y==4)|(y==1)|(y==2)|(y==3)|(y==6))\n",
    "        y_01 = y.copy()\n",
    "        #ind1 = ((y_01==1)|(y_01==2)|(y_01==6))\n",
    "        y_01[ind1] = 1\n",
    "        oc = OneHotEncoder()\n",
    "        y_01 = oc.fit_transform(np.array(y_01)[:,np.newaxis]).toarray()\n",
    "        cw = None#{0:1,1:5}\n",
    "    else:\n",
    "        ind = ((y==1)|(y==2)|(y==6))\n",
    "        #ind = ((y==1)|(y==6))\n",
    "        y_01 = y[ind].copy()\n",
    "        oc = OneHotEncoder()\n",
    "        y_01 = oc.fit_transform(np.array(y_01)[:,np.newaxis]).toarray()\n",
    "        cw = None#{0:5,1:1,2:1}#{0:2,1:1,2:10,3:2}\n",
    "    x_full,x_test,y_full,y_test = train_test_split(np.array(feature)[ind,:],y_01,\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=123,\n",
    "                                                   shuffle=True)\n",
    "    x_train,x_valid,y_train,y_valid = train_test_split(x_full,y_full,\n",
    "                                                       test_size=0.25,\n",
    "                                                       random_state=555,\n",
    "                                                       shuffle=True)\n",
    "    \n",
    "    #sm = BorderlineSMOTE(random_state=50,kind='borderline-2')\n",
    "    #sm = SMOTE(random_state=50)\n",
    "    #print(y_full.shape)\n",
    "    #x_full,y_full = sm.fit_resample(x_full,y_full)\n",
    "    #print(y_full_n.shape)\n",
    "    sc = StandardScaler(with_mean=True)\n",
    "    #sc = MinMaxScaler()\n",
    "    x_train = sc.fit_transform(x_full)\n",
    "    #pca = PCA(n_components=100)\n",
    "    #x_train = pca.fit_transform(x_train)\n",
    "    #x_valid = sc.transform(x_valid)\n",
    "    x_test = sc.transform(x_test)\n",
    "    #x_test = pca.transform(x_test)\n",
    "    #x_train = x_full\n",
    "    \n",
    "    early_stopping = callbacks.EarlyStopping(patience = 20,\n",
    "                                             monitor = 'val_loss', \n",
    "                                             restore_best_weights=True)\n",
    "    history = model.fit(x_train,y_full,validation_data=[x_test,y_test],\n",
    "                        epochs=300,batch_size=32,class_weight=cw,\n",
    "                        callbacks=[early_stopping],\n",
    "                        shuffle=True)\n",
    "    \n",
    "    if binary:\n",
    "        y_pred_t=model.predict(x_test)\n",
    "        test = metrics.accuracy_score(np.argmax(y_test,axis=1),np.argmax(y_pred_t,axis=1))\n",
    "        #test = metrics.accuracy_score(y_test,y_pred_t>0.5)\n",
    "        \n",
    "        #y_pred_v=model.predict(x_valid)\n",
    "        #valid = metrics.accuracy_score(y_valid,np.argmax(y_pred_v,axis=1))\n",
    "        y_pred_ta=model.predict(x_train)\n",
    "        train = metrics.accuracy_score(np.argmax(y_full,axis=1),np.argmax(y_pred_ta,axis=1))\n",
    "        #train = metrics.accuracy_score(y_full,y_pred_ta>0.5)\n",
    "        \n",
    "        print('train: \\n',metrics.confusion_matrix(np.argmax(y_full,axis=1),np.argmax(y_pred_ta,axis=1)))\n",
    "        #print('valid: \\n',metrics.confusion_matrix(np.argmax(y_valid,axis=1),np.argmax(y_pred_v,axis=1)))\n",
    "        print('test: \\n',metrics.confusion_matrix(np.argmax(y_test,axis=1),np.argmax(y_pred_t,axis=1)))\n",
    "        \n",
    "        #print('train: \\n',metrics.confusion_matrix(y_full,y_pred_ta>0.5))\n",
    "        #print('test: \\n',metrics.confusion_matrix(y_test,y_pred_t>0.5))\n",
    "\n",
    "    else:\n",
    "        y_pred_t=model.predict(x_test)\n",
    "        test = metrics.accuracy_score(np.argmax(y_test,axis=1),np.argmax(y_pred_t,axis=1))\n",
    "        #y_pred_v=model.predict(x_valid)\n",
    "        #valid = metrics.accuracy_score(np.argmax(y_valid,axis=1),np.argmax(y_pred_v,axis=1))\n",
    "        y_pred_ta=model.predict(x_train)\n",
    "        train = metrics.accuracy_score(np.argmax(y_full,axis=1),np.argmax(y_pred_ta,axis=1))        \n",
    "        print('train: \\n',metrics.confusion_matrix(np.argmax(y_full,axis=1),np.argmax(y_pred_ta,axis=1)))\n",
    "        #print('valid: \\n',metrics.confusion_matrix(np.argmax(y_valid,axis=1),np.argmax(y_pred_v,axis=1)))\n",
    "        print('test: \\n',metrics.confusion_matrix(np.argmax(y_test,axis=1),np.argmax(y_pred_t,axis=1)))\n",
    "    print('test:%f'%test)\n",
    "    #print('valid:%f'%valid)\n",
    "    print('train:%f'%train)\n",
    "    if file != None:\n",
    "        model.save_model(file)\n",
    "    return train,test,sc#,pca\n",
    "\n",
    "def test_model(model,feature,y,sc,pca):\n",
    "    ind = ((y==4)|(y==1)|(y==2)|(y==3)|(y==6))\n",
    "    #ind = ((y==0)|(y==1)|(y==2)|(y==6))\n",
    "    y_01 = y.copy()\n",
    "    #ind1 = ((y_01==1)|(y_01==2)|(y_01==6))\n",
    "    y_01[ind] = 1\n",
    "    #print(set(y_01))\n",
    "    oh_ec = OneHotEncoder()\n",
    "    y_01 = oh_ec.fit_transform(y_01[:,np.newaxis]).toarray()\n",
    "    #print(y_01)\n",
    "    feature=sc.transform(feature)\n",
    "    #feature=pca.transform(feature)\n",
    "    y_pred=model.predict(feature)\n",
    "    test = metrics.accuracy_score(np.argmax(y_01,axis=1),np.argmax(y_pred,axis=1))\n",
    "    #test = metrics.accuracy_score(y_01,y_pred>0.5)\n",
    "    \n",
    "    print('acc:%f'%test)\n",
    "    print(metrics.confusion_matrix(np.argmax(y_01,axis=1),np.argmax(y_pred,axis=1)))\n",
    "    #print(metrics.confusion_matrix(y_01,y_pred>0.5))\n",
    "    return test\n",
    "\n",
    "def sparse_cost_sensitive_loss (y_true,y_pred):\n",
    "    #cost_matrix = tf.constant([[0,1.,1,1.],\n",
    "    #              [2,0,5,5],\n",
    "    #              [1,1,0,1],\n",
    "    #              [1.,2.,1,0]])\n",
    "    cost_matrix = tf.constant([[0,2.,2],\n",
    "                  [1,0,1],\n",
    "                  [1.0,1.,0]])\n",
    "    #cost_matrix = tf.constant([[0,2.],\n",
    "    #              [2.,0]])\n",
    "    batch_cost_matrix = tf.nn.embedding_lookup(cost_matrix, tf.argmax(y_true,axis=1))\n",
    "    eps = 1e-6\n",
    "    probability = tf.clip_by_value(y_pred, eps, 1-eps)\n",
    "    cost_values = tf.math.log(1-probability)*batch_cost_matrix\n",
    "    loss = tf.reduce_mean(-tf.reduce_sum(cost_values, axis=1))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = ((y==1)|(y==2)|(y==3)|(y==6))\n",
    "#ind = ((y==4)|(y==1)|(y==2)|(y==3)|(y==6))\n",
    "ind_f = [0,1,6,42,46,57,62]\n",
    "#y_01 = y[ind].copy()\n",
    "#y_01[y_01==1]=0\n",
    "#y_01[y_01==2]=1\n",
    "#y_01[y_01==3]=2\n",
    "#y_01[y_01==6]=3\n",
    "y_01 = y[ind].copy()\n",
    "#y_01[ind] = 1\n",
    "oh_ec = OneHotEncoder()\n",
    "y_oh = oh_ec.fit_transform(y_01[:,np.newaxis]).toarray()\n",
    "x_full,x_test,y_full,y_test = train_test_split(feature.loc[ind,:],y_01,test_size=0.2,random_state=123,shuffle=False)\n",
    "x_train,x_valid,y_train,y_valid = train_test_split(x_full,y_full,test_size=0.2,random_state=555,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = layers.Input(shape=feature.shape[1:])#feature.shape[1:]\n",
    "l1 = layers.Dense(128,activation='elu',\n",
    "                  #kernel_initializer='lecun_normal',\n",
    "                  #kernel_regularizer = regularizers.l2(0.001),\n",
    "                 )(input_)\n",
    "#drop1 = layers.Dropout(0.2)(l1)\n",
    "bn1 = layers.BatchNormalization()(l1)\n",
    "l2 = layers.Dense(64,activation='elu',\n",
    "                  #kernel_initializer='lecun_normal',\n",
    "                  #kernel_regularizer = regularizers.l2(0.001),\n",
    "                 )(bn1)\n",
    "#drop2 = layers.Dropout(0.2)(l2)\n",
    "bn2 = layers.BatchNormalization()(l2)\n",
    "l3 = layers.Dense(32,activation='elu',\n",
    "                  #kernel_initializer='lecun_normal',\n",
    "                  #kernel_regularizer = regularizers.l2(0.001),\n",
    "                 )(bn2)\n",
    "#drop3 = layers.Dropout(0.2)(l3)\n",
    "bn3 = layers.BatchNormalization()(l3)\n",
    "l4 = layers.Dense(16,activation='elu',\n",
    "                 #kernel_regularizer = regularizers.l2(0.001),\n",
    "                 )(bn3)\n",
    "#drop4 = layers.Dropout(0.2)(l4)\n",
    "#l5 = layers.Dense(8,activation='relu')(drop4)\n",
    "#drop5 = layers.Dropout(0.5)(l5)\n",
    "output = layers.Dense(3,activation='softmax')(l4)\n",
    "model = Model(inputs=[input_],outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(128,activation='elu',\n",
    "                  #kernel_initializer='lecun_normal',\n",
    "                  #kernel_regularizer = regularizers.l2(0.001),\n",
    "                 ))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(64,activation='elu',\n",
    "                  #kernel_initializer='lecun_normal',\n",
    "                  #kernel_regularizer = regularizers.l2(0.001),\n",
    "                 ))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(32,activation='elu',\n",
    "                  #kernel_initializer='lecun_normal',\n",
    "                  #kernel_regularizer = regularizers.l2(0.001),\n",
    "                 ))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(16,activation='elu',\n",
    "                 #kernel_regularizer = regularizers.l2(0.001),\n",
    "                 ))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(3,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[0 1 2] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12810 samples, validate on 2132 samples\n",
      "Epoch 1/300\n",
      "12810/12810 [==============================] - 5s 360us/sample - loss: 0.8787 - accuracy: 0.5855 - val_loss: 0.6497 - val_accuracy: 0.7308\n",
      "Epoch 2/300\n",
      "12810/12810 [==============================] - 1s 87us/sample - loss: 0.7899 - accuracy: 0.6340 - val_loss: 0.5930 - val_accuracy: 0.7425\n",
      "Epoch 3/300\n",
      "12810/12810 [==============================] - 1s 88us/sample - loss: 0.7316 - accuracy: 0.6693 - val_loss: 0.6297 - val_accuracy: 0.7312\n",
      "Epoch 4/300\n",
      "12810/12810 [==============================] - 1s 85us/sample - loss: 0.7001 - accuracy: 0.6826 - val_loss: 0.5788 - val_accuracy: 0.7580\n",
      "Epoch 5/300\n",
      "12810/12810 [==============================] - 1s 84us/sample - loss: 0.6734 - accuracy: 0.6920 - val_loss: 0.5846 - val_accuracy: 0.7453\n",
      "Epoch 6/300\n",
      "12810/12810 [==============================] - 1s 88us/sample - loss: 0.6495 - accuracy: 0.7037 - val_loss: 0.5810 - val_accuracy: 0.7570\n",
      "Epoch 7/300\n",
      "12810/12810 [==============================] - 1s 88us/sample - loss: 0.6304 - accuracy: 0.7203 - val_loss: 0.5474 - val_accuracy: 0.7683\n",
      "Epoch 8/300\n",
      "12810/12810 [==============================] - 1s 87us/sample - loss: 0.6065 - accuracy: 0.7317 - val_loss: 0.5447 - val_accuracy: 0.7711\n",
      "Epoch 9/300\n",
      "12810/12810 [==============================] - 1s 87us/sample - loss: 0.5877 - accuracy: 0.7371 - val_loss: 0.5325 - val_accuracy: 0.7805\n",
      "Epoch 10/300\n",
      "12810/12810 [==============================] - 1s 86us/sample - loss: 0.5778 - accuracy: 0.7457 - val_loss: 0.5239 - val_accuracy: 0.7786\n",
      "Epoch 11/300\n",
      "12810/12810 [==============================] - 1s 89us/sample - loss: 0.5587 - accuracy: 0.7598 - val_loss: 0.5137 - val_accuracy: 0.7781\n",
      "Epoch 12/300\n",
      "12810/12810 [==============================] - 1s 87us/sample - loss: 0.5426 - accuracy: 0.7670 - val_loss: 0.4971 - val_accuracy: 0.7992\n",
      "Epoch 13/300\n",
      "12810/12810 [==============================] - 1s 87us/sample - loss: 0.5297 - accuracy: 0.7767 - val_loss: 0.5239 - val_accuracy: 0.7819\n",
      "Epoch 14/300\n",
      "12810/12810 [==============================] - 1s 87us/sample - loss: 0.5161 - accuracy: 0.7825 - val_loss: 0.5111 - val_accuracy: 0.7871\n",
      "Epoch 15/300\n",
      "12810/12810 [==============================] - 1s 87us/sample - loss: 0.5007 - accuracy: 0.7891 - val_loss: 0.5145 - val_accuracy: 0.7810\n",
      "Epoch 16/300\n",
      "12810/12810 [==============================] - 1s 86us/sample - loss: 0.4847 - accuracy: 0.7971 - val_loss: 0.5384 - val_accuracy: 0.7772\n",
      "Epoch 17/300\n",
      "12810/12810 [==============================] - 1s 88us/sample - loss: 0.4780 - accuracy: 0.8020 - val_loss: 0.4810 - val_accuracy: 0.7960\n",
      "Epoch 18/300\n",
      "12810/12810 [==============================] - 1s 87us/sample - loss: 0.4669 - accuracy: 0.8023 - val_loss: 0.5202 - val_accuracy: 0.7894\n",
      "Epoch 19/300\n",
      "12810/12810 [==============================] - 1s 87us/sample - loss: 0.4554 - accuracy: 0.8130 - val_loss: 0.5177 - val_accuracy: 0.8007\n",
      "Epoch 20/300\n",
      "12810/12810 [==============================] - 1s 87us/sample - loss: 0.4471 - accuracy: 0.8226 - val_loss: 0.5079 - val_accuracy: 0.8072\n",
      "Epoch 21/300\n",
      "12810/12810 [==============================] - 1s 89us/sample - loss: 0.4348 - accuracy: 0.8214 - val_loss: 0.4954 - val_accuracy: 0.8016\n",
      "Epoch 22/300\n",
      "12810/12810 [==============================] - 1s 85us/sample - loss: 0.4309 - accuracy: 0.8255 - val_loss: 0.4942 - val_accuracy: 0.8119\n",
      "Epoch 23/300\n",
      "12810/12810 [==============================] - 1s 94us/sample - loss: 0.4233 - accuracy: 0.8300 - val_loss: 0.4961 - val_accuracy: 0.8152\n",
      "Epoch 24/300\n",
      "12810/12810 [==============================] - 1s 78us/sample - loss: 0.4167 - accuracy: 0.8351 - val_loss: 0.4871 - val_accuracy: 0.8072\n",
      "Epoch 25/300\n",
      "12810/12810 [==============================] - 1s 77us/sample - loss: 0.4005 - accuracy: 0.8413 - val_loss: 0.5371 - val_accuracy: 0.7861\n",
      "Epoch 26/300\n",
      "12810/12810 [==============================] - 1s 76us/sample - loss: 0.4090 - accuracy: 0.8351 - val_loss: 0.5050 - val_accuracy: 0.7997\n",
      "Epoch 27/300\n",
      "12810/12810 [==============================] - 1s 76us/sample - loss: 0.4007 - accuracy: 0.8431 - val_loss: 0.4942 - val_accuracy: 0.8143\n",
      "Epoch 28/300\n",
      "12810/12810 [==============================] - 1s 75us/sample - loss: 0.3846 - accuracy: 0.8509 - val_loss: 0.4953 - val_accuracy: 0.8119\n",
      "Epoch 29/300\n",
      "12810/12810 [==============================] - 1s 74us/sample - loss: 0.3743 - accuracy: 0.8535 - val_loss: 0.4827 - val_accuracy: 0.8124\n",
      "Epoch 30/300\n",
      "12810/12810 [==============================] - 1s 76us/sample - loss: 0.3712 - accuracy: 0.8514 - val_loss: 0.4850 - val_accuracy: 0.8166\n",
      "Epoch 31/300\n",
      "12810/12810 [==============================] - 1s 76us/sample - loss: 0.3705 - accuracy: 0.8536 - val_loss: 0.4905 - val_accuracy: 0.8133\n",
      "Epoch 32/300\n",
      "12810/12810 [==============================] - 1s 75us/sample - loss: 0.3640 - accuracy: 0.8568 - val_loss: 0.4903 - val_accuracy: 0.8199\n",
      "Epoch 33/300\n",
      "12810/12810 [==============================] - 1s 76us/sample - loss: 0.3569 - accuracy: 0.8596 - val_loss: 0.4703 - val_accuracy: 0.8246\n",
      "Epoch 34/300\n",
      "12810/12810 [==============================] - 1s 74us/sample - loss: 0.3528 - accuracy: 0.8604 - val_loss: 0.4874 - val_accuracy: 0.8180\n",
      "Epoch 35/300\n",
      "12810/12810 [==============================] - 1s 79us/sample - loss: 0.3490 - accuracy: 0.8632 - val_loss: 0.4993 - val_accuracy: 0.8199\n",
      "Epoch 36/300\n",
      "12810/12810 [==============================] - 1s 79us/sample - loss: 0.3384 - accuracy: 0.8654 - val_loss: 0.4872 - val_accuracy: 0.8227\n",
      "Epoch 37/300\n",
      "12810/12810 [==============================] - 1s 75us/sample - loss: 0.3366 - accuracy: 0.8671 - val_loss: 0.4935 - val_accuracy: 0.8246\n",
      "Epoch 38/300\n",
      "12810/12810 [==============================] - 1s 75us/sample - loss: 0.3422 - accuracy: 0.8664 - val_loss: 0.4699 - val_accuracy: 0.8241\n",
      "Epoch 39/300\n",
      "12810/12810 [==============================] - 1s 75us/sample - loss: 0.3278 - accuracy: 0.8713 - val_loss: 0.4547 - val_accuracy: 0.8232\n",
      "Epoch 40/300\n",
      "12810/12810 [==============================] - 1s 74us/sample - loss: 0.3322 - accuracy: 0.8699 - val_loss: 0.4458 - val_accuracy: 0.8269\n",
      "Epoch 41/300\n",
      "12810/12810 [==============================] - 1s 74us/sample - loss: 0.3101 - accuracy: 0.8810 - val_loss: 0.4717 - val_accuracy: 0.8297\n",
      "Epoch 42/300\n",
      "12810/12810 [==============================] - 1s 76us/sample - loss: 0.3213 - accuracy: 0.8761 - val_loss: 0.4649 - val_accuracy: 0.8236\n",
      "Epoch 43/300\n",
      "12810/12810 [==============================] - 1s 74us/sample - loss: 0.3102 - accuracy: 0.8800 - val_loss: 0.4391 - val_accuracy: 0.8335\n",
      "Epoch 44/300\n",
      "12810/12810 [==============================] - 1s 76us/sample - loss: 0.3107 - accuracy: 0.8787 - val_loss: 0.4476 - val_accuracy: 0.8377\n",
      "Epoch 45/300\n",
      "12810/12810 [==============================] - 1s 74us/sample - loss: 0.3079 - accuracy: 0.8837 - val_loss: 0.4602 - val_accuracy: 0.8372\n",
      "Epoch 46/300\n",
      "12810/12810 [==============================] - 1s 75us/sample - loss: 0.2986 - accuracy: 0.8848 - val_loss: 0.4789 - val_accuracy: 0.8260\n",
      "Epoch 47/300\n",
      "12810/12810 [==============================] - 1s 74us/sample - loss: 0.2943 - accuracy: 0.8864 - val_loss: 0.4956 - val_accuracy: 0.8302\n",
      "Epoch 48/300\n",
      "12810/12810 [==============================] - 1s 75us/sample - loss: 0.2901 - accuracy: 0.8910 - val_loss: 0.4517 - val_accuracy: 0.8293\n",
      "Epoch 49/300\n",
      "12810/12810 [==============================] - 1s 76us/sample - loss: 0.2946 - accuracy: 0.8874 - val_loss: 0.4838 - val_accuracy: 0.8269\n",
      "Epoch 50/300\n",
      "12810/12810 [==============================] - 1s 75us/sample - loss: 0.2899 - accuracy: 0.8921 - val_loss: 0.4548 - val_accuracy: 0.8335\n",
      "Epoch 51/300\n",
      "12810/12810 [==============================] - 1s 76us/sample - loss: 0.2931 - accuracy: 0.8878 - val_loss: 0.4745 - val_accuracy: 0.8396\n",
      "Epoch 52/300\n",
      "12810/12810 [==============================] - 1s 75us/sample - loss: 0.2835 - accuracy: 0.8959 - val_loss: 0.4672 - val_accuracy: 0.8335\n",
      "Epoch 53/300\n",
      "12810/12810 [==============================] - 1s 75us/sample - loss: 0.2820 - accuracy: 0.8919 - val_loss: 0.4803 - val_accuracy: 0.8358\n",
      "Epoch 54/300\n",
      "12810/12810 [==============================] - 1s 75us/sample - loss: 0.2790 - accuracy: 0.8945 - val_loss: 0.4665 - val_accuracy: 0.8260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/300\n",
      "12810/12810 [==============================] - 1s 73us/sample - loss: 0.2842 - accuracy: 0.8931 - val_loss: 0.4638 - val_accuracy: 0.8358\n",
      "Epoch 56/300\n",
      "12810/12810 [==============================] - 1s 72us/sample - loss: 0.2681 - accuracy: 0.8959 - val_loss: 0.4813 - val_accuracy: 0.8335\n",
      "Epoch 57/300\n",
      "12810/12810 [==============================] - 1s 73us/sample - loss: 0.2714 - accuracy: 0.8955 - val_loss: 0.4792 - val_accuracy: 0.8326\n",
      "Epoch 58/300\n",
      "12810/12810 [==============================] - 1s 73us/sample - loss: 0.2612 - accuracy: 0.8998 - val_loss: 0.4844 - val_accuracy: 0.8297\n",
      "Epoch 59/300\n",
      "12810/12810 [==============================] - 1s 77us/sample - loss: 0.2757 - accuracy: 0.8967 - val_loss: 0.4587 - val_accuracy: 0.8415\n",
      "Epoch 60/300\n",
      "12810/12810 [==============================] - 1s 73us/sample - loss: 0.2636 - accuracy: 0.8977 - val_loss: 0.4933 - val_accuracy: 0.8480\n",
      "Epoch 61/300\n",
      "12810/12810 [==============================] - 1s 73us/sample - loss: 0.2678 - accuracy: 0.8973 - val_loss: 0.4695 - val_accuracy: 0.8424\n",
      "Epoch 62/300\n",
      "12810/12810 [==============================] - 1s 72us/sample - loss: 0.2577 - accuracy: 0.9023 - val_loss: 0.4521 - val_accuracy: 0.8466\n",
      "Epoch 63/300\n",
      "12810/12810 [==============================] - 1s 74us/sample - loss: 0.2553 - accuracy: 0.9048 - val_loss: 0.4711 - val_accuracy: 0.8471\n",
      "train: \n",
      " [[4047   76  147]\n",
      " [ 304 3835  131]\n",
      " [ 100   16 4154]]\n",
      "test: \n",
      " [[344  64  56]\n",
      " [137 890  51]\n",
      " [ 34  13 543]]\n",
      "test:0.833490\n",
      "train:0.939578\n"
     ]
    }
   ],
   "source": [
    "#sc = StandardScaler(with_mean=True)\n",
    "#feature_sc = sc.fit_transform(feature)\n",
    "#feature2_sc = sc.transform(feature2)\n",
    "#pca = PCA(n_components=160,copy=True)\n",
    "#feature_pca = pca.fit_transform(feature)\n",
    "#feature2_pca = pca.transform(feature2)\n",
    "train,test,sc = train_model(model,feature,np.array(y),False)\n",
    "#rest = test_model(model,feature2,np.array(y2),sc)\n",
    "#acc = [train,valid,test,rest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(model,np.array(feature2),np.array(y2),sc,pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    460\n",
       "2    430\n",
       "1     33\n",
       "3      8\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y2).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_model(model,feature2_sc,np.array(y2))\n",
    "ind = ((y==1)|(y==2)|(y==6))\n",
    "y_01 = y[ind].copy()\n",
    "oc = OneHotEncoder()\n",
    "y_01 = oc.fit_transform(np.array(y_01)[:,np.newaxis]).toarray()\n",
    "pred=model.predict(feature_sc[ind,:])\n",
    "np.argmax(pred,axis=1)\n",
    "np.argmax(y_01,axis=1)\n",
    "metrics.confusion_matrix(np.argmax(y_01,axis=1),np.argmax(pred,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acc_ann = pd.DataFrame(acc,columns=['dnn1'],index=['train','valid','test','rest data'])\n",
    "#acc_ann_com=pd.concat([acc_ann_com,acc_ann.T])\n",
    "#acc_ann.loc['drop_mDWT',:]=[train,valid,test,rest]\n",
    "acc_ann_com.loc['dnn2',:]=acc\n",
    "acc_ann_com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test feature from Left or Right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = layers.Input(shape=feature.loc[:,ind_temp].shape[1:])\n",
    "l1 = layers.Dense(128,activation='elu')(input_)\n",
    "drop1 = layers.Dropout(0.2)(l1)\n",
    "l2 = layers.Dense(64,activation='elu')(drop1)\n",
    "drop2 = layers.Dropout(0.2)(l2)\n",
    "#l3 = layers.Dense(32,activation='elu')(drop2)\n",
    "#drop3 = layers.Dropout(0.2)(l3)\n",
    "#l4 = layers.Dense(16,activation='selu')(l3)\n",
    "#drop4 = layers.Dropout(0.2)(l4)\n",
    "output = layers.Dense(1,activation='sigmoid')(drop2)\n",
    "model = Model(inputs=[input_],outputs=[output])\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23125 samples, validate on 5782 samples\n",
      "Epoch 1/200\n",
      "23125/23125 [==============================] - 4s 167us/sample - loss: 1.9657 - accuracy: 0.5308 - val_loss: 1.3537 - val_accuracy: 0.6404\n",
      "Epoch 2/200\n",
      "23125/23125 [==============================] - 3s 109us/sample - loss: 1.3913 - accuracy: 0.6479 - val_loss: 1.1555 - val_accuracy: 0.7008\n",
      "Epoch 3/200\n",
      "23125/23125 [==============================] - 3s 110us/sample - loss: 1.2045 - accuracy: 0.7052 - val_loss: 1.0439 - val_accuracy: 0.7771\n",
      "Epoch 4/200\n",
      "23125/23125 [==============================] - 2s 105us/sample - loss: 1.1076 - accuracy: 0.7394 - val_loss: 0.9467 - val_accuracy: 0.7608\n",
      "Epoch 5/200\n",
      "23125/23125 [==============================] - 2s 86us/sample - loss: 1.0526 - accuracy: 0.7501 - val_loss: 0.9212 - val_accuracy: 0.7508\n",
      "Epoch 6/200\n",
      "23125/23125 [==============================] - 2s 93us/sample - loss: 0.9990 - accuracy: 0.7677 - val_loss: 0.8937 - val_accuracy: 0.7975\n",
      "Epoch 7/200\n",
      "23125/23125 [==============================] - 2s 98us/sample - loss: 0.9561 - accuracy: 0.7806 - val_loss: 0.8888 - val_accuracy: 0.7916\n",
      "Epoch 8/200\n",
      "23125/23125 [==============================] - 2s 85us/sample - loss: 0.9064 - accuracy: 0.8004 - val_loss: 0.8675 - val_accuracy: 0.8127\n",
      "Epoch 9/200\n",
      "23125/23125 [==============================] - 2s 96us/sample - loss: 0.8361 - accuracy: 0.8109 - val_loss: 0.9959 - val_accuracy: 0.8388\n",
      "Epoch 10/200\n",
      "23125/23125 [==============================] - 2s 91us/sample - loss: 0.8394 - accuracy: 0.8178 - val_loss: 0.8477 - val_accuracy: 0.8080\n",
      "Epoch 11/200\n",
      "23125/23125 [==============================] - 2s 89us/sample - loss: 0.8182 - accuracy: 0.8169 - val_loss: 0.8487 - val_accuracy: 0.8193\n",
      "Epoch 12/200\n",
      "23125/23125 [==============================] - 2s 87us/sample - loss: 0.7716 - accuracy: 0.8304 - val_loss: 1.0611 - val_accuracy: 0.8345\n",
      "Epoch 13/200\n",
      "23125/23125 [==============================] - 2s 87us/sample - loss: 0.8293 - accuracy: 0.8183 - val_loss: 0.9155 - val_accuracy: 0.8390\n",
      "Epoch 14/200\n",
      "23125/23125 [==============================] - 2s 82us/sample - loss: 0.8102 - accuracy: 0.8220 - val_loss: 0.8263 - val_accuracy: 0.8255\n",
      "Epoch 15/200\n",
      "23125/23125 [==============================] - 2s 82us/sample - loss: 0.7460 - accuracy: 0.8396 - val_loss: 0.7475 - val_accuracy: 0.8295\n",
      "Epoch 16/200\n",
      "23125/23125 [==============================] - 3s 109us/sample - loss: 0.7118 - accuracy: 0.8471 - val_loss: 0.8684 - val_accuracy: 0.8412\n",
      "Epoch 17/200\n",
      "23125/23125 [==============================] - 3s 135us/sample - loss: 0.7334 - accuracy: 0.8410 - val_loss: 0.8593 - val_accuracy: 0.8258\n",
      "Epoch 18/200\n",
      "23125/23125 [==============================] - 3s 125us/sample - loss: 0.7021 - accuracy: 0.8490 - val_loss: 0.8953 - val_accuracy: 0.8506\n",
      "Epoch 19/200\n",
      "23125/23125 [==============================] - 3s 121us/sample - loss: 0.6847 - accuracy: 0.8514 - val_loss: 0.9428 - val_accuracy: 0.8566\n",
      "Epoch 20/200\n",
      "23125/23125 [==============================] - 3s 133us/sample - loss: 0.7248 - accuracy: 0.8508 - val_loss: 0.9025 - val_accuracy: 0.8392\n",
      "Epoch 21/200\n",
      "23125/23125 [==============================] - 3s 118us/sample - loss: 0.7017 - accuracy: 0.8458 - val_loss: 0.8396 - val_accuracy: 0.8525\n",
      "Epoch 22/200\n",
      "23125/23125 [==============================] - 3s 110us/sample - loss: 0.6808 - accuracy: 0.8589 - val_loss: 0.8343 - val_accuracy: 0.8454\n",
      "Epoch 23/200\n",
      "23125/23125 [==============================] - 3s 111us/sample - loss: 0.6569 - accuracy: 0.8586 - val_loss: 0.9713 - val_accuracy: 0.8646\n",
      "Epoch 24/200\n",
      "23125/23125 [==============================] - 2s 91us/sample - loss: 0.7113 - accuracy: 0.8530 - val_loss: 0.9063 - val_accuracy: 0.8663\n",
      "Epoch 25/200\n",
      "23125/23125 [==============================] - 2s 87us/sample - loss: 0.6886 - accuracy: 0.8540 - val_loss: 1.0114 - val_accuracy: 0.8729\n",
      "Epoch 26/200\n",
      "23125/23125 [==============================] - 2s 83us/sample - loss: 0.6437 - accuracy: 0.8703 - val_loss: 1.0360 - val_accuracy: 0.8737\n",
      "Epoch 27/200\n",
      "23125/23125 [==============================] - 2s 82us/sample - loss: 0.6396 - accuracy: 0.8684 - val_loss: 1.0674 - val_accuracy: 0.8762\n",
      "Epoch 28/200\n",
      "23125/23125 [==============================] - 2s 87us/sample - loss: 0.5848 - accuracy: 0.8806 - val_loss: 1.3498 - val_accuracy: 0.8853\n",
      "Epoch 29/200\n",
      "23125/23125 [==============================] - 2s 79us/sample - loss: 0.6586 - accuracy: 0.8602 - val_loss: 0.9367 - val_accuracy: 0.8565\n",
      "Epoch 30/200\n",
      "23125/23125 [==============================] - 2s 75us/sample - loss: 0.6776 - accuracy: 0.8599 - val_loss: 1.0857 - val_accuracy: 0.8727\n",
      "Epoch 31/200\n",
      "23125/23125 [==============================] - 2s 71us/sample - loss: 0.6196 - accuracy: 0.8752 - val_loss: 1.0133 - val_accuracy: 0.8807\n",
      "Epoch 32/200\n",
      "23125/23125 [==============================] - 2s 71us/sample - loss: 0.6562 - accuracy: 0.8634 - val_loss: 0.8697 - val_accuracy: 0.8708\n",
      "Epoch 33/200\n",
      "23125/23125 [==============================] - 2s 73us/sample - loss: 0.5973 - accuracy: 0.8750 - val_loss: 0.9950 - val_accuracy: 0.8753\n",
      "Epoch 34/200\n",
      "23125/23125 [==============================] - 2s 73us/sample - loss: 0.5699 - accuracy: 0.8852 - val_loss: 0.9541 - val_accuracy: 0.8786\n",
      "Epoch 35/200\n",
      "23125/23125 [==============================] - 2s 71us/sample - loss: 0.5811 - accuracy: 0.8883 - val_loss: 1.2480 - val_accuracy: 0.8967\n",
      "Epoch 36/200\n",
      "23125/23125 [==============================] - 2s 70us/sample - loss: 0.6094 - accuracy: 0.8775 - val_loss: 0.9992 - val_accuracy: 0.8833\n",
      "Epoch 37/200\n",
      "23125/23125 [==============================] - 2s 80us/sample - loss: 0.5736 - accuracy: 0.8909 - val_loss: 1.0015 - val_accuracy: 0.8864\n",
      "Epoch 38/200\n",
      "23125/23125 [==============================] - 2s 77us/sample - loss: 0.5681 - accuracy: 0.8930 - val_loss: 0.8801 - val_accuracy: 0.8717\n",
      "Epoch 39/200\n",
      "23125/23125 [==============================] - 2s 77us/sample - loss: 0.5511 - accuracy: 0.8872 - val_loss: 1.2918 - val_accuracy: 0.8933\n",
      "Epoch 40/200\n",
      "23125/23125 [==============================] - 2s 74us/sample - loss: 0.5846 - accuracy: 0.8878 - val_loss: 1.0802 - val_accuracy: 0.8919\n",
      "Epoch 41/200\n",
      "23125/23125 [==============================] - 2s 83us/sample - loss: 0.5913 - accuracy: 0.8886 - val_loss: 0.7979 - val_accuracy: 0.8649\n",
      "Epoch 42/200\n",
      "23125/23125 [==============================] - 2s 72us/sample - loss: 0.5855 - accuracy: 0.8799 - val_loss: 0.9434 - val_accuracy: 0.8912\n",
      "Epoch 43/200\n",
      "23125/23125 [==============================] - 2s 71us/sample - loss: 0.5320 - accuracy: 0.8915 - val_loss: 1.4377 - val_accuracy: 0.8942\n",
      "Epoch 44/200\n",
      "23125/23125 [==============================] - 2s 70us/sample - loss: 0.5590 - accuracy: 0.8926 - val_loss: 1.2363 - val_accuracy: 0.8945\n",
      "Epoch 45/200\n",
      "23125/23125 [==============================] - 2s 85us/sample - loss: 0.5660 - accuracy: 0.8974 - val_loss: 0.9355 - val_accuracy: 0.8770\n",
      "train: \n",
      " [[13662  1921]\n",
      " [    0  7542]]\n",
      "test: \n",
      " [[3359  562]\n",
      " [  35 1826]]\n",
      "test:0.896749\n",
      "train:0.916930\n",
      "[0 0 0 ... 0 0 0]\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "acc:0.248125\n",
      "[[ 430    0]\n",
      " [1303    0]]\n",
      "0.24812463935372187\n",
      "Train on 23125 samples, validate on 5782 samples\n",
      "Epoch 1/200\n",
      "23125/23125 [==============================] - 2s 83us/sample - loss: 1.6699 - accuracy: 0.5641 - val_loss: 1.1863 - val_accuracy: 0.6956\n",
      "Epoch 2/200\n",
      "23125/23125 [==============================] - 2s 71us/sample - loss: 1.2186 - accuracy: 0.6931 - val_loss: 1.0834 - val_accuracy: 0.7371\n",
      "Epoch 3/200\n",
      "23125/23125 [==============================] - 2s 71us/sample - loss: 1.0666 - accuracy: 0.7425 - val_loss: 1.0060 - val_accuracy: 0.7791\n",
      "Epoch 4/200\n",
      "23125/23125 [==============================] - 2s 73us/sample - loss: 1.0038 - accuracy: 0.7606 - val_loss: 1.0101 - val_accuracy: 0.7757\n",
      "Epoch 5/200\n",
      "23125/23125 [==============================] - 2s 71us/sample - loss: 1.0121 - accuracy: 0.7549 - val_loss: 0.9530 - val_accuracy: 0.7598\n",
      "Epoch 6/200\n",
      "23125/23125 [==============================] - 2s 75us/sample - loss: 0.8796 - accuracy: 0.7876 - val_loss: 1.0161 - val_accuracy: 0.8279\n",
      "Epoch 7/200\n",
      "23125/23125 [==============================] - 2s 71us/sample - loss: 0.8478 - accuracy: 0.8073 - val_loss: 0.9871 - val_accuracy: 0.8248\n",
      "Epoch 8/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23125/23125 [==============================] - 2s 71us/sample - loss: 0.8517 - accuracy: 0.8045 - val_loss: 0.8904 - val_accuracy: 0.8210\n",
      "Epoch 9/200\n",
      "23125/23125 [==============================] - 2s 71us/sample - loss: 0.8091 - accuracy: 0.8131 - val_loss: 1.0212 - val_accuracy: 0.8426\n",
      "Epoch 10/200\n",
      "23125/23125 [==============================] - 2s 72us/sample - loss: 0.7750 - accuracy: 0.8260 - val_loss: 1.0699 - val_accuracy: 0.8438\n",
      "Epoch 11/200\n",
      "23125/23125 [==============================] - 2s 72us/sample - loss: 0.7591 - accuracy: 0.8365 - val_loss: 0.9963 - val_accuracy: 0.8513\n",
      "Epoch 12/200\n",
      "23125/23125 [==============================] - 2s 70us/sample - loss: 0.7071 - accuracy: 0.8416 - val_loss: 1.0759 - val_accuracy: 0.8464\n",
      "Epoch 13/200\n",
      "23125/23125 [==============================] - 2s 71us/sample - loss: 0.6955 - accuracy: 0.8444 - val_loss: 1.0100 - val_accuracy: 0.8442\n",
      "Epoch 14/200\n",
      "23125/23125 [==============================] - 2s 71us/sample - loss: 0.7017 - accuracy: 0.8478 - val_loss: 1.0484 - val_accuracy: 0.8539\n",
      "Epoch 15/200\n",
      "23125/23125 [==============================] - 2s 70us/sample - loss: 0.7070 - accuracy: 0.8503 - val_loss: 0.9769 - val_accuracy: 0.8648\n",
      "Epoch 16/200\n",
      "23125/23125 [==============================] - 2s 70us/sample - loss: 0.6993 - accuracy: 0.8527 - val_loss: 0.8596 - val_accuracy: 0.8388\n",
      "Epoch 17/200\n",
      "23125/23125 [==============================] - 2s 70us/sample - loss: 0.6776 - accuracy: 0.8485 - val_loss: 1.0544 - val_accuracy: 0.8644\n",
      "Epoch 18/200\n",
      "23125/23125 [==============================] - 2s 70us/sample - loss: 0.6821 - accuracy: 0.8598 - val_loss: 0.9780 - val_accuracy: 0.8658\n",
      "Epoch 19/200\n",
      "23125/23125 [==============================] - 2s 70us/sample - loss: 0.6573 - accuracy: 0.8584 - val_loss: 1.0270 - val_accuracy: 0.8687\n",
      "Epoch 20/200\n",
      "23125/23125 [==============================] - 2s 70us/sample - loss: 0.6057 - accuracy: 0.8704 - val_loss: 1.1063 - val_accuracy: 0.8692\n",
      "Epoch 21/200\n",
      "23125/23125 [==============================] - 2s 71us/sample - loss: 0.6138 - accuracy: 0.8713 - val_loss: 0.9826 - val_accuracy: 0.8469\n",
      "Epoch 22/200\n",
      "23125/23125 [==============================] - 2s 72us/sample - loss: 0.6390 - accuracy: 0.8652 - val_loss: 1.1678 - val_accuracy: 0.8756\n",
      "Epoch 23/200\n",
      "23125/23125 [==============================] - 2s 75us/sample - loss: 0.6374 - accuracy: 0.8704 - val_loss: 1.1649 - val_accuracy: 0.8637\n",
      "Epoch 24/200\n",
      "23125/23125 [==============================] - 2s 73us/sample - loss: 0.6625 - accuracy: 0.8615 - val_loss: 1.0139 - val_accuracy: 0.8644\n",
      "Epoch 25/200\n",
      "23125/23125 [==============================] - 2s 72us/sample - loss: 0.6115 - accuracy: 0.8678 - val_loss: 0.9688 - val_accuracy: 0.8634\n",
      "Epoch 26/200\n",
      "23125/23125 [==============================] - 2s 74us/sample - loss: 0.5845 - accuracy: 0.8767 - val_loss: 1.3254 - val_accuracy: 0.8826\n",
      "Epoch 27/200\n",
      "23125/23125 [==============================] - 2s 71us/sample - loss: 0.5496 - accuracy: 0.8895 - val_loss: 1.3573 - val_accuracy: 0.8796\n",
      "Epoch 28/200\n",
      "23125/23125 [==============================] - 2s 70us/sample - loss: 0.6670 - accuracy: 0.8630 - val_loss: 0.9269 - val_accuracy: 0.8490\n",
      "Epoch 29/200\n",
      "23125/23125 [==============================] - 2s 72us/sample - loss: 0.5767 - accuracy: 0.8770 - val_loss: 1.3259 - val_accuracy: 0.8819\n",
      "Epoch 30/200\n",
      "23125/23125 [==============================] - 2s 71us/sample - loss: 0.6089 - accuracy: 0.8846 - val_loss: 1.0698 - val_accuracy: 0.8691\n",
      "Epoch 31/200\n",
      "23125/23125 [==============================] - 2s 71us/sample - loss: 0.5645 - accuracy: 0.8845 - val_loss: 1.0752 - val_accuracy: 0.8822\n",
      "Epoch 32/200\n",
      "23125/23125 [==============================] - 2s 71us/sample - loss: 0.6610 - accuracy: 0.8730 - val_loss: 0.9069 - val_accuracy: 0.8675\n",
      "Epoch 33/200\n",
      "23125/23125 [==============================] - 2s 70us/sample - loss: 0.5818 - accuracy: 0.8803 - val_loss: 1.0766 - val_accuracy: 0.8833\n",
      "Epoch 34/200\n",
      "23125/23125 [==============================] - 2s 72us/sample - loss: 0.5978 - accuracy: 0.8772 - val_loss: 1.0967 - val_accuracy: 0.8841\n",
      "Epoch 35/200\n",
      "23125/23125 [==============================] - 2s 83us/sample - loss: 0.5508 - accuracy: 0.8896 - val_loss: 1.0682 - val_accuracy: 0.8744\n",
      "Epoch 36/200\n",
      "23125/23125 [==============================] - 2s 81us/sample - loss: 0.5556 - accuracy: 0.8859 - val_loss: 1.1288 - val_accuracy: 0.8796\n",
      "Epoch 37/200\n",
      "23125/23125 [==============================] - 2s 79us/sample - loss: 0.5555 - accuracy: 0.8897 - val_loss: 1.0734 - val_accuracy: 0.8862\n",
      "Epoch 38/200\n",
      "23125/23125 [==============================] - 2s 73us/sample - loss: 0.5966 - accuracy: 0.8803 - val_loss: 0.9272 - val_accuracy: 0.8686\n",
      "Epoch 39/200\n",
      "23125/23125 [==============================] - 2s 75us/sample - loss: 0.5482 - accuracy: 0.8869 - val_loss: 1.3462 - val_accuracy: 0.8966\n",
      "Epoch 40/200\n",
      "23125/23125 [==============================] - 2s 72us/sample - loss: 0.5505 - accuracy: 0.8925 - val_loss: 1.0365 - val_accuracy: 0.8893\n",
      "Epoch 41/200\n",
      "23125/23125 [==============================] - 2s 72us/sample - loss: 0.5973 - accuracy: 0.8802 - val_loss: 0.9774 - val_accuracy: 0.8852\n",
      "Epoch 42/200\n",
      "23125/23125 [==============================] - 2s 81us/sample - loss: 0.5678 - accuracy: 0.8853 - val_loss: 1.2457 - val_accuracy: 0.8910\n",
      "Epoch 43/200\n",
      "23125/23125 [==============================] - 2s 84us/sample - loss: 0.5707 - accuracy: 0.8997 - val_loss: 1.3619 - val_accuracy: 0.8935\n",
      "Epoch 44/200\n",
      "23125/23125 [==============================] - 2s 75us/sample - loss: 0.5471 - accuracy: 0.8922 - val_loss: 1.0956 - val_accuracy: 0.8872\n",
      "Epoch 45/200\n",
      "23125/23125 [==============================] - 2s 74us/sample - loss: 0.5946 - accuracy: 0.8762 - val_loss: 1.0329 - val_accuracy: 0.8777\n",
      "Epoch 46/200\n",
      "23125/23125 [==============================] - 2s 74us/sample - loss: 0.5659 - accuracy: 0.8837 - val_loss: 0.9916 - val_accuracy: 0.8812\n",
      "Epoch 47/200\n",
      "23125/23125 [==============================] - 2s 74us/sample - loss: 0.5310 - accuracy: 0.8933 - val_loss: 0.9934 - val_accuracy: 0.8860\n",
      "Epoch 48/200\n",
      "23125/23125 [==============================] - 2s 73us/sample - loss: 0.5431 - accuracy: 0.8881 - val_loss: 1.0694 - val_accuracy: 0.8884\n",
      "Epoch 49/200\n",
      "23125/23125 [==============================] - 2s 73us/sample - loss: 0.5159 - accuracy: 0.8993 - val_loss: 1.1309 - val_accuracy: 0.8942\n",
      "train: \n",
      " [[13597  1986]\n",
      " [    0  7542]]\n",
      "test: \n",
      " [[3361  560]\n",
      " [  38 1823]]\n",
      "test:0.896576\n",
      "train:0.914119\n",
      "[0 0 0 ... 0 0 0]\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "acc:0.248125\n",
      "[[ 430    0]\n",
      " [1303    0]]\n",
      "0.24812463935372187\n"
     ]
    }
   ],
   "source": [
    "acc={}\n",
    "cols = ['LEFT','RIGHT']\n",
    "\n",
    "#sc = StandardScaler(with_mean=True)\n",
    "\n",
    "for col in cols:\n",
    "    ind_temp=feature.columns.str.contains(col)\n",
    "    #feature_sc = sc.fit_transform(feature.loc[:,ind_temp])\n",
    "    #feature2_sc = sc.transform(feature2.loc[:,ind_temp])\n",
    "    train,test,sc = train_model(model,np.array(feature.loc[:,ind_temp]),np.array(y))\n",
    "    \n",
    "    acc_rest=test_model(model,np.array(feature2.loc[:,ind_temp]),np.array(y2),sc)\n",
    "    #acc[col] = [train,valid,test,acc_rest]\n",
    "    print(acc_rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_lr=pd.DataFrame(acc,index=['train','valid','test','rest data'])#.to_csv('./results/acc_lr_ann.csv')\n",
    "#acc_com=pd.concat([acc_ann_com.drop(['dnn','dnn1'],'index'),acc_lr.T])\n",
    "acc_com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test features from 2 of 8 signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test features from 2 of 8 signals\n",
    "\n",
    "acc_2f={}\n",
    "cols = [ 'LEFT_TA','LEFT_TS','LEFT_BF', 'LEFT_RF',\n",
    "        'RIGHT_TA','RIGHT_TS','RIGHT_BF', 'RIGHT_RF']\n",
    "\n",
    "\n",
    "for p in combinations(cols[:4],2):\n",
    "    ind_temp=feature.columns.str.contains(p[0])| feature.columns.str.contains(p[1])\n",
    "    #feature_sc = sc.fit_transform(feature.loc[:,ind_temp])\n",
    "    #feature2_sc = sc.transform(feature2.loc[:,ind_temp])\n",
    "    train,valid,test,sc = train_model(model,np.array(feature.loc[:,ind_temp]),np.array(y))\n",
    "    acc_rest=test_model(model,np.array(feature2.loc[:,ind_temp]),np.array(y2),sc)\n",
    "    acc_2f[p[0]+'_'+p[1]] = [train,valid,test,acc_rest]\n",
    "    print(acc_rest)\n",
    "    \n",
    "for p in combinations(cols[4:],2):\n",
    "    ind_temp=feature.columns.str.contains(p[0])| feature.columns.str.contains(p[1])\n",
    "    #feature_sc = sc.fit_transform(feature.loc[:,ind_temp])\n",
    "    #feature2_sc = sc.transform(feature2.loc[:,ind_temp])\n",
    "    train,valid,test,sc = train_model(model,np.array(feature.loc[:,ind_temp]),np.array(y))\n",
    "    acc_rest=test_model(model,np.array(feature2.loc[:,ind_temp]),np.array(y2),sc)\n",
    "    acc_2f[p[0]+'_'+p[1]] = [train,valid,test,acc_rest]\n",
    "    print(acc_rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acc_2f_ann = pd.DataFrame(acc_2f,index=['train','valid','test','rest data']).T\n",
    "#acc_com = pd.concat([acc_com,acc_2f_ann])\n",
    "acc_com.to_csv('./results/dropna/acc_com_ann.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(acc_2f,index=['train','valid','test','rest data']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on some of rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_of_rest = ['正常/P940_MSham_B_Walking_trial_6_emg.csv',\n",
    "                '正常/P940_M050_B_Walking_trial_4_emg.csv',\n",
    "                '正常/P812_M100_A_Walking_trial_3_emg.csv',\n",
    "                '正常/P645_M050_A_Walking_trial_3_emg.csv',\n",
    "                '正常/P623_Msham_B_Walking_trial_2_emg.csv',\n",
    "                '正常/P551_M50_B_Walking_trial_6_emg.csv',\n",
    "                'P379_M050_2_OFF_A_FoG_trial_1_emg.csv',\n",
    "                'P551_M050_2_B_FoG_trial_2_emg.csv']\n",
    "#booster = xgb.Booster()\n",
    "#booster.load_model('./model/XGBoost_W256_S64_Left.json')\n",
    "#model = xgb.XGBClassifier()\n",
    "#model._Booster = booster\n",
    "acc = []\n",
    "columns=['LEFT_TA','LEFT_TS','LEFT_BF', 'LEFT_RF']\n",
    "for file in some_of_rest:\n",
    "    path = './data/'+file\n",
    "    feature2,y2 = dp.pipeline_feature(path,width=256,stride=64,scaler=False,\n",
    "                                      threshold_WAMP=threshold_WAMP,\n",
    "                                      threshold_ZC=threshold_ZC,\n",
    "                                      threshold_SSC=threshold_SSC,\n",
    "                                      bins=bins,\n",
    "                                      ranges=HIST_range,\n",
    "                                      show_para=False,\n",
    "                                      filt = 250)\n",
    "    feature2_sc = sc.transform(feature2)\n",
    "    acc += [test_model(model,feature2_sc,y2)]\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(feature2_sc)\n",
    "metrics.accuracy_score(y2,y_pred>0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:1 (16583, 8)\n",
      "i:2 (4489, 8)\n",
      "i:3 (35121, 8)\n",
      "i:4 (31027, 8)\n",
      "i:5 (30783, 8)\n",
      "i:6 (159539, 8)\n",
      "i:7 (225455, 8)\n",
      "i:8 (362273, 8)\n",
      "i:9 (28868, 8)\n",
      "i:10 (20878, 8)\n",
      "i:11 (25322, 8)\n",
      "i:12 (24242, 8)\n",
      "i:13 (21728, 8)\n",
      "i:14 (27916, 8)\n",
      "i:15 (27146, 8)\n",
      "i:16 (25947, 8)\n",
      "i:17 (26203, 8)\n",
      "i:18 (89500, 8)\n",
      "i:19 (70282, 8)\n",
      "i:20 (79595, 8)\n",
      "i:21 (73280, 8)\n",
      "Duration: 4.539805\n"
     ]
    }
   ],
   "source": [
    "files = np.array(df.columns)\n",
    "X = []\n",
    "Y = []\n",
    "#sc = StandardScaler(with_mean=False)\n",
    "i = 0\n",
    "start = time.time()\n",
    "for file in files:\n",
    "    emg_data = pd.read_csv('./data/'+file)\n",
    "    #emg_data = emg_data.fillna({'LEFT_TA':emg_data.LEFT_TA.mean(),\n",
    "    #                            'LEFT_TS':emg_data.LEFT_TS.mean(),\n",
    "    #                            'LEFT_BF':emg_data.LEFT_BF.mean(),\n",
    "    #                            'LEFT_RF':emg_data.LEFT_RF.mean(),\n",
    "    #                            'RIGHT_TA':emg_data.RIGHT_TA.mean(),\n",
    "    #                            'RIGHT_TS':emg_data.RIGHT_TS.mean(),\n",
    "    #                            'RIGHT_BF':emg_data.RIGHT_BF.mean(),\n",
    "    #                            'RIGHT_RF':emg_data.RIGHT_RF.mean()})\n",
    "    #emg_data = emg_data[emg_data.Label1 == emg_data.Label2].reset_index(drop=True)\n",
    "    emg_data = emg_data.dropna().reset_index(drop=True)\n",
    "    x = np.array(emg_data.iloc[:,3:])\n",
    "    y = np.array(emg_data.Label2)\n",
    "    #x,y = dp.generate_window_slide_data(emg_data,width=width,stride=stride,scaler=False,same_label=True)\n",
    "    X += x.tolist()\n",
    "    Y += y.tolist()\n",
    "    i += 1\n",
    "    print('i:%d'%i,x.shape)\n",
    "end = time.time()\n",
    "duration = end-start\n",
    "print('Duration: %f'%(duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,feature,y,binary=True,file=None):\n",
    "    if binary:\n",
    "        ind = ((y==0)|(y==1)|(y==2)|(y==3)|(y==4)|(y==6))\n",
    "        ind1 = ((y==4)|(y==1)|(y==2)|(y==3)|(y==6))\n",
    "        y_01 = y.copy()\n",
    "        #ind1 = ((y_01==1)|(y_01==2)|(y_01==6))\n",
    "        y_01[ind1] = 1\n",
    "        oc = OneHotEncoder()\n",
    "        y_01 = oc.fit_transform(np.array(y_01)[:,np.newaxis]).toarray()\n",
    "        cw = None#{0:1,1:5}\n",
    "    else:\n",
    "        ind = ((y==1)|(y==2)|(y==6))\n",
    "        #ind = ((y==1)|(y==6))\n",
    "        y_01 = y[ind].copy()\n",
    "        oc = OneHotEncoder()\n",
    "        y_01 = oc.fit_transform(np.array(y_01)[:,np.newaxis]).toarray()\n",
    "        cw = None#{0:5,1:1,2:1}#{0:2,1:1,2:10,3:2}\n",
    "    x_full,x_test,y_full,y_test = train_test_split(np.array(feature)[ind,:],y_01,\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=123,\n",
    "                                                   shuffle=True)\n",
    "    x_train,x_valid,y_train,y_valid = train_test_split(x_full,y_full,\n",
    "                                                       test_size=0.25,\n",
    "                                                       random_state=555,\n",
    "                                                       shuffle=True)\n",
    "    \n",
    "    #sm = BorderlineSMOTE(random_state=50,kind='borderline-1')\n",
    "    #sm = SMOTE(random_state=50)\n",
    "    #print(y_full.shape)\n",
    "    #x_full,y_full = sm.fit_resample(x_full,y_full)\n",
    "    #print(y_full_n.shape)\n",
    "    x_full = np.reshape(x_full,(-1,128*8))\n",
    "    sc = StandardScaler(with_mean=False)\n",
    "    #sc = MinMaxScaler((0,1))\n",
    "    x_train = sc.fit_transform(x_full)\n",
    "    x_train = x_train.reshape((-1,128,8))\n",
    "    #pca = PCA(n_components=150)\n",
    "    #x_train = pca.fit_transform(x_train)\n",
    "    #x_valid = sc.transform(x_valid)\n",
    "    x_test = np.reshape(x_test,(-1,128*8))\n",
    "    x_test = sc.transform(x_test)\n",
    "    x_test = x_test.reshape((-1,128,8))\n",
    "    #x_test = pca.transform(x_test)\n",
    "    #x_train = x_full\n",
    "    \n",
    "    early_stopping = callbacks.EarlyStopping(patience = 10,\n",
    "                                             monitor = 'val_accuracy', \n",
    "                                             restore_best_weights=True)\n",
    "    history = model.fit(x_train,y_full,validation_data=[x_test,y_test],\n",
    "                        epochs=300,batch_size=500,class_weight=cw,\n",
    "                        callbacks=[early_stopping],\n",
    "                        shuffle=True)\n",
    "    \n",
    "    if binary:\n",
    "        y_pred_t=model.predict(x_test)\n",
    "        test = metrics.accuracy_score(np.argmax(y_test,axis=1),np.argmax(y_pred_t,axis=1))\n",
    "        #test = metrics.accuracy_score(y_test,y_pred_t>0.5)\n",
    "        \n",
    "        #y_pred_v=model.predict(x_valid)\n",
    "        #valid = metrics.accuracy_score(y_valid,np.argmax(y_pred_v,axis=1))\n",
    "        y_pred_ta=model.predict(x_train)\n",
    "        train = metrics.accuracy_score(np.argmax(y_full,axis=1),np.argmax(y_pred_ta,axis=1))\n",
    "        #train = metrics.accuracy_score(y_full,y_pred_ta>0.5)\n",
    "        \n",
    "        print('train: \\n',metrics.confusion_matrix(np.argmax(y_full,axis=1),np.argmax(y_pred_ta,axis=1)))\n",
    "        #print('valid: \\n',metrics.confusion_matrix(np.argmax(y_valid,axis=1),np.argmax(y_pred_v,axis=1)))\n",
    "        print('test: \\n',metrics.confusion_matrix(np.argmax(y_test,axis=1),np.argmax(y_pred_t,axis=1)))\n",
    "        \n",
    "        #print('train: \\n',metrics.confusion_matrix(y_full,y_pred_ta>0.5))\n",
    "        #print('test: \\n',metrics.confusion_matrix(y_test,y_pred_t>0.5))\n",
    "\n",
    "    else:\n",
    "        y_pred_t=model.predict(x_test)\n",
    "        test = metrics.accuracy_score(np.argmax(y_test,axis=1),np.argmax(y_pred_t,axis=1))\n",
    "        #y_pred_v=model.predict(x_valid)\n",
    "        #valid = metrics.accuracy_score(np.argmax(y_valid,axis=1),np.argmax(y_pred_v,axis=1))\n",
    "        y_pred_ta=model.predict(x_train)\n",
    "        train = metrics.accuracy_score(np.argmax(y_full,axis=1),np.argmax(y_pred_ta,axis=1))        \n",
    "        print('train: \\n',metrics.confusion_matrix(np.argmax(y_full,axis=1),np.argmax(y_pred_ta,axis=1)))\n",
    "        #print('valid: \\n',metrics.confusion_matrix(np.argmax(y_valid,axis=1),np.argmax(y_pred_v,axis=1)))\n",
    "        print('test: \\n',metrics.confusion_matrix(np.argmax(y_test,axis=1),np.argmax(y_pred_t,axis=1)))\n",
    "    print('test:%f'%test)\n",
    "    #print('valid:%f'%valid)\n",
    "    print('train:%f'%train)\n",
    "    if file != None:\n",
    "        model.save_model(file)\n",
    "    return train,test,sc#,pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_re = feature_sc.reshape((-1,X.shape[1],1))\n",
    "x_full,x_test,y_full,y_test = train_test_split(np.array(feature_re),np.array(y_01),test_size=0.2,random_state=123)\n",
    "x_train,x_valid,y_train,y_valid = train_test_split(x_full,y_full,test_size=0.2,random_state=555)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = layers.Input(shape=[128,8])\n",
    "lstm1 = layers.LSTM(50,return_sequences=True)(input_)\n",
    "drop1 = layers.Dropout(0.2)(lstm1)\n",
    "lstm2 = layers.LSTM(50,return_sequences=True)(drop1)\n",
    "drop2 = layers.Dropout(0.2)(lstm2)\n",
    "#lstm3 = layers.LSTM(50,return_sequences=True)(drop2)\n",
    "#drop3 = layers.Dropout(0.2)(lstm3)\n",
    "lstm4 = layers.LSTM(50)(drop2)\n",
    "drop4 = layers.Dropout(0.2)(lstm4)\n",
    "dense1 = layers.Dense(64,activation='relu')(drop4)\n",
    "drop5 = layers.Dropout(0.2)(dense1)\n",
    "dense2 = layers.Dense(32,activation='relu')(drop5)\n",
    "output = layers.Dense(3,activation='softmax')(dense2)\n",
    "model = Model(inputs=[input_],outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "early_stopping = callbacks.EarlyStopping(patience = 20,\n",
    "                                         monitor = 'val_accuracy', \n",
    "                                         restore_best_weights=True)\n",
    "history = model.fit(x_train,y_train,validation_data=[x_valid,y_valid],\n",
    "                    epochs=100,batch_size=500,\n",
    "                   callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8872 samples, validate on 2219 samples\n",
      "Epoch 1/300\n",
      "8872/8872 [==============================] - 88s 10ms/sample - loss: 0.9841 - accuracy: 0.4876 - val_loss: 0.8857 - val_accuracy: 0.5002\n",
      "Epoch 2/300\n",
      "8872/8872 [==============================] - 82s 9ms/sample - loss: 0.8572 - accuracy: 0.5571 - val_loss: 0.8288 - val_accuracy: 0.6471\n",
      "Epoch 3/300\n",
      "8872/8872 [==============================] - 81s 9ms/sample - loss: 0.8051 - accuracy: 0.6443 - val_loss: 0.7573 - val_accuracy: 0.6670\n",
      "Epoch 4/300\n",
      "8872/8872 [==============================] - 81s 9ms/sample - loss: 0.7433 - accuracy: 0.6677 - val_loss: 0.7142 - val_accuracy: 0.6791\n",
      "Epoch 5/300\n",
      "8872/8872 [==============================] - 81s 9ms/sample - loss: 0.7212 - accuracy: 0.6787 - val_loss: 0.6996 - val_accuracy: 0.6886\n",
      "Epoch 6/300\n",
      "8872/8872 [==============================] - 87s 10ms/sample - loss: 0.7071 - accuracy: 0.6878 - val_loss: 0.6952 - val_accuracy: 0.7008\n",
      "Epoch 7/300\n",
      "8872/8872 [==============================] - 81s 9ms/sample - loss: 0.6882 - accuracy: 0.6948 - val_loss: 0.6657 - val_accuracy: 0.7012\n",
      "Epoch 8/300\n",
      "8872/8872 [==============================] - 81s 9ms/sample - loss: 0.6646 - accuracy: 0.7073 - val_loss: 0.6449 - val_accuracy: 0.7265\n",
      "Epoch 9/300\n",
      "8872/8872 [==============================] - 84s 9ms/sample - loss: 0.6623 - accuracy: 0.7076 - val_loss: 0.6351 - val_accuracy: 0.7206\n",
      "Epoch 10/300\n",
      "8872/8872 [==============================] - 81s 9ms/sample - loss: 0.6435 - accuracy: 0.7187 - val_loss: 0.6351 - val_accuracy: 0.7274\n",
      "Epoch 11/300\n",
      "8872/8872 [==============================] - 85s 10ms/sample - loss: 0.6427 - accuracy: 0.7163 - val_loss: 0.6309 - val_accuracy: 0.7260\n",
      "Epoch 12/300\n",
      "8872/8872 [==============================] - 82s 9ms/sample - loss: 0.6384 - accuracy: 0.7187 - val_loss: 0.6255 - val_accuracy: 0.7256\n",
      "Epoch 13/300\n",
      "8872/8872 [==============================] - 87s 10ms/sample - loss: 0.6292 - accuracy: 0.7271 - val_loss: 0.6225 - val_accuracy: 0.7165\n",
      "Epoch 14/300\n",
      "8872/8872 [==============================] - 83s 9ms/sample - loss: 0.6213 - accuracy: 0.7299 - val_loss: 0.6190 - val_accuracy: 0.7210\n",
      "Epoch 15/300\n",
      "3000/8872 [=========>....................] - ETA: 57s - loss: 0.6155 - accuracy: 0.7276 WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-6c283b32f09c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-d3cca95f67ba>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, feature, y, binary, file)\u001b[0m\n\u001b[0;32m     50\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m                         \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m                         shuffle=True)\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    122\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 86\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    485\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1141\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train,test,sc = train_model(model,np.array(x),np.array(y),False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature2_re = feature2_sc.reshape((-1,feature.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(model,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_matrix=np.array([[0,1,1,1],\n",
    "                  [1,0,1,1],\n",
    "                  [10,100,0,10],\n",
    "                  [1.,1.,1,0]])\n",
    "cost_matrix=np.array([[0,2.],\n",
    "                  [5.,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "P0 = 55080/(55080+8181)\n",
    "P1 = 8181/(55080+8181)\n",
    "P = [P0,P1]\n",
    "cost_vec = np.zeros(2)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        if i == j:\n",
    "            continue\n",
    "        cost_vec[i]+=1/(1-P[i])*P[j]*cost_matrix[i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 5.])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1567100, shape=(4, 4), dtype=float64, numpy=\n",
       "array([[  0.,   1.,  10.,   1.],\n",
       "       [  1.,   0., 100.,   1.],\n",
       "       [  1.,   1.,   0.,   1.],\n",
       "       [  1.,   1.,  10.,   0.]])>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.transpose(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [2.],\n",
       "       [5.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape(cost_matrix,(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
