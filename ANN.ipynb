{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import data_processing as dp\n",
    "from scipy import signal\n",
    "from scipy.stats import skew\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "import os\n",
    "import time\n",
    "import h5py\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for dirname, _, filenames in os.walk('.\\data'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2 = '.\\data\\正常\\G11_Walking_trial_4_emg.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.read_csv('./processed data/dataframe_W500_S125_DWTLmax_samelabel_sc.csv')\n",
    "\n",
    "# read file name of data with various Labels\n",
    "df = pd.read_csv('./useful_data_label.csv',index_col=0) \n",
    "drop = 'G07_Freezing_Trial1_trial_1_emg.csv'\n",
    "drop2= 'P812_M050_2_B_FoG_trial_2_emg.csv'\n",
    "drop3= 'P812_M050_2_B_FoG_trial_1_emg.csv'\n",
    "ind_drop = (df.columns!=drop)# & (df.columns!=drop2) & (df.columns!=drop3)\n",
    "# read file name of data with only label 0\n",
    "df2 = pd.read_csv('./unuseful_data_label.csv',index_col=0)\n",
    "# read some of the data with only label 0\n",
    "df3 = pd.read_csv('./data/file_name.txt',header=None)\n",
    "\n",
    "files = np.concatenate([np.array(df.columns),np.array(df3.loc[:,0])])\n",
    "ind = Data.File.isin(files)\n",
    "ind2 = Data.File == drop\n",
    "#ind = (Data.File != drop) & (Data.File != drop2)\n",
    "Data_sel = Data[ind]\n",
    "Data_rest = Data[ind2]\n",
    "#ind2 = Data_rest.File == drop\n",
    "#Data_rest = Data_rest[ind2]\n",
    "#Data_rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_col = ['_IEMG','_MAV','_SSI','_VAR','_RMS',\n",
    "               '_WL','_ZC','_SSC','_WAMP','_skew','_Acti','_AR','_HIST','_MDF']\n",
    "\n",
    "feature_all = Data_sel.iloc[:,1:-1]\n",
    "#ind_temp1 = feature_all.columns.str.contains('_mDWT')\n",
    "#ind_temp2 = feature_all.columns.str.contains('_Coe')\n",
    "#ind_temp3 = feature_all.columns.str.contains('_Scale')\n",
    "#ind_temp4 = feature_all.columns.str.contains('_HIST')\n",
    "#ind_temp = ind_temp1|ind_temp2|ind_temp3|ind_temp4\n",
    "ind_temp = feature_all.columns.str.contains('_mDWT')\n",
    "feature = feature_all.loc[:,~ind_temp]\n",
    "#feature = Data_sel.iloc[:,1:-1]\n",
    "#feature = Data_sel.iloc[:,:-2]\n",
    "y = Data_sel.Label\n",
    "feature2_all = Data_rest.iloc[:,1:-1]\n",
    "#feature2 = feature2_all.loc[:,~ind_temp]\n",
    "feature2 = Data_rest.iloc[:,1:-1]\n",
    "#feature2 = Data_rest.iloc[:,:-2]\n",
    "y2 = Data_rest.Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = pd.DataFrame()\n",
    "feature2 = pd.DataFrame()\n",
    "y = pd.DataFrame()\n",
    "y2 = pd.DataFrame()\n",
    "m = 0\n",
    "for i in set(Data_sel.File):\n",
    "    ind = Data_sel.File==i\n",
    "    temp = Data_sel[ind]\n",
    "    for j in set(temp.Label):\n",
    "        ind2 = temp.Label == j\n",
    "        temp2 = temp[ind2]\n",
    "        l = len(temp2)\n",
    "        feature = pd.concat([feature,temp2.iloc[:int(0.8*l),1:-1]])\n",
    "        y = pd.concat([y,temp2.iloc[:int(0.8*l),0]])\n",
    "        feature2 = pd.concat([feature2,temp2.iloc[int(0.8*l):,1:-1]])\n",
    "        y2 = pd.concat([y2,temp2.iloc[int(0.8*l):,0]])\n",
    "y = np.array(y)[:,0]\n",
    "y2 = np.array(y2)[:,0]\n",
    "#ind_temp = feature.columns.str.contains('_mDWT')\n",
    "#feature = feature.loc[:,~ind_temp]\n",
    "#feature2 = feature2.loc[:,~ind_temp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LEFT_TA_IEMG</th>\n",
       "      <th>LEFT_TS_IEMG</th>\n",
       "      <th>LEFT_BF_IEMG</th>\n",
       "      <th>LEFT_RF_IEMG</th>\n",
       "      <th>RIGHT_TA_IEMG</th>\n",
       "      <th>RIGHT_TS_IEMG</th>\n",
       "      <th>RIGHT_BF_IEMG</th>\n",
       "      <th>RIGHT_RF_IEMG</th>\n",
       "      <th>LEFT_TA_SSI</th>\n",
       "      <th>LEFT_TS_SSI</th>\n",
       "      <th>...</th>\n",
       "      <th>RIGHT_BF_MDF</th>\n",
       "      <th>RIGHT_RF_MDF</th>\n",
       "      <th>LEFT_TA_MNF</th>\n",
       "      <th>LEFT_TS_MNF</th>\n",
       "      <th>LEFT_BF_MNF</th>\n",
       "      <th>LEFT_RF_MNF</th>\n",
       "      <th>RIGHT_TA_MNF</th>\n",
       "      <th>RIGHT_TS_MNF</th>\n",
       "      <th>RIGHT_BF_MNF</th>\n",
       "      <th>RIGHT_RF_MNF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13519</th>\n",
       "      <td>88.962654</td>\n",
       "      <td>77.34741</td>\n",
       "      <td>57.224567</td>\n",
       "      <td>62.383404</td>\n",
       "      <td>91.892540</td>\n",
       "      <td>47.207516</td>\n",
       "      <td>46.380474</td>\n",
       "      <td>68.208664</td>\n",
       "      <td>52.591140</td>\n",
       "      <td>36.242460</td>\n",
       "      <td>...</td>\n",
       "      <td>203.12500</td>\n",
       "      <td>70.31250</td>\n",
       "      <td>140.045230</td>\n",
       "      <td>181.662384</td>\n",
       "      <td>150.619937</td>\n",
       "      <td>137.972132</td>\n",
       "      <td>125.860405</td>\n",
       "      <td>236.136973</td>\n",
       "      <td>211.541490</td>\n",
       "      <td>136.647239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13520</th>\n",
       "      <td>86.452050</td>\n",
       "      <td>74.36432</td>\n",
       "      <td>60.487090</td>\n",
       "      <td>61.635277</td>\n",
       "      <td>94.097824</td>\n",
       "      <td>45.952827</td>\n",
       "      <td>42.839050</td>\n",
       "      <td>65.562744</td>\n",
       "      <td>51.380930</td>\n",
       "      <td>34.295430</td>\n",
       "      <td>...</td>\n",
       "      <td>171.87500</td>\n",
       "      <td>70.31250</td>\n",
       "      <td>138.435458</td>\n",
       "      <td>178.426941</td>\n",
       "      <td>110.770259</td>\n",
       "      <td>127.892318</td>\n",
       "      <td>117.876622</td>\n",
       "      <td>242.906437</td>\n",
       "      <td>203.716326</td>\n",
       "      <td>132.833129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13521</th>\n",
       "      <td>86.365220</td>\n",
       "      <td>71.03250</td>\n",
       "      <td>67.075970</td>\n",
       "      <td>58.983920</td>\n",
       "      <td>90.001495</td>\n",
       "      <td>44.022910</td>\n",
       "      <td>42.633220</td>\n",
       "      <td>65.724830</td>\n",
       "      <td>51.487750</td>\n",
       "      <td>32.098423</td>\n",
       "      <td>...</td>\n",
       "      <td>171.87500</td>\n",
       "      <td>66.40625</td>\n",
       "      <td>139.166098</td>\n",
       "      <td>168.600511</td>\n",
       "      <td>101.430259</td>\n",
       "      <td>120.203195</td>\n",
       "      <td>111.976777</td>\n",
       "      <td>237.209126</td>\n",
       "      <td>203.901220</td>\n",
       "      <td>127.235219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13522</th>\n",
       "      <td>95.490320</td>\n",
       "      <td>67.59361</td>\n",
       "      <td>67.169230</td>\n",
       "      <td>57.006170</td>\n",
       "      <td>85.765870</td>\n",
       "      <td>42.373833</td>\n",
       "      <td>39.899174</td>\n",
       "      <td>61.722763</td>\n",
       "      <td>60.989697</td>\n",
       "      <td>30.739939</td>\n",
       "      <td>...</td>\n",
       "      <td>160.15625</td>\n",
       "      <td>62.50000</td>\n",
       "      <td>143.463454</td>\n",
       "      <td>165.548731</td>\n",
       "      <td>103.543113</td>\n",
       "      <td>121.120256</td>\n",
       "      <td>117.630899</td>\n",
       "      <td>238.297868</td>\n",
       "      <td>195.087730</td>\n",
       "      <td>121.792518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13523</th>\n",
       "      <td>105.050766</td>\n",
       "      <td>64.81915</td>\n",
       "      <td>65.485150</td>\n",
       "      <td>55.373486</td>\n",
       "      <td>82.777890</td>\n",
       "      <td>41.133270</td>\n",
       "      <td>38.543266</td>\n",
       "      <td>57.451298</td>\n",
       "      <td>71.195755</td>\n",
       "      <td>29.257748</td>\n",
       "      <td>...</td>\n",
       "      <td>160.15625</td>\n",
       "      <td>66.40625</td>\n",
       "      <td>136.519421</td>\n",
       "      <td>163.331144</td>\n",
       "      <td>105.638626</td>\n",
       "      <td>121.109534</td>\n",
       "      <td>110.014394</td>\n",
       "      <td>228.041846</td>\n",
       "      <td>195.617437</td>\n",
       "      <td>130.177478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43250</th>\n",
       "      <td>64.833595</td>\n",
       "      <td>96.78418</td>\n",
       "      <td>48.135414</td>\n",
       "      <td>63.579323</td>\n",
       "      <td>59.692368</td>\n",
       "      <td>63.578720</td>\n",
       "      <td>69.708855</td>\n",
       "      <td>54.296165</td>\n",
       "      <td>30.981726</td>\n",
       "      <td>57.836420</td>\n",
       "      <td>...</td>\n",
       "      <td>74.21875</td>\n",
       "      <td>11.71875</td>\n",
       "      <td>120.817626</td>\n",
       "      <td>155.749876</td>\n",
       "      <td>130.621929</td>\n",
       "      <td>66.624950</td>\n",
       "      <td>117.651555</td>\n",
       "      <td>138.848233</td>\n",
       "      <td>94.909326</td>\n",
       "      <td>38.530130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43251</th>\n",
       "      <td>63.496452</td>\n",
       "      <td>94.05290</td>\n",
       "      <td>38.649220</td>\n",
       "      <td>70.976906</td>\n",
       "      <td>58.460938</td>\n",
       "      <td>64.411950</td>\n",
       "      <td>74.785120</td>\n",
       "      <td>56.792942</td>\n",
       "      <td>30.353344</td>\n",
       "      <td>56.520947</td>\n",
       "      <td>...</td>\n",
       "      <td>70.31250</td>\n",
       "      <td>11.71875</td>\n",
       "      <td>119.347708</td>\n",
       "      <td>156.292783</td>\n",
       "      <td>131.199122</td>\n",
       "      <td>61.517871</td>\n",
       "      <td>103.881146</td>\n",
       "      <td>139.020772</td>\n",
       "      <td>87.624188</td>\n",
       "      <td>40.055292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43252</th>\n",
       "      <td>61.259148</td>\n",
       "      <td>87.55627</td>\n",
       "      <td>35.732845</td>\n",
       "      <td>76.422750</td>\n",
       "      <td>54.117054</td>\n",
       "      <td>68.629220</td>\n",
       "      <td>79.662810</td>\n",
       "      <td>56.222706</td>\n",
       "      <td>28.747637</td>\n",
       "      <td>52.033546</td>\n",
       "      <td>...</td>\n",
       "      <td>70.31250</td>\n",
       "      <td>11.71875</td>\n",
       "      <td>114.577111</td>\n",
       "      <td>155.016133</td>\n",
       "      <td>127.824618</td>\n",
       "      <td>66.618924</td>\n",
       "      <td>123.716738</td>\n",
       "      <td>138.830209</td>\n",
       "      <td>86.537925</td>\n",
       "      <td>39.088569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43253</th>\n",
       "      <td>57.529190</td>\n",
       "      <td>84.12217</td>\n",
       "      <td>33.024437</td>\n",
       "      <td>80.876680</td>\n",
       "      <td>48.072784</td>\n",
       "      <td>71.334130</td>\n",
       "      <td>84.322530</td>\n",
       "      <td>57.591923</td>\n",
       "      <td>25.658537</td>\n",
       "      <td>50.555576</td>\n",
       "      <td>...</td>\n",
       "      <td>74.21875</td>\n",
       "      <td>11.71875</td>\n",
       "      <td>118.317610</td>\n",
       "      <td>155.892168</td>\n",
       "      <td>128.157184</td>\n",
       "      <td>66.951979</td>\n",
       "      <td>111.311017</td>\n",
       "      <td>139.915881</td>\n",
       "      <td>91.220167</td>\n",
       "      <td>39.460164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43254</th>\n",
       "      <td>57.858770</td>\n",
       "      <td>80.63014</td>\n",
       "      <td>31.593750</td>\n",
       "      <td>80.837380</td>\n",
       "      <td>40.844006</td>\n",
       "      <td>73.445076</td>\n",
       "      <td>89.229820</td>\n",
       "      <td>63.674923</td>\n",
       "      <td>26.014820</td>\n",
       "      <td>48.781387</td>\n",
       "      <td>...</td>\n",
       "      <td>74.21875</td>\n",
       "      <td>11.71875</td>\n",
       "      <td>109.348590</td>\n",
       "      <td>154.859902</td>\n",
       "      <td>130.926530</td>\n",
       "      <td>68.245859</td>\n",
       "      <td>117.506583</td>\n",
       "      <td>137.952209</td>\n",
       "      <td>95.536156</td>\n",
       "      <td>38.423203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51469 rows × 152 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LEFT_TA_IEMG  LEFT_TS_IEMG  LEFT_BF_IEMG  LEFT_RF_IEMG  RIGHT_TA_IEMG  \\\n",
       "13519     88.962654      77.34741     57.224567     62.383404      91.892540   \n",
       "13520     86.452050      74.36432     60.487090     61.635277      94.097824   \n",
       "13521     86.365220      71.03250     67.075970     58.983920      90.001495   \n",
       "13522     95.490320      67.59361     67.169230     57.006170      85.765870   \n",
       "13523    105.050766      64.81915     65.485150     55.373486      82.777890   \n",
       "...             ...           ...           ...           ...            ...   \n",
       "43250     64.833595      96.78418     48.135414     63.579323      59.692368   \n",
       "43251     63.496452      94.05290     38.649220     70.976906      58.460938   \n",
       "43252     61.259148      87.55627     35.732845     76.422750      54.117054   \n",
       "43253     57.529190      84.12217     33.024437     80.876680      48.072784   \n",
       "43254     57.858770      80.63014     31.593750     80.837380      40.844006   \n",
       "\n",
       "       RIGHT_TS_IEMG  RIGHT_BF_IEMG  RIGHT_RF_IEMG  LEFT_TA_SSI  LEFT_TS_SSI  \\\n",
       "13519      47.207516      46.380474      68.208664    52.591140    36.242460   \n",
       "13520      45.952827      42.839050      65.562744    51.380930    34.295430   \n",
       "13521      44.022910      42.633220      65.724830    51.487750    32.098423   \n",
       "13522      42.373833      39.899174      61.722763    60.989697    30.739939   \n",
       "13523      41.133270      38.543266      57.451298    71.195755    29.257748   \n",
       "...              ...            ...            ...          ...          ...   \n",
       "43250      63.578720      69.708855      54.296165    30.981726    57.836420   \n",
       "43251      64.411950      74.785120      56.792942    30.353344    56.520947   \n",
       "43252      68.629220      79.662810      56.222706    28.747637    52.033546   \n",
       "43253      71.334130      84.322530      57.591923    25.658537    50.555576   \n",
       "43254      73.445076      89.229820      63.674923    26.014820    48.781387   \n",
       "\n",
       "       ...  RIGHT_BF_MDF  RIGHT_RF_MDF  LEFT_TA_MNF  LEFT_TS_MNF  LEFT_BF_MNF  \\\n",
       "13519  ...     203.12500      70.31250   140.045230   181.662384   150.619937   \n",
       "13520  ...     171.87500      70.31250   138.435458   178.426941   110.770259   \n",
       "13521  ...     171.87500      66.40625   139.166098   168.600511   101.430259   \n",
       "13522  ...     160.15625      62.50000   143.463454   165.548731   103.543113   \n",
       "13523  ...     160.15625      66.40625   136.519421   163.331144   105.638626   \n",
       "...    ...           ...           ...          ...          ...          ...   \n",
       "43250  ...      74.21875      11.71875   120.817626   155.749876   130.621929   \n",
       "43251  ...      70.31250      11.71875   119.347708   156.292783   131.199122   \n",
       "43252  ...      70.31250      11.71875   114.577111   155.016133   127.824618   \n",
       "43253  ...      74.21875      11.71875   118.317610   155.892168   128.157184   \n",
       "43254  ...      74.21875      11.71875   109.348590   154.859902   130.926530   \n",
       "\n",
       "       LEFT_RF_MNF  RIGHT_TA_MNF  RIGHT_TS_MNF  RIGHT_BF_MNF  RIGHT_RF_MNF  \n",
       "13519   137.972132    125.860405    236.136973    211.541490    136.647239  \n",
       "13520   127.892318    117.876622    242.906437    203.716326    132.833129  \n",
       "13521   120.203195    111.976777    237.209126    203.901220    127.235219  \n",
       "13522   121.120256    117.630899    238.297868    195.087730    121.792518  \n",
       "13523   121.109534    110.014394    228.041846    195.617437    130.177478  \n",
       "...            ...           ...           ...           ...           ...  \n",
       "43250    66.624950    117.651555    138.848233     94.909326     38.530130  \n",
       "43251    61.517871    103.881146    139.020772     87.624188     40.055292  \n",
       "43252    66.618924    123.716738    138.830209     86.537925     39.088569  \n",
       "43253    66.951979    111.311017    139.915881     91.220167     39.460164  \n",
       "43254    68.245859    117.506583    137.952209     95.536156     38.423203  \n",
       "\n",
       "[51469 rows x 152 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './processed data/data_set_after_window_withoutSC.hdf5'\n",
    "with h5py.File(path,'r') as f:\n",
    "    x = f['cwt_data'][...]\n",
    "    y = f['label2'][...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0bf126e2acfb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mimp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'dp' is not defined"
     ]
    }
   ],
   "source": [
    "import imp\n",
    "imp.reload(dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ctypes\n",
    "player = ctypes.windll.kernel32\n",
    "player.Beep(1000,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Data_rest.File=='P812_M050_2_B_FoG_trial_1_emg.csv').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 256\n",
    "threshold_WAMP = 30\n",
    "threshold_ZC = 0\n",
    "threshold_SSC = 1\n",
    "bins=9\n",
    "bound = 70\n",
    "HIST_range = (-bound,bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = './processed data/data_set_after_window_W128_S64_sameLabel_rect.hdf5'\n",
    "with h5py.File(path,'r') as f:\n",
    "    x = f['data'][...]\n",
    "    y = f['label2'][...]\n",
    "#feature = dp.generate_feature(x,threshold_WAMP=threshold_WAMP,\n",
    "#                              threshold_ZC=threshold_ZC,\n",
    "#                              threshold_SSC=threshold_SSC,\n",
    "#                              bins=bins,ranges=HIST_range)\n",
    "#feature2 = dp.generate_feature(x2)\n",
    "player.Beep(1000,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('./processed data/nfeatures_W256_S64_WAMP30.hdf5','r') as f:\n",
    "    feature = f['features'][...]\n",
    "    y = f['labels'][...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature2,y2 = dp.pipeline_feature(path2,width=256,stride=64,\n",
    "                                  scaler=False,\n",
    "                                  threshold_WAMP=threshold_WAMP,\n",
    "                                  threshold_ZC=threshold_ZC,\n",
    "                                  threshold_SSC=threshold_SSC,\n",
    "                                  bins=bins,ranges=HIST_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('./processed data/nfeatures_rest_W256_S64.hdf5','r') as f:\n",
    "    feature2 = f['features'][...]\n",
    "    y2 = f['labels'][...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler(with_mean=True)\n",
    "feature_sc = sc.fit_transform(feature)\n",
    "feature2_sc = sc.transform(feature2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,Model,callbacks,regularizers,models\n",
    "from sklearn.model_selection import train_test_split,cross_validate\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import OneHotEncoder,normalize,MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE,BorderlineSMOTE,ADASYN,SVMSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,feature,y,binary=True,file=None):\n",
    "    if binary:\n",
    "        ind = ((y==0)|(y==1)|(y==2)|(y==6))\n",
    "        #ind1 = ((y==4)|(y==1)|(y==2)|(y==3)|(y==6))\n",
    "        y_01 = y[ind].copy()\n",
    "        ind1 = ((y_01==1)|(y_01==2)|(y_01==6))\n",
    "        y_01[ind1] = 1\n",
    "        oc = OneHotEncoder()\n",
    "        y_01 = oc.fit_transform(np.array(y_01)[:,np.newaxis]).toarray()\n",
    "        cw = None#{0:1,1:5}\n",
    "    else:\n",
    "        ind = ((y==1)|(y==2)|(y==6))\n",
    "        #ind = ((y==1)|(y==6))\n",
    "        y_01 = y[ind].copy()\n",
    "        oc = OneHotEncoder()\n",
    "        y_01 = oc.fit_transform(np.array(y_01)[:,np.newaxis]).toarray()\n",
    "        cw = None#{0:5,1:1,2:1}#{0:2,1:1,2:10,3:2}\n",
    "    x_full,x_test,y_full,y_test = train_test_split(np.array(feature)[ind,:],y_01,\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=123,\n",
    "                                                   shuffle=True)\n",
    "    x_train,x_valid,y_train,y_valid = train_test_split(x_full,y_full,\n",
    "                                                       test_size=0.25,\n",
    "                                                       random_state=555,\n",
    "                                                       shuffle=True)\n",
    "    \n",
    "    #sm = BorderlineSMOTE(random_state=50,kind='borderline-2')\n",
    "    #sm = SMOTE(random_state=50)\n",
    "    #print(y_full.shape)\n",
    "    #x_full,y_full = sm.fit_resample(x_full,y_full)\n",
    "    #print(y_full_n.shape)\n",
    "    sc = StandardScaler(with_mean=True)\n",
    "    #sc = MinMaxScaler()\n",
    "    x_train = sc.fit_transform(x_full)\n",
    "    pca = PCA(n_components=100)\n",
    "    #x_train = pca.fit_transform(x_train)\n",
    "    #x_valid = sc.transform(x_valid)\n",
    "    x_test = sc.transform(x_test)\n",
    "    #x_test = pca.transform(x_test)\n",
    "    #x_train = x_full\n",
    "    \n",
    "    early_stopping = callbacks.EarlyStopping(patience = 20,\n",
    "                                             monitor = 'val_loss', \n",
    "                                             restore_best_weights=True)\n",
    "    history = model.fit(x_train,y_full,validation_data=[x_test,y_test],\n",
    "                        epochs=100,batch_size=32,class_weight=cw,\n",
    "                        #callbacks=[early_stopping],\n",
    "                        shuffle=True)\n",
    "    \n",
    "    if binary:\n",
    "        y_pred_t=model.predict(x_test)\n",
    "        test = metrics.accuracy_score(np.argmax(y_test,axis=1),np.argmax(y_pred_t,axis=1))\n",
    "        #test = metrics.accuracy_score(y_test,y_pred_t>0.5)\n",
    "        \n",
    "        #y_pred_v=model.predict(x_valid)\n",
    "        #valid = metrics.accuracy_score(y_valid,np.argmax(y_pred_v,axis=1))\n",
    "        y_pred_ta=model.predict(x_train)\n",
    "        train = metrics.accuracy_score(np.argmax(y_full,axis=1),np.argmax(y_pred_ta,axis=1))\n",
    "        #train = metrics.accuracy_score(y_full,y_pred_ta>0.5)\n",
    "        \n",
    "        print('train: \\n',metrics.confusion_matrix(np.argmax(y_full,axis=1),np.argmax(y_pred_ta,axis=1)))\n",
    "        #print('valid: \\n',metrics.confusion_matrix(np.argmax(y_valid,axis=1),np.argmax(y_pred_v,axis=1)))\n",
    "        print('test: \\n',metrics.confusion_matrix(np.argmax(y_test,axis=1),np.argmax(y_pred_t,axis=1)))\n",
    "        \n",
    "        #print('train: \\n',metrics.confusion_matrix(y_full,y_pred_ta>0.5))\n",
    "        #print('test: \\n',metrics.confusion_matrix(y_test,y_pred_t>0.5))\n",
    "\n",
    "    else:\n",
    "        y_pred_t=model.predict(x_test)\n",
    "        test = metrics.accuracy_score(np.argmax(y_test,axis=1),np.argmax(y_pred_t,axis=1))\n",
    "        #y_pred_v=model.predict(x_valid)\n",
    "        #valid = metrics.accuracy_score(np.argmax(y_valid,axis=1),np.argmax(y_pred_v,axis=1))\n",
    "        y_pred_ta=model.predict(x_train)\n",
    "        train = metrics.accuracy_score(np.argmax(y_full,axis=1),np.argmax(y_pred_ta,axis=1))        \n",
    "        print('train: \\n',metrics.confusion_matrix(np.argmax(y_full,axis=1),np.argmax(y_pred_ta,axis=1)))\n",
    "        #print('valid: \\n',metrics.confusion_matrix(np.argmax(y_valid,axis=1),np.argmax(y_pred_v,axis=1)))\n",
    "        print('test: \\n',metrics.confusion_matrix(np.argmax(y_test,axis=1),np.argmax(y_pred_t,axis=1)))\n",
    "    print('test:%f'%test)\n",
    "    #print('valid:%f'%valid)\n",
    "    print('train:%f'%train)\n",
    "    if file != None:\n",
    "        model.save_model(file)\n",
    "    return train,test,sc,pca\n",
    "\n",
    "def test_model(model,feature,y,sc,pca,binary=True):\n",
    "    if binary:\n",
    "        ind = ((y==0)|(y==1)|(y==2)|(y==3)|(y==4)|(y==6))\n",
    "        #ind1 = ((y==4)|(y==1)|(y==2)|(y==3)|(y==6))\n",
    "        y_01 = y[ind].copy()\n",
    "        ind1 = ((y_01==1)|(y_01==2)|(y_01==6))\n",
    "        y_01[ind1] = 1\n",
    "        oc = OneHotEncoder()\n",
    "        y_01 = oc.fit_transform(np.array(y_01)[:,np.newaxis]).toarray()\n",
    "        cw = None#{0:1,1:5}\n",
    "    else:\n",
    "        ind = ((y==1)|(y==2)|(y==6))\n",
    "        #ind = ((y==1)|(y==6))\n",
    "        y_01 = y[ind].copy()\n",
    "        oc = OneHotEncoder()\n",
    "        y_01 = oc.fit_transform(np.array(y_01)[:,np.newaxis]).toarray()\n",
    "        cw = None#{0:5,1:1,2:1}#{0:2,1:1,2:10,3:2}\n",
    "\n",
    "    #print(y_01)\n",
    "    feature=sc.transform(feature[ind])\n",
    "    #feature = feature[ind]\n",
    "    #feature=pca.transform(feature)\n",
    "    y_pred=model.predict(feature)\n",
    "    test = metrics.accuracy_score(np.argmax(y_01,axis=1),np.argmax(y_pred,axis=1))\n",
    "    #test = metrics.accuracy_score(y_01,y_pred>0.5)\n",
    "    \n",
    "    print('acc:%f'%test)\n",
    "    print(metrics.confusion_matrix(np.argmax(y_01,axis=1),np.argmax(y_pred,axis=1)))\n",
    "    #print(metrics.confusion_matrix(y_01,y_pred>0.5))\n",
    "    return test\n",
    "\n",
    "def sparse_cost_sensitive_loss (y_true,y_pred):\n",
    "    #cost_matrix = tf.constant([[0,1.,1,1.],\n",
    "    #              [2,0,5,5],\n",
    "    #              [1,1,0,1],\n",
    "    #              [1.,2.,1,0]])\n",
    "    cost_matrix = tf.constant([[0,2.,2],\n",
    "                  [1,0,1],\n",
    "                  [1.0,1.,0]])\n",
    "    #cost_matrix = tf.constant([[0,1.],\n",
    "    #              [5.,0]])\n",
    "    batch_cost_matrix = tf.nn.embedding_lookup(cost_matrix, tf.argmax(y_true,axis=1))\n",
    "    eps = 1e-6\n",
    "    probability = tf.clip_by_value(y_pred, eps, 1-eps)\n",
    "    cost_values = tf.math.log(1-probability)*batch_cost_matrix\n",
    "    loss = tf.reduce_mean(-tf.reduce_sum(cost_values, axis=1))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = ((y==1)|(y==2)|(y==3)|(y==6))\n",
    "#ind = ((y==4)|(y==1)|(y==2)|(y==3)|(y==6))\n",
    "ind_f = [0,1,6,42,46,57,62]\n",
    "#y_01 = y[ind].copy()\n",
    "#y_01[y_01==1]=0\n",
    "#y_01[y_01==2]=1\n",
    "#y_01[y_01==3]=2\n",
    "#y_01[y_01==6]=3\n",
    "y_01 = y[ind].copy()\n",
    "#y_01[ind] = 1\n",
    "oh_ec = OneHotEncoder()\n",
    "y_oh = oh_ec.fit_transform(y_01[:,np.newaxis]).toarray()\n",
    "x_full,x_test,y_full,y_test = train_test_split(feature.loc[ind,:],y_01,test_size=0.2,random_state=123,shuffle=False)\n",
    "x_train,x_valid,y_train,y_valid = train_test_split(x_full,y_full,test_size=0.2,random_state=555,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = layers.Input(shape=feature.shape[1:])#feature.shape[1:]\n",
    "l1 = layers.Dense(128,activation='elu',\n",
    "                  #kernel_initializer='lecun_normal',\n",
    "                  #kernel_regularizer = regularizers.l2(0.001),\n",
    "                 )(input_)\n",
    "#drop1 = layers.Dropout(0.2)(l1)\n",
    "bn1 = layers.BatchNormalization()(l1)\n",
    "l2 = layers.Dense(64,activation='elu',\n",
    "                  #kernel_initializer='lecun_normal',\n",
    "                  #kernel_regularizer = regularizers.l2(0.001),\n",
    "                 )(bn1)\n",
    "#drop2 = layers.Dropout(0.2)(l2)\n",
    "bn2 = layers.BatchNormalization()(l2)\n",
    "l3 = layers.Dense(32,activation='elu',\n",
    "                  #kernel_initializer='lecun_normal',\n",
    "                  #kernel_regularizer = regularizers.l2(0.001),\n",
    "                 )(bn2)\n",
    "#drop3 = layers.Dropout(0.2)(l3)\n",
    "bn3 = layers.BatchNormalization()(l3)\n",
    "l4 = layers.Dense(16,activation='elu',\n",
    "                 #kernel_regularizer = regularizers.l2(0.001),\n",
    "                 )(bn3)\n",
    "#drop4 = layers.Dropout(0.2)(l4)\n",
    "#l5 = layers.Dense(8,activation='relu')(drop4)\n",
    "#drop5 = layers.Dropout(0.5)(l5)\n",
    "output = layers.Dense(3,activation='softmax')(l4)\n",
    "model = Model(inputs=[input_],outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "#model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(128,#activation='elu',\n",
    "                  #kernel_initializer='lecun_normal',\n",
    "                  #kernel_regularizer = regularizers.l2(0.001),\n",
    "                       #use_bias=False\n",
    "                 ))\n",
    "model.add(layers.Dropout(0.2))\n",
    "#model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('elu'))\n",
    "model.add(layers.Dense(64,#activation='elu',\n",
    "                  #kernel_initializer='lecun_normal',\n",
    "                  #kernel_regularizer = regularizers.l2(0.001),\n",
    "                      # use_bias=False\n",
    "                 ))\n",
    "model.add(layers.Dropout(0.2))\n",
    "#model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('elu'))\n",
    "model.add(layers.Dense(32,#activation='elu',\n",
    "                  #kernel_initializer='lecun_normal',\n",
    "                  #kernel_regularizer = regularizers.l2(0.001),\n",
    "                       #use_bias=False\n",
    "                 ))\n",
    "model.add(layers.Dropout(0.2))\n",
    "#model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('elu'))\n",
    "model.add(layers.Dense(16,#activation='elu',\n",
    "                 #kernel_regularizer = regularizers.l2(0.001),\n",
    "                       #use_bias=False\n",
    "                 ))\n",
    "model.add(layers.Dropout(0.2))\n",
    "#model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(3,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3476 samples, validate on 870 samples\n",
      "Epoch 1/100\n",
      "3476/3476 [==============================] - 1s 322us/sample - loss: 0.8823 - accuracy: 0.6326 - val_loss: 0.5863 - val_accuracy: 0.7471\n",
      "Epoch 2/100\n",
      "3476/3476 [==============================] - 0s 98us/sample - loss: 0.6698 - accuracy: 0.7149 - val_loss: 0.5494 - val_accuracy: 0.7644\n",
      "Epoch 3/100\n",
      "3476/3476 [==============================] - 0s 106us/sample - loss: 0.6204 - accuracy: 0.7394 - val_loss: 0.5271 - val_accuracy: 0.7632\n",
      "Epoch 4/100\n",
      "3476/3476 [==============================] - 0s 106us/sample - loss: 0.5882 - accuracy: 0.7546 - val_loss: 0.5018 - val_accuracy: 0.7874\n",
      "Epoch 5/100\n",
      "3476/3476 [==============================] - 0s 103us/sample - loss: 0.5541 - accuracy: 0.7762 - val_loss: 0.5198 - val_accuracy: 0.7759\n",
      "Epoch 6/100\n",
      "3476/3476 [==============================] - 0s 101us/sample - loss: 0.5145 - accuracy: 0.7886 - val_loss: 0.5212 - val_accuracy: 0.7851\n",
      "Epoch 7/100\n",
      "3476/3476 [==============================] - 0s 109us/sample - loss: 0.5067 - accuracy: 0.7839 - val_loss: 0.4924 - val_accuracy: 0.7885\n",
      "Epoch 8/100\n",
      "3476/3476 [==============================] - 0s 97us/sample - loss: 0.4787 - accuracy: 0.7917 - val_loss: 0.5004 - val_accuracy: 0.7862\n",
      "Epoch 9/100\n",
      "3476/3476 [==============================] - 0s 111us/sample - loss: 0.4738 - accuracy: 0.8003 - val_loss: 0.4862 - val_accuracy: 0.7920\n",
      "Epoch 10/100\n",
      "3476/3476 [==============================] - 0s 104us/sample - loss: 0.4439 - accuracy: 0.8139 - val_loss: 0.4780 - val_accuracy: 0.7954\n",
      "Epoch 11/100\n",
      "3476/3476 [==============================] - 0s 100us/sample - loss: 0.4384 - accuracy: 0.8173 - val_loss: 0.5041 - val_accuracy: 0.7793\n",
      "Epoch 12/100\n",
      "3476/3476 [==============================] - 0s 110us/sample - loss: 0.4014 - accuracy: 0.8236 - val_loss: 0.5473 - val_accuracy: 0.7931\n",
      "Epoch 13/100\n",
      "3476/3476 [==============================] - 0s 98us/sample - loss: 0.4102 - accuracy: 0.8294 - val_loss: 0.4978 - val_accuracy: 0.8103\n",
      "Epoch 14/100\n",
      "3476/3476 [==============================] - 0s 114us/sample - loss: 0.3888 - accuracy: 0.8334 - val_loss: 0.4994 - val_accuracy: 0.8023\n",
      "Epoch 15/100\n",
      "3476/3476 [==============================] - 0s 125us/sample - loss: 0.3712 - accuracy: 0.8392 - val_loss: 0.5493 - val_accuracy: 0.7966\n",
      "Epoch 16/100\n",
      "3476/3476 [==============================] - 0s 98us/sample - loss: 0.3720 - accuracy: 0.8406 - val_loss: 0.5291 - val_accuracy: 0.7931\n",
      "Epoch 17/100\n",
      "3476/3476 [==============================] - 0s 106us/sample - loss: 0.3469 - accuracy: 0.8533 - val_loss: 0.5214 - val_accuracy: 0.8115\n",
      "Epoch 18/100\n",
      "3476/3476 [==============================] - 0s 102us/sample - loss: 0.3282 - accuracy: 0.8631 - val_loss: 0.5333 - val_accuracy: 0.8011\n",
      "Epoch 19/100\n",
      "3476/3476 [==============================] - 0s 108us/sample - loss: 0.3217 - accuracy: 0.8688 - val_loss: 0.5572 - val_accuracy: 0.7966\n",
      "Epoch 20/100\n",
      "3476/3476 [==============================] - 0s 94us/sample - loss: 0.3232 - accuracy: 0.8654 - val_loss: 0.5716 - val_accuracy: 0.8046\n",
      "Epoch 21/100\n",
      "3476/3476 [==============================] - 0s 105us/sample - loss: 0.2979 - accuracy: 0.8751 - val_loss: 0.5570 - val_accuracy: 0.8092\n",
      "Epoch 22/100\n",
      "3476/3476 [==============================] - 0s 108us/sample - loss: 0.3092 - accuracy: 0.8757 - val_loss: 0.5408 - val_accuracy: 0.8092\n",
      "Epoch 23/100\n",
      "3476/3476 [==============================] - 0s 109us/sample - loss: 0.2948 - accuracy: 0.8772 - val_loss: 0.5679 - val_accuracy: 0.7989\n",
      "Epoch 24/100\n",
      "3476/3476 [==============================] - 0s 102us/sample - loss: 0.2611 - accuracy: 0.8947 - val_loss: 0.6264 - val_accuracy: 0.8115\n",
      "Epoch 25/100\n",
      "3476/3476 [==============================] - 0s 103us/sample - loss: 0.2689 - accuracy: 0.8861 - val_loss: 0.5965 - val_accuracy: 0.8069\n",
      "Epoch 26/100\n",
      "3476/3476 [==============================] - 0s 109us/sample - loss: 0.2594 - accuracy: 0.8933 - val_loss: 0.5875 - val_accuracy: 0.8069\n",
      "Epoch 27/100\n",
      "3476/3476 [==============================] - 0s 110us/sample - loss: 0.2459 - accuracy: 0.9028 - val_loss: 0.6127 - val_accuracy: 0.8034\n",
      "Epoch 28/100\n",
      "3476/3476 [==============================] - 0s 128us/sample - loss: 0.2356 - accuracy: 0.9051 - val_loss: 0.6084 - val_accuracy: 0.8092\n",
      "Epoch 29/100\n",
      "3476/3476 [==============================] - 0s 127us/sample - loss: 0.2399 - accuracy: 0.9071 - val_loss: 0.6121 - val_accuracy: 0.8103\n",
      "Epoch 30/100\n",
      "3476/3476 [==============================] - 0s 107us/sample - loss: 0.2343 - accuracy: 0.9048 - val_loss: 0.6368 - val_accuracy: 0.8000\n",
      "Epoch 31/100\n",
      "3476/3476 [==============================] - 0s 99us/sample - loss: 0.2228 - accuracy: 0.9088 - val_loss: 0.7840 - val_accuracy: 0.8034\n",
      "Epoch 32/100\n",
      "3476/3476 [==============================] - 0s 107us/sample - loss: 0.2127 - accuracy: 0.9183 - val_loss: 0.6382 - val_accuracy: 0.8115\n",
      "Epoch 33/100\n",
      "3476/3476 [==============================] - 0s 97us/sample - loss: 0.2174 - accuracy: 0.9117 - val_loss: 0.6889 - val_accuracy: 0.8276\n",
      "Epoch 34/100\n",
      "3476/3476 [==============================] - 0s 111us/sample - loss: 0.2044 - accuracy: 0.9180 - val_loss: 0.6421 - val_accuracy: 0.8276\n",
      "Epoch 35/100\n",
      "3476/3476 [==============================] - 0s 103us/sample - loss: 0.1859 - accuracy: 0.9318 - val_loss: 0.7339 - val_accuracy: 0.8149\n",
      "Epoch 36/100\n",
      "3476/3476 [==============================] - 0s 99us/sample - loss: 0.2012 - accuracy: 0.9258 - val_loss: 0.6788 - val_accuracy: 0.8080\n",
      "Epoch 37/100\n",
      "3476/3476 [==============================] - 0s 97us/sample - loss: 0.1927 - accuracy: 0.9252 - val_loss: 0.7049 - val_accuracy: 0.8126\n",
      "Epoch 38/100\n",
      "3476/3476 [==============================] - 0s 98us/sample - loss: 0.1914 - accuracy: 0.9246 - val_loss: 0.6968 - val_accuracy: 0.8092\n",
      "Epoch 39/100\n",
      "3476/3476 [==============================] - 0s 108us/sample - loss: 0.1567 - accuracy: 0.9350 - val_loss: 0.7399 - val_accuracy: 0.8230\n",
      "Epoch 40/100\n",
      "3476/3476 [==============================] - 0s 100us/sample - loss: 0.1767 - accuracy: 0.9324 - val_loss: 0.7206 - val_accuracy: 0.8069\n",
      "Epoch 41/100\n",
      "3476/3476 [==============================] - 0s 98us/sample - loss: 0.1646 - accuracy: 0.9356 - val_loss: 0.7499 - val_accuracy: 0.8126\n",
      "Epoch 42/100\n",
      "3476/3476 [==============================] - 0s 100us/sample - loss: 0.1551 - accuracy: 0.9379 - val_loss: 0.7291 - val_accuracy: 0.8230\n",
      "Epoch 43/100\n",
      "3476/3476 [==============================] - 0s 142us/sample - loss: 0.1584 - accuracy: 0.9396 - val_loss: 0.7502 - val_accuracy: 0.8138\n",
      "Epoch 44/100\n",
      "3476/3476 [==============================] - 0s 107us/sample - loss: 0.1533 - accuracy: 0.9393 - val_loss: 0.7110 - val_accuracy: 0.8241\n",
      "Epoch 45/100\n",
      "3476/3476 [==============================] - 0s 103us/sample - loss: 0.1457 - accuracy: 0.9410 - val_loss: 0.7385 - val_accuracy: 0.8184\n",
      "Epoch 46/100\n",
      "3476/3476 [==============================] - 0s 100us/sample - loss: 0.1400 - accuracy: 0.9485 - val_loss: 0.8101 - val_accuracy: 0.8276\n",
      "Epoch 47/100\n",
      "3476/3476 [==============================] - 0s 103us/sample - loss: 0.1417 - accuracy: 0.9497 - val_loss: 0.7461 - val_accuracy: 0.8276\n",
      "Epoch 48/100\n",
      "3476/3476 [==============================] - 0s 102us/sample - loss: 0.1299 - accuracy: 0.9488 - val_loss: 0.7866 - val_accuracy: 0.8161\n",
      "Epoch 49/100\n",
      "3476/3476 [==============================] - 0s 102us/sample - loss: 0.1515 - accuracy: 0.9442 - val_loss: 0.7603 - val_accuracy: 0.8230\n",
      "Epoch 50/100\n",
      "3476/3476 [==============================] - 0s 98us/sample - loss: 0.1338 - accuracy: 0.9462 - val_loss: 0.7688 - val_accuracy: 0.8287\n",
      "Epoch 51/100\n",
      "3476/3476 [==============================] - 0s 112us/sample - loss: 0.1270 - accuracy: 0.9508 - val_loss: 0.7953 - val_accuracy: 0.8218\n",
      "Epoch 52/100\n",
      "3476/3476 [==============================] - 0s 100us/sample - loss: 0.1236 - accuracy: 0.9597 - val_loss: 0.7276 - val_accuracy: 0.8345\n",
      "Epoch 53/100\n",
      "3476/3476 [==============================] - 0s 110us/sample - loss: 0.1295 - accuracy: 0.9505 - val_loss: 0.8282 - val_accuracy: 0.8230\n",
      "Epoch 54/100\n",
      "3476/3476 [==============================] - 0s 100us/sample - loss: 0.1155 - accuracy: 0.9609 - val_loss: 0.8263 - val_accuracy: 0.8195\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3476/3476 [==============================] - 0s 142us/sample - loss: 0.1112 - accuracy: 0.9568 - val_loss: 0.8716 - val_accuracy: 0.8115\n",
      "Epoch 56/100\n",
      "3476/3476 [==============================] - 0s 95us/sample - loss: 0.1251 - accuracy: 0.9548 - val_loss: 0.8833 - val_accuracy: 0.8126\n",
      "Epoch 57/100\n",
      "3476/3476 [==============================] - 0s 96us/sample - loss: 0.1228 - accuracy: 0.9534 - val_loss: 0.8004 - val_accuracy: 0.8218\n",
      "Epoch 58/100\n",
      "3476/3476 [==============================] - 0s 103us/sample - loss: 0.1122 - accuracy: 0.9583 - val_loss: 0.8635 - val_accuracy: 0.8195\n",
      "Epoch 59/100\n",
      "3476/3476 [==============================] - 0s 99us/sample - loss: 0.1187 - accuracy: 0.9574 - val_loss: 0.8567 - val_accuracy: 0.8138\n",
      "Epoch 60/100\n",
      "3476/3476 [==============================] - 0s 100us/sample - loss: 0.1076 - accuracy: 0.9594 - val_loss: 0.8144 - val_accuracy: 0.8218\n",
      "Epoch 61/100\n",
      "3476/3476 [==============================] - 0s 115us/sample - loss: 0.1049 - accuracy: 0.9606 - val_loss: 0.8785 - val_accuracy: 0.8149\n",
      "Epoch 62/100\n",
      "3476/3476 [==============================] - 0s 105us/sample - loss: 0.1090 - accuracy: 0.9589 - val_loss: 0.9112 - val_accuracy: 0.8218\n",
      "Epoch 63/100\n",
      "3476/3476 [==============================] - 0s 96us/sample - loss: 0.1059 - accuracy: 0.9635 - val_loss: 0.8259 - val_accuracy: 0.8276\n",
      "Epoch 64/100\n",
      "3476/3476 [==============================] - 0s 108us/sample - loss: 0.1033 - accuracy: 0.9606 - val_loss: 0.8588 - val_accuracy: 0.8138\n",
      "Epoch 65/100\n",
      "3476/3476 [==============================] - 0s 104us/sample - loss: 0.0796 - accuracy: 0.9715 - val_loss: 0.9770 - val_accuracy: 0.8161\n",
      "Epoch 66/100\n",
      "3476/3476 [==============================] - 0s 100us/sample - loss: 0.1097 - accuracy: 0.9589 - val_loss: 0.8979 - val_accuracy: 0.8287\n",
      "Epoch 67/100\n",
      "3476/3476 [==============================] - 0s 110us/sample - loss: 0.1145 - accuracy: 0.9566 - val_loss: 0.8987 - val_accuracy: 0.8207\n",
      "Epoch 68/100\n",
      "3476/3476 [==============================] - 0s 128us/sample - loss: 0.1025 - accuracy: 0.9635 - val_loss: 0.8516 - val_accuracy: 0.8230\n",
      "Epoch 69/100\n",
      "3476/3476 [==============================] - 0s 98us/sample - loss: 0.0852 - accuracy: 0.9704 - val_loss: 0.8886 - val_accuracy: 0.8207\n",
      "Epoch 70/100\n",
      "3476/3476 [==============================] - 0s 99us/sample - loss: 0.0948 - accuracy: 0.9643 - val_loss: 0.8935 - val_accuracy: 0.8276\n",
      "Epoch 71/100\n",
      "3476/3476 [==============================] - 0s 99us/sample - loss: 0.0876 - accuracy: 0.9661 - val_loss: 0.8731 - val_accuracy: 0.8264\n",
      "Epoch 72/100\n",
      "3476/3476 [==============================] - 0s 102us/sample - loss: 0.0977 - accuracy: 0.9661 - val_loss: 0.8790 - val_accuracy: 0.8264\n",
      "Epoch 73/100\n",
      "3476/3476 [==============================] - 0s 105us/sample - loss: 0.0887 - accuracy: 0.9658 - val_loss: 0.9273 - val_accuracy: 0.8218\n",
      "Epoch 74/100\n",
      "3476/3476 [==============================] - 0s 99us/sample - loss: 0.0770 - accuracy: 0.9727 - val_loss: 0.9102 - val_accuracy: 0.8276\n",
      "Epoch 75/100\n",
      "3476/3476 [==============================] - 0s 110us/sample - loss: 0.0820 - accuracy: 0.9735 - val_loss: 0.8761 - val_accuracy: 0.8333\n",
      "Epoch 76/100\n",
      "3476/3476 [==============================] - 0s 99us/sample - loss: 0.0704 - accuracy: 0.9744 - val_loss: 0.9374 - val_accuracy: 0.8264\n",
      "Epoch 77/100\n",
      "3476/3476 [==============================] - 0s 102us/sample - loss: 0.0735 - accuracy: 0.9755 - val_loss: 0.9090 - val_accuracy: 0.8276\n",
      "Epoch 78/100\n",
      "3476/3476 [==============================] - 0s 102us/sample - loss: 0.0695 - accuracy: 0.9755 - val_loss: 0.9388 - val_accuracy: 0.8299\n",
      "Epoch 79/100\n",
      "3476/3476 [==============================] - 0s 96us/sample - loss: 0.0913 - accuracy: 0.9684 - val_loss: 0.8934 - val_accuracy: 0.8333\n",
      "Epoch 80/100\n",
      "3476/3476 [==============================] - 0s 98us/sample - loss: 0.0668 - accuracy: 0.9767 - val_loss: 0.8907 - val_accuracy: 0.8356\n",
      "Epoch 81/100\n",
      "3476/3476 [==============================] - 0s 100us/sample - loss: 0.0676 - accuracy: 0.9767 - val_loss: 0.9587 - val_accuracy: 0.8402\n",
      "Epoch 82/100\n",
      "3476/3476 [==============================] - 0s 100us/sample - loss: 0.0794 - accuracy: 0.9747 - val_loss: 0.9418 - val_accuracy: 0.8287\n",
      "Epoch 83/100\n",
      "3476/3476 [==============================] - 0s 112us/sample - loss: 0.0849 - accuracy: 0.9678 - val_loss: 0.9038 - val_accuracy: 0.8241\n",
      "Epoch 84/100\n",
      "3476/3476 [==============================] - 0s 134us/sample - loss: 0.0761 - accuracy: 0.9718 - val_loss: 0.9019 - val_accuracy: 0.8287\n",
      "Epoch 85/100\n",
      "3476/3476 [==============================] - 0s 108us/sample - loss: 0.0757 - accuracy: 0.9707 - val_loss: 0.8853 - val_accuracy: 0.8414\n",
      "Epoch 86/100\n",
      "3476/3476 [==============================] - 0s 103us/sample - loss: 0.0779 - accuracy: 0.9747 - val_loss: 0.9487 - val_accuracy: 0.8333\n",
      "Epoch 87/100\n",
      "3476/3476 [==============================] - 0s 114us/sample - loss: 0.0594 - accuracy: 0.9807 - val_loss: 0.9895 - val_accuracy: 0.8310\n",
      "Epoch 88/100\n",
      "3476/3476 [==============================] - 0s 106us/sample - loss: 0.0752 - accuracy: 0.9732 - val_loss: 0.9428 - val_accuracy: 0.8368\n",
      "Epoch 89/100\n",
      "3476/3476 [==============================] - 0s 110us/sample - loss: 0.0623 - accuracy: 0.9761 - val_loss: 1.0179 - val_accuracy: 0.8218\n",
      "Epoch 90/100\n",
      "3476/3476 [==============================] - 0s 99us/sample - loss: 0.0749 - accuracy: 0.9747 - val_loss: 0.9152 - val_accuracy: 0.8264\n",
      "Epoch 91/100\n",
      "3476/3476 [==============================] - 0s 102us/sample - loss: 0.0635 - accuracy: 0.9773 - val_loss: 0.9595 - val_accuracy: 0.8299\n",
      "Epoch 92/100\n",
      "3476/3476 [==============================] - 0s 110us/sample - loss: 0.0601 - accuracy: 0.9781 - val_loss: 0.9746 - val_accuracy: 0.8391\n",
      "Epoch 93/100\n",
      "3476/3476 [==============================] - 0s 98us/sample - loss: 0.0697 - accuracy: 0.9744 - val_loss: 1.0807 - val_accuracy: 0.8161\n",
      "Epoch 94/100\n",
      "3476/3476 [==============================] - 0s 98us/sample - loss: 0.0770 - accuracy: 0.9738 - val_loss: 0.8577 - val_accuracy: 0.8299\n",
      "Epoch 95/100\n",
      "3476/3476 [==============================] - 0s 111us/sample - loss: 0.0670 - accuracy: 0.9753 - val_loss: 0.9444 - val_accuracy: 0.8287\n",
      "Epoch 96/100\n",
      "3476/3476 [==============================] - 0s 123us/sample - loss: 0.0641 - accuracy: 0.9790 - val_loss: 0.9712 - val_accuracy: 0.8253\n",
      "Epoch 97/100\n",
      "3476/3476 [==============================] - 0s 104us/sample - loss: 0.0632 - accuracy: 0.9778 - val_loss: 0.9523 - val_accuracy: 0.8299\n",
      "Epoch 98/100\n",
      "3476/3476 [==============================] - 0s 101us/sample - loss: 0.0729 - accuracy: 0.9724 - val_loss: 0.9998 - val_accuracy: 0.8333\n",
      "Epoch 99/100\n",
      "3476/3476 [==============================] - 0s 105us/sample - loss: 0.0690 - accuracy: 0.9793 - val_loss: 0.9242 - val_accuracy: 0.8310\n",
      "Epoch 100/100\n",
      "3476/3476 [==============================] - 0s 106us/sample - loss: 0.0565 - accuracy: 0.9793 - val_loss: 0.9731 - val_accuracy: 0.8299\n",
      "train: \n",
      " [[ 780    4    0]\n",
      " [   4 1749    2]\n",
      " [   0    0  937]]\n",
      "test: \n",
      " [[120  41  23]\n",
      " [ 27 374  21]\n",
      " [ 25  11 228]]\n",
      "test:0.829885\n",
      "train:0.997123\n"
     ]
    }
   ],
   "source": [
    "#sc = StandardScaler(with_mean=True)\n",
    "#feature_sc = sc.fit_transform(feature)\n",
    "#feature2_sc = sc.transform(feature2)\n",
    "#pca = PCA(n_components=160,copy=True)\n",
    "#feature_pca = pca.fit_transform(feature)\n",
    "#feature2_pca = pca.transform(feature2)\n",
    "train,test,sc,pca = train_model(model,feature,np.array(y),False)\n",
    "#rest = test_model(model,feature2,np.array(y2),sc)\n",
    "#acc = [train,valid,test,rest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:0.729167\n",
      "[[ 96  87  65]\n",
      " [ 51 470  34]\n",
      " [ 31  31 239]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7291666666666666"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(model,np.array(feature2),np.array(y2),sc,pca,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model/ann.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       ...,\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = np.array((y==0)|(y==1)|(y==2)|(y==6))\n",
    "#feature\n",
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_model(model,feature2_sc,np.array(y2))\n",
    "ind = ((y==1)|(y==2)|(y==6))\n",
    "y_01 = y[ind].copy()\n",
    "oc = OneHotEncoder()\n",
    "y_01 = oc.fit_transform(np.array(y_01)[:,np.newaxis]).toarray()\n",
    "pred=model.predict(feature_sc[ind,:])\n",
    "np.argmax(pred,axis=1)\n",
    "np.argmax(y_01,axis=1)\n",
    "metrics.confusion_matrix(np.argmax(y_01,axis=1),np.argmax(pred,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acc_ann = pd.DataFrame(acc,columns=['dnn1'],index=['train','valid','test','rest data'])\n",
    "#acc_ann_com=pd.concat([acc_ann_com,acc_ann.T])\n",
    "#acc_ann.loc['drop_mDWT',:]=[train,valid,test,rest]\n",
    "acc_ann_com.loc['dnn2',:]=acc\n",
    "acc_ann_com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test feature from Left or Right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = layers.Input(shape=feature.loc[:,ind_temp].shape[1:])\n",
    "l1 = layers.Dense(128,activation='elu')(input_)\n",
    "drop1 = layers.Dropout(0.2)(l1)\n",
    "l2 = layers.Dense(64,activation='elu')(drop1)\n",
    "drop2 = layers.Dropout(0.2)(l2)\n",
    "#l3 = layers.Dense(32,activation='elu')(drop2)\n",
    "#drop3 = layers.Dropout(0.2)(l3)\n",
    "#l4 = layers.Dense(16,activation='selu')(l3)\n",
    "#drop4 = layers.Dropout(0.2)(l4)\n",
    "output = layers.Dense(1,activation='sigmoid')(drop2)\n",
    "model = Model(inputs=[input_],outputs=[output])\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23125 samples, validate on 5782 samples\n",
      "Epoch 1/200\n",
      "23125/23125 [==============================] - 4s 167us/sample - loss: 1.9657 - accuracy: 0.5308 - val_loss: 1.3537 - val_accuracy: 0.6404\n",
      "Epoch 2/200\n",
      "23125/23125 [==============================] - 3s 109us/sample - loss: 1.3913 - accuracy: 0.6479 - val_loss: 1.1555 - val_accuracy: 0.7008\n",
      "Epoch 3/200\n",
      "23125/23125 [==============================] - 3s 110us/sample - loss: 1.2045 - accuracy: 0.7052 - val_loss: 1.0439 - val_accuracy: 0.7771\n",
      "Epoch 4/200\n",
      "23125/23125 [==============================] - 2s 105us/sample - loss: 1.1076 - accuracy: 0.7394 - val_loss: 0.9467 - val_accuracy: 0.7608\n",
      "Epoch 5/200\n",
      "23125/23125 [==============================] - 2s 86us/sample - loss: 1.0526 - accuracy: 0.7501 - val_loss: 0.9212 - val_accuracy: 0.7508\n",
      "Epoch 6/200\n",
      "23125/23125 [==============================] - 2s 93us/sample - loss: 0.9990 - accuracy: 0.7677 - val_loss: 0.8937 - val_accuracy: 0.7975\n",
      "Epoch 7/200\n",
      "23125/23125 [==============================] - 2s 98us/sample - loss: 0.9561 - accuracy: 0.7806 - val_loss: 0.8888 - val_accuracy: 0.7916\n",
      "Epoch 8/200\n",
      "23125/23125 [==============================] - 2s 85us/sample - loss: 0.9064 - accuracy: 0.8004 - val_loss: 0.8675 - val_accuracy: 0.8127\n",
      "Epoch 9/200\n",
      "23125/23125 [==============================] - 2s 96us/sample - loss: 0.8361 - accuracy: 0.8109 - val_loss: 0.9959 - val_accuracy: 0.8388\n",
      "Epoch 10/200\n",
      "23125/23125 [==============================] - 2s 91us/sample - loss: 0.8394 - accuracy: 0.8178 - val_loss: 0.8477 - val_accuracy: 0.8080\n",
      "Epoch 11/200\n",
      "23125/23125 [==============================] - 2s 89us/sample - loss: 0.8182 - accuracy: 0.8169 - val_loss: 0.8487 - val_accuracy: 0.8193\n",
      "Epoch 12/200\n",
      "23125/23125 [==============================] - 2s 87us/sample - loss: 0.7716 - accuracy: 0.8304 - val_loss: 1.0611 - val_accuracy: 0.8345\n",
      "Epoch 13/200\n",
      "23125/23125 [==============================] - 2s 87us/sample - loss: 0.8293 - accuracy: 0.8183 - val_loss: 0.9155 - val_accuracy: 0.8390\n",
      "Epoch 14/200\n",
      "23125/23125 [==============================] - 2s 82us/sample - loss: 0.8102 - accuracy: 0.8220 - val_loss: 0.8263 - val_accuracy: 0.8255\n",
      "Epoch 15/200\n",
      "23125/23125 [==============================] - 2s 82us/sample - loss: 0.7460 - accuracy: 0.8396 - val_loss: 0.7475 - val_accuracy: 0.8295\n",
      "Epoch 16/200\n",
      "23125/23125 [==============================] - 3s 109us/sample - loss: 0.7118 - accuracy: 0.8471 - val_loss: 0.8684 - val_accuracy: 0.8412\n",
      "Epoch 17/200\n",
      "23125/23125 [==============================] - 3s 135us/sample - loss: 0.7334 - accuracy: 0.8410 - val_loss: 0.8593 - val_accuracy: 0.8258\n",
      "Epoch 18/200\n",
      "23125/23125 [==============================] - 3s 125us/sample - loss: 0.7021 - accuracy: 0.8490 - val_loss: 0.8953 - val_accuracy: 0.8506\n",
      "Epoch 19/200\n",
      "23125/23125 [==============================] - 3s 121us/sample - loss: 0.6847 - accuracy: 0.8514 - val_loss: 0.9428 - val_accuracy: 0.8566\n",
      "Epoch 20/200\n",
      "23125/23125 [==============================] - 3s 133us/sample - loss: 0.7248 - accuracy: 0.8508 - val_loss: 0.9025 - val_accuracy: 0.8392\n",
      "Epoch 21/200\n",
      "23125/23125 [==============================] - 3s 118us/sample - loss: 0.7017 - accuracy: 0.8458 - val_loss: 0.8396 - val_accuracy: 0.8525\n",
      "Epoch 22/200\n",
      "23125/23125 [==============================] - 3s 110us/sample - loss: 0.6808 - accuracy: 0.8589 - val_loss: 0.8343 - val_accuracy: 0.8454\n",
      "Epoch 23/200\n",
      "23125/23125 [==============================] - 3s 111us/sample - loss: 0.6569 - accuracy: 0.8586 - val_loss: 0.9713 - val_accuracy: 0.8646\n",
      "Epoch 24/200\n",
      "23125/23125 [==============================] - 2s 91us/sample - loss: 0.7113 - accuracy: 0.8530 - val_loss: 0.9063 - val_accuracy: 0.8663\n",
      "Epoch 25/200\n",
      "23125/23125 [==============================] - 2s 87us/sample - loss: 0.6886 - accuracy: 0.8540 - val_loss: 1.0114 - val_accuracy: 0.8729\n",
      "Epoch 26/200\n",
      "23125/23125 [==============================] - 2s 83us/sample - loss: 0.6437 - accuracy: 0.8703 - val_loss: 1.0360 - val_accuracy: 0.8737\n",
      "Epoch 27/200\n",
      "23125/23125 [==============================] - 2s 82us/sample - loss: 0.6396 - accuracy: 0.8684 - val_loss: 1.0674 - val_accuracy: 0.8762\n",
      "Epoch 28/200\n",
      "23125/23125 [==============================] - 2s 87us/sample - loss: 0.5848 - accuracy: 0.8806 - val_loss: 1.3498 - val_accuracy: 0.8853\n",
      "Epoch 29/200\n",
      "23125/23125 [==============================] - 2s 79us/sample - loss: 0.6586 - accuracy: 0.8602 - val_loss: 0.9367 - val_accuracy: 0.8565\n",
      "Epoch 30/200\n",
      "23125/23125 [==============================] - 2s 75us/sample - loss: 0.6776 - accuracy: 0.8599 - val_loss: 1.0857 - val_accuracy: 0.8727\n",
      "Epoch 31/200\n",
      "23125/23125 [==============================] - 2s 71us/sample - loss: 0.6196 - accuracy: 0.8752 - val_loss: 1.0133 - val_accuracy: 0.8807\n",
      "Epoch 32/200\n",
      "23125/23125 [==============================] - 2s 71us/sample - loss: 0.6562 - accuracy: 0.8634 - val_loss: 0.8697 - val_accuracy: 0.8708\n",
      "Epoch 33/200\n",
      "23125/23125 [==============================] - 2s 73us/sample - loss: 0.5973 - accuracy: 0.8750 - val_loss: 0.9950 - val_accuracy: 0.8753\n",
      "Epoch 34/200\n",
      "23125/23125 [==============================] - 2s 73us/sample - loss: 0.5699 - accuracy: 0.8852 - val_loss: 0.9541 - val_accuracy: 0.8786\n",
      "Epoch 35/200\n",
      "23125/23125 [==============================] - 2s 71us/sample - loss: 0.5811 - accuracy: 0.8883 - val_loss: 1.2480 - val_accuracy: 0.8967\n",
      "Epoch 36/200\n",
      "23125/23125 [==============================] - 2s 70us/sample - loss: 0.6094 - accuracy: 0.8775 - val_loss: 0.9992 - val_accuracy: 0.8833\n",
      "Epoch 37/200\n",
      "23125/23125 [==============================] - 2s 80us/sample - loss: 0.5736 - accuracy: 0.8909 - val_loss: 1.0015 - val_accuracy: 0.8864\n",
      "Epoch 38/200\n",
      "23125/23125 [==============================] - 2s 77us/sample - loss: 0.5681 - accuracy: 0.8930 - val_loss: 0.8801 - val_accuracy: 0.8717\n",
      "Epoch 39/200\n",
      "23125/23125 [==============================] - 2s 77us/sample - loss: 0.5511 - accuracy: 0.8872 - val_loss: 1.2918 - val_accuracy: 0.8933\n",
      "Epoch 40/200\n",
      "23125/23125 [==============================] - 2s 74us/sample - loss: 0.5846 - accuracy: 0.8878 - val_loss: 1.0802 - val_accuracy: 0.8919\n",
      "Epoch 41/200\n",
      "23125/23125 [==============================] - 2s 83us/sample - loss: 0.5913 - accuracy: 0.8886 - val_loss: 0.7979 - val_accuracy: 0.8649\n",
      "Epoch 42/200\n",
      "23125/23125 [==============================] - 2s 72us/sample - loss: 0.5855 - accuracy: 0.8799 - val_loss: 0.9434 - val_accuracy: 0.8912\n",
      "Epoch 43/200\n",
      "23125/23125 [==============================] - 2s 71us/sample - loss: 0.5320 - accuracy: 0.8915 - val_loss: 1.4377 - val_accuracy: 0.8942\n",
      "Epoch 44/200\n",
      "23125/23125 [==============================] - 2s 70us/sample - loss: 0.5590 - accuracy: 0.8926 - val_loss: 1.2363 - val_accuracy: 0.8945\n",
      "Epoch 45/200\n",
      "23125/23125 [==============================] - 2s 85us/sample - loss: 0.5660 - accuracy: 0.8974 - val_loss: 0.9355 - val_accuracy: 0.8770\n",
      "train: \n",
      " [[13662  1921]\n",
      " [    0  7542]]\n",
      "test: \n",
      " [[3359  562]\n",
      " [  35 1826]]\n",
      "test:0.896749\n",
      "train:0.916930\n",
      "[0 0 0 ... 0 0 0]\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "acc:0.248125\n",
      "[[ 430    0]\n",
      " [1303    0]]\n",
      "0.24812463935372187\n",
      "Train on 23125 samples, validate on 5782 samples\n",
      "Epoch 1/200\n",
      "23125/23125 [==============================] - 2s 83us/sample - loss: 1.6699 - accuracy: 0.5641 - val_loss: 1.1863 - val_accuracy: 0.6956\n",
      "Epoch 2/200\n",
      "23125/23125 [==============================] - 2s 71us/sample - loss: 1.2186 - accuracy: 0.6931 - val_loss: 1.0834 - val_accuracy: 0.7371\n",
      "Epoch 3/200\n",
      "23125/23125 [==============================] - 2s 71us/sample - loss: 1.0666 - accuracy: 0.7425 - val_loss: 1.0060 - val_accuracy: 0.7791\n",
      "Epoch 4/200\n",
      "23125/23125 [==============================] - 2s 73us/sample - loss: 1.0038 - accuracy: 0.7606 - val_loss: 1.0101 - val_accuracy: 0.7757\n",
      "Epoch 5/200\n",
      "23125/23125 [==============================] - 2s 71us/sample - loss: 1.0121 - accuracy: 0.7549 - val_loss: 0.9530 - val_accuracy: 0.7598\n",
      "Epoch 6/200\n",
      "23125/23125 [==============================] - 2s 75us/sample - loss: 0.8796 - accuracy: 0.7876 - val_loss: 1.0161 - val_accuracy: 0.8279\n",
      "Epoch 7/200\n",
      "23125/23125 [==============================] - 2s 71us/sample - loss: 0.8478 - accuracy: 0.8073 - val_loss: 0.9871 - val_accuracy: 0.8248\n",
      "Epoch 8/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23125/23125 [==============================] - 2s 71us/sample - loss: 0.8517 - accuracy: 0.8045 - val_loss: 0.8904 - val_accuracy: 0.8210\n",
      "Epoch 9/200\n",
      "23125/23125 [==============================] - 2s 71us/sample - loss: 0.8091 - accuracy: 0.8131 - val_loss: 1.0212 - val_accuracy: 0.8426\n",
      "Epoch 10/200\n",
      "23125/23125 [==============================] - 2s 72us/sample - loss: 0.7750 - accuracy: 0.8260 - val_loss: 1.0699 - val_accuracy: 0.8438\n",
      "Epoch 11/200\n",
      "23125/23125 [==============================] - 2s 72us/sample - loss: 0.7591 - accuracy: 0.8365 - val_loss: 0.9963 - val_accuracy: 0.8513\n",
      "Epoch 12/200\n",
      "23125/23125 [==============================] - 2s 70us/sample - loss: 0.7071 - accuracy: 0.8416 - val_loss: 1.0759 - val_accuracy: 0.8464\n",
      "Epoch 13/200\n",
      "23125/23125 [==============================] - 2s 71us/sample - loss: 0.6955 - accuracy: 0.8444 - val_loss: 1.0100 - val_accuracy: 0.8442\n",
      "Epoch 14/200\n",
      "23125/23125 [==============================] - 2s 71us/sample - loss: 0.7017 - accuracy: 0.8478 - val_loss: 1.0484 - val_accuracy: 0.8539\n",
      "Epoch 15/200\n",
      "23125/23125 [==============================] - 2s 70us/sample - loss: 0.7070 - accuracy: 0.8503 - val_loss: 0.9769 - val_accuracy: 0.8648\n",
      "Epoch 16/200\n",
      "23125/23125 [==============================] - 2s 70us/sample - loss: 0.6993 - accuracy: 0.8527 - val_loss: 0.8596 - val_accuracy: 0.8388\n",
      "Epoch 17/200\n",
      "23125/23125 [==============================] - 2s 70us/sample - loss: 0.6776 - accuracy: 0.8485 - val_loss: 1.0544 - val_accuracy: 0.8644\n",
      "Epoch 18/200\n",
      "23125/23125 [==============================] - 2s 70us/sample - loss: 0.6821 - accuracy: 0.8598 - val_loss: 0.9780 - val_accuracy: 0.8658\n",
      "Epoch 19/200\n",
      "23125/23125 [==============================] - 2s 70us/sample - loss: 0.6573 - accuracy: 0.8584 - val_loss: 1.0270 - val_accuracy: 0.8687\n",
      "Epoch 20/200\n",
      "23125/23125 [==============================] - 2s 70us/sample - loss: 0.6057 - accuracy: 0.8704 - val_loss: 1.1063 - val_accuracy: 0.8692\n",
      "Epoch 21/200\n",
      "23125/23125 [==============================] - 2s 71us/sample - loss: 0.6138 - accuracy: 0.8713 - val_loss: 0.9826 - val_accuracy: 0.8469\n",
      "Epoch 22/200\n",
      "23125/23125 [==============================] - 2s 72us/sample - loss: 0.6390 - accuracy: 0.8652 - val_loss: 1.1678 - val_accuracy: 0.8756\n",
      "Epoch 23/200\n",
      "23125/23125 [==============================] - 2s 75us/sample - loss: 0.6374 - accuracy: 0.8704 - val_loss: 1.1649 - val_accuracy: 0.8637\n",
      "Epoch 24/200\n",
      "23125/23125 [==============================] - 2s 73us/sample - loss: 0.6625 - accuracy: 0.8615 - val_loss: 1.0139 - val_accuracy: 0.8644\n",
      "Epoch 25/200\n",
      "23125/23125 [==============================] - 2s 72us/sample - loss: 0.6115 - accuracy: 0.8678 - val_loss: 0.9688 - val_accuracy: 0.8634\n",
      "Epoch 26/200\n",
      "23125/23125 [==============================] - 2s 74us/sample - loss: 0.5845 - accuracy: 0.8767 - val_loss: 1.3254 - val_accuracy: 0.8826\n",
      "Epoch 27/200\n",
      "23125/23125 [==============================] - 2s 71us/sample - loss: 0.5496 - accuracy: 0.8895 - val_loss: 1.3573 - val_accuracy: 0.8796\n",
      "Epoch 28/200\n",
      "23125/23125 [==============================] - 2s 70us/sample - loss: 0.6670 - accuracy: 0.8630 - val_loss: 0.9269 - val_accuracy: 0.8490\n",
      "Epoch 29/200\n",
      "23125/23125 [==============================] - 2s 72us/sample - loss: 0.5767 - accuracy: 0.8770 - val_loss: 1.3259 - val_accuracy: 0.8819\n",
      "Epoch 30/200\n",
      "23125/23125 [==============================] - 2s 71us/sample - loss: 0.6089 - accuracy: 0.8846 - val_loss: 1.0698 - val_accuracy: 0.8691\n",
      "Epoch 31/200\n",
      "23125/23125 [==============================] - 2s 71us/sample - loss: 0.5645 - accuracy: 0.8845 - val_loss: 1.0752 - val_accuracy: 0.8822\n",
      "Epoch 32/200\n",
      "23125/23125 [==============================] - 2s 71us/sample - loss: 0.6610 - accuracy: 0.8730 - val_loss: 0.9069 - val_accuracy: 0.8675\n",
      "Epoch 33/200\n",
      "23125/23125 [==============================] - 2s 70us/sample - loss: 0.5818 - accuracy: 0.8803 - val_loss: 1.0766 - val_accuracy: 0.8833\n",
      "Epoch 34/200\n",
      "23125/23125 [==============================] - 2s 72us/sample - loss: 0.5978 - accuracy: 0.8772 - val_loss: 1.0967 - val_accuracy: 0.8841\n",
      "Epoch 35/200\n",
      "23125/23125 [==============================] - 2s 83us/sample - loss: 0.5508 - accuracy: 0.8896 - val_loss: 1.0682 - val_accuracy: 0.8744\n",
      "Epoch 36/200\n",
      "23125/23125 [==============================] - 2s 81us/sample - loss: 0.5556 - accuracy: 0.8859 - val_loss: 1.1288 - val_accuracy: 0.8796\n",
      "Epoch 37/200\n",
      "23125/23125 [==============================] - 2s 79us/sample - loss: 0.5555 - accuracy: 0.8897 - val_loss: 1.0734 - val_accuracy: 0.8862\n",
      "Epoch 38/200\n",
      "23125/23125 [==============================] - 2s 73us/sample - loss: 0.5966 - accuracy: 0.8803 - val_loss: 0.9272 - val_accuracy: 0.8686\n",
      "Epoch 39/200\n",
      "23125/23125 [==============================] - 2s 75us/sample - loss: 0.5482 - accuracy: 0.8869 - val_loss: 1.3462 - val_accuracy: 0.8966\n",
      "Epoch 40/200\n",
      "23125/23125 [==============================] - 2s 72us/sample - loss: 0.5505 - accuracy: 0.8925 - val_loss: 1.0365 - val_accuracy: 0.8893\n",
      "Epoch 41/200\n",
      "23125/23125 [==============================] - 2s 72us/sample - loss: 0.5973 - accuracy: 0.8802 - val_loss: 0.9774 - val_accuracy: 0.8852\n",
      "Epoch 42/200\n",
      "23125/23125 [==============================] - 2s 81us/sample - loss: 0.5678 - accuracy: 0.8853 - val_loss: 1.2457 - val_accuracy: 0.8910\n",
      "Epoch 43/200\n",
      "23125/23125 [==============================] - 2s 84us/sample - loss: 0.5707 - accuracy: 0.8997 - val_loss: 1.3619 - val_accuracy: 0.8935\n",
      "Epoch 44/200\n",
      "23125/23125 [==============================] - 2s 75us/sample - loss: 0.5471 - accuracy: 0.8922 - val_loss: 1.0956 - val_accuracy: 0.8872\n",
      "Epoch 45/200\n",
      "23125/23125 [==============================] - 2s 74us/sample - loss: 0.5946 - accuracy: 0.8762 - val_loss: 1.0329 - val_accuracy: 0.8777\n",
      "Epoch 46/200\n",
      "23125/23125 [==============================] - 2s 74us/sample - loss: 0.5659 - accuracy: 0.8837 - val_loss: 0.9916 - val_accuracy: 0.8812\n",
      "Epoch 47/200\n",
      "23125/23125 [==============================] - 2s 74us/sample - loss: 0.5310 - accuracy: 0.8933 - val_loss: 0.9934 - val_accuracy: 0.8860\n",
      "Epoch 48/200\n",
      "23125/23125 [==============================] - 2s 73us/sample - loss: 0.5431 - accuracy: 0.8881 - val_loss: 1.0694 - val_accuracy: 0.8884\n",
      "Epoch 49/200\n",
      "23125/23125 [==============================] - 2s 73us/sample - loss: 0.5159 - accuracy: 0.8993 - val_loss: 1.1309 - val_accuracy: 0.8942\n",
      "train: \n",
      " [[13597  1986]\n",
      " [    0  7542]]\n",
      "test: \n",
      " [[3361  560]\n",
      " [  38 1823]]\n",
      "test:0.896576\n",
      "train:0.914119\n",
      "[0 0 0 ... 0 0 0]\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "acc:0.248125\n",
      "[[ 430    0]\n",
      " [1303    0]]\n",
      "0.24812463935372187\n"
     ]
    }
   ],
   "source": [
    "acc={}\n",
    "cols = ['LEFT','RIGHT']\n",
    "\n",
    "#sc = StandardScaler(with_mean=True)\n",
    "\n",
    "for col in cols:\n",
    "    ind_temp=feature.columns.str.contains(col)\n",
    "    #feature_sc = sc.fit_transform(feature.loc[:,ind_temp])\n",
    "    #feature2_sc = sc.transform(feature2.loc[:,ind_temp])\n",
    "    train,test,sc = train_model(model,np.array(feature.loc[:,ind_temp]),np.array(y))\n",
    "    \n",
    "    acc_rest=test_model(model,np.array(feature2.loc[:,ind_temp]),np.array(y2),sc)\n",
    "    #acc[col] = [train,valid,test,acc_rest]\n",
    "    print(acc_rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_lr=pd.DataFrame(acc,index=['train','valid','test','rest data'])#.to_csv('./results/acc_lr_ann.csv')\n",
    "#acc_com=pd.concat([acc_ann_com.drop(['dnn','dnn1'],'index'),acc_lr.T])\n",
    "acc_com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test features from 2 of 8 signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test features from 2 of 8 signals\n",
    "\n",
    "acc_2f={}\n",
    "cols = [ 'LEFT_TA','LEFT_TS','LEFT_BF', 'LEFT_RF',\n",
    "        'RIGHT_TA','RIGHT_TS','RIGHT_BF', 'RIGHT_RF']\n",
    "\n",
    "\n",
    "for p in combinations(cols[:4],2):\n",
    "    ind_temp=feature.columns.str.contains(p[0])| feature.columns.str.contains(p[1])\n",
    "    #feature_sc = sc.fit_transform(feature.loc[:,ind_temp])\n",
    "    #feature2_sc = sc.transform(feature2.loc[:,ind_temp])\n",
    "    train,valid,test,sc = train_model(model,np.array(feature.loc[:,ind_temp]),np.array(y))\n",
    "    acc_rest=test_model(model,np.array(feature2.loc[:,ind_temp]),np.array(y2),sc)\n",
    "    acc_2f[p[0]+'_'+p[1]] = [train,valid,test,acc_rest]\n",
    "    print(acc_rest)\n",
    "    \n",
    "for p in combinations(cols[4:],2):\n",
    "    ind_temp=feature.columns.str.contains(p[0])| feature.columns.str.contains(p[1])\n",
    "    #feature_sc = sc.fit_transform(feature.loc[:,ind_temp])\n",
    "    #feature2_sc = sc.transform(feature2.loc[:,ind_temp])\n",
    "    train,valid,test,sc = train_model(model,np.array(feature.loc[:,ind_temp]),np.array(y))\n",
    "    acc_rest=test_model(model,np.array(feature2.loc[:,ind_temp]),np.array(y2),sc)\n",
    "    acc_2f[p[0]+'_'+p[1]] = [train,valid,test,acc_rest]\n",
    "    print(acc_rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acc_2f_ann = pd.DataFrame(acc_2f,index=['train','valid','test','rest data']).T\n",
    "#acc_com = pd.concat([acc_com,acc_2f_ann])\n",
    "acc_com.to_csv('./results/dropna/acc_com_ann.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(acc_2f,index=['train','valid','test','rest data']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on some of rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_of_rest = ['正常/P940_MSham_B_Walking_trial_6_emg.csv',\n",
    "                '正常/P940_M050_B_Walking_trial_4_emg.csv',\n",
    "                '正常/P812_M100_A_Walking_trial_3_emg.csv',\n",
    "                '正常/P645_M050_A_Walking_trial_3_emg.csv',\n",
    "                '正常/P623_Msham_B_Walking_trial_2_emg.csv',\n",
    "                '正常/P551_M50_B_Walking_trial_6_emg.csv',\n",
    "                'P379_M050_2_OFF_A_FoG_trial_1_emg.csv',\n",
    "                'P551_M050_2_B_FoG_trial_2_emg.csv']\n",
    "#booster = xgb.Booster()\n",
    "#booster.load_model('./model/XGBoost_W256_S64_Left.json')\n",
    "#model = xgb.XGBClassifier()\n",
    "#model._Booster = booster\n",
    "acc = []\n",
    "columns=['LEFT_TA','LEFT_TS','LEFT_BF', 'LEFT_RF']\n",
    "for file in some_of_rest:\n",
    "    path = './data/'+file\n",
    "    feature2,y2 = dp.pipeline_feature(path,width=256,stride=64,scaler=False,\n",
    "                                      threshold_WAMP=threshold_WAMP,\n",
    "                                      threshold_ZC=threshold_ZC,\n",
    "                                      threshold_SSC=threshold_SSC,\n",
    "                                      bins=bins,\n",
    "                                      ranges=HIST_range,\n",
    "                                      show_para=False,\n",
    "                                      filt = 250)\n",
    "    feature2_sc = sc.transform(feature2)\n",
    "    acc += [test_model(model,feature2_sc,y2)]\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(feature2_sc)\n",
    "metrics.accuracy_score(y2,y_pred>0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:1 (16583, 8)\n",
      "i:2 (4489, 8)\n",
      "i:3 (35121, 8)\n",
      "i:4 (31027, 8)\n",
      "i:5 (30783, 8)\n",
      "i:6 (159539, 8)\n",
      "i:7 (225455, 8)\n",
      "i:8 (362273, 8)\n",
      "i:9 (28868, 8)\n",
      "i:10 (20878, 8)\n",
      "i:11 (25322, 8)\n",
      "i:12 (24242, 8)\n",
      "i:13 (21728, 8)\n",
      "i:14 (27916, 8)\n",
      "i:15 (27146, 8)\n",
      "i:16 (25947, 8)\n",
      "i:17 (26203, 8)\n",
      "i:18 (89500, 8)\n",
      "i:19 (70282, 8)\n",
      "i:20 (79595, 8)\n",
      "i:21 (73280, 8)\n",
      "Duration: 4.539805\n"
     ]
    }
   ],
   "source": [
    "files = np.array(df.columns)\n",
    "X = []\n",
    "Y = []\n",
    "#sc = StandardScaler(with_mean=False)\n",
    "i = 0\n",
    "start = time.time()\n",
    "for file in files:\n",
    "    emg_data = pd.read_csv('./data/'+file)\n",
    "    #emg_data = emg_data.fillna({'LEFT_TA':emg_data.LEFT_TA.mean(),\n",
    "    #                            'LEFT_TS':emg_data.LEFT_TS.mean(),\n",
    "    #                            'LEFT_BF':emg_data.LEFT_BF.mean(),\n",
    "    #                            'LEFT_RF':emg_data.LEFT_RF.mean(),\n",
    "    #                            'RIGHT_TA':emg_data.RIGHT_TA.mean(),\n",
    "    #                            'RIGHT_TS':emg_data.RIGHT_TS.mean(),\n",
    "    #                            'RIGHT_BF':emg_data.RIGHT_BF.mean(),\n",
    "    #                            'RIGHT_RF':emg_data.RIGHT_RF.mean()})\n",
    "    #emg_data = emg_data[emg_data.Label1 == emg_data.Label2].reset_index(drop=True)\n",
    "    emg_data = emg_data.dropna().reset_index(drop=True)\n",
    "    x = np.array(emg_data.iloc[:,3:])\n",
    "    y = np.array(emg_data.Label2)\n",
    "    #x,y = dp.generate_window_slide_data(emg_data,width=width,stride=stride,scaler=False,same_label=True)\n",
    "    X += x.tolist()\n",
    "    Y += y.tolist()\n",
    "    i += 1\n",
    "    print('i:%d'%i,x.shape)\n",
    "end = time.time()\n",
    "duration = end-start\n",
    "print('Duration: %f'%(duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,feature,y,binary=True,file=None):\n",
    "    if binary:\n",
    "        ind = ((y==0)|(y==1)|(y==2)|(y==3)|(y==4)|(y==6))\n",
    "        ind1 = ((y==4)|(y==1)|(y==2)|(y==3)|(y==6))\n",
    "        y_01 = y.copy()\n",
    "        #ind1 = ((y_01==1)|(y_01==2)|(y_01==6))\n",
    "        y_01[ind1] = 1\n",
    "        oc = OneHotEncoder()\n",
    "        y_01 = oc.fit_transform(np.array(y_01)[:,np.newaxis]).toarray()\n",
    "        cw = None#{0:1,1:5}\n",
    "    else:\n",
    "        ind = ((y==1)|(y==2)|(y==6))\n",
    "        #ind = ((y==1)|(y==6))\n",
    "        y_01 = y[ind].copy()\n",
    "        oc = OneHotEncoder()\n",
    "        y_01 = oc.fit_transform(np.array(y_01)[:,np.newaxis]).toarray()\n",
    "        cw = None#{0:5,1:1,2:1}#{0:2,1:1,2:10,3:2}\n",
    "    x_full,x_test,y_full,y_test = train_test_split(np.array(feature)[ind,:],y_01,\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=123,\n",
    "                                                   shuffle=True)\n",
    "    x_train,x_valid,y_train,y_valid = train_test_split(x_full,y_full,\n",
    "                                                       test_size=0.25,\n",
    "                                                       random_state=555,\n",
    "                                                       shuffle=True)\n",
    "    \n",
    "    #sm = BorderlineSMOTE(random_state=50,kind='borderline-1')\n",
    "    #sm = SMOTE(random_state=50)\n",
    "    #print(y_full.shape)\n",
    "    #x_full,y_full = sm.fit_resample(x_full,y_full)\n",
    "    #print(y_full_n.shape)\n",
    "    x_full = np.reshape(x_full,(-1,128*8))\n",
    "    sc = StandardScaler(with_mean=False)\n",
    "    #sc = MinMaxScaler((0,1))\n",
    "    x_train = sc.fit_transform(x_full)\n",
    "    x_train = x_train.reshape((-1,128,8))\n",
    "    #pca = PCA(n_components=150)\n",
    "    #x_train = pca.fit_transform(x_train)\n",
    "    #x_valid = sc.transform(x_valid)\n",
    "    x_test = np.reshape(x_test,(-1,128*8))\n",
    "    x_test = sc.transform(x_test)\n",
    "    x_test = x_test.reshape((-1,128,8))\n",
    "    #x_test = pca.transform(x_test)\n",
    "    #x_train = x_full\n",
    "    \n",
    "    early_stopping = callbacks.EarlyStopping(patience = 10,\n",
    "                                             monitor = 'val_accuracy', \n",
    "                                             restore_best_weights=True)\n",
    "    history = model.fit(x_train,y_full,validation_data=[x_test,y_test],\n",
    "                        epochs=300,batch_size=500,class_weight=cw,\n",
    "                        callbacks=[early_stopping],\n",
    "                        shuffle=True)\n",
    "    \n",
    "    if binary:\n",
    "        y_pred_t=model.predict(x_test)\n",
    "        test = metrics.accuracy_score(np.argmax(y_test,axis=1),np.argmax(y_pred_t,axis=1))\n",
    "        #test = metrics.accuracy_score(y_test,y_pred_t>0.5)\n",
    "        \n",
    "        #y_pred_v=model.predict(x_valid)\n",
    "        #valid = metrics.accuracy_score(y_valid,np.argmax(y_pred_v,axis=1))\n",
    "        y_pred_ta=model.predict(x_train)\n",
    "        train = metrics.accuracy_score(np.argmax(y_full,axis=1),np.argmax(y_pred_ta,axis=1))\n",
    "        #train = metrics.accuracy_score(y_full,y_pred_ta>0.5)\n",
    "        \n",
    "        print('train: \\n',metrics.confusion_matrix(np.argmax(y_full,axis=1),np.argmax(y_pred_ta,axis=1)))\n",
    "        #print('valid: \\n',metrics.confusion_matrix(np.argmax(y_valid,axis=1),np.argmax(y_pred_v,axis=1)))\n",
    "        print('test: \\n',metrics.confusion_matrix(np.argmax(y_test,axis=1),np.argmax(y_pred_t,axis=1)))\n",
    "        \n",
    "        #print('train: \\n',metrics.confusion_matrix(y_full,y_pred_ta>0.5))\n",
    "        #print('test: \\n',metrics.confusion_matrix(y_test,y_pred_t>0.5))\n",
    "\n",
    "    else:\n",
    "        y_pred_t=model.predict(x_test)\n",
    "        test = metrics.accuracy_score(np.argmax(y_test,axis=1),np.argmax(y_pred_t,axis=1))\n",
    "        #y_pred_v=model.predict(x_valid)\n",
    "        #valid = metrics.accuracy_score(np.argmax(y_valid,axis=1),np.argmax(y_pred_v,axis=1))\n",
    "        y_pred_ta=model.predict(x_train)\n",
    "        train = metrics.accuracy_score(np.argmax(y_full,axis=1),np.argmax(y_pred_ta,axis=1))        \n",
    "        print('train: \\n',metrics.confusion_matrix(np.argmax(y_full,axis=1),np.argmax(y_pred_ta,axis=1)))\n",
    "        #print('valid: \\n',metrics.confusion_matrix(np.argmax(y_valid,axis=1),np.argmax(y_pred_v,axis=1)))\n",
    "        print('test: \\n',metrics.confusion_matrix(np.argmax(y_test,axis=1),np.argmax(y_pred_t,axis=1)))\n",
    "    print('test:%f'%test)\n",
    "    #print('valid:%f'%valid)\n",
    "    print('train:%f'%train)\n",
    "    if file != None:\n",
    "        model.save_model(file)\n",
    "    return train,test,sc#,pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_re = feature_sc.reshape((-1,X.shape[1],1))\n",
    "x_full,x_test,y_full,y_test = train_test_split(np.array(feature_re),np.array(y_01),test_size=0.2,random_state=123)\n",
    "x_train,x_valid,y_train,y_valid = train_test_split(x_full,y_full,test_size=0.2,random_state=555)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = layers.Input(shape=[128,8])\n",
    "lstm1 = layers.LSTM(50,return_sequences=True)(input_)\n",
    "drop1 = layers.Dropout(0.2)(lstm1)\n",
    "lstm2 = layers.LSTM(50,return_sequences=True)(drop1)\n",
    "drop2 = layers.Dropout(0.2)(lstm2)\n",
    "#lstm3 = layers.LSTM(50,return_sequences=True)(drop2)\n",
    "#drop3 = layers.Dropout(0.2)(lstm3)\n",
    "lstm4 = layers.LSTM(50)(drop2)\n",
    "drop4 = layers.Dropout(0.2)(lstm4)\n",
    "dense1 = layers.Dense(64,activation='relu')(drop4)\n",
    "drop5 = layers.Dropout(0.2)(dense1)\n",
    "dense2 = layers.Dense(32,activation='relu')(drop5)\n",
    "output = layers.Dense(3,activation='softmax')(dense2)\n",
    "model = Model(inputs=[input_],outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "early_stopping = callbacks.EarlyStopping(patience = 20,\n",
    "                                         monitor = 'val_accuracy', \n",
    "                                         restore_best_weights=True)\n",
    "history = model.fit(x_train,y_train,validation_data=[x_valid,y_valid],\n",
    "                    epochs=100,batch_size=500,\n",
    "                   callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8872 samples, validate on 2219 samples\n",
      "Epoch 1/300\n",
      "8872/8872 [==============================] - 88s 10ms/sample - loss: 0.9841 - accuracy: 0.4876 - val_loss: 0.8857 - val_accuracy: 0.5002\n",
      "Epoch 2/300\n",
      "8872/8872 [==============================] - 82s 9ms/sample - loss: 0.8572 - accuracy: 0.5571 - val_loss: 0.8288 - val_accuracy: 0.6471\n",
      "Epoch 3/300\n",
      "8872/8872 [==============================] - 81s 9ms/sample - loss: 0.8051 - accuracy: 0.6443 - val_loss: 0.7573 - val_accuracy: 0.6670\n",
      "Epoch 4/300\n",
      "8872/8872 [==============================] - 81s 9ms/sample - loss: 0.7433 - accuracy: 0.6677 - val_loss: 0.7142 - val_accuracy: 0.6791\n",
      "Epoch 5/300\n",
      "8872/8872 [==============================] - 81s 9ms/sample - loss: 0.7212 - accuracy: 0.6787 - val_loss: 0.6996 - val_accuracy: 0.6886\n",
      "Epoch 6/300\n",
      "8872/8872 [==============================] - 87s 10ms/sample - loss: 0.7071 - accuracy: 0.6878 - val_loss: 0.6952 - val_accuracy: 0.7008\n",
      "Epoch 7/300\n",
      "8872/8872 [==============================] - 81s 9ms/sample - loss: 0.6882 - accuracy: 0.6948 - val_loss: 0.6657 - val_accuracy: 0.7012\n",
      "Epoch 8/300\n",
      "8872/8872 [==============================] - 81s 9ms/sample - loss: 0.6646 - accuracy: 0.7073 - val_loss: 0.6449 - val_accuracy: 0.7265\n",
      "Epoch 9/300\n",
      "8872/8872 [==============================] - 84s 9ms/sample - loss: 0.6623 - accuracy: 0.7076 - val_loss: 0.6351 - val_accuracy: 0.7206\n",
      "Epoch 10/300\n",
      "8872/8872 [==============================] - 81s 9ms/sample - loss: 0.6435 - accuracy: 0.7187 - val_loss: 0.6351 - val_accuracy: 0.7274\n",
      "Epoch 11/300\n",
      "8872/8872 [==============================] - 85s 10ms/sample - loss: 0.6427 - accuracy: 0.7163 - val_loss: 0.6309 - val_accuracy: 0.7260\n",
      "Epoch 12/300\n",
      "8872/8872 [==============================] - 82s 9ms/sample - loss: 0.6384 - accuracy: 0.7187 - val_loss: 0.6255 - val_accuracy: 0.7256\n",
      "Epoch 13/300\n",
      "8872/8872 [==============================] - 87s 10ms/sample - loss: 0.6292 - accuracy: 0.7271 - val_loss: 0.6225 - val_accuracy: 0.7165\n",
      "Epoch 14/300\n",
      "8872/8872 [==============================] - 83s 9ms/sample - loss: 0.6213 - accuracy: 0.7299 - val_loss: 0.6190 - val_accuracy: 0.7210\n",
      "Epoch 15/300\n",
      "3000/8872 [=========>....................] - ETA: 57s - loss: 0.6155 - accuracy: 0.7276 WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-6c283b32f09c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-d3cca95f67ba>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, feature, y, binary, file)\u001b[0m\n\u001b[0;32m     50\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m                         \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m                         shuffle=True)\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    122\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 86\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    485\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1141\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train,test,sc = train_model(model,np.array(x),np.array(y),False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature2_re = feature2_sc.reshape((-1,feature.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(model,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_matrix=np.array([[0,1,1,1],\n",
    "                  [1,0,1,1],\n",
    "                  [10,100,0,10],\n",
    "                  [1.,1.,1,0]])\n",
    "cost_matrix=np.array([[0,2.],\n",
    "                  [5.,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "P0 = 55080/(55080+8181)\n",
    "P1 = 8181/(55080+8181)\n",
    "P = [P0,P1]\n",
    "cost_vec = np.zeros(2)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        if i == j:\n",
    "            continue\n",
    "        cost_vec[i]+=1/(1-P[i])*P[j]*cost_matrix[i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 5.])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1567100, shape=(4, 4), dtype=float64, numpy=\n",
       "array([[  0.,   1.,  10.,   1.],\n",
       "       [  1.,   0., 100.,   1.],\n",
       "       [  1.,   1.,   0.,   1.],\n",
       "       [  1.,   1.,  10.,   0.]])>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.transpose(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [2.],\n",
       "       [5.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape(cost_matrix,(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
