{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import data_processing as dp\n",
    "from scipy import signal\n",
    "from scipy.stats import skew\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "import os\n",
    "import time\n",
    "import h5py\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\data\\G04_FoG_trial_1_emg.csv\n",
      ".\\data\\G04_FoG_trial_2_emg.csv\n",
      ".\\data\\G06_FoG_trial_1_emg.csv\n",
      ".\\data\\G06_FoG_trial_2_emg.csv\n",
      ".\\data\\G06_FoG_trial_3_emg.csv\n",
      ".\\data\\G07_Freezing_Trial1_trial_1_emg.csv\n",
      ".\\data\\G08_FoG_1_trial_1_emg.csv\n",
      ".\\data\\G08_FoG_2_trial_1_emg.csv\n",
      ".\\data\\G11_FoG_trial_1_emg.csv\n",
      ".\\data\\G11_FoG_trial_2_emg.csv\n",
      ".\\data\\P379_M050_2_OFF_A_FoG_trial_1_emg.csv\n",
      ".\\data\\P379_M050_2_OFF_A_FoG_trial_2_emg.csv\n",
      ".\\data\\P379_M050_2_OFF_A_FoG_trial_3_emg.csv\n",
      ".\\data\\P379_M050_2_OFF_B_FoG_trial_1_emg.csv\n",
      ".\\data\\P379_M050_2_OFF_B_FoG_trial_2_emg.csv\n",
      ".\\data\\P379_M050_2_OFF_B_FoG_trial_3_emg.csv\n",
      ".\\data\\P551_M050_2_A_FoG_trial_1_emg.csv\n",
      ".\\data\\P551_M050_2_B_FoG_trial_1_emg.csv\n",
      ".\\data\\P551_M050_2_B_FoG_trial_2_emg.csv\n",
      ".\\data\\P812_M050_2_B_FoG_trial_1_emg.csv\n",
      ".\\data\\P812_M050_2_B_FoG_trial_2_emg.csv\n",
      ".\\data\\其他\\labels.txt\n",
      ".\\data\\其他\\P812_M050_2_B_FoG_trial1_annotation.csv\n",
      ".\\data\\其他\\P812_M050_2_B_FoG_trials.mat\n",
      ".\\data\\其他\\P812_M050_2_B_FoG_trial_1_out_left_foot.csv\n",
      ".\\data\\其他\\P812_M050_2_B_FoG_trial_1_out_lower_left_foot.csv\n",
      ".\\data\\其他\\P812_M050_2_B_FoG_trial_1_out_lower_right_foot.csv\n",
      ".\\data\\其他\\P812_M050_2_B_FoG_trial_1_out_right_foot.csv\n",
      ".\\data\\其他\\P812_M050_2_B_FoG_trial_2_out_left_foot.csv\n",
      ".\\data\\其他\\P812_M050_2_B_FoG_trial_2_out_lower_left_foot.csv\n",
      ".\\data\\其他\\P812_M050_2_B_FoG_trial_2_out_lower_right_foot.csv\n",
      ".\\data\\其他\\P812_M050_2_B_FoG_trial_2_out_right_foot.csv\n",
      ".\\data\\其他\\P812_M50_2_B_FoG_trial2_annotation.csv\n",
      ".\\data\\正常\\G02_Walking_trial_1_emg.csv\n",
      ".\\data\\正常\\G03_Walking_trial_1_emg.csv\n",
      ".\\data\\正常\\G03_Walking_trial_2_emg.csv\n",
      ".\\data\\正常\\G05_Walking_struct_fixed_trial_1_emg.csv\n",
      ".\\data\\正常\\G05_Walking_struct_fixed_trial_2_emg.csv\n",
      ".\\data\\正常\\G05_Walking_struct_fixed_trial_3_emg.csv\n",
      ".\\data\\正常\\G09_FoG_trial_1_emg.csv\n",
      ".\\data\\正常\\G09_FoG_trial_2_emg.csv\n",
      ".\\data\\正常\\G09_FoG_trial_3_emg.csv\n",
      ".\\data\\正常\\G09_Walking_trial_2_emg.csv\n",
      ".\\data\\正常\\G09_Walking_trial_4_emg.csv\n",
      ".\\data\\正常\\G09_Walking_trial_6_emg.csv\n",
      ".\\data\\正常\\G11_Walking_trial_2_emg.csv\n",
      ".\\data\\正常\\G11_Walking_trial_4_emg.csv\n"
     ]
    }
   ],
   "source": [
    "for dirname, _, filenames in os.walk('.\\data'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2 = '.\\data\\正常\\G11_Walking_trial_4_emg.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.read_csv('./processed data/dataframe_W256_S64_dropna.csv')\n",
    "\n",
    "# read file name of data with various Labels\n",
    "df = pd.read_csv('./useful_data_label.csv',index_col=0) \n",
    "drop = 'P551_M050_2_B_FoG_trial_2_emg.csv'\n",
    "ind_drop = df.columns!=drop\n",
    "# read file name of data with only label 0\n",
    "df2 = pd.read_csv('./unuseful_data_label.csv',index_col=0)\n",
    "# read some of the data with only label 0\n",
    "df3 = pd.read_csv('./data/file_name.txt',header=None)\n",
    "\n",
    "files = np.concatenate([np.array(df.columns),np.array(df3.loc[:,0])])\n",
    "ind = Data.File.isin(files)\n",
    "Data_sel = Data[ind]\n",
    "Data_rest = Data[~ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_col = ['_IEMG','_MAV','_SSI','_VAR','_RMS',\n",
    "               '_WL','_ZC','_SSC','_WAMP','_skew','_Acti','_AR','_HIST','_MDF']\n",
    "\n",
    "feature_all = Data_sel.iloc[:,1:-1]\n",
    "#ind_temp1 = feature_all.columns.str.contains('MAV')\n",
    "#ind_temp2 = feature_all.columns.str.contains('RMS')\n",
    "#ind_temp3 = feature_all.columns.str.contains('VAR')\n",
    "#ind_temp = ind_temp1|ind_temp2|ind_temp3\n",
    "#ind_temp = feature_all.columns.str.contains('mDWT')\n",
    "feature = feature_all.loc[:,~ind_temp]\n",
    "#feature = Data_sel.iloc[:,1:-1]\n",
    "#feature = Data_sel.iloc[:,:-2]\n",
    "y = Data_sel.Label\n",
    "feature2_all = Data_rest.iloc[:,1:-1]\n",
    "feature2 = feature2_all.loc[:,~ind_temp]\n",
    "#feature2 = Data_rest.iloc[:,1:-1]\n",
    "#feature2 = Data_rest.iloc[:,:-2]\n",
    "y2 = Data_rest.Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './processed data/data_set_after_window_withoutSC.hdf5'\n",
    "with h5py.File(path,'r') as f:\n",
    "    x = f['cwt_data'][...]\n",
    "    y = f['label2'][...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data_processing' from 'E:\\\\Document\\\\jupyter\\\\Master Thesis\\\\data_processing.py'>"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imp\n",
    "imp.reload(dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ctypes\n",
    "player = ctypes.windll.kernel32\n",
    "player.Beep(1000,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>LEFT_TA_IEMG</th>\n",
       "      <th>LEFT_TS_IEMG</th>\n",
       "      <th>LEFT_BF_IEMG</th>\n",
       "      <th>LEFT_RF_IEMG</th>\n",
       "      <th>RIGHT_TA_IEMG</th>\n",
       "      <th>RIGHT_TS_IEMG</th>\n",
       "      <th>RIGHT_BF_IEMG</th>\n",
       "      <th>RIGHT_RF_IEMG</th>\n",
       "      <th>LEFT_TA_SSI</th>\n",
       "      <th>...</th>\n",
       "      <th>RIGHT_BF_mDWT5</th>\n",
       "      <th>RIGHT_BF_mDWT6</th>\n",
       "      <th>RIGHT_BF_mDWT7</th>\n",
       "      <th>RIGHT_RF_mDWT0</th>\n",
       "      <th>RIGHT_RF_mDWT1</th>\n",
       "      <th>RIGHT_RF_mDWT2</th>\n",
       "      <th>RIGHT_RF_mDWT3</th>\n",
       "      <th>RIGHT_RF_mDWT4</th>\n",
       "      <th>RIGHT_RF_mDWT5</th>\n",
       "      <th>RIGHT_RF_mDWT6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>454.0</td>\n",
       "      <td>748.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>1406.0</td>\n",
       "      <td>4458.0</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>887.0</td>\n",
       "      <td>2070.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2262.686279</td>\n",
       "      <td>1259.309937</td>\n",
       "      <td>661.646484</td>\n",
       "      <td>627.024109</td>\n",
       "      <td>422.331390</td>\n",
       "      <td>325.584045</td>\n",
       "      <td>149.540817</td>\n",
       "      <td>34.614529</td>\n",
       "      <td>15.235371</td>\n",
       "      <td>7.567358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>476.0</td>\n",
       "      <td>794.0</td>\n",
       "      <td>647.0</td>\n",
       "      <td>1235.0</td>\n",
       "      <td>3225.0</td>\n",
       "      <td>2104.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>2124.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6361.942383</td>\n",
       "      <td>3565.255371</td>\n",
       "      <td>1878.698730</td>\n",
       "      <td>17489.666016</td>\n",
       "      <td>17283.833984</td>\n",
       "      <td>17201.283203</td>\n",
       "      <td>17021.105469</td>\n",
       "      <td>16690.128906</td>\n",
       "      <td>10616.111328</td>\n",
       "      <td>5948.324219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>525.0</td>\n",
       "      <td>477.0</td>\n",
       "      <td>731.0</td>\n",
       "      <td>624.0</td>\n",
       "      <td>1090.0</td>\n",
       "      <td>3633.0</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>895.0</td>\n",
       "      <td>2051.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6153.169922</td>\n",
       "      <td>3460.817871</td>\n",
       "      <td>1826.467285</td>\n",
       "      <td>962.496521</td>\n",
       "      <td>765.000916</td>\n",
       "      <td>657.255798</td>\n",
       "      <td>257.338440</td>\n",
       "      <td>152.738708</td>\n",
       "      <td>69.780663</td>\n",
       "      <td>35.270126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>446.0</td>\n",
       "      <td>699.0</td>\n",
       "      <td>625.0</td>\n",
       "      <td>1108.0</td>\n",
       "      <td>5036.0</td>\n",
       "      <td>1751.0</td>\n",
       "      <td>808.0</td>\n",
       "      <td>2287.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10430.298828</td>\n",
       "      <td>5854.774414</td>\n",
       "      <td>3087.293457</td>\n",
       "      <td>7725.885254</td>\n",
       "      <td>7557.866211</td>\n",
       "      <td>7455.998047</td>\n",
       "      <td>7061.154297</td>\n",
       "      <td>6838.061035</td>\n",
       "      <td>4317.638672</td>\n",
       "      <td>2414.769287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>541.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>759.0</td>\n",
       "      <td>579.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>3126.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>906.0</td>\n",
       "      <td>2159.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23542.087891</td>\n",
       "      <td>13179.492188</td>\n",
       "      <td>6941.858398</td>\n",
       "      <td>11195.717773</td>\n",
       "      <td>11015.741211</td>\n",
       "      <td>10906.076172</td>\n",
       "      <td>10106.732422</td>\n",
       "      <td>9888.559570</td>\n",
       "      <td>6314.685059</td>\n",
       "      <td>3541.675293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78514</th>\n",
       "      <td>0</td>\n",
       "      <td>1208.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>536.0</td>\n",
       "      <td>736.0</td>\n",
       "      <td>522.0</td>\n",
       "      <td>626.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>15176.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2121.493652</td>\n",
       "      <td>1188.896484</td>\n",
       "      <td>626.485840</td>\n",
       "      <td>415.748596</td>\n",
       "      <td>266.493896</td>\n",
       "      <td>197.534225</td>\n",
       "      <td>27.509951</td>\n",
       "      <td>2.184534</td>\n",
       "      <td>0.766539</td>\n",
       "      <td>0.433579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78515</th>\n",
       "      <td>0</td>\n",
       "      <td>1240.0</td>\n",
       "      <td>394.0</td>\n",
       "      <td>1108.0</td>\n",
       "      <td>529.0</td>\n",
       "      <td>753.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>626.0</td>\n",
       "      <td>567.0</td>\n",
       "      <td>15334.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.271651</td>\n",
       "      <td>4.113052</td>\n",
       "      <td>2.175889</td>\n",
       "      <td>3639.195801</td>\n",
       "      <td>3455.077148</td>\n",
       "      <td>3390.203369</td>\n",
       "      <td>3334.017578</td>\n",
       "      <td>3263.763428</td>\n",
       "      <td>2090.744141</td>\n",
       "      <td>1173.604248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78516</th>\n",
       "      <td>0</td>\n",
       "      <td>1455.0</td>\n",
       "      <td>407.0</td>\n",
       "      <td>1077.0</td>\n",
       "      <td>521.0</td>\n",
       "      <td>754.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>588.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>19859.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.267348</td>\n",
       "      <td>4.110372</td>\n",
       "      <td>2.174457</td>\n",
       "      <td>28013.242188</td>\n",
       "      <td>27784.912109</td>\n",
       "      <td>27694.750000</td>\n",
       "      <td>27228.414062</td>\n",
       "      <td>26790.941406</td>\n",
       "      <td>17023.996094</td>\n",
       "      <td>9536.416016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78517</th>\n",
       "      <td>0</td>\n",
       "      <td>1483.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>948.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>819.0</td>\n",
       "      <td>547.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>597.0</td>\n",
       "      <td>20093.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10665.289062</td>\n",
       "      <td>5972.991699</td>\n",
       "      <td>3146.582275</td>\n",
       "      <td>874.318542</td>\n",
       "      <td>654.879395</td>\n",
       "      <td>566.956238</td>\n",
       "      <td>34.042343</td>\n",
       "      <td>7.987534</td>\n",
       "      <td>5.287806</td>\n",
       "      <td>2.990932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78518</th>\n",
       "      <td>0</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>408.0</td>\n",
       "      <td>762.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>794.0</td>\n",
       "      <td>557.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>598.0</td>\n",
       "      <td>20040.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8498.360352</td>\n",
       "      <td>4761.543945</td>\n",
       "      <td>2508.862793</td>\n",
       "      <td>3940.172119</td>\n",
       "      <td>3761.514648</td>\n",
       "      <td>3660.756348</td>\n",
       "      <td>3470.881592</td>\n",
       "      <td>3399.096191</td>\n",
       "      <td>2149.707275</td>\n",
       "      <td>1202.755371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34866 rows × 224 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Label  LEFT_TA_IEMG  LEFT_TS_IEMG  LEFT_BF_IEMG  LEFT_RF_IEMG  \\\n",
       "0          0         540.0         454.0         748.0         620.0   \n",
       "1          0         540.0         476.0         794.0         647.0   \n",
       "2          0         525.0         477.0         731.0         624.0   \n",
       "3          0         577.0         446.0         699.0         625.0   \n",
       "4          0         541.0         432.0         759.0         579.0   \n",
       "...      ...           ...           ...           ...           ...   \n",
       "78514      0        1208.0         405.0        1124.0         536.0   \n",
       "78515      0        1240.0         394.0        1108.0         529.0   \n",
       "78516      0        1455.0         407.0        1077.0         521.0   \n",
       "78517      0        1483.0         401.0         948.0         546.0   \n",
       "78518      0        1518.0         408.0         762.0         555.0   \n",
       "\n",
       "       RIGHT_TA_IEMG  RIGHT_TS_IEMG  RIGHT_BF_IEMG  RIGHT_RF_IEMG  \\\n",
       "0             1406.0         4458.0         1992.0          887.0   \n",
       "1             1235.0         3225.0         2104.0          975.0   \n",
       "2             1090.0         3633.0         1726.0          895.0   \n",
       "3             1108.0         5036.0         1751.0          808.0   \n",
       "4             1024.0         3126.0         2008.0          906.0   \n",
       "...              ...            ...            ...            ...   \n",
       "78514          736.0          522.0          626.0          546.0   \n",
       "78515          753.0          540.0          626.0          567.0   \n",
       "78516          754.0          549.0          588.0          580.0   \n",
       "78517          819.0          547.0          563.0          597.0   \n",
       "78518          794.0          557.0          531.0          598.0   \n",
       "\n",
       "       LEFT_TA_SSI  ...  RIGHT_BF_mDWT5  RIGHT_BF_mDWT6  RIGHT_BF_mDWT7  \\\n",
       "0           2070.0  ...     2262.686279     1259.309937      661.646484   \n",
       "1           2124.0  ...     6361.942383     3565.255371     1878.698730   \n",
       "2           2051.0  ...     6153.169922     3460.817871     1826.467285   \n",
       "3           2287.0  ...    10430.298828     5854.774414     3087.293457   \n",
       "4           2159.0  ...    23542.087891    13179.492188     6941.858398   \n",
       "...            ...  ...             ...             ...             ...   \n",
       "78514      15176.0  ...     2121.493652     1188.896484      626.485840   \n",
       "78515      15334.0  ...        7.271651        4.113052        2.175889   \n",
       "78516      19859.0  ...        7.267348        4.110372        2.174457   \n",
       "78517      20093.0  ...    10665.289062     5972.991699     3146.582275   \n",
       "78518      20040.0  ...     8498.360352     4761.543945     2508.862793   \n",
       "\n",
       "       RIGHT_RF_mDWT0  RIGHT_RF_mDWT1  RIGHT_RF_mDWT2  RIGHT_RF_mDWT3  \\\n",
       "0          627.024109      422.331390      325.584045      149.540817   \n",
       "1        17489.666016    17283.833984    17201.283203    17021.105469   \n",
       "2          962.496521      765.000916      657.255798      257.338440   \n",
       "3         7725.885254     7557.866211     7455.998047     7061.154297   \n",
       "4        11195.717773    11015.741211    10906.076172    10106.732422   \n",
       "...               ...             ...             ...             ...   \n",
       "78514      415.748596      266.493896      197.534225       27.509951   \n",
       "78515     3639.195801     3455.077148     3390.203369     3334.017578   \n",
       "78516    28013.242188    27784.912109    27694.750000    27228.414062   \n",
       "78517      874.318542      654.879395      566.956238       34.042343   \n",
       "78518     3940.172119     3761.514648     3660.756348     3470.881592   \n",
       "\n",
       "       RIGHT_RF_mDWT4  RIGHT_RF_mDWT5  RIGHT_RF_mDWT6  \n",
       "0           34.614529       15.235371        7.567358  \n",
       "1        16690.128906    10616.111328     5948.324219  \n",
       "2          152.738708       69.780663       35.270126  \n",
       "3         6838.061035     4317.638672     2414.769287  \n",
       "4         9888.559570     6314.685059     3541.675293  \n",
       "...               ...             ...             ...  \n",
       "78514        2.184534        0.766539        0.433579  \n",
       "78515     3263.763428     2090.744141     1173.604248  \n",
       "78516    26790.941406    17023.996094     9536.416016  \n",
       "78517        7.987534        5.287806        2.990932  \n",
       "78518     3399.096191     2149.707275     1202.755371  \n",
       "\n",
       "[34866 rows x 224 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 256\n",
    "threshold_WAMP = 30\n",
    "threshold_ZC = 0\n",
    "threshold_SSC = 1\n",
    "bins=9\n",
    "bound = 70\n",
    "HIST_range = (-bound,bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold_WAMP:30.0, threshold_ZC:0.0, threshold_SSC:1.0,bins:9,ranges:(-70,70)\n",
      "IEMG,MAV,SSI,VAR,RMS,WL,ZC,SSC,WAMP,skew,Acti,AR,HIST\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = './processed data/data_set_after_window_S64_withoutSC_allPa.hdf5'\n",
    "with h5py.File(path,'r') as f:\n",
    "    x = f['cwt_data'][...]\n",
    "    y = f['label2'][...]\n",
    "feature = dp.generate_feature(x,threshold_WAMP=threshold_WAMP,\n",
    "                              threshold_ZC=threshold_ZC,\n",
    "                              threshold_SSC=threshold_SSC,\n",
    "                              bins=bins,ranges=HIST_range)\n",
    "#feature2 = dp.generate_feature(x2)\n",
    "player.Beep(1000,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('./processed data/nfeatures_W256_S64_WAMP30.hdf5','r') as f:\n",
    "    feature = f['features'][...]\n",
    "    y = f['labels'][...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature2,y2 = dp.pipeline_feature(path2,width=256,stride=64,\n",
    "                                  scaler=False,\n",
    "                                  threshold_WAMP=threshold_WAMP,\n",
    "                                  threshold_ZC=threshold_ZC,\n",
    "                                  threshold_SSC=threshold_SSC,\n",
    "                                  bins=bins,ranges=HIST_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('./processed data/nfeatures_rest_W256_S64.hdf5','r') as f:\n",
    "    feature2 = f['features'][...]\n",
    "    y2 = f['labels'][...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler(with_mean=True)\n",
    "feature_sc = sc.fit_transform(feature)\n",
    "feature2_sc = sc.transform(feature2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers,Model,callbacks\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,feature,y,binary=True,file=None):\n",
    "    if binary:\n",
    "        ind = ((y==0)|(y==4)|(y==1)|(y==2)|(y==3)|(y==6))\n",
    "        ind1 = ((y==4)|(y==1)|(y==2)|(y==3)|(y==6))\n",
    "        y_01 = y.copy()\n",
    "        y_01[ind1] = 1\n",
    "        cw = None\n",
    "    else:\n",
    "        ind = ((y==1)|(y==2)|(y==6))\n",
    "        y_01 = y[ind].copy()\n",
    "        oc = OneHotEncoder()\n",
    "        y_01 = oc.fit_transform(np.array(y_01)[:,np.newaxis]).toarray()\n",
    "        cw = None#{0:2,1:1.,2:2}\n",
    "    x_full,x_test,y_full,y_test = train_test_split(np.array(feature)[ind,:],y_01,\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=123,\n",
    "                                                   shuffle=False)\n",
    "    x_train,x_valid,y_train,y_valid = train_test_split(x_full,y_full,\n",
    "                                                       test_size=0.2,\n",
    "                                                       random_state=555,\n",
    "                                                       shuffle=True)\n",
    "    \n",
    "    \n",
    "    early_stopping = callbacks.EarlyStopping(patience = 20,\n",
    "                                             monitor = 'val_accuracy', \n",
    "                                             restore_best_weights=True)\n",
    "    history = model.fit(x_train,y_train,validation_data=[x_valid,y_valid],\n",
    "                        epochs=200,batch_size=50,class_weight=cw,\n",
    "                        callbacks=[early_stopping])\n",
    "    \n",
    "    if binary:\n",
    "        y_pred_t=model.predict(x_test)\n",
    "        test = metrics.accuracy_score(y_test,y_pred_t>0.5)\n",
    "        y_pred_v=model.predict(x_valid)\n",
    "        valid = metrics.accuracy_score(y_valid,y_pred_v>0.5)\n",
    "        y_pred_ta=model.predict(x_train)\n",
    "        train = metrics.accuracy_score(y_train,y_pred_ta>0.5)\n",
    "    else:\n",
    "        y_pred_t=model.predict(x_test)\n",
    "        test = metrics.accuracy_score(np.argmax(y_test,axis=1),np.argmax(y_pred_t,axis=1))\n",
    "        y_pred_v=model.predict(x_valid)\n",
    "        valid = metrics.accuracy_score(np.argmax(y_valid,axis=1),np.argmax(y_pred_v,axis=1))\n",
    "        y_pred_ta=model.predict(x_train)\n",
    "        train = metrics.accuracy_score(np.argmax(y_train,axis=1),np.argmax(y_pred_ta,axis=1))        \n",
    "        print('train: \\n',metrics.confusion_matrix(np.argmax(y_train,axis=1),np.argmax(y_pred_ta,axis=1)))\n",
    "        print('valid: \\n',metrics.confusion_matrix(np.argmax(y_valid,axis=1),np.argmax(y_pred_v,axis=1)))\n",
    "        print('test: \\n',metrics.confusion_matrix(np.argmax(y_test,axis=1),np.argmax(y_pred_t,axis=1)))\n",
    "    print('test:%f'%test)\n",
    "    print('valid:%f'%valid)\n",
    "    print('train:%f'%train)\n",
    "    if file != None:\n",
    "        model.save_model(file)\n",
    "    return train,valid,test\n",
    "\n",
    "def test_model(model,feature,y):\n",
    "    ind = ((y==4)|(y==1)|(y==2)|(y==3)|(y==6))\n",
    "    y_01 = y.copy()\n",
    "    y_01[ind] = 1\n",
    "    y_pred=model.predict(feature)\n",
    "    test = metrics.accuracy_score(y_01,y_pred>0.5)\n",
    "    print('acc:%f'%test)\n",
    "    return test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ind = ((y==1)|(y==2)|(y==3)|(y==6))\n",
    "ind = ((y==4)|(y==1)|(y==2)|(y==3)|(y==6))\n",
    "ind_f = [0,1,6,42,46,57,62]\n",
    "#y_01 = y[ind].copy()\n",
    "#y_01[y_01==1]=0\n",
    "#y_01[y_01==2]=1\n",
    "#y_01[y_01==3]=2\n",
    "#y_01[y_01==6]=3\n",
    "y_01 = y.copy()\n",
    "y_01[ind] = 1\n",
    "oh_ec = OneHotEncoder()\n",
    "y_oh = oh_ec.fit_transform(y_01[:,np.newaxis]).toarray()\n",
    "x_full,x_test,y_full,y_test = train_test_split(feature_sc,y_01,test_size=0.2,random_state=123,shuffle=False)\n",
    "x_train,x_valid,y_train,y_valid = train_test_split(x_full,y_full,test_size=0.2,random_state=555,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = layers.Input(shape=feature_sc.shape[1:])\n",
    "l1 = layers.Dense(128,activation='elu')(input_)\n",
    "drop1 = layers.Dropout(0.2)(l1)\n",
    "l2 = layers.Dense(64,activation='elu')(drop1)\n",
    "drop2 = layers.Dropout(0.2)(l2)\n",
    "l3 = layers.Dense(32,activation='elu')(drop2)\n",
    "drop3 = layers.Dropout(0.2)(l3)\n",
    "l4 = layers.Dense(16,activation='elu')(drop3)\n",
    "drop4 = layers.Dropout(0.2)(l4)\n",
    "output = layers.Dense(1,activation='sigmoid')(drop4)\n",
    "model = Model(inputs=[input_],outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = callbacks.EarlyStopping(patience = 20,\n",
    "                                         monitor = 'val_accuracy', \n",
    "                                         restore_best_weights=True)\n",
    "history = model.fit(x_train,y_train,validation_data=[x_valid,y_valid],\n",
    "                    epochs=200,batch_size=50,\n",
    "                   callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22313 samples, validate on 5579 samples\n",
      "Epoch 1/200\n",
      "22313/22313 [==============================] - 3s 128us/sample - loss: 0.3188 - accuracy: 0.8719 - val_loss: 0.2063 - val_accuracy: 0.9208\n",
      "Epoch 2/200\n",
      "22313/22313 [==============================] - 2s 73us/sample - loss: 0.2338 - accuracy: 0.9132 - val_loss: 0.1841 - val_accuracy: 0.9317\n",
      "Epoch 3/200\n",
      "22313/22313 [==============================] - 2s 70us/sample - loss: 0.2108 - accuracy: 0.9217 - val_loss: 0.1699 - val_accuracy: 0.9349\n",
      "Epoch 4/200\n",
      "22313/22313 [==============================] - 2s 72us/sample - loss: 0.1942 - accuracy: 0.9269 - val_loss: 0.1591 - val_accuracy: 0.9417\n",
      "Epoch 5/200\n",
      "22313/22313 [==============================] - 2s 74us/sample - loss: 0.1820 - accuracy: 0.9327 - val_loss: 0.1469 - val_accuracy: 0.9452\n",
      "Epoch 6/200\n",
      "22313/22313 [==============================] - 2s 72us/sample - loss: 0.1708 - accuracy: 0.9377 - val_loss: 0.1377 - val_accuracy: 0.9478\n",
      "Epoch 7/200\n",
      "22313/22313 [==============================] - 2s 74us/sample - loss: 0.1593 - accuracy: 0.9416 - val_loss: 0.1379 - val_accuracy: 0.9482\n",
      "Epoch 8/200\n",
      "22313/22313 [==============================] - 2s 72us/sample - loss: 0.1539 - accuracy: 0.9442 - val_loss: 0.1254 - val_accuracy: 0.9538\n",
      "Epoch 9/200\n",
      "22313/22313 [==============================] - 2s 70us/sample - loss: 0.1472 - accuracy: 0.9458 - val_loss: 0.1263 - val_accuracy: 0.9527\n",
      "Epoch 10/200\n",
      "22313/22313 [==============================] - 2s 69us/sample - loss: 0.1413 - accuracy: 0.9483 - val_loss: 0.1235 - val_accuracy: 0.9547\n",
      "Epoch 11/200\n",
      "22313/22313 [==============================] - 2s 71us/sample - loss: 0.1358 - accuracy: 0.9502 - val_loss: 0.1220 - val_accuracy: 0.9532\n",
      "Epoch 12/200\n",
      "22313/22313 [==============================] - 2s 72us/sample - loss: 0.1285 - accuracy: 0.9529 - val_loss: 0.1134 - val_accuracy: 0.9564\n",
      "Epoch 13/200\n",
      "22313/22313 [==============================] - 2s 73us/sample - loss: 0.1245 - accuracy: 0.9550 - val_loss: 0.1113 - val_accuracy: 0.9593\n",
      "Epoch 14/200\n",
      "22313/22313 [==============================] - 2s 71us/sample - loss: 0.1204 - accuracy: 0.9550 - val_loss: 0.1116 - val_accuracy: 0.9572\n",
      "Epoch 15/200\n",
      "22313/22313 [==============================] - 2s 72us/sample - loss: 0.1140 - accuracy: 0.9592 - val_loss: 0.1202 - val_accuracy: 0.9529\n",
      "Epoch 16/200\n",
      "22313/22313 [==============================] - 2s 70us/sample - loss: 0.1115 - accuracy: 0.9581 - val_loss: 0.1030 - val_accuracy: 0.9593\n",
      "Epoch 17/200\n",
      "22313/22313 [==============================] - 2s 72us/sample - loss: 0.1115 - accuracy: 0.9593 - val_loss: 0.1009 - val_accuracy: 0.9604\n",
      "Epoch 18/200\n",
      "22313/22313 [==============================] - 2s 72us/sample - loss: 0.1042 - accuracy: 0.9612 - val_loss: 0.1042 - val_accuracy: 0.9591\n",
      "Epoch 19/200\n",
      "22313/22313 [==============================] - 2s 73us/sample - loss: 0.1003 - accuracy: 0.9635 - val_loss: 0.1031 - val_accuracy: 0.9613\n",
      "Epoch 20/200\n",
      "22313/22313 [==============================] - 2s 74us/sample - loss: 0.0964 - accuracy: 0.9645 - val_loss: 0.0912 - val_accuracy: 0.9643\n",
      "Epoch 21/200\n",
      "22313/22313 [==============================] - 2s 72us/sample - loss: 0.0982 - accuracy: 0.9637 - val_loss: 0.0978 - val_accuracy: 0.9616\n",
      "Epoch 22/200\n",
      "22313/22313 [==============================] - 2s 76us/sample - loss: 0.0937 - accuracy: 0.9648 - val_loss: 0.0937 - val_accuracy: 0.9654\n",
      "Epoch 23/200\n",
      "22313/22313 [==============================] - 2s 72us/sample - loss: 0.0924 - accuracy: 0.9679 - val_loss: 0.0936 - val_accuracy: 0.9661\n",
      "Epoch 24/200\n",
      "22313/22313 [==============================] - 2s 73us/sample - loss: 0.0893 - accuracy: 0.9671 - val_loss: 0.0850 - val_accuracy: 0.9677\n",
      "Epoch 25/200\n",
      "22313/22313 [==============================] - 2s 72us/sample - loss: 0.0850 - accuracy: 0.9693 - val_loss: 0.0912 - val_accuracy: 0.9668\n",
      "Epoch 26/200\n",
      "22313/22313 [==============================] - 2s 71us/sample - loss: 0.0794 - accuracy: 0.9719 - val_loss: 0.0789 - val_accuracy: 0.9713\n",
      "Epoch 27/200\n",
      "22313/22313 [==============================] - 2s 74us/sample - loss: 0.0809 - accuracy: 0.9711 - val_loss: 0.0868 - val_accuracy: 0.9658\n",
      "Epoch 28/200\n",
      "22313/22313 [==============================] - 2s 72us/sample - loss: 0.0789 - accuracy: 0.9700 - val_loss: 0.0792 - val_accuracy: 0.9726\n",
      "Epoch 29/200\n",
      "22313/22313 [==============================] - 2s 71us/sample - loss: 0.0759 - accuracy: 0.9721 - val_loss: 0.0783 - val_accuracy: 0.9710\n",
      "Epoch 30/200\n",
      "22313/22313 [==============================] - 2s 72us/sample - loss: 0.0774 - accuracy: 0.9713 - val_loss: 0.0793 - val_accuracy: 0.9693\n",
      "Epoch 31/200\n",
      "22313/22313 [==============================] - 2s 74us/sample - loss: 0.0707 - accuracy: 0.9737 - val_loss: 0.0802 - val_accuracy: 0.9719\n",
      "Epoch 32/200\n",
      "22313/22313 [==============================] - 2s 72us/sample - loss: 0.0711 - accuracy: 0.9740 - val_loss: 0.0796 - val_accuracy: 0.9674\n",
      "Epoch 33/200\n",
      "22313/22313 [==============================] - 2s 74us/sample - loss: 0.0692 - accuracy: 0.9742 - val_loss: 0.0803 - val_accuracy: 0.9710\n",
      "Epoch 34/200\n",
      "22313/22313 [==============================] - 2s 72us/sample - loss: 0.0658 - accuracy: 0.9757 - val_loss: 0.0713 - val_accuracy: 0.9720\n",
      "Epoch 35/200\n",
      "22313/22313 [==============================] - 2s 72us/sample - loss: 0.0650 - accuracy: 0.9758 - val_loss: 0.0785 - val_accuracy: 0.9679\n",
      "Epoch 36/200\n",
      "22313/22313 [==============================] - 2s 76us/sample - loss: 0.0625 - accuracy: 0.9768 - val_loss: 0.0811 - val_accuracy: 0.9697\n",
      "Epoch 37/200\n",
      "22313/22313 [==============================] - 2s 73us/sample - loss: 0.0642 - accuracy: 0.9777 - val_loss: 0.0700 - val_accuracy: 0.9735\n",
      "Epoch 38/200\n",
      "22313/22313 [==============================] - 2s 74us/sample - loss: 0.0619 - accuracy: 0.9776 - val_loss: 0.0741 - val_accuracy: 0.9742\n",
      "Epoch 39/200\n",
      "22313/22313 [==============================] - 2s 72us/sample - loss: 0.0611 - accuracy: 0.9778 - val_loss: 0.0715 - val_accuracy: 0.9742\n",
      "Epoch 40/200\n",
      "22313/22313 [==============================] - 2s 73us/sample - loss: 0.0560 - accuracy: 0.9803 - val_loss: 0.0674 - val_accuracy: 0.9747\n",
      "Epoch 41/200\n",
      "22313/22313 [==============================] - 2s 72us/sample - loss: 0.0537 - accuracy: 0.9800 - val_loss: 0.0732 - val_accuracy: 0.9754\n",
      "Epoch 42/200\n",
      "22313/22313 [==============================] - 2s 75us/sample - loss: 0.0557 - accuracy: 0.9798 - val_loss: 0.0718 - val_accuracy: 0.9731\n",
      "Epoch 43/200\n",
      "22313/22313 [==============================] - 2s 75us/sample - loss: 0.0529 - accuracy: 0.9821 - val_loss: 0.0693 - val_accuracy: 0.9754\n",
      "Epoch 44/200\n",
      "22313/22313 [==============================] - 2s 74us/sample - loss: 0.0541 - accuracy: 0.9797 - val_loss: 0.0686 - val_accuracy: 0.9745\n",
      "Epoch 45/200\n",
      "22313/22313 [==============================] - 2s 73us/sample - loss: 0.0543 - accuracy: 0.9805 - val_loss: 0.0649 - val_accuracy: 0.9769\n",
      "Epoch 46/200\n",
      "22313/22313 [==============================] - 2s 73us/sample - loss: 0.0503 - accuracy: 0.9826 - val_loss: 0.0663 - val_accuracy: 0.9762\n",
      "Epoch 47/200\n",
      "22313/22313 [==============================] - 2s 71us/sample - loss: 0.0489 - accuracy: 0.9818 - val_loss: 0.0640 - val_accuracy: 0.9758\n",
      "Epoch 48/200\n",
      "22313/22313 [==============================] - 2s 73us/sample - loss: 0.0493 - accuracy: 0.9813 - val_loss: 0.0782 - val_accuracy: 0.9719\n",
      "Epoch 49/200\n",
      "22313/22313 [==============================] - 2s 75us/sample - loss: 0.0493 - accuracy: 0.9815 - val_loss: 0.0690 - val_accuracy: 0.9760\n",
      "Epoch 50/200\n",
      "22313/22313 [==============================] - 2s 75us/sample - loss: 0.0474 - accuracy: 0.9831 - val_loss: 0.0634 - val_accuracy: 0.9763\n",
      "Epoch 51/200\n",
      "22313/22313 [==============================] - 2s 74us/sample - loss: 0.0475 - accuracy: 0.9826 - val_loss: 0.0632 - val_accuracy: 0.9772\n",
      "Epoch 52/200\n",
      "22313/22313 [==============================] - 2s 72us/sample - loss: 0.0453 - accuracy: 0.9833 - val_loss: 0.0602 - val_accuracy: 0.9781\n",
      "Epoch 53/200\n",
      "22313/22313 [==============================] - 2s 74us/sample - loss: 0.0445 - accuracy: 0.9842 - val_loss: 0.0605 - val_accuracy: 0.9781\n",
      "Epoch 54/200\n",
      "22313/22313 [==============================] - 2s 73us/sample - loss: 0.0449 - accuracy: 0.9844 - val_loss: 0.0607 - val_accuracy: 0.9790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/200\n",
      "22313/22313 [==============================] - 2s 70us/sample - loss: 0.0427 - accuracy: 0.9842 - val_loss: 0.0656 - val_accuracy: 0.9787\n",
      "Epoch 56/200\n",
      "22313/22313 [==============================] - 2s 70us/sample - loss: 0.0442 - accuracy: 0.9845 - val_loss: 0.0569 - val_accuracy: 0.9796\n",
      "Epoch 57/200\n",
      "22313/22313 [==============================] - 2s 69us/sample - loss: 0.0412 - accuracy: 0.9860 - val_loss: 0.0690 - val_accuracy: 0.9771\n",
      "Epoch 58/200\n",
      "22313/22313 [==============================] - 2s 69us/sample - loss: 0.0420 - accuracy: 0.9850 - val_loss: 0.0699 - val_accuracy: 0.9780\n",
      "Epoch 59/200\n",
      "22313/22313 [==============================] - 2s 78us/sample - loss: 0.0399 - accuracy: 0.9862 - val_loss: 0.0658 - val_accuracy: 0.9781\n",
      "Epoch 60/200\n",
      "22313/22313 [==============================] - 2s 69us/sample - loss: 0.0362 - accuracy: 0.9870 - val_loss: 0.0754 - val_accuracy: 0.9763\n",
      "Epoch 61/200\n",
      "22313/22313 [==============================] - 2s 70us/sample - loss: 0.0423 - accuracy: 0.9844 - val_loss: 0.0602 - val_accuracy: 0.9778\n",
      "Epoch 62/200\n",
      "22313/22313 [==============================] - 2s 70us/sample - loss: 0.0375 - accuracy: 0.9868 - val_loss: 0.0740 - val_accuracy: 0.9771\n",
      "Epoch 63/200\n",
      "22313/22313 [==============================] - 2s 69us/sample - loss: 0.0385 - accuracy: 0.9862 - val_loss: 0.0650 - val_accuracy: 0.9794\n",
      "Epoch 64/200\n",
      "22313/22313 [==============================] - 2s 71us/sample - loss: 0.0402 - accuracy: 0.9860 - val_loss: 0.0624 - val_accuracy: 0.9788\n",
      "Epoch 65/200\n",
      "22313/22313 [==============================] - 1s 67us/sample - loss: 0.0354 - accuracy: 0.9876 - val_loss: 0.0574 - val_accuracy: 0.9812\n",
      "Epoch 66/200\n",
      "22313/22313 [==============================] - 2s 67us/sample - loss: 0.0390 - accuracy: 0.9864 - val_loss: 0.0591 - val_accuracy: 0.9796\n",
      "Epoch 67/200\n",
      "22313/22313 [==============================] - 2s 68us/sample - loss: 0.0321 - accuracy: 0.9890 - val_loss: 0.0665 - val_accuracy: 0.9776\n",
      "Epoch 68/200\n",
      "22313/22313 [==============================] - 2s 69us/sample - loss: 0.0374 - accuracy: 0.9867 - val_loss: 0.0603 - val_accuracy: 0.9785\n",
      "Epoch 69/200\n",
      "22313/22313 [==============================] - 2s 70us/sample - loss: 0.0307 - accuracy: 0.9894 - val_loss: 0.0672 - val_accuracy: 0.9806\n",
      "Epoch 70/200\n",
      "22313/22313 [==============================] - 2s 68us/sample - loss: 0.0365 - accuracy: 0.9875 - val_loss: 0.0638 - val_accuracy: 0.9806\n",
      "Epoch 71/200\n",
      "22313/22313 [==============================] - 2s 89us/sample - loss: 0.0334 - accuracy: 0.9880 - val_loss: 0.0591 - val_accuracy: 0.9821\n",
      "Epoch 72/200\n",
      "22313/22313 [==============================] - 2s 90us/sample - loss: 0.0329 - accuracy: 0.9877 - val_loss: 0.0588 - val_accuracy: 0.9839\n",
      "Epoch 73/200\n",
      "22313/22313 [==============================] - 2s 72us/sample - loss: 0.0312 - accuracy: 0.9892 - val_loss: 0.0580 - val_accuracy: 0.9797\n",
      "Epoch 74/200\n",
      "22313/22313 [==============================] - 2s 69us/sample - loss: 0.0340 - accuracy: 0.9877 - val_loss: 0.0568 - val_accuracy: 0.9819\n",
      "Epoch 75/200\n",
      "22313/22313 [==============================] - 2s 69us/sample - loss: 0.0314 - accuracy: 0.9891 - val_loss: 0.0667 - val_accuracy: 0.9806\n",
      "Epoch 76/200\n",
      "22313/22313 [==============================] - 2s 68us/sample - loss: 0.0334 - accuracy: 0.9886 - val_loss: 0.0562 - val_accuracy: 0.9821\n",
      "Epoch 77/200\n",
      "22313/22313 [==============================] - 2s 68us/sample - loss: 0.0310 - accuracy: 0.9894 - val_loss: 0.0590 - val_accuracy: 0.9821\n",
      "Epoch 78/200\n",
      "22313/22313 [==============================] - 2s 67us/sample - loss: 0.0304 - accuracy: 0.9886 - val_loss: 0.0649 - val_accuracy: 0.9806\n",
      "Epoch 79/200\n",
      "22313/22313 [==============================] - 2s 69us/sample - loss: 0.0327 - accuracy: 0.9882 - val_loss: 0.0626 - val_accuracy: 0.9824\n",
      "Epoch 80/200\n",
      "22313/22313 [==============================] - 2s 69us/sample - loss: 0.0294 - accuracy: 0.9901 - val_loss: 0.0602 - val_accuracy: 0.9821\n",
      "Epoch 81/200\n",
      "22313/22313 [==============================] - 2s 69us/sample - loss: 0.0287 - accuracy: 0.9897 - val_loss: 0.0590 - val_accuracy: 0.9823\n",
      "Epoch 82/200\n",
      "22313/22313 [==============================] - 2s 70us/sample - loss: 0.0301 - accuracy: 0.9892 - val_loss: 0.0601 - val_accuracy: 0.9806\n",
      "Epoch 83/200\n",
      "22313/22313 [==============================] - 2s 69us/sample - loss: 0.0288 - accuracy: 0.9900 - val_loss: 0.0670 - val_accuracy: 0.9792\n",
      "Epoch 84/200\n",
      "22313/22313 [==============================] - 2s 68us/sample - loss: 0.0290 - accuracy: 0.9903 - val_loss: 0.0607 - val_accuracy: 0.9815\n",
      "Epoch 85/200\n",
      "22313/22313 [==============================] - 2s 69us/sample - loss: 0.0266 - accuracy: 0.9906 - val_loss: 0.0649 - val_accuracy: 0.9832\n",
      "Epoch 86/200\n",
      "22313/22313 [==============================] - 2s 69us/sample - loss: 0.0265 - accuracy: 0.9905 - val_loss: 0.0573 - val_accuracy: 0.9837\n",
      "Epoch 87/200\n",
      "22313/22313 [==============================] - 2s 69us/sample - loss: 0.0285 - accuracy: 0.9897 - val_loss: 0.0575 - val_accuracy: 0.9815\n",
      "Epoch 88/200\n",
      "22313/22313 [==============================] - 2s 69us/sample - loss: 0.0266 - accuracy: 0.9901 - val_loss: 0.0688 - val_accuracy: 0.9792\n",
      "Epoch 89/200\n",
      "22313/22313 [==============================] - 2s 69us/sample - loss: 0.0290 - accuracy: 0.9901 - val_loss: 0.0589 - val_accuracy: 0.9826\n",
      "Epoch 90/200\n",
      "22313/22313 [==============================] - 2s 68us/sample - loss: 0.0295 - accuracy: 0.9894 - val_loss: 0.0512 - val_accuracy: 0.9840\n",
      "Epoch 91/200\n",
      "22313/22313 [==============================] - 2s 68us/sample - loss: 0.0256 - accuracy: 0.9913 - val_loss: 0.0632 - val_accuracy: 0.9833\n",
      "Epoch 92/200\n",
      "22313/22313 [==============================] - 2s 69us/sample - loss: 0.0243 - accuracy: 0.9912 - val_loss: 0.0599 - val_accuracy: 0.9828\n",
      "Epoch 93/200\n",
      "22313/22313 [==============================] - 2s 69us/sample - loss: 0.0257 - accuracy: 0.9913 - val_loss: 0.0551 - val_accuracy: 0.9853\n",
      "Epoch 94/200\n",
      "22313/22313 [==============================] - 2s 70us/sample - loss: 0.0268 - accuracy: 0.9905 - val_loss: 0.0632 - val_accuracy: 0.9806\n",
      "Epoch 95/200\n",
      "22313/22313 [==============================] - 2s 69us/sample - loss: 0.0256 - accuracy: 0.9912 - val_loss: 0.0742 - val_accuracy: 0.9805\n",
      "Epoch 96/200\n",
      "22313/22313 [==============================] - 2s 70us/sample - loss: 0.0288 - accuracy: 0.9902 - val_loss: 0.0576 - val_accuracy: 0.9842\n",
      "Epoch 97/200\n",
      "22313/22313 [==============================] - 2s 74us/sample - loss: 0.0251 - accuracy: 0.9916 - val_loss: 0.0644 - val_accuracy: 0.9823\n",
      "Epoch 98/200\n",
      "22313/22313 [==============================] - 2s 68us/sample - loss: 0.0245 - accuracy: 0.9912 - val_loss: 0.0576 - val_accuracy: 0.9837\n",
      "Epoch 99/200\n",
      "22313/22313 [==============================] - 2s 70us/sample - loss: 0.0234 - accuracy: 0.9920 - val_loss: 0.0602 - val_accuracy: 0.9830\n",
      "Epoch 100/200\n",
      "22313/22313 [==============================] - 2s 70us/sample - loss: 0.0280 - accuracy: 0.9911 - val_loss: 0.0581 - val_accuracy: 0.9821\n",
      "Epoch 101/200\n",
      "22313/22313 [==============================] - 2s 69us/sample - loss: 0.0237 - accuracy: 0.9913 - val_loss: 0.0536 - val_accuracy: 0.9848\n",
      "Epoch 102/200\n",
      "22313/22313 [==============================] - 2s 69us/sample - loss: 0.0252 - accuracy: 0.9907 - val_loss: 0.0538 - val_accuracy: 0.9840\n",
      "Epoch 103/200\n",
      "22313/22313 [==============================] - 2s 68us/sample - loss: 0.0237 - accuracy: 0.9914 - val_loss: 0.0545 - val_accuracy: 0.9844\n",
      "Epoch 104/200\n",
      "22313/22313 [==============================] - 2s 67us/sample - loss: 0.0209 - accuracy: 0.9923 - val_loss: 0.0705 - val_accuracy: 0.9814\n",
      "Epoch 105/200\n",
      "22313/22313 [==============================] - 2s 70us/sample - loss: 0.0238 - accuracy: 0.9918 - val_loss: 0.0703 - val_accuracy: 0.9840\n",
      "Epoch 106/200\n",
      "22313/22313 [==============================] - 2s 70us/sample - loss: 0.0254 - accuracy: 0.9917 - val_loss: 0.0544 - val_accuracy: 0.9830\n",
      "Epoch 107/200\n",
      "22313/22313 [==============================] - 2s 70us/sample - loss: 0.0223 - accuracy: 0.9928 - val_loss: 0.0617 - val_accuracy: 0.9828\n",
      "Epoch 108/200\n",
      "22313/22313 [==============================] - 2s 69us/sample - loss: 0.0222 - accuracy: 0.9930 - val_loss: 0.0591 - val_accuracy: 0.9824\n",
      "Epoch 109/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22313/22313 [==============================] - 2s 68us/sample - loss: 0.0229 - accuracy: 0.9921 - val_loss: 0.0602 - val_accuracy: 0.9835\n",
      "Epoch 110/200\n",
      "22313/22313 [==============================] - 1s 67us/sample - loss: 0.0254 - accuracy: 0.9911 - val_loss: 0.0586 - val_accuracy: 0.9833\n",
      "Epoch 111/200\n",
      "22313/22313 [==============================] - 2s 82us/sample - loss: 0.0242 - accuracy: 0.9917 - val_loss: 0.0524 - val_accuracy: 0.9846\n",
      "Epoch 112/200\n",
      "22313/22313 [==============================] - 2s 108us/sample - loss: 0.0204 - accuracy: 0.9931 - val_loss: 0.0558 - val_accuracy: 0.9833\n",
      "Epoch 113/200\n",
      "22313/22313 [==============================] - 2s 86us/sample - loss: 0.0222 - accuracy: 0.9926 - val_loss: 0.0550 - val_accuracy: 0.9808\n",
      "test:0.943648\n",
      "valid:0.985302\n",
      "train:0.999417\n",
      "acc:0.960683\n"
     ]
    }
   ],
   "source": [
    "sc = StandardScaler(with_mean=True)\n",
    "feature_sc = sc.fit_transform(feature)\n",
    "feature2_sc = sc.transform(feature2)\n",
    "#pca = PCA(n_components=160,copy=True)\n",
    "#feature_pca = pca.fit_transform(feature)\n",
    "#feature2_pca = pca.transform(feature2)\n",
    "train,valid,test = train_model(model,feature_sc,np.array(y),True)\n",
    "rest = test_model(model,feature2_sc,np.array(y2))\n",
    "acc = [train,valid,test,rest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:0.961351\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9613514827418571"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(model,feature2_sc,np.array(y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3498,  205,  215],\n",
       "       [ 147, 6362,   61],\n",
       "       [ 165,   58, 3178]], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_model(model,feature2_sc,np.array(y2))\n",
    "ind = ((y==1)|(y==2)|(y==6))\n",
    "y_01 = y[ind].copy()\n",
    "oc = OneHotEncoder()\n",
    "y_01 = oc.fit_transform(np.array(y_01)[:,np.newaxis]).toarray()\n",
    "pred=model.predict(feature_sc[ind,:])\n",
    "np.argmax(pred,axis=1)\n",
    "np.argmax(y_01,axis=1)\n",
    "metrics.confusion_matrix(np.argmax(y_01,axis=1),np.argmax(pred,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>valid</th>\n",
       "      <th>test</th>\n",
       "      <th>rest data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all_TT</th>\n",
       "      <td>0.999597</td>\n",
       "      <td>0.975802</td>\n",
       "      <td>0.973616</td>\n",
       "      <td>0.984079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drop_mDWT</th>\n",
       "      <td>0.999910</td>\n",
       "      <td>0.978849</td>\n",
       "      <td>0.978348</td>\n",
       "      <td>0.984524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              train     valid      test  rest data\n",
       "all_TT     0.999597  0.975802  0.973616   0.984079\n",
       "drop_mDWT  0.999910  0.978849  0.978348   0.984524"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#acc_ann = pd.DataFrame([0.9995966476941693, 0.9758021150743861, 0.9736162890737023,0.9840787554691298],columns=['all_TT'],index=['train','valid','test','rest data'])\n",
    "#acc_ann=acc_ann.T\n",
    "#acc_ann.loc['drop_mDWT',:]=[train,valid,test,rest]\n",
    "acc_ann"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test feature from Left or Right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22313 samples, validate on 5579 samples\n",
      "Epoch 1/200\n",
      "22313/22313 [==============================] - 2s 99us/sample - loss: 0.3881 - accuracy: 0.8370 - val_loss: 0.2879 - val_accuracy: 0.8901\n",
      "Epoch 2/200\n",
      "22313/22313 [==============================] - 1s 63us/sample - loss: 0.3186 - accuracy: 0.8696 - val_loss: 0.2700 - val_accuracy: 0.8953\n",
      "Epoch 3/200\n",
      "22313/22313 [==============================] - 1s 55us/sample - loss: 0.2965 - accuracy: 0.8804 - val_loss: 0.2495 - val_accuracy: 0.9046\n",
      "Epoch 4/200\n",
      "22313/22313 [==============================] - 1s 57us/sample - loss: 0.2836 - accuracy: 0.8871 - val_loss: 0.2379 - val_accuracy: 0.9072\n",
      "Epoch 5/200\n",
      "22313/22313 [==============================] - 1s 66us/sample - loss: 0.2686 - accuracy: 0.8953 - val_loss: 0.2283 - val_accuracy: 0.9120\n",
      "Epoch 6/200\n",
      "22313/22313 [==============================] - 1s 56us/sample - loss: 0.2626 - accuracy: 0.8985 - val_loss: 0.2242 - val_accuracy: 0.9161\n",
      "Epoch 7/200\n",
      "22313/22313 [==============================] - 1s 58us/sample - loss: 0.2525 - accuracy: 0.9023 - val_loss: 0.2237 - val_accuracy: 0.9165\n",
      "Epoch 8/200\n",
      "22313/22313 [==============================] - 1s 54us/sample - loss: 0.2474 - accuracy: 0.9048 - val_loss: 0.2104 - val_accuracy: 0.9226\n",
      "Epoch 9/200\n",
      "22313/22313 [==============================] - 1s 59us/sample - loss: 0.2389 - accuracy: 0.9082 - val_loss: 0.2093 - val_accuracy: 0.9226\n",
      "Epoch 10/200\n",
      "22313/22313 [==============================] - 1s 66us/sample - loss: 0.2360 - accuracy: 0.9078 - val_loss: 0.2050 - val_accuracy: 0.9186\n",
      "Epoch 11/200\n",
      "22313/22313 [==============================] - 2s 84us/sample - loss: 0.2309 - accuracy: 0.9106 - val_loss: 0.1981 - val_accuracy: 0.9254\n",
      "Epoch 12/200\n",
      "22313/22313 [==============================] - 2s 93us/sample - loss: 0.2299 - accuracy: 0.9113 - val_loss: 0.2000 - val_accuracy: 0.9224\n",
      "Epoch 13/200\n",
      "22313/22313 [==============================] - 2s 84us/sample - loss: 0.2225 - accuracy: 0.9173 - val_loss: 0.1946 - val_accuracy: 0.9262\n",
      "Epoch 14/200\n",
      "22313/22313 [==============================] - 2s 81us/sample - loss: 0.2190 - accuracy: 0.9176 - val_loss: 0.1919 - val_accuracy: 0.9265\n",
      "Epoch 15/200\n",
      "22313/22313 [==============================] - 2s 85us/sample - loss: 0.2167 - accuracy: 0.9168 - val_loss: 0.1939 - val_accuracy: 0.9263\n",
      "Epoch 16/200\n",
      "22313/22313 [==============================] - 2s 84us/sample - loss: 0.2149 - accuracy: 0.9168 - val_loss: 0.1880 - val_accuracy: 0.9285\n",
      "Epoch 17/200\n",
      "22313/22313 [==============================] - 2s 83us/sample - loss: 0.2075 - accuracy: 0.9217 - val_loss: 0.1909 - val_accuracy: 0.9281\n",
      "Epoch 18/200\n",
      "22313/22313 [==============================] - 2s 89us/sample - loss: 0.2045 - accuracy: 0.9243 - val_loss: 0.1883 - val_accuracy: 0.9288\n",
      "Epoch 19/200\n",
      "22313/22313 [==============================] - 2s 81us/sample - loss: 0.2037 - accuracy: 0.9226 - val_loss: 0.1835 - val_accuracy: 0.9290\n",
      "Epoch 20/200\n",
      "22313/22313 [==============================] - 2s 85us/sample - loss: 0.2006 - accuracy: 0.9247 - val_loss: 0.1896 - val_accuracy: 0.9278\n",
      "Epoch 21/200\n",
      "22313/22313 [==============================] - 2s 94us/sample - loss: 0.1963 - accuracy: 0.9268 - val_loss: 0.1843 - val_accuracy: 0.9305\n",
      "Epoch 22/200\n",
      "22313/22313 [==============================] - 2s 88us/sample - loss: 0.1961 - accuracy: 0.9266 - val_loss: 0.1787 - val_accuracy: 0.9297\n",
      "Epoch 23/200\n",
      "22313/22313 [==============================] - 2s 93us/sample - loss: 0.1905 - accuracy: 0.9287 - val_loss: 0.1829 - val_accuracy: 0.9321\n",
      "Epoch 24/200\n",
      "22313/22313 [==============================] - 2s 90us/sample - loss: 0.1904 - accuracy: 0.9286 - val_loss: 0.1723 - val_accuracy: 0.9331\n",
      "Epoch 25/200\n",
      "22313/22313 [==============================] - 2s 77us/sample - loss: 0.1868 - accuracy: 0.9303 - val_loss: 0.1726 - val_accuracy: 0.9349\n",
      "Epoch 26/200\n",
      "22313/22313 [==============================] - 2s 85us/sample - loss: 0.1832 - accuracy: 0.9291 - val_loss: 0.1749 - val_accuracy: 0.9312\n",
      "Epoch 27/200\n",
      "22313/22313 [==============================] - 2s 86us/sample - loss: 0.1829 - accuracy: 0.9300 - val_loss: 0.1690 - val_accuracy: 0.9355\n",
      "Epoch 28/200\n",
      "22313/22313 [==============================] - 2s 82us/sample - loss: 0.1841 - accuracy: 0.9296 - val_loss: 0.1700 - val_accuracy: 0.9340\n",
      "Epoch 29/200\n",
      "22313/22313 [==============================] - 2s 81us/sample - loss: 0.1784 - accuracy: 0.9329 - val_loss: 0.1718 - val_accuracy: 0.9358\n",
      "Epoch 30/200\n",
      "22313/22313 [==============================] - 2s 78us/sample - loss: 0.1771 - accuracy: 0.9340 - val_loss: 0.1605 - val_accuracy: 0.9373\n",
      "Epoch 31/200\n",
      "22313/22313 [==============================] - 2s 82us/sample - loss: 0.1781 - accuracy: 0.9331 - val_loss: 0.1644 - val_accuracy: 0.9400\n",
      "Epoch 32/200\n",
      "22313/22313 [==============================] - 2s 77us/sample - loss: 0.1725 - accuracy: 0.9349 - val_loss: 0.1634 - val_accuracy: 0.9355\n",
      "Epoch 33/200\n",
      "22313/22313 [==============================] - 2s 80us/sample - loss: 0.1703 - accuracy: 0.9342 - val_loss: 0.1625 - val_accuracy: 0.9380\n",
      "Epoch 34/200\n",
      "22313/22313 [==============================] - 2s 83us/sample - loss: 0.1743 - accuracy: 0.9344 - val_loss: 0.1598 - val_accuracy: 0.9371\n",
      "Epoch 35/200\n",
      "22313/22313 [==============================] - 2s 77us/sample - loss: 0.1698 - accuracy: 0.9354 - val_loss: 0.1649 - val_accuracy: 0.9371\n",
      "Epoch 36/200\n",
      "22313/22313 [==============================] - 2s 79us/sample - loss: 0.1669 - accuracy: 0.9373 - val_loss: 0.1578 - val_accuracy: 0.9394\n",
      "Epoch 37/200\n",
      "22313/22313 [==============================] - 2s 80us/sample - loss: 0.1660 - accuracy: 0.9377 - val_loss: 0.1565 - val_accuracy: 0.9398\n",
      "Epoch 38/200\n",
      "22313/22313 [==============================] - 2s 81us/sample - loss: 0.1650 - accuracy: 0.9381 - val_loss: 0.1552 - val_accuracy: 0.9421\n",
      "Epoch 39/200\n",
      "22313/22313 [==============================] - 2s 80us/sample - loss: 0.1612 - accuracy: 0.9405 - val_loss: 0.1528 - val_accuracy: 0.9410\n",
      "Epoch 40/200\n",
      "22313/22313 [==============================] - 2s 82us/sample - loss: 0.1593 - accuracy: 0.9409 - val_loss: 0.1551 - val_accuracy: 0.9426\n",
      "Epoch 41/200\n",
      "22313/22313 [==============================] - 2s 81us/sample - loss: 0.1600 - accuracy: 0.9397 - val_loss: 0.1532 - val_accuracy: 0.9401\n",
      "Epoch 42/200\n",
      "22313/22313 [==============================] - 2s 83us/sample - loss: 0.1560 - accuracy: 0.9408 - val_loss: 0.1535 - val_accuracy: 0.9400\n",
      "Epoch 43/200\n",
      "22313/22313 [==============================] - 2s 80us/sample - loss: 0.1581 - accuracy: 0.9407 - val_loss: 0.1572 - val_accuracy: 0.9396\n",
      "Epoch 44/200\n",
      "22313/22313 [==============================] - 2s 83us/sample - loss: 0.1591 - accuracy: 0.9399 - val_loss: 0.1529 - val_accuracy: 0.9439\n",
      "Epoch 45/200\n",
      "22313/22313 [==============================] - 2s 85us/sample - loss: 0.1520 - accuracy: 0.9440 - val_loss: 0.1512 - val_accuracy: 0.9437\n",
      "Epoch 46/200\n",
      "22313/22313 [==============================] - 2s 80us/sample - loss: 0.1530 - accuracy: 0.9429 - val_loss: 0.1532 - val_accuracy: 0.9419\n",
      "Epoch 47/200\n",
      "22313/22313 [==============================] - 2s 96us/sample - loss: 0.1502 - accuracy: 0.9430 - val_loss: 0.1508 - val_accuracy: 0.9419\n",
      "Epoch 48/200\n",
      "22313/22313 [==============================] - 2s 87us/sample - loss: 0.1510 - accuracy: 0.9437 - val_loss: 0.1436 - val_accuracy: 0.9464\n",
      "Epoch 49/200\n",
      "22313/22313 [==============================] - 2s 83us/sample - loss: 0.1484 - accuracy: 0.9442 - val_loss: 0.1514 - val_accuracy: 0.9430\n",
      "Epoch 50/200\n",
      "22313/22313 [==============================] - 2s 85us/sample - loss: 0.1456 - accuracy: 0.9449 - val_loss: 0.1444 - val_accuracy: 0.9448\n",
      "Epoch 51/200\n",
      "22313/22313 [==============================] - 2s 88us/sample - loss: 0.1477 - accuracy: 0.9448 - val_loss: 0.1445 - val_accuracy: 0.9444\n",
      "Epoch 52/200\n",
      "22313/22313 [==============================] - 2s 82us/sample - loss: 0.1435 - accuracy: 0.9464 - val_loss: 0.1495 - val_accuracy: 0.9435\n",
      "Epoch 53/200\n",
      "22313/22313 [==============================] - 2s 83us/sample - loss: 0.1482 - accuracy: 0.9436 - val_loss: 0.1478 - val_accuracy: 0.9448\n",
      "Epoch 54/200\n",
      "22313/22313 [==============================] - 1s 59us/sample - loss: 0.1423 - accuracy: 0.9464 - val_loss: 0.1470 - val_accuracy: 0.9450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/200\n",
      "22313/22313 [==============================] - 1s 55us/sample - loss: 0.1405 - accuracy: 0.9469 - val_loss: 0.1475 - val_accuracy: 0.9469\n",
      "Epoch 56/200\n",
      "22313/22313 [==============================] - 1s 58us/sample - loss: 0.1398 - accuracy: 0.9465 - val_loss: 0.1416 - val_accuracy: 0.9471\n",
      "Epoch 57/200\n",
      "22313/22313 [==============================] - 1s 58us/sample - loss: 0.1387 - accuracy: 0.9491 - val_loss: 0.1482 - val_accuracy: 0.9441\n",
      "Epoch 58/200\n",
      "22313/22313 [==============================] - 1s 53us/sample - loss: 0.1408 - accuracy: 0.9469 - val_loss: 0.1416 - val_accuracy: 0.9443\n",
      "Epoch 59/200\n",
      "22313/22313 [==============================] - 1s 54us/sample - loss: 0.1371 - accuracy: 0.9486 - val_loss: 0.1397 - val_accuracy: 0.9441\n",
      "Epoch 60/200\n",
      "22313/22313 [==============================] - 1s 55us/sample - loss: 0.1342 - accuracy: 0.9502 - val_loss: 0.1420 - val_accuracy: 0.9441\n",
      "Epoch 61/200\n",
      "22313/22313 [==============================] - 1s 55us/sample - loss: 0.1354 - accuracy: 0.9484 - val_loss: 0.1344 - val_accuracy: 0.9457\n",
      "Epoch 62/200\n",
      "22313/22313 [==============================] - 1s 54us/sample - loss: 0.1325 - accuracy: 0.9521 - val_loss: 0.1446 - val_accuracy: 0.9452\n",
      "Epoch 63/200\n",
      "22313/22313 [==============================] - 1s 55us/sample - loss: 0.1381 - accuracy: 0.9486 - val_loss: 0.1359 - val_accuracy: 0.9475\n",
      "Epoch 64/200\n",
      "22313/22313 [==============================] - 1s 59us/sample - loss: 0.1317 - accuracy: 0.9506 - val_loss: 0.1354 - val_accuracy: 0.9462\n",
      "Epoch 65/200\n",
      "22313/22313 [==============================] - 1s 55us/sample - loss: 0.1324 - accuracy: 0.9491 - val_loss: 0.1355 - val_accuracy: 0.9507\n",
      "Epoch 66/200\n",
      "22313/22313 [==============================] - 1s 55us/sample - loss: 0.1313 - accuracy: 0.9515 - val_loss: 0.1349 - val_accuracy: 0.9529\n",
      "Epoch 67/200\n",
      "22313/22313 [==============================] - 1s 60us/sample - loss: 0.1271 - accuracy: 0.9523 - val_loss: 0.1385 - val_accuracy: 0.9487\n",
      "Epoch 68/200\n",
      "22313/22313 [==============================] - 1s 65us/sample - loss: 0.1301 - accuracy: 0.9498 - val_loss: 0.1332 - val_accuracy: 0.9486\n",
      "Epoch 69/200\n",
      "22313/22313 [==============================] - 1s 56us/sample - loss: 0.1235 - accuracy: 0.9522 - val_loss: 0.1339 - val_accuracy: 0.9493\n",
      "Epoch 70/200\n",
      "22313/22313 [==============================] - 1s 56us/sample - loss: 0.1303 - accuracy: 0.9522 - val_loss: 0.1377 - val_accuracy: 0.9487\n",
      "Epoch 71/200\n",
      "22313/22313 [==============================] - 1s 55us/sample - loss: 0.1272 - accuracy: 0.9522 - val_loss: 0.1393 - val_accuracy: 0.9477\n",
      "Epoch 72/200\n",
      "22313/22313 [==============================] - 1s 55us/sample - loss: 0.1242 - accuracy: 0.9552 - val_loss: 0.1409 - val_accuracy: 0.9478\n",
      "Epoch 73/200\n",
      "22313/22313 [==============================] - 1s 54us/sample - loss: 0.1270 - accuracy: 0.9533 - val_loss: 0.1319 - val_accuracy: 0.9512\n",
      "Epoch 74/200\n",
      "22313/22313 [==============================] - 1s 54us/sample - loss: 0.1235 - accuracy: 0.9543 - val_loss: 0.1342 - val_accuracy: 0.9500\n",
      "Epoch 75/200\n",
      "22313/22313 [==============================] - 1s 55us/sample - loss: 0.1240 - accuracy: 0.9523 - val_loss: 0.1342 - val_accuracy: 0.9509\n",
      "Epoch 76/200\n",
      "22313/22313 [==============================] - 1s 58us/sample - loss: 0.1192 - accuracy: 0.9557 - val_loss: 0.1369 - val_accuracy: 0.9498\n",
      "Epoch 77/200\n",
      "22313/22313 [==============================] - 1s 53us/sample - loss: 0.1200 - accuracy: 0.9559 - val_loss: 0.1396 - val_accuracy: 0.9489\n",
      "Epoch 78/200\n",
      "22313/22313 [==============================] - 1s 55us/sample - loss: 0.1184 - accuracy: 0.9554 - val_loss: 0.1330 - val_accuracy: 0.9500\n",
      "Epoch 79/200\n",
      "22313/22313 [==============================] - 1s 54us/sample - loss: 0.1206 - accuracy: 0.9543 - val_loss: 0.1306 - val_accuracy: 0.9520\n",
      "Epoch 80/200\n",
      "22313/22313 [==============================] - 1s 57us/sample - loss: 0.1177 - accuracy: 0.9560 - val_loss: 0.1326 - val_accuracy: 0.9505\n",
      "Epoch 81/200\n",
      "22313/22313 [==============================] - 1s 55us/sample - loss: 0.1198 - accuracy: 0.9542 - val_loss: 0.1364 - val_accuracy: 0.9507\n",
      "Epoch 82/200\n",
      "22313/22313 [==============================] - 1s 62us/sample - loss: 0.1192 - accuracy: 0.9558 - val_loss: 0.1314 - val_accuracy: 0.9512\n",
      "Epoch 83/200\n",
      "22313/22313 [==============================] - 1s 58us/sample - loss: 0.1169 - accuracy: 0.9582 - val_loss: 0.1288 - val_accuracy: 0.9507\n",
      "Epoch 84/200\n",
      "22313/22313 [==============================] - 1s 62us/sample - loss: 0.1133 - accuracy: 0.9585 - val_loss: 0.1330 - val_accuracy: 0.9511\n",
      "Epoch 85/200\n",
      "22313/22313 [==============================] - 1s 55us/sample - loss: 0.1136 - accuracy: 0.9574 - val_loss: 0.1270 - val_accuracy: 0.9521\n",
      "Epoch 86/200\n",
      "22313/22313 [==============================] - 1s 56us/sample - loss: 0.1176 - accuracy: 0.9564 - val_loss: 0.1282 - val_accuracy: 0.9507\n",
      "test:0.918268\n",
      "valid:0.952859\n",
      "train:0.971452\n",
      "acc:0.923675\n",
      "0.9236752552260573\n",
      "Train on 22313 samples, validate on 5579 samples\n",
      "Epoch 1/200\n",
      "22313/22313 [==============================] - 1s 56us/sample - loss: 0.3813 - accuracy: 0.8455 - val_loss: 0.2771 - val_accuracy: 0.8955\n",
      "Epoch 2/200\n",
      "22313/22313 [==============================] - 1s 56us/sample - loss: 0.3087 - accuracy: 0.8788 - val_loss: 0.2505 - val_accuracy: 0.9036\n",
      "Epoch 3/200\n",
      "22313/22313 [==============================] - 1s 54us/sample - loss: 0.2842 - accuracy: 0.8863 - val_loss: 0.2330 - val_accuracy: 0.9106\n",
      "Epoch 4/200\n",
      "22313/22313 [==============================] - 1s 56us/sample - loss: 0.2679 - accuracy: 0.8935 - val_loss: 0.2222 - val_accuracy: 0.9134\n",
      "Epoch 5/200\n",
      "22313/22313 [==============================] - 1s 55us/sample - loss: 0.2589 - accuracy: 0.8999 - val_loss: 0.2115 - val_accuracy: 0.9210\n",
      "Epoch 6/200\n",
      "22313/22313 [==============================] - 1s 67us/sample - loss: 0.2417 - accuracy: 0.9058 - val_loss: 0.2073 - val_accuracy: 0.9224\n",
      "Epoch 7/200\n",
      "22313/22313 [==============================] - 1s 58us/sample - loss: 0.2377 - accuracy: 0.9080 - val_loss: 0.2024 - val_accuracy: 0.9211\n",
      "Epoch 8/200\n",
      "22313/22313 [==============================] - 1s 60us/sample - loss: 0.2307 - accuracy: 0.9094 - val_loss: 0.1986 - val_accuracy: 0.9229\n",
      "Epoch 9/200\n",
      "22313/22313 [==============================] - 1s 55us/sample - loss: 0.2247 - accuracy: 0.9123 - val_loss: 0.1935 - val_accuracy: 0.9245\n",
      "Epoch 10/200\n",
      "22313/22313 [==============================] - 1s 55us/sample - loss: 0.2195 - accuracy: 0.9129 - val_loss: 0.1869 - val_accuracy: 0.9276\n",
      "Epoch 11/200\n",
      "22313/22313 [==============================] - 1s 57us/sample - loss: 0.2192 - accuracy: 0.9135 - val_loss: 0.1863 - val_accuracy: 0.9269\n",
      "Epoch 12/200\n",
      "22313/22313 [==============================] - 1s 53us/sample - loss: 0.2082 - accuracy: 0.9206 - val_loss: 0.1849 - val_accuracy: 0.9294\n",
      "Epoch 13/200\n",
      "22313/22313 [==============================] - 1s 55us/sample - loss: 0.2030 - accuracy: 0.9216 - val_loss: 0.1767 - val_accuracy: 0.9296\n",
      "Epoch 14/200\n",
      "22313/22313 [==============================] - 1s 54us/sample - loss: 0.2026 - accuracy: 0.9237 - val_loss: 0.1759 - val_accuracy: 0.9292\n",
      "Epoch 15/200\n",
      "22313/22313 [==============================] - 1s 63us/sample - loss: 0.1981 - accuracy: 0.9248 - val_loss: 0.1714 - val_accuracy: 0.9337\n",
      "Epoch 16/200\n",
      "22313/22313 [==============================] - 1s 56us/sample - loss: 0.1913 - accuracy: 0.9252 - val_loss: 0.1717 - val_accuracy: 0.9339\n",
      "Epoch 17/200\n",
      "22313/22313 [==============================] - 1s 54us/sample - loss: 0.1866 - accuracy: 0.9270 - val_loss: 0.1684 - val_accuracy: 0.9342\n",
      "Epoch 18/200\n",
      "22313/22313 [==============================] - 1s 55us/sample - loss: 0.1865 - accuracy: 0.9268 - val_loss: 0.1675 - val_accuracy: 0.9349\n",
      "Epoch 19/200\n",
      "22313/22313 [==============================] - 2s 84us/sample - loss: 0.1841 - accuracy: 0.9291 - val_loss: 0.1643 - val_accuracy: 0.9364\n",
      "Epoch 20/200\n",
      "22313/22313 [==============================] - 1s 57us/sample - loss: 0.1818 - accuracy: 0.9303 - val_loss: 0.1634 - val_accuracy: 0.9396\n",
      "Epoch 21/200\n",
      "22313/22313 [==============================] - 1s 54us/sample - loss: 0.1787 - accuracy: 0.9321 - val_loss: 0.1620 - val_accuracy: 0.9387\n",
      "Epoch 22/200\n",
      "22313/22313 [==============================] - 1s 54us/sample - loss: 0.1773 - accuracy: 0.9320 - val_loss: 0.1611 - val_accuracy: 0.9376\n",
      "Epoch 23/200\n",
      "22313/22313 [==============================] - 1s 54us/sample - loss: 0.1706 - accuracy: 0.9334 - val_loss: 0.1591 - val_accuracy: 0.9385\n",
      "Epoch 24/200\n",
      "22313/22313 [==============================] - 1s 54us/sample - loss: 0.1719 - accuracy: 0.9342 - val_loss: 0.1633 - val_accuracy: 0.9383\n",
      "Epoch 25/200\n",
      "22313/22313 [==============================] - 1s 53us/sample - loss: 0.1702 - accuracy: 0.9336 - val_loss: 0.1569 - val_accuracy: 0.9400\n",
      "Epoch 26/200\n",
      "22313/22313 [==============================] - 1s 53us/sample - loss: 0.1693 - accuracy: 0.9343 - val_loss: 0.1541 - val_accuracy: 0.9400\n",
      "Epoch 27/200\n",
      "22313/22313 [==============================] - 1s 54us/sample - loss: 0.1662 - accuracy: 0.9369 - val_loss: 0.1569 - val_accuracy: 0.9408\n",
      "Epoch 28/200\n",
      "22313/22313 [==============================] - 1s 55us/sample - loss: 0.1626 - accuracy: 0.9382 - val_loss: 0.1512 - val_accuracy: 0.9401\n",
      "Epoch 29/200\n",
      "22313/22313 [==============================] - 1s 53us/sample - loss: 0.1621 - accuracy: 0.9372 - val_loss: 0.1521 - val_accuracy: 0.9396\n",
      "Epoch 30/200\n",
      "22313/22313 [==============================] - 1s 53us/sample - loss: 0.1653 - accuracy: 0.9373 - val_loss: 0.1525 - val_accuracy: 0.9400\n",
      "Epoch 31/200\n",
      "22313/22313 [==============================] - 1s 55us/sample - loss: 0.1600 - accuracy: 0.9382 - val_loss: 0.1494 - val_accuracy: 0.9426\n",
      "Epoch 32/200\n",
      "22313/22313 [==============================] - 1s 53us/sample - loss: 0.1557 - accuracy: 0.9409 - val_loss: 0.1489 - val_accuracy: 0.9430\n",
      "Epoch 33/200\n",
      "22313/22313 [==============================] - 1s 53us/sample - loss: 0.1518 - accuracy: 0.9434 - val_loss: 0.1567 - val_accuracy: 0.9398\n",
      "Epoch 34/200\n",
      "22313/22313 [==============================] - 1s 54us/sample - loss: 0.1529 - accuracy: 0.9411 - val_loss: 0.1514 - val_accuracy: 0.9414\n",
      "Epoch 35/200\n",
      "22313/22313 [==============================] - 1s 53us/sample - loss: 0.1504 - accuracy: 0.9438 - val_loss: 0.1498 - val_accuracy: 0.9416\n",
      "Epoch 36/200\n",
      "22313/22313 [==============================] - 1s 55us/sample - loss: 0.1496 - accuracy: 0.9403 - val_loss: 0.1507 - val_accuracy: 0.9430\n",
      "Epoch 37/200\n",
      "22313/22313 [==============================] - 1s 59us/sample - loss: 0.1504 - accuracy: 0.9417 - val_loss: 0.1491 - val_accuracy: 0.9423\n",
      "Epoch 38/200\n",
      "22313/22313 [==============================] - 1s 54us/sample - loss: 0.1453 - accuracy: 0.9456 - val_loss: 0.1495 - val_accuracy: 0.9414\n",
      "Epoch 39/200\n",
      "22313/22313 [==============================] - 1s 56us/sample - loss: 0.1488 - accuracy: 0.9434 - val_loss: 0.1474 - val_accuracy: 0.9423\n",
      "Epoch 40/200\n",
      "22313/22313 [==============================] - 1s 58us/sample - loss: 0.1461 - accuracy: 0.9438 - val_loss: 0.1520 - val_accuracy: 0.9416\n",
      "Epoch 41/200\n",
      "22313/22313 [==============================] - 1s 59us/sample - loss: 0.1432 - accuracy: 0.9442 - val_loss: 0.1487 - val_accuracy: 0.9450\n",
      "Epoch 42/200\n",
      "22313/22313 [==============================] - 1s 65us/sample - loss: 0.1465 - accuracy: 0.9428 - val_loss: 0.1471 - val_accuracy: 0.9459\n",
      "Epoch 43/200\n",
      "22313/22313 [==============================] - 2s 76us/sample - loss: 0.1441 - accuracy: 0.9455 - val_loss: 0.1448 - val_accuracy: 0.9434\n",
      "Epoch 44/200\n",
      "22313/22313 [==============================] - 1s 56us/sample - loss: 0.1428 - accuracy: 0.9460 - val_loss: 0.1383 - val_accuracy: 0.9448\n",
      "Epoch 45/200\n",
      "22313/22313 [==============================] - 1s 55us/sample - loss: 0.1404 - accuracy: 0.9462 - val_loss: 0.1403 - val_accuracy: 0.9460\n",
      "Epoch 46/200\n",
      "22313/22313 [==============================] - 2s 69us/sample - loss: 0.1355 - accuracy: 0.9462 - val_loss: 0.1439 - val_accuracy: 0.9432\n",
      "Epoch 47/200\n",
      "22313/22313 [==============================] - 1s 60us/sample - loss: 0.1371 - accuracy: 0.9471 - val_loss: 0.1446 - val_accuracy: 0.9464\n",
      "Epoch 48/200\n",
      "22313/22313 [==============================] - 1s 54us/sample - loss: 0.1354 - accuracy: 0.9490 - val_loss: 0.1386 - val_accuracy: 0.9480\n",
      "Epoch 49/200\n",
      "22313/22313 [==============================] - 1s 54us/sample - loss: 0.1322 - accuracy: 0.9508 - val_loss: 0.1388 - val_accuracy: 0.9466\n",
      "Epoch 50/200\n",
      "22313/22313 [==============================] - 1s 56us/sample - loss: 0.1336 - accuracy: 0.9502 - val_loss: 0.1351 - val_accuracy: 0.9484\n",
      "Epoch 51/200\n",
      "22313/22313 [==============================] - 1s 56us/sample - loss: 0.1334 - accuracy: 0.9468 - val_loss: 0.1399 - val_accuracy: 0.9471\n",
      "Epoch 52/200\n",
      "22313/22313 [==============================] - ETA: 0s - loss: 0.1337 - accuracy: 0.94 - 1s 55us/sample - loss: 0.1332 - accuracy: 0.9477 - val_loss: 0.1417 - val_accuracy: 0.9464\n",
      "Epoch 53/200\n",
      "22313/22313 [==============================] - 1s 53us/sample - loss: 0.1343 - accuracy: 0.9485 - val_loss: 0.1385 - val_accuracy: 0.9475\n",
      "Epoch 54/200\n",
      "22313/22313 [==============================] - 1s 55us/sample - loss: 0.1303 - accuracy: 0.9512 - val_loss: 0.1393 - val_accuracy: 0.9457\n",
      "Epoch 55/200\n",
      "22313/22313 [==============================] - 1s 54us/sample - loss: 0.1314 - accuracy: 0.9507 - val_loss: 0.1387 - val_accuracy: 0.9478\n",
      "Epoch 56/200\n",
      "22313/22313 [==============================] - 1s 59us/sample - loss: 0.1362 - accuracy: 0.9483 - val_loss: 0.1361 - val_accuracy: 0.9460\n",
      "Epoch 57/200\n",
      "22313/22313 [==============================] - 1s 63us/sample - loss: 0.1263 - accuracy: 0.9516 - val_loss: 0.1425 - val_accuracy: 0.9455\n",
      "Epoch 58/200\n",
      "22313/22313 [==============================] - 1s 55us/sample - loss: 0.1292 - accuracy: 0.9491 - val_loss: 0.1385 - val_accuracy: 0.9475\n",
      "Epoch 59/200\n",
      "22313/22313 [==============================] - 2s 78us/sample - loss: 0.1265 - accuracy: 0.9530 - val_loss: 0.1343 - val_accuracy: 0.9464\n",
      "Epoch 60/200\n",
      "22313/22313 [==============================] - 2s 90us/sample - loss: 0.1253 - accuracy: 0.9524 - val_loss: 0.1384 - val_accuracy: 0.9469\n",
      "Epoch 61/200\n",
      "22313/22313 [==============================] - 2s 79us/sample - loss: 0.1256 - accuracy: 0.9519 - val_loss: 0.1421 - val_accuracy: 0.9462\n",
      "Epoch 62/200\n",
      "22313/22313 [==============================] - 2s 76us/sample - loss: 0.1261 - accuracy: 0.9525 - val_loss: 0.1356 - val_accuracy: 0.9469\n",
      "Epoch 63/200\n",
      "22313/22313 [==============================] - 2s 77us/sample - loss: 0.1224 - accuracy: 0.9536 - val_loss: 0.1341 - val_accuracy: 0.9500\n",
      "Epoch 64/200\n",
      "22313/22313 [==============================] - 2s 75us/sample - loss: 0.1226 - accuracy: 0.9540 - val_loss: 0.1334 - val_accuracy: 0.9498\n",
      "Epoch 65/200\n",
      "22313/22313 [==============================] - 2s 75us/sample - loss: 0.1227 - accuracy: 0.9543 - val_loss: 0.1301 - val_accuracy: 0.9493\n",
      "Epoch 66/200\n",
      "22313/22313 [==============================] - 2s 75us/sample - loss: 0.1223 - accuracy: 0.9539 - val_loss: 0.1400 - val_accuracy: 0.9468\n",
      "Epoch 67/200\n",
      "22313/22313 [==============================] - 2s 77us/sample - loss: 0.1207 - accuracy: 0.9529 - val_loss: 0.1302 - val_accuracy: 0.9487\n",
      "Epoch 68/200\n",
      "22313/22313 [==============================] - 2s 73us/sample - loss: 0.1205 - accuracy: 0.9524 - val_loss: 0.1363 - val_accuracy: 0.9491\n",
      "Epoch 69/200\n",
      "22313/22313 [==============================] - 2s 79us/sample - loss: 0.1168 - accuracy: 0.9555 - val_loss: 0.1331 - val_accuracy: 0.9455\n",
      "Epoch 70/200\n",
      "22313/22313 [==============================] - 2s 85us/sample - loss: 0.1197 - accuracy: 0.9552 - val_loss: 0.1393 - val_accuracy: 0.9500\n",
      "Epoch 71/200\n",
      "22313/22313 [==============================] - 2s 77us/sample - loss: 0.1191 - accuracy: 0.9544 - val_loss: 0.1367 - val_accuracy: 0.9482\n",
      "Epoch 72/200\n",
      "22313/22313 [==============================] - 2s 85us/sample - loss: 0.1218 - accuracy: 0.9537 - val_loss: 0.1330 - val_accuracy: 0.9511\n",
      "Epoch 73/200\n",
      "22313/22313 [==============================] - 2s 83us/sample - loss: 0.1193 - accuracy: 0.9548 - val_loss: 0.1302 - val_accuracy: 0.9493\n",
      "Epoch 74/200\n",
      "22313/22313 [==============================] - 2s 86us/sample - loss: 0.1195 - accuracy: 0.9537 - val_loss: 0.1292 - val_accuracy: 0.9505\n",
      "Epoch 75/200\n",
      "22313/22313 [==============================] - 2s 80us/sample - loss: 0.1178 - accuracy: 0.9556 - val_loss: 0.1286 - val_accuracy: 0.9527\n",
      "Epoch 76/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22313/22313 [==============================] - 2s 80us/sample - loss: 0.1158 - accuracy: 0.9552 - val_loss: 0.1330 - val_accuracy: 0.9516\n",
      "Epoch 77/200\n",
      "22313/22313 [==============================] - 2s 80us/sample - loss: 0.1175 - accuracy: 0.9552 - val_loss: 0.1312 - val_accuracy: 0.9527\n",
      "Epoch 78/200\n",
      "22313/22313 [==============================] - 2s 78us/sample - loss: 0.1125 - accuracy: 0.9575 - val_loss: 0.1292 - val_accuracy: 0.9538\n",
      "Epoch 79/200\n",
      "22313/22313 [==============================] - 2s 79us/sample - loss: 0.1141 - accuracy: 0.9558 - val_loss: 0.1279 - val_accuracy: 0.9538\n",
      "Epoch 80/200\n",
      "22313/22313 [==============================] - 2s 75us/sample - loss: 0.1141 - accuracy: 0.9564 - val_loss: 0.1304 - val_accuracy: 0.9538\n",
      "Epoch 81/200\n",
      "22313/22313 [==============================] - 2s 80us/sample - loss: 0.1132 - accuracy: 0.9580 - val_loss: 0.1310 - val_accuracy: 0.9516\n",
      "Epoch 82/200\n",
      "22313/22313 [==============================] - 2s 75us/sample - loss: 0.1125 - accuracy: 0.9573 - val_loss: 0.1264 - val_accuracy: 0.9538\n",
      "Epoch 83/200\n",
      "22313/22313 [==============================] - 2s 75us/sample - loss: 0.1105 - accuracy: 0.9585 - val_loss: 0.1279 - val_accuracy: 0.9502\n",
      "Epoch 84/200\n",
      "22313/22313 [==============================] - 2s 77us/sample - loss: 0.1136 - accuracy: 0.9574 - val_loss: 0.1271 - val_accuracy: 0.9525\n",
      "Epoch 85/200\n",
      "22313/22313 [==============================] - 2s 84us/sample - loss: 0.1080 - accuracy: 0.9595 - val_loss: 0.1269 - val_accuracy: 0.9532\n",
      "Epoch 86/200\n",
      "22313/22313 [==============================] - 2s 76us/sample - loss: 0.1106 - accuracy: 0.9597 - val_loss: 0.1296 - val_accuracy: 0.9520\n",
      "Epoch 87/200\n",
      "22313/22313 [==============================] - 2s 83us/sample - loss: 0.1086 - accuracy: 0.9601 - val_loss: 0.1235 - val_accuracy: 0.9543\n",
      "Epoch 88/200\n",
      "22313/22313 [==============================] - 2s 78us/sample - loss: 0.1091 - accuracy: 0.9589 - val_loss: 0.1266 - val_accuracy: 0.9538\n",
      "Epoch 89/200\n",
      "22313/22313 [==============================] - 2s 80us/sample - loss: 0.1084 - accuracy: 0.9591 - val_loss: 0.1232 - val_accuracy: 0.9539\n",
      "Epoch 90/200\n",
      "22313/22313 [==============================] - 2s 80us/sample - loss: 0.1087 - accuracy: 0.9600 - val_loss: 0.1277 - val_accuracy: 0.9534\n",
      "Epoch 91/200\n",
      "22313/22313 [==============================] - 2s 75us/sample - loss: 0.1047 - accuracy: 0.9607 - val_loss: 0.1319 - val_accuracy: 0.9539\n",
      "Epoch 92/200\n",
      "22313/22313 [==============================] - 2s 76us/sample - loss: 0.1072 - accuracy: 0.9602 - val_loss: 0.1312 - val_accuracy: 0.9534\n",
      "Epoch 93/200\n",
      "22313/22313 [==============================] - 2s 78us/sample - loss: 0.1044 - accuracy: 0.9611 - val_loss: 0.1311 - val_accuracy: 0.9527\n",
      "Epoch 94/200\n",
      "22313/22313 [==============================] - 2s 73us/sample - loss: 0.1062 - accuracy: 0.9594 - val_loss: 0.1286 - val_accuracy: 0.9557\n",
      "Epoch 95/200\n",
      "22313/22313 [==============================] - 2s 76us/sample - loss: 0.1012 - accuracy: 0.9620 - val_loss: 0.1308 - val_accuracy: 0.9534\n",
      "Epoch 96/200\n",
      "22313/22313 [==============================] - 2s 77us/sample - loss: 0.1034 - accuracy: 0.9616 - val_loss: 0.1283 - val_accuracy: 0.9582\n",
      "Epoch 97/200\n",
      "22313/22313 [==============================] - 2s 76us/sample - loss: 0.1027 - accuracy: 0.9603 - val_loss: 0.1256 - val_accuracy: 0.9529\n",
      "Epoch 98/200\n",
      "22313/22313 [==============================] - 2s 77us/sample - loss: 0.1037 - accuracy: 0.9607 - val_loss: 0.1213 - val_accuracy: 0.9538\n",
      "Epoch 99/200\n",
      "22313/22313 [==============================] - 2s 77us/sample - loss: 0.1049 - accuracy: 0.9614 - val_loss: 0.1305 - val_accuracy: 0.9570\n",
      "Epoch 100/200\n",
      "22313/22313 [==============================] - 2s 76us/sample - loss: 0.1036 - accuracy: 0.9610 - val_loss: 0.1216 - val_accuracy: 0.9561\n",
      "Epoch 101/200\n",
      "22313/22313 [==============================] - 2s 78us/sample - loss: 0.1046 - accuracy: 0.9615 - val_loss: 0.1245 - val_accuracy: 0.9552\n",
      "Epoch 102/200\n",
      "22313/22313 [==============================] - 2s 76us/sample - loss: 0.1044 - accuracy: 0.9623 - val_loss: 0.1260 - val_accuracy: 0.9538\n",
      "Epoch 103/200\n",
      "22313/22313 [==============================] - 2s 77us/sample - loss: 0.0997 - accuracy: 0.9626 - val_loss: 0.1241 - val_accuracy: 0.9545\n",
      "Epoch 104/200\n",
      "22313/22313 [==============================] - 2s 76us/sample - loss: 0.1025 - accuracy: 0.9618 - val_loss: 0.1258 - val_accuracy: 0.9543\n",
      "Epoch 105/200\n",
      "22313/22313 [==============================] - 2s 77us/sample - loss: 0.1028 - accuracy: 0.9606 - val_loss: 0.1207 - val_accuracy: 0.9552\n",
      "Epoch 106/200\n",
      "22313/22313 [==============================] - 2s 75us/sample - loss: 0.1030 - accuracy: 0.9624 - val_loss: 0.1205 - val_accuracy: 0.9547\n",
      "Epoch 107/200\n",
      "22313/22313 [==============================] - 2s 76us/sample - loss: 0.1034 - accuracy: 0.9615 - val_loss: 0.1224 - val_accuracy: 0.9555\n",
      "Epoch 108/200\n",
      "22313/22313 [==============================] - 2s 77us/sample - loss: 0.0994 - accuracy: 0.9629 - val_loss: 0.1195 - val_accuracy: 0.9563\n",
      "Epoch 109/200\n",
      "22313/22313 [==============================] - 2s 75us/sample - loss: 0.0954 - accuracy: 0.9653 - val_loss: 0.1207 - val_accuracy: 0.9579\n",
      "Epoch 110/200\n",
      "22313/22313 [==============================] - 2s 77us/sample - loss: 0.0976 - accuracy: 0.9629 - val_loss: 0.1262 - val_accuracy: 0.9527\n",
      "Epoch 111/200\n",
      "22313/22313 [==============================] - 2s 73us/sample - loss: 0.0974 - accuracy: 0.9623 - val_loss: 0.1225 - val_accuracy: 0.9554\n",
      "Epoch 112/200\n",
      "22313/22313 [==============================] - 2s 74us/sample - loss: 0.0983 - accuracy: 0.9637 - val_loss: 0.1237 - val_accuracy: 0.9557\n",
      "Epoch 113/200\n",
      "22313/22313 [==============================] - 2s 75us/sample - loss: 0.0997 - accuracy: 0.9635 - val_loss: 0.1257 - val_accuracy: 0.9555\n",
      "Epoch 114/200\n",
      "22313/22313 [==============================] - 2s 79us/sample - loss: 0.0997 - accuracy: 0.9630 - val_loss: 0.1269 - val_accuracy: 0.9536\n",
      "Epoch 115/200\n",
      "22313/22313 [==============================] - 2s 77us/sample - loss: 0.0973 - accuracy: 0.9640 - val_loss: 0.1257 - val_accuracy: 0.9541\n",
      "Epoch 116/200\n",
      "22313/22313 [==============================] - 2s 80us/sample - loss: 0.0972 - accuracy: 0.9634 - val_loss: 0.1193 - val_accuracy: 0.9568\n",
      "test:0.903642\n",
      "valid:0.958236\n",
      "train:0.982701\n",
      "acc:0.914580\n",
      "0.9145802949278885\n"
     ]
    }
   ],
   "source": [
    "acc={}\n",
    "cols = ['LEFT','RIGHT']\n",
    "\n",
    "sc = StandardScaler(with_mean=True)\n",
    "\n",
    "for col in cols:\n",
    "    ind_temp=feature.columns.str.contains(col)\n",
    "    feature_sc = sc.fit_transform(feature.loc[:,ind_temp])\n",
    "    feature2_sc = sc.transform(feature2.loc[:,ind_temp])\n",
    "    train,valid,test = train_model(model,feature_sc,np.array(y))\n",
    "    \n",
    "    acc_rest=test_model(model,feature2_sc,np.array(y2))\n",
    "    acc[col] = [train,valid,test,acc_rest]\n",
    "    print(acc_rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LEFT</th>\n",
       "      <th>RIGHT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.987864</td>\n",
       "      <td>0.986136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid</th>\n",
       "      <td>0.954364</td>\n",
       "      <td>0.951091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.920873</td>\n",
       "      <td>0.904291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rest data</th>\n",
       "      <td>0.927044</td>\n",
       "      <td>0.894982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               LEFT     RIGHT\n",
       "train      0.987864  0.986136\n",
       "valid      0.954364  0.951091\n",
       "test       0.920873  0.904291\n",
       "rest data  0.927044  0.894982"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(acc,index=['train','valid','test','rest data']).to_csv('./results/acc_lr_ann.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test features from 2 of 8 signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22000 samples, validate on 5500 samples\n",
      "Epoch 1/200\n",
      "22000/22000 [==============================] - 2s 93us/sample - loss: 0.2918 - accuracy: 0.8795 - val_loss: 0.2951 - val_accuracy: 0.8795\n",
      "Epoch 2/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2900 - accuracy: 0.8787 - val_loss: 0.2929 - val_accuracy: 0.8813\n",
      "Epoch 3/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2927 - accuracy: 0.8792 - val_loss: 0.2951 - val_accuracy: 0.8778\n",
      "Epoch 4/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2918 - accuracy: 0.8788 - val_loss: 0.2927 - val_accuracy: 0.8804\n",
      "Epoch 5/200\n",
      "22000/22000 [==============================] - 1s 61us/sample - loss: 0.2853 - accuracy: 0.8810 - val_loss: 0.2954 - val_accuracy: 0.8773\n",
      "Epoch 6/200\n",
      "22000/22000 [==============================] - 1s 57us/sample - loss: 0.2922 - accuracy: 0.8788 - val_loss: 0.2912 - val_accuracy: 0.8793\n",
      "Epoch 7/200\n",
      "22000/22000 [==============================] - 1s 58us/sample - loss: 0.2880 - accuracy: 0.8820 - val_loss: 0.2935 - val_accuracy: 0.8787\n",
      "Epoch 8/200\n",
      "22000/22000 [==============================] - 1s 60us/sample - loss: 0.2906 - accuracy: 0.8812 - val_loss: 0.2871 - val_accuracy: 0.8795\n",
      "Epoch 9/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.2892 - accuracy: 0.8817 - val_loss: 0.2919 - val_accuracy: 0.8796\n",
      "Epoch 10/200\n",
      "22000/22000 [==============================] - 1s 60us/sample - loss: 0.2909 - accuracy: 0.8793 - val_loss: 0.2909 - val_accuracy: 0.8804\n",
      "Epoch 11/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.2893 - accuracy: 0.8824 - val_loss: 0.2930 - val_accuracy: 0.8773\n",
      "Epoch 12/200\n",
      "22000/22000 [==============================] - 2s 71us/sample - loss: 0.2903 - accuracy: 0.8800 - val_loss: 0.2935 - val_accuracy: 0.8789\n",
      "Epoch 13/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.2883 - accuracy: 0.8811 - val_loss: 0.2912 - val_accuracy: 0.8796\n",
      "Epoch 14/200\n",
      "22000/22000 [==============================] - 2s 74us/sample - loss: 0.2851 - accuracy: 0.8834 - val_loss: 0.2940 - val_accuracy: 0.8789\n",
      "Epoch 15/200\n",
      "22000/22000 [==============================] - 1s 60us/sample - loss: 0.2830 - accuracy: 0.8839 - val_loss: 0.2987 - val_accuracy: 0.8782\n",
      "Epoch 16/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.2891 - accuracy: 0.8822 - val_loss: 0.2932 - val_accuracy: 0.8769\n",
      "Epoch 17/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2865 - accuracy: 0.8824 - val_loss: 0.2966 - val_accuracy: 0.8765\n",
      "Epoch 18/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2847 - accuracy: 0.8835 - val_loss: 0.2918 - val_accuracy: 0.8793\n",
      "Epoch 19/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2835 - accuracy: 0.8844 - val_loss: 0.2939 - val_accuracy: 0.8778\n",
      "Epoch 20/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2869 - accuracy: 0.8813 - val_loss: 0.2904 - val_accuracy: 0.8798\n",
      "Epoch 21/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2849 - accuracy: 0.8820 - val_loss: 0.2929 - val_accuracy: 0.8804\n",
      "Epoch 22/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.2799 - accuracy: 0.8860 - val_loss: 0.2936 - val_accuracy: 0.8782\n",
      "test:0.789818\n",
      "valid:0.881273\n",
      "train:0.912545\n",
      "acc:0.782118\n",
      "0.7821184299710395\n",
      "Train on 22000 samples, validate on 5500 samples\n",
      "Epoch 1/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.4150 - accuracy: 0.8175 - val_loss: 0.3306 - val_accuracy: 0.8625\n",
      "Epoch 2/200\n",
      "22000/22000 [==============================] - 1s 57us/sample - loss: 0.3566 - accuracy: 0.8516 - val_loss: 0.3174 - val_accuracy: 0.8716\n",
      "Epoch 3/200\n",
      "22000/22000 [==============================] - 1s 63us/sample - loss: 0.3375 - accuracy: 0.8602 - val_loss: 0.3025 - val_accuracy: 0.8767\n",
      "Epoch 4/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.3287 - accuracy: 0.8653 - val_loss: 0.2945 - val_accuracy: 0.8782\n",
      "Epoch 5/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.3220 - accuracy: 0.8691 - val_loss: 0.2927 - val_accuracy: 0.8804\n",
      "Epoch 6/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.3168 - accuracy: 0.8711 - val_loss: 0.2893 - val_accuracy: 0.8813\n",
      "Epoch 7/200\n",
      "22000/22000 [==============================] - 1s 63us/sample - loss: 0.3126 - accuracy: 0.8722 - val_loss: 0.2862 - val_accuracy: 0.8804\n",
      "Epoch 8/200\n",
      "22000/22000 [==============================] - 2s 71us/sample - loss: 0.3067 - accuracy: 0.8760 - val_loss: 0.2846 - val_accuracy: 0.8844\n",
      "Epoch 9/200\n",
      "22000/22000 [==============================] - 1s 60us/sample - loss: 0.3035 - accuracy: 0.8783 - val_loss: 0.2836 - val_accuracy: 0.8849\n",
      "Epoch 10/200\n",
      "22000/22000 [==============================] - 1s 62us/sample - loss: 0.2992 - accuracy: 0.8770 - val_loss: 0.2793 - val_accuracy: 0.8862\n",
      "Epoch 11/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2963 - accuracy: 0.8791 - val_loss: 0.2744 - val_accuracy: 0.8893\n",
      "Epoch 12/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2959 - accuracy: 0.8811 - val_loss: 0.2753 - val_accuracy: 0.8898\n",
      "Epoch 13/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.2931 - accuracy: 0.8818 - val_loss: 0.2703 - val_accuracy: 0.8885\n",
      "Epoch 14/200\n",
      "22000/22000 [==============================] - 1s 57us/sample - loss: 0.2906 - accuracy: 0.8829 - val_loss: 0.2705 - val_accuracy: 0.8891\n",
      "Epoch 15/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.2885 - accuracy: 0.8833 - val_loss: 0.2710 - val_accuracy: 0.8907\n",
      "Epoch 16/200\n",
      "22000/22000 [==============================] - 1s 60us/sample - loss: 0.2853 - accuracy: 0.8828 - val_loss: 0.2694 - val_accuracy: 0.8915\n",
      "Epoch 17/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2835 - accuracy: 0.8858 - val_loss: 0.2664 - val_accuracy: 0.8915\n",
      "Epoch 18/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.2833 - accuracy: 0.8838 - val_loss: 0.2654 - val_accuracy: 0.8965\n",
      "Epoch 19/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.2825 - accuracy: 0.8853 - val_loss: 0.2647 - val_accuracy: 0.8938\n",
      "Epoch 20/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2786 - accuracy: 0.8885 - val_loss: 0.2629 - val_accuracy: 0.8935\n",
      "Epoch 21/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2772 - accuracy: 0.8866 - val_loss: 0.2668 - val_accuracy: 0.8909\n",
      "Epoch 22/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.2739 - accuracy: 0.8900 - val_loss: 0.2621 - val_accuracy: 0.8978\n",
      "Epoch 23/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.2763 - accuracy: 0.8901 - val_loss: 0.2641 - val_accuracy: 0.8971\n",
      "Epoch 24/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.2719 - accuracy: 0.8903 - val_loss: 0.2604 - val_accuracy: 0.8989\n",
      "Epoch 25/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.2736 - accuracy: 0.8910 - val_loss: 0.2571 - val_accuracy: 0.8991\n",
      "Epoch 26/200\n",
      "22000/22000 [==============================] - 1s 56us/sample - loss: 0.2694 - accuracy: 0.8942 - val_loss: 0.2603 - val_accuracy: 0.8971\n",
      "Epoch 27/200\n",
      "22000/22000 [==============================] - 1s 61us/sample - loss: 0.2722 - accuracy: 0.8890 - val_loss: 0.2563 - val_accuracy: 0.8989\n",
      "Epoch 28/200\n",
      "22000/22000 [==============================] - ETA: 0s - loss: 0.2701 - accuracy: 0.89 - 1s 53us/sample - loss: 0.2710 - accuracy: 0.8911 - val_loss: 0.2586 - val_accuracy: 0.8973\n",
      "Epoch 29/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2710 - accuracy: 0.8899 - val_loss: 0.2587 - val_accuracy: 0.8960\n",
      "Epoch 30/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2666 - accuracy: 0.8939 - val_loss: 0.2582 - val_accuracy: 0.8985\n",
      "Epoch 31/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2700 - accuracy: 0.8921 - val_loss: 0.2559 - val_accuracy: 0.8975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.2643 - accuracy: 0.8957 - val_loss: 0.2539 - val_accuracy: 0.8984\n",
      "Epoch 33/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2653 - accuracy: 0.8923 - val_loss: 0.2553 - val_accuracy: 0.8984\n",
      "Epoch 34/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2624 - accuracy: 0.8951 - val_loss: 0.2546 - val_accuracy: 0.8989\n",
      "Epoch 35/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2610 - accuracy: 0.8941 - val_loss: 0.2507 - val_accuracy: 0.8989\n",
      "Epoch 36/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2653 - accuracy: 0.8940 - val_loss: 0.2509 - val_accuracy: 0.8980\n",
      "Epoch 37/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2595 - accuracy: 0.8942 - val_loss: 0.2515 - val_accuracy: 0.9020\n",
      "Epoch 38/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2605 - accuracy: 0.8960 - val_loss: 0.2544 - val_accuracy: 0.8980\n",
      "Epoch 39/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2583 - accuracy: 0.8950 - val_loss: 0.2525 - val_accuracy: 0.8982\n",
      "Epoch 40/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2597 - accuracy: 0.8968 - val_loss: 0.2511 - val_accuracy: 0.8989\n",
      "Epoch 41/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2586 - accuracy: 0.8963 - val_loss: 0.2488 - val_accuracy: 0.8998\n",
      "Epoch 42/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2594 - accuracy: 0.8959 - val_loss: 0.2501 - val_accuracy: 0.8993\n",
      "Epoch 43/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2562 - accuracy: 0.8968 - val_loss: 0.2469 - val_accuracy: 0.9016\n",
      "Epoch 44/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.2552 - accuracy: 0.8985 - val_loss: 0.2480 - val_accuracy: 0.9022\n",
      "Epoch 45/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.2554 - accuracy: 0.8977 - val_loss: 0.2507 - val_accuracy: 0.8993\n",
      "Epoch 46/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2537 - accuracy: 0.8967 - val_loss: 0.2464 - val_accuracy: 0.9013\n",
      "Epoch 47/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2553 - accuracy: 0.8979 - val_loss: 0.2470 - val_accuracy: 0.9004\n",
      "Epoch 48/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.2533 - accuracy: 0.8998 - val_loss: 0.2454 - val_accuracy: 0.9025\n",
      "Epoch 49/200\n",
      "22000/22000 [==============================] - 1s 56us/sample - loss: 0.2520 - accuracy: 0.8997 - val_loss: 0.2459 - val_accuracy: 0.9024\n",
      "Epoch 50/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2524 - accuracy: 0.8997 - val_loss: 0.2455 - val_accuracy: 0.9013\n",
      "Epoch 51/200\n",
      "22000/22000 [==============================] - 1s 56us/sample - loss: 0.2478 - accuracy: 0.9009 - val_loss: 0.2446 - val_accuracy: 0.9036\n",
      "Epoch 52/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2514 - accuracy: 0.8999 - val_loss: 0.2448 - val_accuracy: 0.9018\n",
      "Epoch 53/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2503 - accuracy: 0.9003 - val_loss: 0.2489 - val_accuracy: 0.9009\n",
      "Epoch 54/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2476 - accuracy: 0.9009 - val_loss: 0.2464 - val_accuracy: 0.9033\n",
      "Epoch 55/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2489 - accuracy: 0.9007 - val_loss: 0.2471 - val_accuracy: 0.9004\n",
      "Epoch 56/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2443 - accuracy: 0.9033 - val_loss: 0.2462 - val_accuracy: 0.9018\n",
      "Epoch 57/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.2468 - accuracy: 0.9011 - val_loss: 0.2474 - val_accuracy: 0.9031\n",
      "Epoch 58/200\n",
      "22000/22000 [==============================] - 1s 67us/sample - loss: 0.2476 - accuracy: 0.9019 - val_loss: 0.2468 - val_accuracy: 0.9016\n",
      "Epoch 59/200\n",
      "22000/22000 [==============================] - 1s 64us/sample - loss: 0.2456 - accuracy: 0.9021 - val_loss: 0.2437 - val_accuracy: 0.9047\n",
      "Epoch 60/200\n",
      "22000/22000 [==============================] - 1s 56us/sample - loss: 0.2439 - accuracy: 0.9036 - val_loss: 0.2460 - val_accuracy: 0.9029\n",
      "Epoch 61/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.2492 - accuracy: 0.9018 - val_loss: 0.2446 - val_accuracy: 0.9024\n",
      "Epoch 62/200\n",
      "22000/22000 [==============================] - ETA: 0s - loss: 0.2440 - accuracy: 0.90 - 1s 46us/sample - loss: 0.2434 - accuracy: 0.9029 - val_loss: 0.2426 - val_accuracy: 0.9013\n",
      "Epoch 63/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2406 - accuracy: 0.9040 - val_loss: 0.2411 - val_accuracy: 0.9069\n",
      "Epoch 64/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2414 - accuracy: 0.9044 - val_loss: 0.2429 - val_accuracy: 0.9036\n",
      "Epoch 65/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2437 - accuracy: 0.9020 - val_loss: 0.2413 - val_accuracy: 0.9035\n",
      "Epoch 66/200\n",
      "22000/22000 [==============================] - ETA: 0s - loss: 0.2434 - accuracy: 0.90 - 1s 46us/sample - loss: 0.2431 - accuracy: 0.9031 - val_loss: 0.2398 - val_accuracy: 0.9040\n",
      "Epoch 67/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2386 - accuracy: 0.9043 - val_loss: 0.2426 - val_accuracy: 0.9051\n",
      "Epoch 68/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2382 - accuracy: 0.9049 - val_loss: 0.2406 - val_accuracy: 0.9024\n",
      "Epoch 69/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.2402 - accuracy: 0.9044 - val_loss: 0.2409 - val_accuracy: 0.9053\n",
      "Epoch 70/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2360 - accuracy: 0.9052 - val_loss: 0.2397 - val_accuracy: 0.9049\n",
      "Epoch 71/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2372 - accuracy: 0.9056 - val_loss: 0.2395 - val_accuracy: 0.9056\n",
      "Epoch 72/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.2397 - accuracy: 0.9061 - val_loss: 0.2420 - val_accuracy: 0.9042\n",
      "Epoch 73/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.2435 - accuracy: 0.9030 - val_loss: 0.2415 - val_accuracy: 0.9031\n",
      "Epoch 74/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2413 - accuracy: 0.9047 - val_loss: 0.2402 - val_accuracy: 0.9031\n",
      "Epoch 75/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2407 - accuracy: 0.9040 - val_loss: 0.2402 - val_accuracy: 0.9047\n",
      "Epoch 76/200\n",
      "22000/22000 [==============================] - 1s 62us/sample - loss: 0.2358 - accuracy: 0.9078 - val_loss: 0.2424 - val_accuracy: 0.9009\n",
      "Epoch 77/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.2397 - accuracy: 0.9055 - val_loss: 0.2441 - val_accuracy: 0.9018\n",
      "Epoch 78/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2347 - accuracy: 0.9077 - val_loss: 0.2442 - val_accuracy: 0.9015\n",
      "Epoch 79/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2362 - accuracy: 0.9075 - val_loss: 0.2418 - val_accuracy: 0.9042\n",
      "Epoch 80/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2362 - accuracy: 0.9045 - val_loss: 0.2385 - val_accuracy: 0.9055\n",
      "Epoch 81/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2393 - accuracy: 0.9050 - val_loss: 0.2402 - val_accuracy: 0.9044\n",
      "Epoch 82/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2381 - accuracy: 0.9030 - val_loss: 0.2385 - val_accuracy: 0.9062\n",
      "Epoch 83/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2307 - accuracy: 0.9086 - val_loss: 0.2401 - val_accuracy: 0.9045\n",
      "test:0.904873\n",
      "valid:0.906909\n",
      "train:0.931636\n",
      "acc:0.864276\n",
      "0.8642758847330909\n",
      "Train on 22000 samples, validate on 5500 samples\n",
      "Epoch 1/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.4149 - accuracy: 0.8152 - val_loss: 0.3775 - val_accuracy: 0.8311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.3814 - accuracy: 0.8343 - val_loss: 0.3601 - val_accuracy: 0.8460\n",
      "Epoch 3/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.3690 - accuracy: 0.8378 - val_loss: 0.3516 - val_accuracy: 0.8525\n",
      "Epoch 4/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.3555 - accuracy: 0.8460 - val_loss: 0.3409 - val_accuracy: 0.8587\n",
      "Epoch 5/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.3517 - accuracy: 0.8492 - val_loss: 0.3383 - val_accuracy: 0.8555\n",
      "Epoch 6/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.3486 - accuracy: 0.8501 - val_loss: 0.3328 - val_accuracy: 0.8573\n",
      "Epoch 7/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.3387 - accuracy: 0.8545 - val_loss: 0.3308 - val_accuracy: 0.8602\n",
      "Epoch 8/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.3397 - accuracy: 0.8539 - val_loss: 0.3253 - val_accuracy: 0.8645\n",
      "Epoch 9/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.3364 - accuracy: 0.8550 - val_loss: 0.3245 - val_accuracy: 0.8613\n",
      "Epoch 10/200\n",
      "22000/22000 [==============================] - 1s 58us/sample - loss: 0.3302 - accuracy: 0.8599 - val_loss: 0.3204 - val_accuracy: 0.8645\n",
      "Epoch 11/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.3252 - accuracy: 0.8599 - val_loss: 0.3183 - val_accuracy: 0.8633\n",
      "Epoch 12/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.3290 - accuracy: 0.8592 - val_loss: 0.3184 - val_accuracy: 0.8651\n",
      "Epoch 13/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.3248 - accuracy: 0.8611 - val_loss: 0.3223 - val_accuracy: 0.8624\n",
      "Epoch 14/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.3228 - accuracy: 0.8625 - val_loss: 0.3157 - val_accuracy: 0.8656\n",
      "Epoch 15/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.3194 - accuracy: 0.8655 - val_loss: 0.3117 - val_accuracy: 0.8678\n",
      "Epoch 16/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.3186 - accuracy: 0.8648 - val_loss: 0.3121 - val_accuracy: 0.8658\n",
      "Epoch 17/200\n",
      "22000/22000 [==============================] - 1s 64us/sample - loss: 0.3163 - accuracy: 0.8640 - val_loss: 0.3100 - val_accuracy: 0.8682\n",
      "Epoch 18/200\n",
      "22000/22000 [==============================] - 1s 59us/sample - loss: 0.3140 - accuracy: 0.8652 - val_loss: 0.3104 - val_accuracy: 0.8689\n",
      "Epoch 19/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.3107 - accuracy: 0.8693 - val_loss: 0.3129 - val_accuracy: 0.8689\n",
      "Epoch 20/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.3098 - accuracy: 0.8678 - val_loss: 0.3093 - val_accuracy: 0.8689\n",
      "Epoch 21/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.3080 - accuracy: 0.8696 - val_loss: 0.3075 - val_accuracy: 0.8707\n",
      "Epoch 22/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.3057 - accuracy: 0.8690 - val_loss: 0.3071 - val_accuracy: 0.8705\n",
      "Epoch 23/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.3045 - accuracy: 0.8716 - val_loss: 0.3060 - val_accuracy: 0.8685\n",
      "Epoch 24/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.3036 - accuracy: 0.8705 - val_loss: 0.3053 - val_accuracy: 0.8729\n",
      "Epoch 25/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.3005 - accuracy: 0.8730 - val_loss: 0.3076 - val_accuracy: 0.8718\n",
      "Epoch 26/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.3009 - accuracy: 0.8716 - val_loss: 0.3032 - val_accuracy: 0.8689\n",
      "Epoch 27/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.3008 - accuracy: 0.8727 - val_loss: 0.3041 - val_accuracy: 0.8715\n",
      "Epoch 28/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2991 - accuracy: 0.8739 - val_loss: 0.3046 - val_accuracy: 0.8700\n",
      "Epoch 29/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.3008 - accuracy: 0.8759 - val_loss: 0.3036 - val_accuracy: 0.8731\n",
      "Epoch 30/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2987 - accuracy: 0.8722 - val_loss: 0.3000 - val_accuracy: 0.8720\n",
      "Epoch 31/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2951 - accuracy: 0.8766 - val_loss: 0.3006 - val_accuracy: 0.8740\n",
      "Epoch 32/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2937 - accuracy: 0.8750 - val_loss: 0.2983 - val_accuracy: 0.8731\n",
      "Epoch 33/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2942 - accuracy: 0.8775 - val_loss: 0.3011 - val_accuracy: 0.8733\n",
      "Epoch 34/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2916 - accuracy: 0.8780 - val_loss: 0.2978 - val_accuracy: 0.8782\n",
      "Epoch 35/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2929 - accuracy: 0.8794 - val_loss: 0.2951 - val_accuracy: 0.8731\n",
      "Epoch 36/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2950 - accuracy: 0.8751 - val_loss: 0.2984 - val_accuracy: 0.8789\n",
      "Epoch 37/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2944 - accuracy: 0.8760 - val_loss: 0.2948 - val_accuracy: 0.8764\n",
      "Epoch 38/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2892 - accuracy: 0.8781 - val_loss: 0.2983 - val_accuracy: 0.8736\n",
      "Epoch 39/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2916 - accuracy: 0.8779 - val_loss: 0.2963 - val_accuracy: 0.8727\n",
      "Epoch 40/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2921 - accuracy: 0.8757 - val_loss: 0.2959 - val_accuracy: 0.8760\n",
      "Epoch 41/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2892 - accuracy: 0.8791 - val_loss: 0.2942 - val_accuracy: 0.8744\n",
      "Epoch 42/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2873 - accuracy: 0.8801 - val_loss: 0.2929 - val_accuracy: 0.8756\n",
      "Epoch 43/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2856 - accuracy: 0.8804 - val_loss: 0.2939 - val_accuracy: 0.8758\n",
      "Epoch 44/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2865 - accuracy: 0.8799 - val_loss: 0.2943 - val_accuracy: 0.8787\n",
      "Epoch 45/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2861 - accuracy: 0.8805 - val_loss: 0.2976 - val_accuracy: 0.8760\n",
      "Epoch 46/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2863 - accuracy: 0.8770 - val_loss: 0.2954 - val_accuracy: 0.8738\n",
      "Epoch 47/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2865 - accuracy: 0.8805 - val_loss: 0.2952 - val_accuracy: 0.8791\n",
      "Epoch 48/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2851 - accuracy: 0.8807 - val_loss: 0.2919 - val_accuracy: 0.8785\n",
      "Epoch 49/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2819 - accuracy: 0.8827 - val_loss: 0.2950 - val_accuracy: 0.8785\n",
      "Epoch 50/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2786 - accuracy: 0.8832 - val_loss: 0.2879 - val_accuracy: 0.8795\n",
      "Epoch 51/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2848 - accuracy: 0.8810 - val_loss: 0.2912 - val_accuracy: 0.8793\n",
      "Epoch 52/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2802 - accuracy: 0.8815 - val_loss: 0.2927 - val_accuracy: 0.8789\n",
      "Epoch 53/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.2776 - accuracy: 0.8865 - val_loss: 0.2915 - val_accuracy: 0.8758\n",
      "Epoch 54/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2797 - accuracy: 0.8842 - val_loss: 0.2910 - val_accuracy: 0.8782\n",
      "Epoch 55/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2800 - accuracy: 0.8825 - val_loss: 0.2919 - val_accuracy: 0.8800\n",
      "Epoch 56/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2824 - accuracy: 0.8822 - val_loss: 0.2874 - val_accuracy: 0.8791\n",
      "Epoch 57/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2788 - accuracy: 0.8834 - val_loss: 0.2890 - val_accuracy: 0.8845\n",
      "Epoch 58/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2760 - accuracy: 0.8841 - val_loss: 0.2897 - val_accuracy: 0.8805\n",
      "Epoch 59/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.2759 - accuracy: 0.8855 - val_loss: 0.2874 - val_accuracy: 0.8789\n",
      "Epoch 60/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2776 - accuracy: 0.8847 - val_loss: 0.2865 - val_accuracy: 0.8782\n",
      "Epoch 61/200\n",
      "22000/22000 [==============================] - 1s 57us/sample - loss: 0.2760 - accuracy: 0.8849 - val_loss: 0.2832 - val_accuracy: 0.8833\n",
      "Epoch 62/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2777 - accuracy: 0.8853 - val_loss: 0.2865 - val_accuracy: 0.8791\n",
      "Epoch 63/200\n",
      "22000/22000 [==============================] - 1s 62us/sample - loss: 0.2784 - accuracy: 0.8832 - val_loss: 0.2850 - val_accuracy: 0.8791\n",
      "Epoch 64/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.2732 - accuracy: 0.8858 - val_loss: 0.2852 - val_accuracy: 0.8805\n",
      "Epoch 65/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2750 - accuracy: 0.8848 - val_loss: 0.2857 - val_accuracy: 0.8811\n",
      "Epoch 66/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2726 - accuracy: 0.8871 - val_loss: 0.2834 - val_accuracy: 0.8820\n",
      "Epoch 67/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2739 - accuracy: 0.8862 - val_loss: 0.2874 - val_accuracy: 0.8800\n",
      "Epoch 68/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2699 - accuracy: 0.8867 - val_loss: 0.2855 - val_accuracy: 0.8789\n",
      "Epoch 69/200\n",
      "22000/22000 [==============================] - 2s 78us/sample - loss: 0.2701 - accuracy: 0.8884 - val_loss: 0.2855 - val_accuracy: 0.8793\n",
      "Epoch 70/200\n",
      "22000/22000 [==============================] - 1s 67us/sample - loss: 0.2706 - accuracy: 0.8882 - val_loss: 0.2843 - val_accuracy: 0.8831\n",
      "Epoch 71/200\n",
      "22000/22000 [==============================] - 1s 64us/sample - loss: 0.2711 - accuracy: 0.8881 - val_loss: 0.2804 - val_accuracy: 0.8820\n",
      "Epoch 72/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2696 - accuracy: 0.8880 - val_loss: 0.2807 - val_accuracy: 0.8811\n",
      "Epoch 73/200\n",
      "22000/22000 [==============================] - 1s 43us/sample - loss: 0.2691 - accuracy: 0.8872 - val_loss: 0.2820 - val_accuracy: 0.8835\n",
      "Epoch 74/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2705 - accuracy: 0.8874 - val_loss: 0.2851 - val_accuracy: 0.8815\n",
      "Epoch 75/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.2671 - accuracy: 0.8894 - val_loss: 0.2822 - val_accuracy: 0.8833\n",
      "Epoch 76/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2683 - accuracy: 0.8911 - val_loss: 0.2794 - val_accuracy: 0.8827\n",
      "Epoch 77/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.2668 - accuracy: 0.8892 - val_loss: 0.2831 - val_accuracy: 0.8840\n",
      "test:0.859200\n",
      "valid:0.884545\n",
      "train:0.915045\n",
      "acc:0.898761\n",
      "0.898761476369462\n",
      "Train on 22000 samples, validate on 5500 samples\n",
      "Epoch 1/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.4827 - accuracy: 0.7740 - val_loss: 0.3916 - val_accuracy: 0.8185\n",
      "Epoch 2/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.4096 - accuracy: 0.8185 - val_loss: 0.3691 - val_accuracy: 0.8329\n",
      "Epoch 3/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.3851 - accuracy: 0.8309 - val_loss: 0.3542 - val_accuracy: 0.8418\n",
      "Epoch 4/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.3735 - accuracy: 0.8402 - val_loss: 0.3441 - val_accuracy: 0.8464\n",
      "Epoch 5/200\n",
      "22000/22000 [==============================] - 1s 43us/sample - loss: 0.3633 - accuracy: 0.8449 - val_loss: 0.3352 - val_accuracy: 0.8535\n",
      "Epoch 6/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.3538 - accuracy: 0.8510 - val_loss: 0.3287 - val_accuracy: 0.8602\n",
      "Epoch 7/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.3485 - accuracy: 0.8541 - val_loss: 0.3199 - val_accuracy: 0.8625\n",
      "Epoch 8/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.3426 - accuracy: 0.8566 - val_loss: 0.3169 - val_accuracy: 0.8651\n",
      "Epoch 9/200\n",
      "22000/22000 [==============================] - 1s 43us/sample - loss: 0.3376 - accuracy: 0.8598 - val_loss: 0.3151 - val_accuracy: 0.8684\n",
      "Epoch 10/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.3303 - accuracy: 0.8626 - val_loss: 0.3095 - val_accuracy: 0.8698\n",
      "Epoch 11/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.3272 - accuracy: 0.8637 - val_loss: 0.3090 - val_accuracy: 0.8716\n",
      "Epoch 12/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.3237 - accuracy: 0.8690 - val_loss: 0.3034 - val_accuracy: 0.8733\n",
      "Epoch 13/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.3223 - accuracy: 0.8683 - val_loss: 0.2983 - val_accuracy: 0.8771\n",
      "Epoch 14/200\n",
      "22000/22000 [==============================] - 1s 43us/sample - loss: 0.3239 - accuracy: 0.8676 - val_loss: 0.2978 - val_accuracy: 0.8800\n",
      "Epoch 15/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.3181 - accuracy: 0.8701 - val_loss: 0.2952 - val_accuracy: 0.8785\n",
      "Epoch 16/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.3165 - accuracy: 0.8712 - val_loss: 0.2954 - val_accuracy: 0.8813\n",
      "Epoch 17/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.3123 - accuracy: 0.8730 - val_loss: 0.2960 - val_accuracy: 0.8776\n",
      "Epoch 18/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.3088 - accuracy: 0.8759 - val_loss: 0.2908 - val_accuracy: 0.8815\n",
      "Epoch 19/200\n",
      "22000/22000 [==============================] - 1s 43us/sample - loss: 0.3087 - accuracy: 0.8729 - val_loss: 0.2933 - val_accuracy: 0.8804\n",
      "Epoch 20/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.3052 - accuracy: 0.8771 - val_loss: 0.2912 - val_accuracy: 0.8820\n",
      "Epoch 21/200\n",
      "22000/22000 [==============================] - 1s 43us/sample - loss: 0.3061 - accuracy: 0.8775 - val_loss: 0.2870 - val_accuracy: 0.8833\n",
      "Epoch 22/200\n",
      "22000/22000 [==============================] - 1s 43us/sample - loss: 0.3025 - accuracy: 0.8765 - val_loss: 0.2881 - val_accuracy: 0.8862\n",
      "Epoch 23/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.3009 - accuracy: 0.8779 - val_loss: 0.2880 - val_accuracy: 0.8827\n",
      "Epoch 24/200\n",
      "22000/22000 [==============================] - 1s 43us/sample - loss: 0.3017 - accuracy: 0.8773 - val_loss: 0.2858 - val_accuracy: 0.8862\n",
      "Epoch 25/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.2990 - accuracy: 0.8796 - val_loss: 0.2893 - val_accuracy: 0.8838\n",
      "Epoch 26/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2947 - accuracy: 0.8818 - val_loss: 0.2830 - val_accuracy: 0.8845\n",
      "Epoch 27/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2953 - accuracy: 0.8811 - val_loss: 0.2834 - val_accuracy: 0.8867\n",
      "Epoch 28/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2926 - accuracy: 0.8835 - val_loss: 0.2818 - val_accuracy: 0.8882\n",
      "Epoch 29/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2913 - accuracy: 0.8827 - val_loss: 0.2809 - val_accuracy: 0.8869\n",
      "Epoch 30/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2904 - accuracy: 0.8836 - val_loss: 0.2825 - val_accuracy: 0.8845\n",
      "Epoch 31/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2915 - accuracy: 0.8832 - val_loss: 0.2825 - val_accuracy: 0.8849\n",
      "Epoch 32/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2885 - accuracy: 0.8839 - val_loss: 0.2788 - val_accuracy: 0.8869\n",
      "Epoch 33/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2867 - accuracy: 0.8831 - val_loss: 0.2801 - val_accuracy: 0.8856\n",
      "Epoch 34/200\n",
      "22000/22000 [==============================] - 1s 43us/sample - loss: 0.2852 - accuracy: 0.8864 - val_loss: 0.2775 - val_accuracy: 0.8876\n",
      "Epoch 35/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2873 - accuracy: 0.8850 - val_loss: 0.2775 - val_accuracy: 0.8853\n",
      "Epoch 36/200\n",
      "22000/22000 [==============================] - 1s 43us/sample - loss: 0.2847 - accuracy: 0.8878 - val_loss: 0.2754 - val_accuracy: 0.8871\n",
      "Epoch 37/200\n",
      "22000/22000 [==============================] - 1s 43us/sample - loss: 0.2847 - accuracy: 0.8849 - val_loss: 0.2763 - val_accuracy: 0.8858\n",
      "Epoch 38/200\n",
      "22000/22000 [==============================] - 1s 43us/sample - loss: 0.2848 - accuracy: 0.8857 - val_loss: 0.2788 - val_accuracy: 0.8862\n",
      "Epoch 39/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2845 - accuracy: 0.8845 - val_loss: 0.2779 - val_accuracy: 0.8887\n",
      "Epoch 40/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.2755 - accuracy: 0.8900 - val_loss: 0.2734 - val_accuracy: 0.8911\n",
      "Epoch 41/200\n",
      "22000/22000 [==============================] - 1s 43us/sample - loss: 0.2805 - accuracy: 0.8881 - val_loss: 0.2742 - val_accuracy: 0.8911\n",
      "Epoch 42/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.2783 - accuracy: 0.8877 - val_loss: 0.2757 - val_accuracy: 0.8904\n",
      "Epoch 43/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2808 - accuracy: 0.8858 - val_loss: 0.2770 - val_accuracy: 0.8900\n",
      "Epoch 44/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.2719 - accuracy: 0.8918 - val_loss: 0.2720 - val_accuracy: 0.8915\n",
      "Epoch 45/200\n",
      "22000/22000 [==============================] - 1s 43us/sample - loss: 0.2720 - accuracy: 0.8922 - val_loss: 0.2753 - val_accuracy: 0.8893\n",
      "Epoch 46/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2745 - accuracy: 0.8918 - val_loss: 0.2751 - val_accuracy: 0.8895\n",
      "Epoch 47/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2732 - accuracy: 0.8900 - val_loss: 0.2713 - val_accuracy: 0.8935\n",
      "Epoch 48/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.2755 - accuracy: 0.8904 - val_loss: 0.2741 - val_accuracy: 0.8911\n",
      "Epoch 49/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.2727 - accuracy: 0.8917 - val_loss: 0.2737 - val_accuracy: 0.8891\n",
      "Epoch 50/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2727 - accuracy: 0.8913 - val_loss: 0.2747 - val_accuracy: 0.8882\n",
      "Epoch 51/200\n",
      "22000/22000 [==============================] - 1s 56us/sample - loss: 0.2726 - accuracy: 0.8922 - val_loss: 0.2706 - val_accuracy: 0.8916\n",
      "Epoch 52/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.2734 - accuracy: 0.8915 - val_loss: 0.2717 - val_accuracy: 0.8905\n",
      "Epoch 53/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2679 - accuracy: 0.8947 - val_loss: 0.2714 - val_accuracy: 0.8918\n",
      "Epoch 54/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.2685 - accuracy: 0.8935 - val_loss: 0.2703 - val_accuracy: 0.8929\n",
      "Epoch 55/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.2699 - accuracy: 0.8921 - val_loss: 0.2696 - val_accuracy: 0.8925\n",
      "Epoch 56/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.2691 - accuracy: 0.8917 - val_loss: 0.2702 - val_accuracy: 0.8920\n",
      "Epoch 57/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.2666 - accuracy: 0.8945 - val_loss: 0.2675 - val_accuracy: 0.8905\n",
      "Epoch 58/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2656 - accuracy: 0.8952 - val_loss: 0.2693 - val_accuracy: 0.8927\n",
      "Epoch 59/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.2663 - accuracy: 0.8933 - val_loss: 0.2684 - val_accuracy: 0.8933\n",
      "Epoch 60/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2636 - accuracy: 0.8952 - val_loss: 0.2730 - val_accuracy: 0.8905\n",
      "Epoch 61/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2647 - accuracy: 0.8956 - val_loss: 0.2667 - val_accuracy: 0.8944\n",
      "Epoch 62/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2632 - accuracy: 0.8957 - val_loss: 0.2686 - val_accuracy: 0.8927\n",
      "Epoch 63/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2649 - accuracy: 0.8934 - val_loss: 0.2717 - val_accuracy: 0.8931\n",
      "Epoch 64/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2642 - accuracy: 0.8950 - val_loss: 0.2694 - val_accuracy: 0.8909\n",
      "Epoch 65/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2643 - accuracy: 0.8964 - val_loss: 0.2718 - val_accuracy: 0.8924\n",
      "Epoch 66/200\n",
      "22000/22000 [==============================] - 1s 43us/sample - loss: 0.2620 - accuracy: 0.8954 - val_loss: 0.2657 - val_accuracy: 0.8945\n",
      "Epoch 67/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2633 - accuracy: 0.8955 - val_loss: 0.2665 - val_accuracy: 0.8964\n",
      "Epoch 68/200\n",
      "22000/22000 [==============================] - 1s 43us/sample - loss: 0.2618 - accuracy: 0.8969 - val_loss: 0.2638 - val_accuracy: 0.8964\n",
      "Epoch 69/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.2597 - accuracy: 0.8975 - val_loss: 0.2668 - val_accuracy: 0.8962\n",
      "Epoch 70/200\n",
      "22000/22000 [==============================] - 1s 43us/sample - loss: 0.2598 - accuracy: 0.8958 - val_loss: 0.2701 - val_accuracy: 0.8938\n",
      "Epoch 71/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2593 - accuracy: 0.8983 - val_loss: 0.2661 - val_accuracy: 0.8953\n",
      "Epoch 72/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.2587 - accuracy: 0.8965 - val_loss: 0.2689 - val_accuracy: 0.8936\n",
      "Epoch 73/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.2590 - accuracy: 0.8985 - val_loss: 0.2689 - val_accuracy: 0.8927\n",
      "Epoch 74/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.2565 - accuracy: 0.9007 - val_loss: 0.2671 - val_accuracy: 0.8924\n",
      "Epoch 75/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.2573 - accuracy: 0.8988 - val_loss: 0.2680 - val_accuracy: 0.8933\n",
      "Epoch 76/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2590 - accuracy: 0.8971 - val_loss: 0.2656 - val_accuracy: 0.8933\n",
      "Epoch 77/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2552 - accuracy: 0.8987 - val_loss: 0.2650 - val_accuracy: 0.8933\n",
      "Epoch 78/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2540 - accuracy: 0.9000 - val_loss: 0.2654 - val_accuracy: 0.8920\n",
      "Epoch 79/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.2539 - accuracy: 0.8996 - val_loss: 0.2652 - val_accuracy: 0.8951\n",
      "Epoch 80/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2526 - accuracy: 0.8999 - val_loss: 0.2625 - val_accuracy: 0.8944\n",
      "Epoch 81/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2529 - accuracy: 0.9007 - val_loss: 0.2652 - val_accuracy: 0.8951\n",
      "Epoch 82/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2515 - accuracy: 0.8997 - val_loss: 0.2654 - val_accuracy: 0.8964\n",
      "Epoch 83/200\n",
      "22000/22000 [==============================] - 1s 43us/sample - loss: 0.2501 - accuracy: 0.9022 - val_loss: 0.2632 - val_accuracy: 0.8956\n",
      "Epoch 84/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2520 - accuracy: 0.9001 - val_loss: 0.2702 - val_accuracy: 0.8933\n",
      "Epoch 85/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2530 - accuracy: 0.8991 - val_loss: 0.2671 - val_accuracy: 0.8975\n",
      "Epoch 86/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.2542 - accuracy: 0.9000 - val_loss: 0.2630 - val_accuracy: 0.8951\n",
      "Epoch 87/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2475 - accuracy: 0.9024 - val_loss: 0.2644 - val_accuracy: 0.8965\n",
      "Epoch 88/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2528 - accuracy: 0.9009 - val_loss: 0.2627 - val_accuracy: 0.8987\n",
      "Epoch 89/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2473 - accuracy: 0.9022 - val_loss: 0.2649 - val_accuracy: 0.8958\n",
      "Epoch 90/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2508 - accuracy: 0.8996 - val_loss: 0.2590 - val_accuracy: 0.8996\n",
      "Epoch 91/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.2501 - accuracy: 0.9020 - val_loss: 0.2600 - val_accuracy: 0.8991\n",
      "Epoch 92/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.2471 - accuracy: 0.9030 - val_loss: 0.2655 - val_accuracy: 0.8964\n",
      "Epoch 93/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2473 - accuracy: 0.9029 - val_loss: 0.2605 - val_accuracy: 0.8978\n",
      "Epoch 94/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2443 - accuracy: 0.9053 - val_loss: 0.2580 - val_accuracy: 0.8973\n",
      "Epoch 95/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2485 - accuracy: 0.9023 - val_loss: 0.2634 - val_accuracy: 0.8958\n",
      "Epoch 96/200\n",
      "22000/22000 [==============================] - 1s 43us/sample - loss: 0.2456 - accuracy: 0.9042 - val_loss: 0.2667 - val_accuracy: 0.8971\n",
      "Epoch 97/200\n",
      "22000/22000 [==============================] - 1s 43us/sample - loss: 0.2462 - accuracy: 0.9019 - val_loss: 0.2627 - val_accuracy: 0.8989\n",
      "Epoch 98/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2439 - accuracy: 0.9043 - val_loss: 0.2619 - val_accuracy: 0.8978\n",
      "Epoch 99/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2459 - accuracy: 0.9036 - val_loss: 0.2654 - val_accuracy: 0.8971\n",
      "Epoch 100/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2429 - accuracy: 0.9055 - val_loss: 0.2608 - val_accuracy: 0.8984\n",
      "Epoch 101/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2478 - accuracy: 0.9028 - val_loss: 0.2589 - val_accuracy: 0.8995\n",
      "Epoch 102/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2473 - accuracy: 0.9011 - val_loss: 0.2619 - val_accuracy: 0.8993\n",
      "Epoch 103/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2451 - accuracy: 0.9039 - val_loss: 0.2641 - val_accuracy: 0.8993\n",
      "Epoch 104/200\n",
      "22000/22000 [==============================] - 1s 43us/sample - loss: 0.2430 - accuracy: 0.9053 - val_loss: 0.2629 - val_accuracy: 0.8993\n",
      "Epoch 105/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2453 - accuracy: 0.9020 - val_loss: 0.2558 - val_accuracy: 0.9016\n",
      "Epoch 106/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2453 - accuracy: 0.9046 - val_loss: 0.2570 - val_accuracy: 0.9009\n",
      "Epoch 107/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2411 - accuracy: 0.9047 - val_loss: 0.2542 - val_accuracy: 0.8985\n",
      "Epoch 108/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2446 - accuracy: 0.9043 - val_loss: 0.2621 - val_accuracy: 0.8982\n",
      "Epoch 109/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2429 - accuracy: 0.9040 - val_loss: 0.2597 - val_accuracy: 0.8987\n",
      "Epoch 110/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2419 - accuracy: 0.9020 - val_loss: 0.2640 - val_accuracy: 0.9009\n",
      "Epoch 111/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2422 - accuracy: 0.9057 - val_loss: 0.2588 - val_accuracy: 0.8991\n",
      "Epoch 112/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2414 - accuracy: 0.9057 - val_loss: 0.2577 - val_accuracy: 0.9000\n",
      "Epoch 113/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2436 - accuracy: 0.9052 - val_loss: 0.2573 - val_accuracy: 0.8993\n",
      "Epoch 114/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2389 - accuracy: 0.9061 - val_loss: 0.2593 - val_accuracy: 0.8985\n",
      "Epoch 115/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2418 - accuracy: 0.9050 - val_loss: 0.2650 - val_accuracy: 0.8964\n",
      "Epoch 116/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2412 - accuracy: 0.9059 - val_loss: 0.2609 - val_accuracy: 0.8964\n",
      "Epoch 117/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2382 - accuracy: 0.9063 - val_loss: 0.2604 - val_accuracy: 0.8975\n",
      "Epoch 118/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2442 - accuracy: 0.9017 - val_loss: 0.2590 - val_accuracy: 0.8956\n",
      "Epoch 119/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2386 - accuracy: 0.9049 - val_loss: 0.2548 - val_accuracy: 0.8996\n",
      "Epoch 120/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2398 - accuracy: 0.9032 - val_loss: 0.2543 - val_accuracy: 0.9013\n",
      "Epoch 121/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2378 - accuracy: 0.9070 - val_loss: 0.2561 - val_accuracy: 0.8982\n",
      "Epoch 122/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2408 - accuracy: 0.9054 - val_loss: 0.2593 - val_accuracy: 0.9013\n",
      "Epoch 123/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2373 - accuracy: 0.9054 - val_loss: 0.2610 - val_accuracy: 0.9004\n",
      "Epoch 124/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2392 - accuracy: 0.9069 - val_loss: 0.2551 - val_accuracy: 0.8998\n",
      "Epoch 125/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2379 - accuracy: 0.9071 - val_loss: 0.2605 - val_accuracy: 0.9004\n",
      "test:0.848727\n",
      "valid:0.901636\n",
      "train:0.933955\n",
      "acc:0.824697\n",
      "0.8246965309014727\n",
      "Train on 22000 samples, validate on 5500 samples\n",
      "Epoch 1/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.4490 - accuracy: 0.7946 - val_loss: 0.4089 - val_accuracy: 0.8145\n",
      "Epoch 2/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.4105 - accuracy: 0.8171 - val_loss: 0.3831 - val_accuracy: 0.8282\n",
      "Epoch 3/200\n",
      "22000/22000 [==============================] - 1s 43us/sample - loss: 0.3938 - accuracy: 0.8252 - val_loss: 0.3721 - val_accuracy: 0.8338\n",
      "Epoch 4/200\n",
      "22000/22000 [==============================] - 1s 43us/sample - loss: 0.3845 - accuracy: 0.8313 - val_loss: 0.3596 - val_accuracy: 0.8400\n",
      "Epoch 5/200\n",
      "22000/22000 [==============================] - 1s 43us/sample - loss: 0.3773 - accuracy: 0.8337 - val_loss: 0.3532 - val_accuracy: 0.8451\n",
      "Epoch 6/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.3656 - accuracy: 0.8405 - val_loss: 0.3491 - val_accuracy: 0.8453\n",
      "Epoch 7/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.3672 - accuracy: 0.8380 - val_loss: 0.3482 - val_accuracy: 0.8500\n",
      "Epoch 8/200\n",
      "22000/22000 [==============================] - 1s 43us/sample - loss: 0.3543 - accuracy: 0.8462 - val_loss: 0.3407 - val_accuracy: 0.8529\n",
      "Epoch 9/200\n",
      "22000/22000 [==============================] - 1s 43us/sample - loss: 0.3548 - accuracy: 0.8458 - val_loss: 0.3385 - val_accuracy: 0.8529\n",
      "Epoch 10/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.3497 - accuracy: 0.8485 - val_loss: 0.3348 - val_accuracy: 0.8545\n",
      "Epoch 11/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.3486 - accuracy: 0.8493 - val_loss: 0.3361 - val_accuracy: 0.8542\n",
      "Epoch 12/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.3470 - accuracy: 0.8506 - val_loss: 0.3319 - val_accuracy: 0.8573\n",
      "Epoch 13/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.3386 - accuracy: 0.8555 - val_loss: 0.3306 - val_accuracy: 0.8598\n",
      "Epoch 14/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.3383 - accuracy: 0.8573 - val_loss: 0.3274 - val_accuracy: 0.8620\n",
      "Epoch 15/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.3376 - accuracy: 0.8555 - val_loss: 0.3259 - val_accuracy: 0.8616\n",
      "Epoch 16/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.3353 - accuracy: 0.8575 - val_loss: 0.3257 - val_accuracy: 0.8627\n",
      "Epoch 17/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.3268 - accuracy: 0.8595 - val_loss: 0.3222 - val_accuracy: 0.8624\n",
      "Epoch 18/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.3288 - accuracy: 0.8601 - val_loss: 0.3203 - val_accuracy: 0.8631\n",
      "Epoch 19/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.3242 - accuracy: 0.8609 - val_loss: 0.3194 - val_accuracy: 0.8644\n",
      "Epoch 20/200\n",
      "22000/22000 [==============================] - 1s 43us/sample - loss: 0.3259 - accuracy: 0.8617 - val_loss: 0.3179 - val_accuracy: 0.8645\n",
      "Epoch 21/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.3243 - accuracy: 0.8616 - val_loss: 0.3189 - val_accuracy: 0.8627\n",
      "Epoch 22/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.3228 - accuracy: 0.8612 - val_loss: 0.3174 - val_accuracy: 0.8627\n",
      "Epoch 23/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.3227 - accuracy: 0.8613 - val_loss: 0.3157 - val_accuracy: 0.8664\n",
      "Epoch 24/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.3236 - accuracy: 0.8639 - val_loss: 0.3142 - val_accuracy: 0.8665\n",
      "Epoch 25/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.3177 - accuracy: 0.8645 - val_loss: 0.3130 - val_accuracy: 0.8655\n",
      "Epoch 26/200\n",
      "22000/22000 [==============================] - 1s 43us/sample - loss: 0.3107 - accuracy: 0.8677 - val_loss: 0.3150 - val_accuracy: 0.8685\n",
      "Epoch 27/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.3163 - accuracy: 0.8663 - val_loss: 0.3136 - val_accuracy: 0.8671\n",
      "Epoch 28/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.3132 - accuracy: 0.8675 - val_loss: 0.3113 - val_accuracy: 0.8664\n",
      "Epoch 29/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.3096 - accuracy: 0.8703 - val_loss: 0.3109 - val_accuracy: 0.8680\n",
      "Epoch 30/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.3105 - accuracy: 0.8690 - val_loss: 0.3100 - val_accuracy: 0.8685\n",
      "Epoch 31/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.3113 - accuracy: 0.8699 - val_loss: 0.3082 - val_accuracy: 0.8718\n",
      "Epoch 32/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.3078 - accuracy: 0.8685 - val_loss: 0.3085 - val_accuracy: 0.8685\n",
      "Epoch 33/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.3079 - accuracy: 0.8703 - val_loss: 0.3082 - val_accuracy: 0.8680\n",
      "Epoch 34/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.3063 - accuracy: 0.8701 - val_loss: 0.3118 - val_accuracy: 0.8671\n",
      "Epoch 35/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.3060 - accuracy: 0.8708 - val_loss: 0.3068 - val_accuracy: 0.8702\n",
      "Epoch 36/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.3068 - accuracy: 0.8686 - val_loss: 0.3044 - val_accuracy: 0.8704\n",
      "Epoch 37/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.3040 - accuracy: 0.8690 - val_loss: 0.3055 - val_accuracy: 0.8735\n",
      "Epoch 38/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.3054 - accuracy: 0.8706 - val_loss: 0.3063 - val_accuracy: 0.8704\n",
      "Epoch 39/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2997 - accuracy: 0.8743 - val_loss: 0.3066 - val_accuracy: 0.8691\n",
      "Epoch 40/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.3012 - accuracy: 0.8726 - val_loss: 0.3086 - val_accuracy: 0.8684\n",
      "Epoch 41/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2967 - accuracy: 0.8752 - val_loss: 0.3072 - val_accuracy: 0.8698\n",
      "Epoch 42/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.3032 - accuracy: 0.8725 - val_loss: 0.3052 - val_accuracy: 0.8720\n",
      "Epoch 43/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2980 - accuracy: 0.8720 - val_loss: 0.3030 - val_accuracy: 0.8722\n",
      "Epoch 44/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2965 - accuracy: 0.8730 - val_loss: 0.3045 - val_accuracy: 0.8720\n",
      "Epoch 45/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2965 - accuracy: 0.8740 - val_loss: 0.3027 - val_accuracy: 0.8725\n",
      "Epoch 46/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2974 - accuracy: 0.8724 - val_loss: 0.3014 - val_accuracy: 0.8693\n",
      "Epoch 47/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2949 - accuracy: 0.8752 - val_loss: 0.3031 - val_accuracy: 0.8705\n",
      "Epoch 48/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2901 - accuracy: 0.8781 - val_loss: 0.3032 - val_accuracy: 0.8693\n",
      "Epoch 49/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2955 - accuracy: 0.8725 - val_loss: 0.2997 - val_accuracy: 0.8735\n",
      "Epoch 50/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2962 - accuracy: 0.8751 - val_loss: 0.3041 - val_accuracy: 0.8720\n",
      "Epoch 51/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2923 - accuracy: 0.8767 - val_loss: 0.3048 - val_accuracy: 0.8707\n",
      "Epoch 52/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2933 - accuracy: 0.8745 - val_loss: 0.3020 - val_accuracy: 0.8740\n",
      "Epoch 53/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2898 - accuracy: 0.8776 - val_loss: 0.3006 - val_accuracy: 0.8729\n",
      "Epoch 54/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2887 - accuracy: 0.8775 - val_loss: 0.2999 - val_accuracy: 0.8731\n",
      "Epoch 55/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2887 - accuracy: 0.8795 - val_loss: 0.3013 - val_accuracy: 0.8724\n",
      "Epoch 56/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2878 - accuracy: 0.8795 - val_loss: 0.3016 - val_accuracy: 0.8685\n",
      "Epoch 57/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2875 - accuracy: 0.8793 - val_loss: 0.3007 - val_accuracy: 0.8742\n",
      "Epoch 58/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2879 - accuracy: 0.8790 - val_loss: 0.2979 - val_accuracy: 0.8735\n",
      "Epoch 59/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2871 - accuracy: 0.8787 - val_loss: 0.3019 - val_accuracy: 0.8700\n",
      "Epoch 60/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2856 - accuracy: 0.8815 - val_loss: 0.2989 - val_accuracy: 0.8722\n",
      "Epoch 61/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2851 - accuracy: 0.8805 - val_loss: 0.3026 - val_accuracy: 0.8753\n",
      "Epoch 62/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2847 - accuracy: 0.8792 - val_loss: 0.2993 - val_accuracy: 0.8713\n",
      "Epoch 63/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2828 - accuracy: 0.8813 - val_loss: 0.2975 - val_accuracy: 0.8716\n",
      "Epoch 64/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2817 - accuracy: 0.8813 - val_loss: 0.3028 - val_accuracy: 0.8738\n",
      "Epoch 65/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2835 - accuracy: 0.8821 - val_loss: 0.2991 - val_accuracy: 0.8751\n",
      "Epoch 66/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2820 - accuracy: 0.8834 - val_loss: 0.3005 - val_accuracy: 0.8727\n",
      "Epoch 67/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2773 - accuracy: 0.8825 - val_loss: 0.2963 - val_accuracy: 0.8747\n",
      "Epoch 68/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2840 - accuracy: 0.8807 - val_loss: 0.2978 - val_accuracy: 0.8751\n",
      "Epoch 69/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2815 - accuracy: 0.8815 - val_loss: 0.2989 - val_accuracy: 0.8756\n",
      "Epoch 70/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2751 - accuracy: 0.8840 - val_loss: 0.2987 - val_accuracy: 0.8771\n",
      "Epoch 71/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2808 - accuracy: 0.8844 - val_loss: 0.2941 - val_accuracy: 0.8735\n",
      "Epoch 72/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2754 - accuracy: 0.8857 - val_loss: 0.2945 - val_accuracy: 0.8758\n",
      "Epoch 73/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2789 - accuracy: 0.8831 - val_loss: 0.2986 - val_accuracy: 0.8765\n",
      "Epoch 74/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2818 - accuracy: 0.8825 - val_loss: 0.2987 - val_accuracy: 0.8764\n",
      "Epoch 75/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2767 - accuracy: 0.8845 - val_loss: 0.2934 - val_accuracy: 0.8773\n",
      "Epoch 76/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2771 - accuracy: 0.8831 - val_loss: 0.2948 - val_accuracy: 0.8745\n",
      "Epoch 77/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2753 - accuracy: 0.8856 - val_loss: 0.2949 - val_accuracy: 0.8744\n",
      "Epoch 78/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2805 - accuracy: 0.8841 - val_loss: 0.2947 - val_accuracy: 0.8767\n",
      "Epoch 79/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2746 - accuracy: 0.8869 - val_loss: 0.2959 - val_accuracy: 0.8736\n",
      "Epoch 80/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2720 - accuracy: 0.8859 - val_loss: 0.2979 - val_accuracy: 0.8718\n",
      "Epoch 81/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2769 - accuracy: 0.8850 - val_loss: 0.2989 - val_accuracy: 0.8735\n",
      "Epoch 82/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2737 - accuracy: 0.8839 - val_loss: 0.2950 - val_accuracy: 0.8762\n",
      "Epoch 83/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2747 - accuracy: 0.8839 - val_loss: 0.2961 - val_accuracy: 0.8760\n",
      "Epoch 84/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2681 - accuracy: 0.8872 - val_loss: 0.2955 - val_accuracy: 0.8771\n",
      "Epoch 85/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2777 - accuracy: 0.8853 - val_loss: 0.2952 - val_accuracy: 0.8771\n",
      "Epoch 86/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2720 - accuracy: 0.8865 - val_loss: 0.2939 - val_accuracy: 0.8760\n",
      "Epoch 87/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2733 - accuracy: 0.8861 - val_loss: 0.2941 - val_accuracy: 0.8789\n",
      "Epoch 88/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2729 - accuracy: 0.8881 - val_loss: 0.2952 - val_accuracy: 0.8778\n",
      "Epoch 89/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2719 - accuracy: 0.8876 - val_loss: 0.2937 - val_accuracy: 0.8782\n",
      "Epoch 90/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2705 - accuracy: 0.8860 - val_loss: 0.2938 - val_accuracy: 0.8751\n",
      "Epoch 91/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2701 - accuracy: 0.8865 - val_loss: 0.2921 - val_accuracy: 0.8785\n",
      "Epoch 92/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2696 - accuracy: 0.8862 - val_loss: 0.2935 - val_accuracy: 0.8782\n",
      "Epoch 93/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2728 - accuracy: 0.8873 - val_loss: 0.2947 - val_accuracy: 0.8785\n",
      "Epoch 94/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2674 - accuracy: 0.8881 - val_loss: 0.2958 - val_accuracy: 0.8760\n",
      "Epoch 95/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2689 - accuracy: 0.8860 - val_loss: 0.2965 - val_accuracy: 0.8791\n",
      "Epoch 96/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2715 - accuracy: 0.8870 - val_loss: 0.2927 - val_accuracy: 0.8791\n",
      "Epoch 97/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.2694 - accuracy: 0.8885 - val_loss: 0.2904 - val_accuracy: 0.8804\n",
      "Epoch 98/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.2668 - accuracy: 0.8910 - val_loss: 0.2979 - val_accuracy: 0.8785\n",
      "Epoch 99/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2673 - accuracy: 0.8878 - val_loss: 0.2948 - val_accuracy: 0.8765\n",
      "Epoch 100/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2684 - accuracy: 0.8870 - val_loss: 0.2938 - val_accuracy: 0.8789\n",
      "Epoch 101/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2657 - accuracy: 0.8903 - val_loss: 0.2975 - val_accuracy: 0.8784\n",
      "Epoch 102/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2646 - accuracy: 0.8910 - val_loss: 0.2934 - val_accuracy: 0.8769\n",
      "Epoch 103/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2667 - accuracy: 0.8882 - val_loss: 0.2915 - val_accuracy: 0.8791\n",
      "Epoch 104/200\n",
      "22000/22000 [==============================] - 1s 57us/sample - loss: 0.2640 - accuracy: 0.8901 - val_loss: 0.2945 - val_accuracy: 0.8758\n",
      "Epoch 105/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2663 - accuracy: 0.8855 - val_loss: 0.2975 - val_accuracy: 0.8778\n",
      "Epoch 106/200\n",
      "22000/22000 [==============================] - 1s 63us/sample - loss: 0.2662 - accuracy: 0.8893 - val_loss: 0.2975 - val_accuracy: 0.8758\n",
      "Epoch 107/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2626 - accuracy: 0.8903 - val_loss: 0.2946 - val_accuracy: 0.8789\n",
      "Epoch 108/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2642 - accuracy: 0.8886 - val_loss: 0.2933 - val_accuracy: 0.8789\n",
      "Epoch 109/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2637 - accuracy: 0.8920 - val_loss: 0.2917 - val_accuracy: 0.8764\n",
      "Epoch 110/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2652 - accuracy: 0.8902 - val_loss: 0.2942 - val_accuracy: 0.8805\n",
      "Epoch 111/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2647 - accuracy: 0.8895 - val_loss: 0.2879 - val_accuracy: 0.8773\n",
      "Epoch 112/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2659 - accuracy: 0.8890 - val_loss: 0.2943 - val_accuracy: 0.8820\n",
      "Epoch 113/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2658 - accuracy: 0.8905 - val_loss: 0.2911 - val_accuracy: 0.8782\n",
      "Epoch 114/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2618 - accuracy: 0.8931 - val_loss: 0.2914 - val_accuracy: 0.8760\n",
      "Epoch 115/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2625 - accuracy: 0.8906 - val_loss: 0.2964 - val_accuracy: 0.8778\n",
      "Epoch 116/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2615 - accuracy: 0.8930 - val_loss: 0.2928 - val_accuracy: 0.8782\n",
      "Epoch 117/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2616 - accuracy: 0.8915 - val_loss: 0.2950 - val_accuracy: 0.8749\n",
      "Epoch 118/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2619 - accuracy: 0.8918 - val_loss: 0.2949 - val_accuracy: 0.8782\n",
      "Epoch 119/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2589 - accuracy: 0.8942 - val_loss: 0.2927 - val_accuracy: 0.8782\n",
      "Epoch 120/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2626 - accuracy: 0.8895 - val_loss: 0.3026 - val_accuracy: 0.8782\n",
      "Epoch 121/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2600 - accuracy: 0.8930 - val_loss: 0.2905 - val_accuracy: 0.8813\n",
      "Epoch 122/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2606 - accuracy: 0.8922 - val_loss: 0.2889 - val_accuracy: 0.8800\n",
      "Epoch 123/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2576 - accuracy: 0.8935 - val_loss: 0.2903 - val_accuracy: 0.8820\n",
      "Epoch 124/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2608 - accuracy: 0.8918 - val_loss: 0.2908 - val_accuracy: 0.8798\n",
      "Epoch 125/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2587 - accuracy: 0.8927 - val_loss: 0.2980 - val_accuracy: 0.8811\n",
      "Epoch 126/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2566 - accuracy: 0.8954 - val_loss: 0.2900 - val_accuracy: 0.8824\n",
      "Epoch 127/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2568 - accuracy: 0.8924 - val_loss: 0.2917 - val_accuracy: 0.8789\n",
      "Epoch 128/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2581 - accuracy: 0.8938 - val_loss: 0.2927 - val_accuracy: 0.8767\n",
      "Epoch 129/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2580 - accuracy: 0.8940 - val_loss: 0.2907 - val_accuracy: 0.8825\n",
      "Epoch 130/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2579 - accuracy: 0.8913 - val_loss: 0.2856 - val_accuracy: 0.8796\n",
      "Epoch 131/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.2550 - accuracy: 0.8940 - val_loss: 0.2888 - val_accuracy: 0.8782\n",
      "Epoch 132/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2577 - accuracy: 0.8934 - val_loss: 0.2903 - val_accuracy: 0.8798\n",
      "Epoch 133/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2590 - accuracy: 0.8905 - val_loss: 0.2921 - val_accuracy: 0.8789\n",
      "Epoch 134/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2537 - accuracy: 0.8942 - val_loss: 0.2967 - val_accuracy: 0.8802\n",
      "Epoch 135/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2580 - accuracy: 0.8928 - val_loss: 0.2939 - val_accuracy: 0.8822\n",
      "Epoch 136/200\n",
      "22000/22000 [==============================] - 1s 57us/sample - loss: 0.2560 - accuracy: 0.8936 - val_loss: 0.2903 - val_accuracy: 0.8811\n",
      "Epoch 137/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2577 - accuracy: 0.8933 - val_loss: 0.2897 - val_accuracy: 0.8809\n",
      "Epoch 138/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2535 - accuracy: 0.8930 - val_loss: 0.2909 - val_accuracy: 0.8795\n",
      "Epoch 139/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2536 - accuracy: 0.8945 - val_loss: 0.2917 - val_accuracy: 0.8791\n",
      "Epoch 140/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.2549 - accuracy: 0.8966 - val_loss: 0.2957 - val_accuracy: 0.8809\n",
      "Epoch 141/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2496 - accuracy: 0.8949 - val_loss: 0.2895 - val_accuracy: 0.8815\n",
      "Epoch 142/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2559 - accuracy: 0.8951 - val_loss: 0.2910 - val_accuracy: 0.8804\n",
      "Epoch 143/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.2547 - accuracy: 0.8936 - val_loss: 0.2899 - val_accuracy: 0.8791\n",
      "Epoch 144/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2521 - accuracy: 0.8939 - val_loss: 0.2970 - val_accuracy: 0.8805\n",
      "Epoch 145/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2528 - accuracy: 0.8948 - val_loss: 0.2885 - val_accuracy: 0.8800\n",
      "Epoch 146/200\n",
      "22000/22000 [==============================] - 1s 43us/sample - loss: 0.2546 - accuracy: 0.8955 - val_loss: 0.2902 - val_accuracy: 0.8795\n",
      "Epoch 147/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2577 - accuracy: 0.8943 - val_loss: 0.2944 - val_accuracy: 0.8800\n",
      "Epoch 148/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2584 - accuracy: 0.8917 - val_loss: 0.2879 - val_accuracy: 0.8842\n",
      "Epoch 149/200\n",
      "22000/22000 [==============================] - 1s 58us/sample - loss: 0.2541 - accuracy: 0.8954 - val_loss: 0.2848 - val_accuracy: 0.8804\n",
      "Epoch 150/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2540 - accuracy: 0.8951 - val_loss: 0.2888 - val_accuracy: 0.8793\n",
      "Epoch 151/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2533 - accuracy: 0.8961 - val_loss: 0.2843 - val_accuracy: 0.8820\n",
      "Epoch 152/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.2551 - accuracy: 0.8926 - val_loss: 0.2896 - val_accuracy: 0.8804\n",
      "Epoch 153/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.2519 - accuracy: 0.8964 - val_loss: 0.2871 - val_accuracy: 0.8798\n",
      "Epoch 154/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.2534 - accuracy: 0.8978 - val_loss: 0.2898 - val_accuracy: 0.8778\n",
      "Epoch 155/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2494 - accuracy: 0.8961 - val_loss: 0.2927 - val_accuracy: 0.8818\n",
      "Epoch 156/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.2504 - accuracy: 0.8988 - val_loss: 0.2890 - val_accuracy: 0.8798\n",
      "Epoch 157/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2469 - accuracy: 0.8977 - val_loss: 0.2890 - val_accuracy: 0.8824\n",
      "Epoch 158/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2492 - accuracy: 0.8970 - val_loss: 0.2927 - val_accuracy: 0.8815\n",
      "Epoch 159/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2526 - accuracy: 0.8970 - val_loss: 0.2852 - val_accuracy: 0.8813\n",
      "Epoch 160/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.2499 - accuracy: 0.8980 - val_loss: 0.2870 - val_accuracy: 0.8811\n",
      "Epoch 161/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.2483 - accuracy: 0.8978 - val_loss: 0.2914 - val_accuracy: 0.8775\n",
      "Epoch 162/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.2503 - accuracy: 0.8971 - val_loss: 0.2879 - val_accuracy: 0.8815\n",
      "Epoch 163/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2478 - accuracy: 0.8981 - val_loss: 0.2886 - val_accuracy: 0.8800\n",
      "Epoch 164/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.2515 - accuracy: 0.8960 - val_loss: 0.2901 - val_accuracy: 0.8825\n",
      "Epoch 165/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.2462 - accuracy: 0.8996 - val_loss: 0.2861 - val_accuracy: 0.8816\n",
      "Epoch 166/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.2524 - accuracy: 0.8970 - val_loss: 0.2891 - val_accuracy: 0.8816\n",
      "Epoch 167/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.2481 - accuracy: 0.8986 - val_loss: 0.2942 - val_accuracy: 0.8807\n",
      "Epoch 168/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2482 - accuracy: 0.8989 - val_loss: 0.2928 - val_accuracy: 0.8835\n",
      "test:0.848582\n",
      "valid:0.884182\n",
      "train:0.933045\n",
      "acc:0.856040\n",
      "0.8560395998931953\n",
      "Train on 22000 samples, validate on 5500 samples\n",
      "Epoch 1/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.4663 - accuracy: 0.7900 - val_loss: 0.3762 - val_accuracy: 0.8389\n",
      "Epoch 2/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.3929 - accuracy: 0.8325 - val_loss: 0.3570 - val_accuracy: 0.8505\n",
      "Epoch 3/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.3776 - accuracy: 0.8410 - val_loss: 0.3428 - val_accuracy: 0.8567\n",
      "Epoch 4/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.3618 - accuracy: 0.8482 - val_loss: 0.3329 - val_accuracy: 0.8604\n",
      "Epoch 5/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.3546 - accuracy: 0.8536 - val_loss: 0.3264 - val_accuracy: 0.8638\n",
      "Epoch 6/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.3433 - accuracy: 0.8605 - val_loss: 0.3236 - val_accuracy: 0.8649\n",
      "Epoch 7/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.3396 - accuracy: 0.8608 - val_loss: 0.3157 - val_accuracy: 0.8682\n",
      "Epoch 8/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.3335 - accuracy: 0.8647 - val_loss: 0.3121 - val_accuracy: 0.8733\n",
      "Epoch 9/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.3293 - accuracy: 0.8648 - val_loss: 0.3098 - val_accuracy: 0.8700\n",
      "Epoch 10/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.3241 - accuracy: 0.8680 - val_loss: 0.3077 - val_accuracy: 0.8749\n",
      "Epoch 11/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.3173 - accuracy: 0.8705 - val_loss: 0.3054 - val_accuracy: 0.8738\n",
      "Epoch 12/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.3174 - accuracy: 0.8696 - val_loss: 0.3047 - val_accuracy: 0.8742\n",
      "Epoch 13/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.3173 - accuracy: 0.8718 - val_loss: 0.2978 - val_accuracy: 0.8780\n",
      "Epoch 14/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.3118 - accuracy: 0.8732 - val_loss: 0.2968 - val_accuracy: 0.8804\n",
      "Epoch 15/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.3100 - accuracy: 0.8750 - val_loss: 0.2943 - val_accuracy: 0.8802\n",
      "Epoch 16/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.3040 - accuracy: 0.8770 - val_loss: 0.2939 - val_accuracy: 0.8791\n",
      "Epoch 17/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.3027 - accuracy: 0.8777 - val_loss: 0.2929 - val_accuracy: 0.8811\n",
      "Epoch 18/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.3013 - accuracy: 0.8776 - val_loss: 0.2917 - val_accuracy: 0.8822\n",
      "Epoch 19/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2997 - accuracy: 0.8782 - val_loss: 0.2888 - val_accuracy: 0.8831\n",
      "Epoch 20/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2947 - accuracy: 0.8786 - val_loss: 0.2917 - val_accuracy: 0.8822\n",
      "Epoch 21/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2961 - accuracy: 0.8816 - val_loss: 0.2880 - val_accuracy: 0.8840\n",
      "Epoch 22/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.2946 - accuracy: 0.8810 - val_loss: 0.2864 - val_accuracy: 0.8853\n",
      "Epoch 23/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2964 - accuracy: 0.8808 - val_loss: 0.2861 - val_accuracy: 0.8856\n",
      "Epoch 24/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2909 - accuracy: 0.8839 - val_loss: 0.2853 - val_accuracy: 0.8849\n",
      "Epoch 25/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2946 - accuracy: 0.8835 - val_loss: 0.2878 - val_accuracy: 0.8840\n",
      "Epoch 26/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2870 - accuracy: 0.8856 - val_loss: 0.2846 - val_accuracy: 0.8844\n",
      "Epoch 27/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2863 - accuracy: 0.8866 - val_loss: 0.2839 - val_accuracy: 0.8855\n",
      "Epoch 28/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2891 - accuracy: 0.8840 - val_loss: 0.2812 - val_accuracy: 0.8873\n",
      "Epoch 29/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2829 - accuracy: 0.8867 - val_loss: 0.2843 - val_accuracy: 0.8845\n",
      "Epoch 30/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2831 - accuracy: 0.8862 - val_loss: 0.2806 - val_accuracy: 0.8865\n",
      "Epoch 31/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2832 - accuracy: 0.8857 - val_loss: 0.2777 - val_accuracy: 0.8876\n",
      "Epoch 32/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.2833 - accuracy: 0.8885 - val_loss: 0.2809 - val_accuracy: 0.8860\n",
      "Epoch 33/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.2795 - accuracy: 0.8873 - val_loss: 0.2769 - val_accuracy: 0.8895\n",
      "Epoch 34/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2802 - accuracy: 0.8887 - val_loss: 0.2781 - val_accuracy: 0.8873\n",
      "Epoch 35/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.2786 - accuracy: 0.8884 - val_loss: 0.2771 - val_accuracy: 0.8842\n",
      "Epoch 36/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2750 - accuracy: 0.8912 - val_loss: 0.2766 - val_accuracy: 0.8904\n",
      "Epoch 37/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.2785 - accuracy: 0.8892 - val_loss: 0.2759 - val_accuracy: 0.8900\n",
      "Epoch 38/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2735 - accuracy: 0.8898 - val_loss: 0.2744 - val_accuracy: 0.8885\n",
      "Epoch 39/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2735 - accuracy: 0.8903 - val_loss: 0.2758 - val_accuracy: 0.8878\n",
      "Epoch 40/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2730 - accuracy: 0.8887 - val_loss: 0.2746 - val_accuracy: 0.8895\n",
      "Epoch 41/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.2728 - accuracy: 0.8905 - val_loss: 0.2737 - val_accuracy: 0.8902\n",
      "Epoch 42/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2716 - accuracy: 0.8928 - val_loss: 0.2736 - val_accuracy: 0.8905\n",
      "Epoch 43/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2679 - accuracy: 0.8928 - val_loss: 0.2729 - val_accuracy: 0.8884\n",
      "Epoch 44/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2703 - accuracy: 0.8922 - val_loss: 0.2742 - val_accuracy: 0.8895\n",
      "Epoch 45/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.2670 - accuracy: 0.8921 - val_loss: 0.2740 - val_accuracy: 0.8896\n",
      "Epoch 46/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.2674 - accuracy: 0.8935 - val_loss: 0.2750 - val_accuracy: 0.8913\n",
      "Epoch 47/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2681 - accuracy: 0.8914 - val_loss: 0.2774 - val_accuracy: 0.8887\n",
      "Epoch 48/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.2657 - accuracy: 0.8937 - val_loss: 0.2741 - val_accuracy: 0.8896\n",
      "Epoch 49/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2658 - accuracy: 0.8956 - val_loss: 0.2693 - val_accuracy: 0.8900\n",
      "Epoch 50/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2648 - accuracy: 0.8954 - val_loss: 0.2708 - val_accuracy: 0.8909\n",
      "Epoch 51/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.2620 - accuracy: 0.8939 - val_loss: 0.2703 - val_accuracy: 0.8905\n",
      "Epoch 52/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2626 - accuracy: 0.8945 - val_loss: 0.2694 - val_accuracy: 0.8938\n",
      "Epoch 53/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2637 - accuracy: 0.8937 - val_loss: 0.2685 - val_accuracy: 0.8927\n",
      "Epoch 54/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2596 - accuracy: 0.8955 - val_loss: 0.2681 - val_accuracy: 0.8955\n",
      "Epoch 55/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2601 - accuracy: 0.8955 - val_loss: 0.2704 - val_accuracy: 0.8916\n",
      "Epoch 56/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2569 - accuracy: 0.8983 - val_loss: 0.2704 - val_accuracy: 0.8924\n",
      "Epoch 57/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2572 - accuracy: 0.8977 - val_loss: 0.2657 - val_accuracy: 0.8947\n",
      "Epoch 58/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2574 - accuracy: 0.8988 - val_loss: 0.2682 - val_accuracy: 0.8942\n",
      "Epoch 59/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2556 - accuracy: 0.8959 - val_loss: 0.2654 - val_accuracy: 0.8955\n",
      "Epoch 60/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2548 - accuracy: 0.8981 - val_loss: 0.2738 - val_accuracy: 0.8907\n",
      "Epoch 61/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2584 - accuracy: 0.8963 - val_loss: 0.2673 - val_accuracy: 0.8944\n",
      "Epoch 62/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2534 - accuracy: 0.8981 - val_loss: 0.2667 - val_accuracy: 0.8935\n",
      "Epoch 63/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2565 - accuracy: 0.8961 - val_loss: 0.2643 - val_accuracy: 0.8958\n",
      "Epoch 64/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2561 - accuracy: 0.8976 - val_loss: 0.2662 - val_accuracy: 0.8942\n",
      "Epoch 65/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2532 - accuracy: 0.8980 - val_loss: 0.2627 - val_accuracy: 0.8953\n",
      "Epoch 66/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2539 - accuracy: 0.8980 - val_loss: 0.2638 - val_accuracy: 0.8956\n",
      "Epoch 67/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.2513 - accuracy: 0.8987 - val_loss: 0.2683 - val_accuracy: 0.8940\n",
      "Epoch 68/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2539 - accuracy: 0.8973 - val_loss: 0.2645 - val_accuracy: 0.8953\n",
      "Epoch 69/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2509 - accuracy: 0.9015 - val_loss: 0.2640 - val_accuracy: 0.8987\n",
      "Epoch 70/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.2506 - accuracy: 0.9017 - val_loss: 0.2626 - val_accuracy: 0.8989\n",
      "Epoch 71/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.2500 - accuracy: 0.8998 - val_loss: 0.2623 - val_accuracy: 0.8962\n",
      "Epoch 72/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.2492 - accuracy: 0.9015 - val_loss: 0.2642 - val_accuracy: 0.8944\n",
      "Epoch 73/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2498 - accuracy: 0.9011 - val_loss: 0.2615 - val_accuracy: 0.8973\n",
      "Epoch 74/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2485 - accuracy: 0.9008 - val_loss: 0.2628 - val_accuracy: 0.8938\n",
      "Epoch 75/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2458 - accuracy: 0.9011 - val_loss: 0.2642 - val_accuracy: 0.8980\n",
      "Epoch 76/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2440 - accuracy: 0.9030 - val_loss: 0.2624 - val_accuracy: 0.8929\n",
      "Epoch 77/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2487 - accuracy: 0.9005 - val_loss: 0.2612 - val_accuracy: 0.8964\n",
      "Epoch 78/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2462 - accuracy: 0.9026 - val_loss: 0.2652 - val_accuracy: 0.8935\n",
      "Epoch 79/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.2437 - accuracy: 0.9040 - val_loss: 0.2605 - val_accuracy: 0.8940\n",
      "Epoch 80/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2451 - accuracy: 0.9035 - val_loss: 0.2624 - val_accuracy: 0.8940\n",
      "Epoch 81/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2455 - accuracy: 0.9024 - val_loss: 0.2675 - val_accuracy: 0.8955\n",
      "Epoch 82/200\n",
      "22000/22000 [==============================] - 1s 43us/sample - loss: 0.2467 - accuracy: 0.9019 - val_loss: 0.2610 - val_accuracy: 0.8958\n",
      "Epoch 83/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2421 - accuracy: 0.9029 - val_loss: 0.2626 - val_accuracy: 0.8945\n",
      "Epoch 84/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2436 - accuracy: 0.9041 - val_loss: 0.2613 - val_accuracy: 0.8925\n",
      "Epoch 85/200\n",
      "22000/22000 [==============================] - 1s 43us/sample - loss: 0.2435 - accuracy: 0.9046 - val_loss: 0.2598 - val_accuracy: 0.8944\n",
      "Epoch 86/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2433 - accuracy: 0.9025 - val_loss: 0.2562 - val_accuracy: 0.8944\n",
      "Epoch 87/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.2389 - accuracy: 0.9052 - val_loss: 0.2595 - val_accuracy: 0.8947\n",
      "Epoch 88/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.2417 - accuracy: 0.9035 - val_loss: 0.2567 - val_accuracy: 0.8962\n",
      "Epoch 89/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2391 - accuracy: 0.9052 - val_loss: 0.2617 - val_accuracy: 0.8956\n",
      "Epoch 90/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2411 - accuracy: 0.9049 - val_loss: 0.2583 - val_accuracy: 0.8962\n",
      "test:0.876073\n",
      "valid:0.898909\n",
      "train:0.927545\n",
      "acc:0.868178\n",
      "0.8681783638342884\n",
      "Train on 22000 samples, validate on 5500 samples\n",
      "Epoch 1/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.6002 - accuracy: 0.6850 - val_loss: 0.4445 - val_accuracy: 0.7964\n",
      "Epoch 2/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.4658 - accuracy: 0.7898 - val_loss: 0.3984 - val_accuracy: 0.8267\n",
      "Epoch 3/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.4285 - accuracy: 0.8128 - val_loss: 0.3799 - val_accuracy: 0.8440\n",
      "Epoch 4/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.4087 - accuracy: 0.8277 - val_loss: 0.3626 - val_accuracy: 0.8511\n",
      "Epoch 5/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.3917 - accuracy: 0.8367 - val_loss: 0.3492 - val_accuracy: 0.8591\n",
      "Epoch 6/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.3813 - accuracy: 0.8429 - val_loss: 0.3435 - val_accuracy: 0.8664\n",
      "Epoch 7/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.3717 - accuracy: 0.8491 - val_loss: 0.3332 - val_accuracy: 0.8671\n",
      "Epoch 8/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.3649 - accuracy: 0.8519 - val_loss: 0.3295 - val_accuracy: 0.8695\n",
      "Epoch 9/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.3560 - accuracy: 0.8565 - val_loss: 0.3216 - val_accuracy: 0.8727\n",
      "Epoch 10/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.3503 - accuracy: 0.8587 - val_loss: 0.3189 - val_accuracy: 0.8764\n",
      "Epoch 11/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.3473 - accuracy: 0.8611 - val_loss: 0.3151 - val_accuracy: 0.8769\n",
      "Epoch 12/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.3356 - accuracy: 0.8655 - val_loss: 0.3094 - val_accuracy: 0.8762\n",
      "Epoch 13/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.3344 - accuracy: 0.8672 - val_loss: 0.3069 - val_accuracy: 0.8789\n",
      "Epoch 14/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.3305 - accuracy: 0.8689 - val_loss: 0.3030 - val_accuracy: 0.8818\n",
      "Epoch 15/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.3254 - accuracy: 0.8698 - val_loss: 0.2983 - val_accuracy: 0.8782\n",
      "Epoch 16/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.3235 - accuracy: 0.8712 - val_loss: 0.2960 - val_accuracy: 0.8820\n",
      "Epoch 17/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.3192 - accuracy: 0.8734 - val_loss: 0.2967 - val_accuracy: 0.8805\n",
      "Epoch 18/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.3162 - accuracy: 0.8754 - val_loss: 0.2901 - val_accuracy: 0.8813\n",
      "Epoch 19/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.3112 - accuracy: 0.8774 - val_loss: 0.2888 - val_accuracy: 0.8842\n",
      "Epoch 20/200\n",
      "22000/22000 [==============================] - 1s 43us/sample - loss: 0.3098 - accuracy: 0.8772 - val_loss: 0.2856 - val_accuracy: 0.8842\n",
      "Epoch 21/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.3068 - accuracy: 0.8785 - val_loss: 0.2857 - val_accuracy: 0.8847\n",
      "Epoch 22/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.3021 - accuracy: 0.8812 - val_loss: 0.2837 - val_accuracy: 0.8860\n",
      "Epoch 23/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.3031 - accuracy: 0.8789 - val_loss: 0.2785 - val_accuracy: 0.8869\n",
      "Epoch 24/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.3014 - accuracy: 0.8838 - val_loss: 0.2850 - val_accuracy: 0.8875\n",
      "Epoch 25/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.2952 - accuracy: 0.8838 - val_loss: 0.2770 - val_accuracy: 0.8893\n",
      "Epoch 26/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.2984 - accuracy: 0.8823 - val_loss: 0.2772 - val_accuracy: 0.8878\n",
      "Epoch 27/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2950 - accuracy: 0.8845 - val_loss: 0.2791 - val_accuracy: 0.8876\n",
      "Epoch 28/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.2940 - accuracy: 0.8851 - val_loss: 0.2759 - val_accuracy: 0.8893\n",
      "Epoch 29/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2876 - accuracy: 0.8860 - val_loss: 0.2739 - val_accuracy: 0.8885\n",
      "Epoch 30/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.2894 - accuracy: 0.8850 - val_loss: 0.2745 - val_accuracy: 0.8893\n",
      "Epoch 31/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2879 - accuracy: 0.8872 - val_loss: 0.2725 - val_accuracy: 0.8864\n",
      "Epoch 32/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2856 - accuracy: 0.8883 - val_loss: 0.2723 - val_accuracy: 0.8884\n",
      "Epoch 33/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2873 - accuracy: 0.8871 - val_loss: 0.2703 - val_accuracy: 0.8935\n",
      "Epoch 34/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2815 - accuracy: 0.8903 - val_loss: 0.2731 - val_accuracy: 0.8893\n",
      "Epoch 35/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2826 - accuracy: 0.8884 - val_loss: 0.2701 - val_accuracy: 0.8909\n",
      "Epoch 36/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2832 - accuracy: 0.8871 - val_loss: 0.2677 - val_accuracy: 0.8933\n",
      "Epoch 37/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.2817 - accuracy: 0.8881 - val_loss: 0.2698 - val_accuracy: 0.8942\n",
      "Epoch 38/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2748 - accuracy: 0.8919 - val_loss: 0.2641 - val_accuracy: 0.8953\n",
      "Epoch 39/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2783 - accuracy: 0.8913 - val_loss: 0.2671 - val_accuracy: 0.8953\n",
      "Epoch 40/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2738 - accuracy: 0.8935 - val_loss: 0.2661 - val_accuracy: 0.8936\n",
      "Epoch 41/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.2741 - accuracy: 0.8921 - val_loss: 0.2651 - val_accuracy: 0.8935\n",
      "Epoch 42/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2731 - accuracy: 0.8906 - val_loss: 0.2682 - val_accuracy: 0.8951\n",
      "Epoch 43/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2689 - accuracy: 0.8945 - val_loss: 0.2640 - val_accuracy: 0.8953\n",
      "Epoch 44/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2688 - accuracy: 0.8936 - val_loss: 0.2643 - val_accuracy: 0.8973\n",
      "Epoch 45/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2703 - accuracy: 0.8923 - val_loss: 0.2645 - val_accuracy: 0.8960\n",
      "Epoch 46/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2688 - accuracy: 0.8951 - val_loss: 0.2622 - val_accuracy: 0.8967\n",
      "Epoch 47/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2681 - accuracy: 0.8954 - val_loss: 0.2627 - val_accuracy: 0.8960\n",
      "Epoch 48/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.2626 - accuracy: 0.8987 - val_loss: 0.2630 - val_accuracy: 0.8980\n",
      "Epoch 49/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2676 - accuracy: 0.8952 - val_loss: 0.2600 - val_accuracy: 0.8965\n",
      "Epoch 50/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2623 - accuracy: 0.8991 - val_loss: 0.2615 - val_accuracy: 0.8962\n",
      "Epoch 51/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2638 - accuracy: 0.8960 - val_loss: 0.2604 - val_accuracy: 0.8978\n",
      "Epoch 52/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.2654 - accuracy: 0.8965 - val_loss: 0.2583 - val_accuracy: 0.8975\n",
      "Epoch 53/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2589 - accuracy: 0.8988 - val_loss: 0.2633 - val_accuracy: 0.8960\n",
      "Epoch 54/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2640 - accuracy: 0.8952 - val_loss: 0.2625 - val_accuracy: 0.8973\n",
      "Epoch 55/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.2599 - accuracy: 0.8987 - val_loss: 0.2606 - val_accuracy: 0.8962\n",
      "Epoch 56/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.2620 - accuracy: 0.8981 - val_loss: 0.2586 - val_accuracy: 0.8973\n",
      "Epoch 57/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.2589 - accuracy: 0.8988 - val_loss: 0.2563 - val_accuracy: 0.8976\n",
      "Epoch 58/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2606 - accuracy: 0.8980 - val_loss: 0.2614 - val_accuracy: 0.8985\n",
      "Epoch 59/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2582 - accuracy: 0.9013 - val_loss: 0.2535 - val_accuracy: 0.8995\n",
      "Epoch 60/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2584 - accuracy: 0.8987 - val_loss: 0.2568 - val_accuracy: 0.8985\n",
      "Epoch 61/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2560 - accuracy: 0.9017 - val_loss: 0.2569 - val_accuracy: 0.8987\n",
      "Epoch 62/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2525 - accuracy: 0.9015 - val_loss: 0.2545 - val_accuracy: 0.9004\n",
      "Epoch 63/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2545 - accuracy: 0.8987 - val_loss: 0.2540 - val_accuracy: 0.8993\n",
      "Epoch 64/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2564 - accuracy: 0.9010 - val_loss: 0.2545 - val_accuracy: 0.9002\n",
      "Epoch 65/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2507 - accuracy: 0.9007 - val_loss: 0.2537 - val_accuracy: 0.9020\n",
      "Epoch 66/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.2512 - accuracy: 0.9024 - val_loss: 0.2518 - val_accuracy: 0.9007\n",
      "Epoch 67/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2484 - accuracy: 0.9035 - val_loss: 0.2542 - val_accuracy: 0.8980\n",
      "Epoch 68/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2464 - accuracy: 0.9047 - val_loss: 0.2513 - val_accuracy: 0.9002\n",
      "Epoch 69/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2522 - accuracy: 0.9022 - val_loss: 0.2525 - val_accuracy: 0.9000\n",
      "Epoch 70/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2512 - accuracy: 0.9023 - val_loss: 0.2541 - val_accuracy: 0.8998\n",
      "Epoch 71/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2512 - accuracy: 0.9016 - val_loss: 0.2523 - val_accuracy: 0.8978\n",
      "Epoch 72/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.2491 - accuracy: 0.9036 - val_loss: 0.2497 - val_accuracy: 0.9004\n",
      "Epoch 73/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2463 - accuracy: 0.9045 - val_loss: 0.2513 - val_accuracy: 0.9015\n",
      "Epoch 74/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2496 - accuracy: 0.9007 - val_loss: 0.2510 - val_accuracy: 0.8995\n",
      "Epoch 75/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.2429 - accuracy: 0.9056 - val_loss: 0.2525 - val_accuracy: 0.9000\n",
      "Epoch 76/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.2456 - accuracy: 0.9055 - val_loss: 0.2546 - val_accuracy: 0.9000\n",
      "Epoch 77/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.2446 - accuracy: 0.9057 - val_loss: 0.2510 - val_accuracy: 0.8998\n",
      "Epoch 78/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2445 - accuracy: 0.9052 - val_loss: 0.2504 - val_accuracy: 0.9013\n",
      "Epoch 79/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.2434 - accuracy: 0.9058 - val_loss: 0.2502 - val_accuracy: 0.9002\n",
      "Epoch 80/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2451 - accuracy: 0.9039 - val_loss: 0.2510 - val_accuracy: 0.9009\n",
      "Epoch 81/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2435 - accuracy: 0.9048 - val_loss: 0.2457 - val_accuracy: 0.9004\n",
      "Epoch 82/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2376 - accuracy: 0.9088 - val_loss: 0.2535 - val_accuracy: 0.9013\n",
      "Epoch 83/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2438 - accuracy: 0.9067 - val_loss: 0.2456 - val_accuracy: 0.8998\n",
      "Epoch 84/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2417 - accuracy: 0.9081 - val_loss: 0.2469 - val_accuracy: 0.9018\n",
      "Epoch 85/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2395 - accuracy: 0.9060 - val_loss: 0.2517 - val_accuracy: 0.9011\n",
      "test:0.865164\n",
      "valid:0.902000\n",
      "train:0.928909\n",
      "acc:0.850987\n",
      "0.8509869164253292\n",
      "Train on 22000 samples, validate on 5500 samples\n",
      "Epoch 1/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.4454 - accuracy: 0.8032 - val_loss: 0.3712 - val_accuracy: 0.8447\n",
      "Epoch 2/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.3881 - accuracy: 0.8352 - val_loss: 0.3432 - val_accuracy: 0.8560\n",
      "Epoch 3/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.3712 - accuracy: 0.8462 - val_loss: 0.3334 - val_accuracy: 0.8600\n",
      "Epoch 4/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.3621 - accuracy: 0.8526 - val_loss: 0.3271 - val_accuracy: 0.8633\n",
      "Epoch 5/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.3495 - accuracy: 0.8545 - val_loss: 0.3188 - val_accuracy: 0.8695\n",
      "Epoch 6/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.3449 - accuracy: 0.8579 - val_loss: 0.3114 - val_accuracy: 0.8744\n",
      "Epoch 7/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.3383 - accuracy: 0.8621 - val_loss: 0.3063 - val_accuracy: 0.8738\n",
      "Epoch 8/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.3280 - accuracy: 0.8664 - val_loss: 0.3011 - val_accuracy: 0.8782\n",
      "Epoch 9/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.3250 - accuracy: 0.8668 - val_loss: 0.2978 - val_accuracy: 0.8791\n",
      "Epoch 10/200\n",
      "22000/22000 [==============================] - 1s 43us/sample - loss: 0.3214 - accuracy: 0.8695 - val_loss: 0.2958 - val_accuracy: 0.8765\n",
      "Epoch 11/200\n",
      "22000/22000 [==============================] - 1s 43us/sample - loss: 0.3157 - accuracy: 0.8732 - val_loss: 0.2942 - val_accuracy: 0.8804\n",
      "Epoch 12/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.3169 - accuracy: 0.8705 - val_loss: 0.2934 - val_accuracy: 0.8807\n",
      "Epoch 13/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.3113 - accuracy: 0.8740 - val_loss: 0.2910 - val_accuracy: 0.8833\n",
      "Epoch 14/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.3099 - accuracy: 0.8765 - val_loss: 0.2920 - val_accuracy: 0.8815\n",
      "Epoch 15/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.3076 - accuracy: 0.8766 - val_loss: 0.2867 - val_accuracy: 0.8796\n",
      "Epoch 16/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.3027 - accuracy: 0.8775 - val_loss: 0.2847 - val_accuracy: 0.8815\n",
      "Epoch 17/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.2995 - accuracy: 0.8805 - val_loss: 0.2820 - val_accuracy: 0.8825\n",
      "Epoch 18/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.3019 - accuracy: 0.8788 - val_loss: 0.2817 - val_accuracy: 0.8825\n",
      "Epoch 19/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2998 - accuracy: 0.8800 - val_loss: 0.2785 - val_accuracy: 0.8840\n",
      "Epoch 20/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2954 - accuracy: 0.8812 - val_loss: 0.2791 - val_accuracy: 0.8844\n",
      "Epoch 21/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.2954 - accuracy: 0.8809 - val_loss: 0.2797 - val_accuracy: 0.8835\n",
      "Epoch 22/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2944 - accuracy: 0.8826 - val_loss: 0.2777 - val_accuracy: 0.8873\n",
      "Epoch 23/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.2923 - accuracy: 0.8835 - val_loss: 0.2769 - val_accuracy: 0.8851\n",
      "Epoch 24/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2886 - accuracy: 0.8841 - val_loss: 0.2737 - val_accuracy: 0.8860\n",
      "Epoch 25/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.2849 - accuracy: 0.8870 - val_loss: 0.2760 - val_accuracy: 0.8838\n",
      "Epoch 26/200\n",
      "22000/22000 [==============================] - 1s 43us/sample - loss: 0.2873 - accuracy: 0.8861 - val_loss: 0.2742 - val_accuracy: 0.8876\n",
      "Epoch 27/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.2798 - accuracy: 0.8893 - val_loss: 0.2726 - val_accuracy: 0.8856\n",
      "Epoch 28/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2825 - accuracy: 0.8883 - val_loss: 0.2758 - val_accuracy: 0.8862\n",
      "Epoch 29/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2800 - accuracy: 0.8884 - val_loss: 0.2700 - val_accuracy: 0.8882\n",
      "Epoch 30/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.2751 - accuracy: 0.8891 - val_loss: 0.2720 - val_accuracy: 0.8900\n",
      "Epoch 31/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2767 - accuracy: 0.8895 - val_loss: 0.2702 - val_accuracy: 0.8887\n",
      "Epoch 32/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.2740 - accuracy: 0.8913 - val_loss: 0.2673 - val_accuracy: 0.8915\n",
      "Epoch 33/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2739 - accuracy: 0.8901 - val_loss: 0.2710 - val_accuracy: 0.8898\n",
      "Epoch 34/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.2785 - accuracy: 0.8900 - val_loss: 0.2696 - val_accuracy: 0.8898\n",
      "Epoch 35/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2743 - accuracy: 0.8909 - val_loss: 0.2655 - val_accuracy: 0.8924\n",
      "Epoch 36/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.2741 - accuracy: 0.8919 - val_loss: 0.2637 - val_accuracy: 0.8920\n",
      "Epoch 37/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2718 - accuracy: 0.8919 - val_loss: 0.2693 - val_accuracy: 0.8918\n",
      "Epoch 38/200\n",
      "22000/22000 [==============================] - 1s 40us/sample - loss: 0.2686 - accuracy: 0.8904 - val_loss: 0.2654 - val_accuracy: 0.8922\n",
      "Epoch 39/200\n",
      "22000/22000 [==============================] - 1s 41us/sample - loss: 0.2681 - accuracy: 0.8939 - val_loss: 0.2638 - val_accuracy: 0.8940\n",
      "Epoch 40/200\n",
      "22000/22000 [==============================] - 1s 42us/sample - loss: 0.2659 - accuracy: 0.8944 - val_loss: 0.2641 - val_accuracy: 0.8929\n",
      "Epoch 41/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2678 - accuracy: 0.8938 - val_loss: 0.2610 - val_accuracy: 0.8965\n",
      "Epoch 42/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2648 - accuracy: 0.8941 - val_loss: 0.2626 - val_accuracy: 0.8924\n",
      "Epoch 43/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2661 - accuracy: 0.8950 - val_loss: 0.2627 - val_accuracy: 0.8922\n",
      "Epoch 44/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2643 - accuracy: 0.8955 - val_loss: 0.2630 - val_accuracy: 0.8940\n",
      "Epoch 45/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2649 - accuracy: 0.8946 - val_loss: 0.2669 - val_accuracy: 0.8915\n",
      "Epoch 46/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2613 - accuracy: 0.8974 - val_loss: 0.2650 - val_accuracy: 0.8931\n",
      "Epoch 47/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2649 - accuracy: 0.8937 - val_loss: 0.2622 - val_accuracy: 0.8945\n",
      "Epoch 48/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2600 - accuracy: 0.8969 - val_loss: 0.2626 - val_accuracy: 0.8924\n",
      "Epoch 49/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2622 - accuracy: 0.8962 - val_loss: 0.2598 - val_accuracy: 0.8944\n",
      "Epoch 50/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.2628 - accuracy: 0.8947 - val_loss: 0.2628 - val_accuracy: 0.8922\n",
      "Epoch 51/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2624 - accuracy: 0.8974 - val_loss: 0.2597 - val_accuracy: 0.8935\n",
      "Epoch 52/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2571 - accuracy: 0.8987 - val_loss: 0.2576 - val_accuracy: 0.8935\n",
      "Epoch 53/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2542 - accuracy: 0.9017 - val_loss: 0.2606 - val_accuracy: 0.8935\n",
      "Epoch 54/200\n",
      "22000/22000 [==============================] - 1s 60us/sample - loss: 0.2536 - accuracy: 0.9002 - val_loss: 0.2598 - val_accuracy: 0.8938\n",
      "Epoch 55/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2526 - accuracy: 0.9006 - val_loss: 0.2605 - val_accuracy: 0.8949\n",
      "Epoch 56/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.2589 - accuracy: 0.8982 - val_loss: 0.2600 - val_accuracy: 0.8942\n",
      "Epoch 57/200\n",
      "22000/22000 [==============================] - 1s 58us/sample - loss: 0.2571 - accuracy: 0.8985 - val_loss: 0.2587 - val_accuracy: 0.8980\n",
      "Epoch 58/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2531 - accuracy: 0.9001 - val_loss: 0.2581 - val_accuracy: 0.8942\n",
      "Epoch 59/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.2533 - accuracy: 0.9021 - val_loss: 0.2556 - val_accuracy: 0.8967\n",
      "Epoch 60/200\n",
      "22000/22000 [==============================] - 1s 56us/sample - loss: 0.2482 - accuracy: 0.9010 - val_loss: 0.2620 - val_accuracy: 0.8940\n",
      "Epoch 61/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.2497 - accuracy: 0.9006 - val_loss: 0.2589 - val_accuracy: 0.8958\n",
      "Epoch 62/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.2501 - accuracy: 0.9021 - val_loss: 0.2584 - val_accuracy: 0.8933\n",
      "Epoch 63/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.2518 - accuracy: 0.9005 - val_loss: 0.2611 - val_accuracy: 0.8956\n",
      "Epoch 64/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2493 - accuracy: 0.9035 - val_loss: 0.2589 - val_accuracy: 0.8953\n",
      "Epoch 65/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2480 - accuracy: 0.9013 - val_loss: 0.2550 - val_accuracy: 0.8982\n",
      "Epoch 66/200\n",
      "22000/22000 [==============================] - 1s 58us/sample - loss: 0.2486 - accuracy: 0.9027 - val_loss: 0.2560 - val_accuracy: 0.8978\n",
      "Epoch 67/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2470 - accuracy: 0.9012 - val_loss: 0.2564 - val_accuracy: 0.8960\n",
      "Epoch 68/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2472 - accuracy: 0.9012 - val_loss: 0.2543 - val_accuracy: 0.8976\n",
      "Epoch 69/200\n",
      "22000/22000 [==============================] - 1s 62us/sample - loss: 0.2482 - accuracy: 0.9029 - val_loss: 0.2543 - val_accuracy: 0.8980\n",
      "Epoch 70/200\n",
      "22000/22000 [==============================] - 1s 64us/sample - loss: 0.2453 - accuracy: 0.9021 - val_loss: 0.2529 - val_accuracy: 0.8995\n",
      "Epoch 71/200\n",
      "22000/22000 [==============================] - 1s 58us/sample - loss: 0.2463 - accuracy: 0.9035 - val_loss: 0.2531 - val_accuracy: 0.8982\n",
      "Epoch 72/200\n",
      "22000/22000 [==============================] - 1s 59us/sample - loss: 0.2415 - accuracy: 0.9049 - val_loss: 0.2567 - val_accuracy: 0.8982\n",
      "Epoch 73/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.2472 - accuracy: 0.9018 - val_loss: 0.2542 - val_accuracy: 0.8989\n",
      "Epoch 74/200\n",
      "22000/22000 [==============================] - 1s 57us/sample - loss: 0.2459 - accuracy: 0.9042 - val_loss: 0.2529 - val_accuracy: 0.8995\n",
      "Epoch 75/200\n",
      "22000/22000 [==============================] - 1s 63us/sample - loss: 0.2414 - accuracy: 0.9056 - val_loss: 0.2540 - val_accuracy: 0.8973\n",
      "Epoch 76/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2446 - accuracy: 0.9031 - val_loss: 0.2564 - val_accuracy: 0.8969\n",
      "Epoch 77/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2383 - accuracy: 0.9076 - val_loss: 0.2550 - val_accuracy: 0.8971\n",
      "Epoch 78/200\n",
      "22000/22000 [==============================] - 1s 63us/sample - loss: 0.2404 - accuracy: 0.9066 - val_loss: 0.2548 - val_accuracy: 0.8955\n",
      "Epoch 79/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.2393 - accuracy: 0.9075 - val_loss: 0.2566 - val_accuracy: 0.8967\n",
      "Epoch 80/200\n",
      "22000/22000 [==============================] - 1s 58us/sample - loss: 0.2390 - accuracy: 0.9071 - val_loss: 0.2575 - val_accuracy: 0.8965\n",
      "Epoch 81/200\n",
      "22000/22000 [==============================] - 1s 56us/sample - loss: 0.2393 - accuracy: 0.9067 - val_loss: 0.2562 - val_accuracy: 0.8993\n",
      "Epoch 82/200\n",
      "22000/22000 [==============================] - 1s 56us/sample - loss: 0.2378 - accuracy: 0.9060 - val_loss: 0.2553 - val_accuracy: 0.8984\n",
      "Epoch 83/200\n",
      "22000/22000 [==============================] - 1s 57us/sample - loss: 0.2397 - accuracy: 0.9060 - val_loss: 0.2539 - val_accuracy: 0.9004\n",
      "Epoch 84/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2384 - accuracy: 0.9067 - val_loss: 0.2560 - val_accuracy: 0.9016\n",
      "Epoch 85/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2350 - accuracy: 0.9076 - val_loss: 0.2534 - val_accuracy: 0.9029\n",
      "Epoch 86/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2355 - accuracy: 0.9081 - val_loss: 0.2548 - val_accuracy: 0.8976\n",
      "Epoch 87/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2375 - accuracy: 0.9069 - val_loss: 0.2520 - val_accuracy: 0.9011\n",
      "Epoch 88/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2369 - accuracy: 0.9067 - val_loss: 0.2527 - val_accuracy: 0.9007\n",
      "Epoch 89/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2365 - accuracy: 0.9081 - val_loss: 0.2522 - val_accuracy: 0.9007\n",
      "Epoch 90/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2363 - accuracy: 0.9081 - val_loss: 0.2507 - val_accuracy: 0.8989\n",
      "Epoch 91/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.2335 - accuracy: 0.9077 - val_loss: 0.2521 - val_accuracy: 0.9036\n",
      "Epoch 92/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.2364 - accuracy: 0.9076 - val_loss: 0.2497 - val_accuracy: 0.9033\n",
      "Epoch 93/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2338 - accuracy: 0.9088 - val_loss: 0.2533 - val_accuracy: 0.8993\n",
      "Epoch 94/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2360 - accuracy: 0.9069 - val_loss: 0.2506 - val_accuracy: 0.8978\n",
      "Epoch 95/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2308 - accuracy: 0.9091 - val_loss: 0.2526 - val_accuracy: 0.8996\n",
      "Epoch 96/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.2362 - accuracy: 0.9077 - val_loss: 0.2490 - val_accuracy: 0.9024\n",
      "Epoch 97/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2333 - accuracy: 0.9087 - val_loss: 0.2499 - val_accuracy: 0.8985\n",
      "Epoch 98/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2292 - accuracy: 0.9092 - val_loss: 0.2502 - val_accuracy: 0.9009\n",
      "Epoch 99/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2348 - accuracy: 0.9080 - val_loss: 0.2483 - val_accuracy: 0.9031\n",
      "Epoch 100/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2334 - accuracy: 0.9087 - val_loss: 0.2494 - val_accuracy: 0.9033\n",
      "Epoch 101/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2326 - accuracy: 0.9098 - val_loss: 0.2467 - val_accuracy: 0.9045\n",
      "Epoch 102/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2283 - accuracy: 0.9112 - val_loss: 0.2515 - val_accuracy: 0.8998\n",
      "Epoch 103/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2283 - accuracy: 0.9103 - val_loss: 0.2515 - val_accuracy: 0.9024\n",
      "Epoch 104/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2300 - accuracy: 0.9090 - val_loss: 0.2466 - val_accuracy: 0.9060\n",
      "Epoch 105/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2288 - accuracy: 0.9092 - val_loss: 0.2533 - val_accuracy: 0.9020\n",
      "Epoch 106/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.2278 - accuracy: 0.9100 - val_loss: 0.2504 - val_accuracy: 0.9015\n",
      "Epoch 107/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2315 - accuracy: 0.9103 - val_loss: 0.2497 - val_accuracy: 0.9035\n",
      "Epoch 108/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2288 - accuracy: 0.9100 - val_loss: 0.2448 - val_accuracy: 0.9029\n",
      "Epoch 109/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2312 - accuracy: 0.9091 - val_loss: 0.2492 - val_accuracy: 0.9027\n",
      "Epoch 110/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2251 - accuracy: 0.9110 - val_loss: 0.2506 - val_accuracy: 0.9020\n",
      "Epoch 111/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2258 - accuracy: 0.9125 - val_loss: 0.2508 - val_accuracy: 0.9020\n",
      "Epoch 112/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2254 - accuracy: 0.9105 - val_loss: 0.2461 - val_accuracy: 0.9035\n",
      "Epoch 113/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2222 - accuracy: 0.9122 - val_loss: 0.2539 - val_accuracy: 0.9029\n",
      "Epoch 114/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2228 - accuracy: 0.9150 - val_loss: 0.2524 - val_accuracy: 0.9011\n",
      "Epoch 115/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2258 - accuracy: 0.9118 - val_loss: 0.2497 - val_accuracy: 0.9031\n",
      "Epoch 116/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2288 - accuracy: 0.9111 - val_loss: 0.2530 - val_accuracy: 0.9002\n",
      "Epoch 117/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2280 - accuracy: 0.9120 - val_loss: 0.2509 - val_accuracy: 0.9022\n",
      "Epoch 118/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2277 - accuracy: 0.9101 - val_loss: 0.2468 - val_accuracy: 0.9047\n",
      "Epoch 119/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2234 - accuracy: 0.9138 - val_loss: 0.2475 - val_accuracy: 0.9040\n",
      "Epoch 120/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2238 - accuracy: 0.9129 - val_loss: 0.2511 - val_accuracy: 0.9022\n",
      "Epoch 121/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2248 - accuracy: 0.9130 - val_loss: 0.2495 - val_accuracy: 0.9040\n",
      "Epoch 122/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2197 - accuracy: 0.9139 - val_loss: 0.2440 - val_accuracy: 0.9058\n",
      "Epoch 123/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2280 - accuracy: 0.9119 - val_loss: 0.2455 - val_accuracy: 0.9055\n",
      "Epoch 124/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.2212 - accuracy: 0.9136 - val_loss: 0.2505 - val_accuracy: 0.9044\n",
      "test:0.872582\n",
      "valid:0.906000\n",
      "train:0.938591\n",
      "acc:0.864995\n",
      "0.8649947624622589\n",
      "Train on 22000 samples, validate on 5500 samples\n",
      "Epoch 1/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.4135 - accuracy: 0.8224 - val_loss: 0.3445 - val_accuracy: 0.8573\n",
      "Epoch 2/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.3736 - accuracy: 0.8420 - val_loss: 0.3290 - val_accuracy: 0.8660\n",
      "Epoch 3/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.3553 - accuracy: 0.8507 - val_loss: 0.3171 - val_accuracy: 0.8716\n",
      "Epoch 4/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.3463 - accuracy: 0.8555 - val_loss: 0.3088 - val_accuracy: 0.8745\n",
      "Epoch 5/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.3379 - accuracy: 0.8587 - val_loss: 0.3060 - val_accuracy: 0.8775\n",
      "Epoch 6/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.3290 - accuracy: 0.8640 - val_loss: 0.2941 - val_accuracy: 0.8833\n",
      "Epoch 7/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.3215 - accuracy: 0.8644 - val_loss: 0.2946 - val_accuracy: 0.8822\n",
      "Epoch 8/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.3158 - accuracy: 0.8676 - val_loss: 0.2926 - val_accuracy: 0.8847\n",
      "Epoch 9/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.3142 - accuracy: 0.8711 - val_loss: 0.2884 - val_accuracy: 0.8865\n",
      "Epoch 10/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.3151 - accuracy: 0.8707 - val_loss: 0.2892 - val_accuracy: 0.8864\n",
      "Epoch 11/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.3066 - accuracy: 0.8745 - val_loss: 0.2891 - val_accuracy: 0.8851\n",
      "Epoch 12/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.3005 - accuracy: 0.8764 - val_loss: 0.2843 - val_accuracy: 0.8878\n",
      "Epoch 13/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2991 - accuracy: 0.8777 - val_loss: 0.2795 - val_accuracy: 0.8909\n",
      "Epoch 14/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.3013 - accuracy: 0.8768 - val_loss: 0.2815 - val_accuracy: 0.8911\n",
      "Epoch 15/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2974 - accuracy: 0.8787 - val_loss: 0.2771 - val_accuracy: 0.8907\n",
      "Epoch 16/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2934 - accuracy: 0.8807 - val_loss: 0.2739 - val_accuracy: 0.8935\n",
      "Epoch 17/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2917 - accuracy: 0.8803 - val_loss: 0.2759 - val_accuracy: 0.8904\n",
      "Epoch 18/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2890 - accuracy: 0.8825 - val_loss: 0.2776 - val_accuracy: 0.8907\n",
      "Epoch 19/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2905 - accuracy: 0.8833 - val_loss: 0.2703 - val_accuracy: 0.8920\n",
      "Epoch 20/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2881 - accuracy: 0.8818 - val_loss: 0.2684 - val_accuracy: 0.8938\n",
      "Epoch 21/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2826 - accuracy: 0.8862 - val_loss: 0.2701 - val_accuracy: 0.8933\n",
      "Epoch 22/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2824 - accuracy: 0.8856 - val_loss: 0.2671 - val_accuracy: 0.8944\n",
      "Epoch 23/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2789 - accuracy: 0.8851 - val_loss: 0.2661 - val_accuracy: 0.8945\n",
      "Epoch 24/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.2792 - accuracy: 0.8870 - val_loss: 0.2653 - val_accuracy: 0.8927\n",
      "Epoch 25/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2777 - accuracy: 0.8871 - val_loss: 0.2660 - val_accuracy: 0.8920\n",
      "Epoch 26/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2779 - accuracy: 0.8880 - val_loss: 0.2664 - val_accuracy: 0.8942\n",
      "Epoch 27/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2727 - accuracy: 0.8894 - val_loss: 0.2659 - val_accuracy: 0.8949\n",
      "Epoch 28/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2802 - accuracy: 0.8839 - val_loss: 0.2625 - val_accuracy: 0.8931\n",
      "Epoch 29/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2726 - accuracy: 0.8865 - val_loss: 0.2680 - val_accuracy: 0.8924\n",
      "Epoch 30/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2690 - accuracy: 0.8890 - val_loss: 0.2623 - val_accuracy: 0.8936\n",
      "Epoch 31/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2709 - accuracy: 0.8905 - val_loss: 0.2634 - val_accuracy: 0.8920\n",
      "Epoch 32/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2665 - accuracy: 0.8899 - val_loss: 0.2608 - val_accuracy: 0.8947\n",
      "Epoch 33/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2667 - accuracy: 0.8900 - val_loss: 0.2607 - val_accuracy: 0.8965\n",
      "Epoch 34/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2658 - accuracy: 0.8929 - val_loss: 0.2607 - val_accuracy: 0.8955\n",
      "Epoch 35/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2636 - accuracy: 0.8933 - val_loss: 0.2623 - val_accuracy: 0.8969\n",
      "Epoch 36/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2644 - accuracy: 0.8923 - val_loss: 0.2643 - val_accuracy: 0.8982\n",
      "Epoch 37/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2621 - accuracy: 0.8949 - val_loss: 0.2593 - val_accuracy: 0.8969\n",
      "Epoch 38/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.2640 - accuracy: 0.8931 - val_loss: 0.2600 - val_accuracy: 0.8969\n",
      "Epoch 39/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2560 - accuracy: 0.8976 - val_loss: 0.2583 - val_accuracy: 0.8967\n",
      "Epoch 40/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2591 - accuracy: 0.8936 - val_loss: 0.2574 - val_accuracy: 0.8984\n",
      "Epoch 41/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2588 - accuracy: 0.8959 - val_loss: 0.2531 - val_accuracy: 0.8987\n",
      "Epoch 42/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2601 - accuracy: 0.8968 - val_loss: 0.2583 - val_accuracy: 0.8978\n",
      "Epoch 43/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2601 - accuracy: 0.8949 - val_loss: 0.2550 - val_accuracy: 0.8965\n",
      "Epoch 44/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2590 - accuracy: 0.8970 - val_loss: 0.2586 - val_accuracy: 0.8965\n",
      "Epoch 45/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2542 - accuracy: 0.8970 - val_loss: 0.2534 - val_accuracy: 0.8973\n",
      "Epoch 46/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2541 - accuracy: 0.8980 - val_loss: 0.2569 - val_accuracy: 0.8958\n",
      "Epoch 47/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2524 - accuracy: 0.8984 - val_loss: 0.2569 - val_accuracy: 0.8967\n",
      "Epoch 48/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2496 - accuracy: 0.8991 - val_loss: 0.2541 - val_accuracy: 0.8991\n",
      "Epoch 49/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2520 - accuracy: 0.8975 - val_loss: 0.2536 - val_accuracy: 0.8982\n",
      "Epoch 50/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2508 - accuracy: 0.8979 - val_loss: 0.2528 - val_accuracy: 0.8975\n",
      "Epoch 51/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2520 - accuracy: 0.8969 - val_loss: 0.2541 - val_accuracy: 0.8984\n",
      "Epoch 52/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2530 - accuracy: 0.8989 - val_loss: 0.2534 - val_accuracy: 0.8967\n",
      "Epoch 53/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2513 - accuracy: 0.9005 - val_loss: 0.2516 - val_accuracy: 0.9018\n",
      "Epoch 54/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2535 - accuracy: 0.8966 - val_loss: 0.2516 - val_accuracy: 0.9000\n",
      "Epoch 55/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2474 - accuracy: 0.9024 - val_loss: 0.2504 - val_accuracy: 0.8991\n",
      "Epoch 56/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.2477 - accuracy: 0.8995 - val_loss: 0.2532 - val_accuracy: 0.8984\n",
      "Epoch 57/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2481 - accuracy: 0.9018 - val_loss: 0.2491 - val_accuracy: 0.9025\n",
      "Epoch 58/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.2453 - accuracy: 0.9009 - val_loss: 0.2503 - val_accuracy: 0.8995\n",
      "Epoch 59/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2414 - accuracy: 0.9034 - val_loss: 0.2542 - val_accuracy: 0.8980\n",
      "Epoch 60/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2469 - accuracy: 0.9018 - val_loss: 0.2485 - val_accuracy: 0.8973\n",
      "Epoch 61/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2469 - accuracy: 0.9003 - val_loss: 0.2466 - val_accuracy: 0.9004\n",
      "Epoch 62/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2457 - accuracy: 0.9018 - val_loss: 0.2571 - val_accuracy: 0.8949\n",
      "Epoch 63/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2403 - accuracy: 0.9035 - val_loss: 0.2540 - val_accuracy: 0.9000\n",
      "Epoch 64/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2426 - accuracy: 0.9020 - val_loss: 0.2483 - val_accuracy: 0.9000\n",
      "Epoch 65/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2403 - accuracy: 0.9041 - val_loss: 0.2508 - val_accuracy: 0.8995\n",
      "Epoch 66/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2425 - accuracy: 0.9029 - val_loss: 0.2481 - val_accuracy: 0.8991\n",
      "Epoch 67/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2411 - accuracy: 0.9024 - val_loss: 0.2470 - val_accuracy: 0.9011\n",
      "Epoch 68/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2424 - accuracy: 0.9034 - val_loss: 0.2484 - val_accuracy: 0.8978\n",
      "Epoch 69/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2376 - accuracy: 0.9065 - val_loss: 0.2491 - val_accuracy: 0.9005\n",
      "Epoch 70/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2387 - accuracy: 0.9041 - val_loss: 0.2528 - val_accuracy: 0.9005\n",
      "Epoch 71/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2365 - accuracy: 0.9049 - val_loss: 0.2493 - val_accuracy: 0.9022\n",
      "Epoch 72/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2370 - accuracy: 0.9066 - val_loss: 0.2489 - val_accuracy: 0.8991\n",
      "Epoch 73/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2391 - accuracy: 0.9047 - val_loss: 0.2482 - val_accuracy: 0.9013\n",
      "Epoch 74/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2394 - accuracy: 0.9048 - val_loss: 0.2510 - val_accuracy: 0.9007\n",
      "Epoch 75/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2329 - accuracy: 0.9075 - val_loss: 0.2485 - val_accuracy: 0.9024\n",
      "Epoch 76/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.2347 - accuracy: 0.9067 - val_loss: 0.2518 - val_accuracy: 0.8993\n",
      "Epoch 77/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2332 - accuracy: 0.9063 - val_loss: 0.2512 - val_accuracy: 0.8985\n",
      "test:0.877818\n",
      "valid:0.902545\n",
      "train:0.928455\n",
      "acc:0.857539\n",
      "0.8575389734426028\n",
      "Train on 22000 samples, validate on 5500 samples\n",
      "Epoch 1/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.4659 - accuracy: 0.7871 - val_loss: 0.3998 - val_accuracy: 0.8236\n",
      "Epoch 2/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.3987 - accuracy: 0.8275 - val_loss: 0.3623 - val_accuracy: 0.8484\n",
      "Epoch 3/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.3777 - accuracy: 0.8425 - val_loss: 0.3485 - val_accuracy: 0.8531\n",
      "Epoch 4/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.3618 - accuracy: 0.8489 - val_loss: 0.3399 - val_accuracy: 0.8591\n",
      "Epoch 5/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.3508 - accuracy: 0.8554 - val_loss: 0.3321 - val_accuracy: 0.8642\n",
      "Epoch 6/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.3452 - accuracy: 0.8542 - val_loss: 0.3255 - val_accuracy: 0.8671\n",
      "Epoch 7/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.3380 - accuracy: 0.8605 - val_loss: 0.3214 - val_accuracy: 0.8689\n",
      "Epoch 8/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.3352 - accuracy: 0.8623 - val_loss: 0.3167 - val_accuracy: 0.8693\n",
      "Epoch 9/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.3317 - accuracy: 0.8649 - val_loss: 0.3172 - val_accuracy: 0.8711\n",
      "Epoch 10/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.3246 - accuracy: 0.8685 - val_loss: 0.3123 - val_accuracy: 0.8731\n",
      "Epoch 11/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.3219 - accuracy: 0.8704 - val_loss: 0.3087 - val_accuracy: 0.8753\n",
      "Epoch 12/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.3181 - accuracy: 0.8707 - val_loss: 0.3071 - val_accuracy: 0.8735\n",
      "Epoch 13/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.3139 - accuracy: 0.8724 - val_loss: 0.3047 - val_accuracy: 0.8773\n",
      "Epoch 14/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.3112 - accuracy: 0.8733 - val_loss: 0.3011 - val_accuracy: 0.8784\n",
      "Epoch 15/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.3083 - accuracy: 0.8756 - val_loss: 0.2996 - val_accuracy: 0.8796\n",
      "Epoch 16/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.3047 - accuracy: 0.8786 - val_loss: 0.2986 - val_accuracy: 0.8800\n",
      "Epoch 17/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.3014 - accuracy: 0.8799 - val_loss: 0.2981 - val_accuracy: 0.8805\n",
      "Epoch 18/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.3028 - accuracy: 0.8780 - val_loss: 0.2973 - val_accuracy: 0.8787\n",
      "Epoch 19/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2979 - accuracy: 0.8805 - val_loss: 0.2943 - val_accuracy: 0.8836\n",
      "Epoch 20/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2996 - accuracy: 0.8805 - val_loss: 0.2948 - val_accuracy: 0.8816\n",
      "Epoch 21/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2974 - accuracy: 0.8807 - val_loss: 0.2956 - val_accuracy: 0.8804\n",
      "Epoch 22/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.2943 - accuracy: 0.8826 - val_loss: 0.2905 - val_accuracy: 0.8847\n",
      "Epoch 23/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2901 - accuracy: 0.8835 - val_loss: 0.2901 - val_accuracy: 0.8833\n",
      "Epoch 24/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2896 - accuracy: 0.8847 - val_loss: 0.2902 - val_accuracy: 0.8836\n",
      "Epoch 25/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2886 - accuracy: 0.8858 - val_loss: 0.2892 - val_accuracy: 0.8860\n",
      "Epoch 26/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2860 - accuracy: 0.8855 - val_loss: 0.2862 - val_accuracy: 0.8858\n",
      "Epoch 27/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2835 - accuracy: 0.8880 - val_loss: 0.2836 - val_accuracy: 0.8853\n",
      "Epoch 28/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2804 - accuracy: 0.8879 - val_loss: 0.2851 - val_accuracy: 0.8885\n",
      "Epoch 29/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.2830 - accuracy: 0.8859 - val_loss: 0.2819 - val_accuracy: 0.8873\n",
      "Epoch 30/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2792 - accuracy: 0.8905 - val_loss: 0.2821 - val_accuracy: 0.8862\n",
      "Epoch 31/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2772 - accuracy: 0.8914 - val_loss: 0.2825 - val_accuracy: 0.8871\n",
      "Epoch 32/200\n",
      "22000/22000 [==============================] - 1s 58us/sample - loss: 0.2783 - accuracy: 0.8896 - val_loss: 0.2805 - val_accuracy: 0.8895\n",
      "Epoch 33/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2757 - accuracy: 0.8910 - val_loss: 0.2806 - val_accuracy: 0.8865\n",
      "Epoch 34/200\n",
      "22000/22000 [==============================] - 1s 60us/sample - loss: 0.2758 - accuracy: 0.8887 - val_loss: 0.2796 - val_accuracy: 0.8880\n",
      "Epoch 35/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2752 - accuracy: 0.8916 - val_loss: 0.2806 - val_accuracy: 0.8885\n",
      "Epoch 36/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2715 - accuracy: 0.8933 - val_loss: 0.2779 - val_accuracy: 0.8911\n",
      "Epoch 37/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2706 - accuracy: 0.8942 - val_loss: 0.2799 - val_accuracy: 0.8895\n",
      "Epoch 38/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2716 - accuracy: 0.8936 - val_loss: 0.2794 - val_accuracy: 0.8907\n",
      "Epoch 39/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2676 - accuracy: 0.8944 - val_loss: 0.2791 - val_accuracy: 0.8907\n",
      "Epoch 40/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2692 - accuracy: 0.8935 - val_loss: 0.2770 - val_accuracy: 0.8895\n",
      "Epoch 41/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2697 - accuracy: 0.8923 - val_loss: 0.2732 - val_accuracy: 0.8907\n",
      "Epoch 42/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.2663 - accuracy: 0.8933 - val_loss: 0.2777 - val_accuracy: 0.8898\n",
      "Epoch 43/200\n",
      "22000/22000 [==============================] - 1s 60us/sample - loss: 0.2631 - accuracy: 0.8965 - val_loss: 0.2755 - val_accuracy: 0.8915\n",
      "Epoch 44/200\n",
      "22000/22000 [==============================] - 1s 58us/sample - loss: 0.2625 - accuracy: 0.8973 - val_loss: 0.2753 - val_accuracy: 0.8933\n",
      "Epoch 45/200\n",
      "22000/22000 [==============================] - 1s 57us/sample - loss: 0.2635 - accuracy: 0.8964 - val_loss: 0.2745 - val_accuracy: 0.8927\n",
      "Epoch 46/200\n",
      "22000/22000 [==============================] - 1s 57us/sample - loss: 0.2618 - accuracy: 0.8968 - val_loss: 0.2742 - val_accuracy: 0.8929\n",
      "Epoch 47/200\n",
      "22000/22000 [==============================] - 1s 60us/sample - loss: 0.2630 - accuracy: 0.8961 - val_loss: 0.2759 - val_accuracy: 0.8898\n",
      "Epoch 48/200\n",
      "22000/22000 [==============================] - 2s 72us/sample - loss: 0.2626 - accuracy: 0.8944 - val_loss: 0.2740 - val_accuracy: 0.8909\n",
      "Epoch 49/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2617 - accuracy: 0.8965 - val_loss: 0.2777 - val_accuracy: 0.8909\n",
      "Epoch 50/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2611 - accuracy: 0.8980 - val_loss: 0.2718 - val_accuracy: 0.8920\n",
      "Epoch 51/200\n",
      "22000/22000 [==============================] - 1s 59us/sample - loss: 0.2598 - accuracy: 0.8976 - val_loss: 0.2718 - val_accuracy: 0.8936\n",
      "Epoch 52/200\n",
      "22000/22000 [==============================] - 1s 65us/sample - loss: 0.2568 - accuracy: 0.9004 - val_loss: 0.2749 - val_accuracy: 0.8933\n",
      "Epoch 53/200\n",
      "22000/22000 [==============================] - 1s 56us/sample - loss: 0.2602 - accuracy: 0.8977 - val_loss: 0.2760 - val_accuracy: 0.8918\n",
      "Epoch 54/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2531 - accuracy: 0.9018 - val_loss: 0.2720 - val_accuracy: 0.8915\n",
      "Epoch 55/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.2596 - accuracy: 0.8974 - val_loss: 0.2700 - val_accuracy: 0.8929\n",
      "Epoch 56/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.2541 - accuracy: 0.9008 - val_loss: 0.2725 - val_accuracy: 0.8882\n",
      "Epoch 57/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2496 - accuracy: 0.9019 - val_loss: 0.2719 - val_accuracy: 0.8918\n",
      "Epoch 58/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.2505 - accuracy: 0.9031 - val_loss: 0.2698 - val_accuracy: 0.8893\n",
      "Epoch 59/200\n",
      "22000/22000 [==============================] - 1s 59us/sample - loss: 0.2546 - accuracy: 0.8983 - val_loss: 0.2696 - val_accuracy: 0.8920\n",
      "Epoch 60/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2482 - accuracy: 0.9025 - val_loss: 0.2666 - val_accuracy: 0.8922\n",
      "Epoch 61/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2466 - accuracy: 0.9051 - val_loss: 0.2761 - val_accuracy: 0.8927\n",
      "Epoch 62/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.2522 - accuracy: 0.9011 - val_loss: 0.2660 - val_accuracy: 0.8920\n",
      "Epoch 63/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.2487 - accuracy: 0.9000 - val_loss: 0.2685 - val_accuracy: 0.8949\n",
      "Epoch 64/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2502 - accuracy: 0.9029 - val_loss: 0.2718 - val_accuracy: 0.8944\n",
      "Epoch 65/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2483 - accuracy: 0.9019 - val_loss: 0.2727 - val_accuracy: 0.8949\n",
      "Epoch 66/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.2481 - accuracy: 0.9035 - val_loss: 0.2696 - val_accuracy: 0.8947\n",
      "Epoch 67/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.2503 - accuracy: 0.9029 - val_loss: 0.2655 - val_accuracy: 0.8951\n",
      "Epoch 68/200\n",
      "22000/22000 [==============================] - 1s 58us/sample - loss: 0.2487 - accuracy: 0.9038 - val_loss: 0.2665 - val_accuracy: 0.8958\n",
      "Epoch 69/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2442 - accuracy: 0.9046 - val_loss: 0.2705 - val_accuracy: 0.8938\n",
      "Epoch 70/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2414 - accuracy: 0.9059 - val_loss: 0.2656 - val_accuracy: 0.8947\n",
      "Epoch 71/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.2473 - accuracy: 0.9054 - val_loss: 0.2679 - val_accuracy: 0.8975\n",
      "Epoch 72/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2460 - accuracy: 0.9050 - val_loss: 0.2643 - val_accuracy: 0.8956\n",
      "Epoch 73/200\n",
      "22000/22000 [==============================] - 1s 68us/sample - loss: 0.2441 - accuracy: 0.9048 - val_loss: 0.2652 - val_accuracy: 0.8962\n",
      "Epoch 74/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.2428 - accuracy: 0.9057 - val_loss: 0.2626 - val_accuracy: 0.8985\n",
      "Epoch 75/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2395 - accuracy: 0.9062 - val_loss: 0.2700 - val_accuracy: 0.8965\n",
      "Epoch 76/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2459 - accuracy: 0.9047 - val_loss: 0.2645 - val_accuracy: 0.8969\n",
      "Epoch 77/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2387 - accuracy: 0.9048 - val_loss: 0.2702 - val_accuracy: 0.8965\n",
      "Epoch 78/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2416 - accuracy: 0.9080 - val_loss: 0.2625 - val_accuracy: 0.8987\n",
      "Epoch 79/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2424 - accuracy: 0.9044 - val_loss: 0.2691 - val_accuracy: 0.8958\n",
      "Epoch 80/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2413 - accuracy: 0.9050 - val_loss: 0.2669 - val_accuracy: 0.8953\n",
      "Epoch 81/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.2404 - accuracy: 0.9075 - val_loss: 0.2626 - val_accuracy: 0.8973\n",
      "Epoch 82/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2389 - accuracy: 0.9056 - val_loss: 0.2633 - val_accuracy: 0.8975\n",
      "Epoch 83/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2356 - accuracy: 0.9087 - val_loss: 0.2644 - val_accuracy: 0.8991\n",
      "Epoch 84/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2397 - accuracy: 0.9063 - val_loss: 0.2646 - val_accuracy: 0.8996\n",
      "Epoch 85/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2368 - accuracy: 0.9082 - val_loss: 0.2622 - val_accuracy: 0.9002\n",
      "Epoch 86/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2389 - accuracy: 0.9077 - val_loss: 0.2670 - val_accuracy: 0.8985\n",
      "Epoch 87/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2354 - accuracy: 0.9074 - val_loss: 0.2654 - val_accuracy: 0.8993\n",
      "Epoch 88/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.2362 - accuracy: 0.9060 - val_loss: 0.2647 - val_accuracy: 0.8973\n",
      "Epoch 89/200\n",
      "22000/22000 [==============================] - 2s 82us/sample - loss: 0.2377 - accuracy: 0.9065 - val_loss: 0.2626 - val_accuracy: 0.8984\n",
      "Epoch 90/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2332 - accuracy: 0.9099 - val_loss: 0.2627 - val_accuracy: 0.8973\n",
      "Epoch 91/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2332 - accuracy: 0.9109 - val_loss: 0.2646 - val_accuracy: 0.8987\n",
      "Epoch 92/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2346 - accuracy: 0.9084 - val_loss: 0.2631 - val_accuracy: 0.8989\n",
      "Epoch 93/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2345 - accuracy: 0.9095 - val_loss: 0.2608 - val_accuracy: 0.9016\n",
      "Epoch 94/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2325 - accuracy: 0.9105 - val_loss: 0.2613 - val_accuracy: 0.9002\n",
      "Epoch 95/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2346 - accuracy: 0.9087 - val_loss: 0.2569 - val_accuracy: 0.9027\n",
      "Epoch 96/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2310 - accuracy: 0.9104 - val_loss: 0.2682 - val_accuracy: 0.8969\n",
      "Epoch 97/200\n",
      "22000/22000 [==============================] - 2s 99us/sample - loss: 0.2317 - accuracy: 0.9097 - val_loss: 0.2654 - val_accuracy: 0.8962\n",
      "Epoch 98/200\n",
      "22000/22000 [==============================] - 1s 57us/sample - loss: 0.2310 - accuracy: 0.9081 - val_loss: 0.2627 - val_accuracy: 0.8967\n",
      "Epoch 99/200\n",
      "22000/22000 [==============================] - 1s 61us/sample - loss: 0.2301 - accuracy: 0.9107 - val_loss: 0.2600 - val_accuracy: 0.9004\n",
      "Epoch 100/200\n",
      "22000/22000 [==============================] - 2s 108us/sample - loss: 0.2270 - accuracy: 0.9106 - val_loss: 0.2666 - val_accuracy: 0.8995\n",
      "Epoch 101/200\n",
      "22000/22000 [==============================] - 2s 86us/sample - loss: 0.2294 - accuracy: 0.9102 - val_loss: 0.2600 - val_accuracy: 0.9005\n",
      "Epoch 102/200\n",
      "22000/22000 [==============================] - 2s 78us/sample - loss: 0.2273 - accuracy: 0.9109 - val_loss: 0.2592 - val_accuracy: 0.8998\n",
      "Epoch 103/200\n",
      "22000/22000 [==============================] - 2s 81us/sample - loss: 0.2303 - accuracy: 0.9105 - val_loss: 0.2589 - val_accuracy: 0.9018\n",
      "Epoch 104/200\n",
      "22000/22000 [==============================] - 2s 76us/sample - loss: 0.2311 - accuracy: 0.9112 - val_loss: 0.2688 - val_accuracy: 0.8985\n",
      "Epoch 105/200\n",
      "22000/22000 [==============================] - 2s 77us/sample - loss: 0.2288 - accuracy: 0.9118 - val_loss: 0.2671 - val_accuracy: 0.8982\n",
      "Epoch 106/200\n",
      "22000/22000 [==============================] - 2s 79us/sample - loss: 0.2307 - accuracy: 0.9104 - val_loss: 0.2626 - val_accuracy: 0.9009\n",
      "Epoch 107/200\n",
      "22000/22000 [==============================] - 2s 82us/sample - loss: 0.2301 - accuracy: 0.9101 - val_loss: 0.2616 - val_accuracy: 0.9018\n",
      "Epoch 108/200\n",
      "22000/22000 [==============================] - 2s 94us/sample - loss: 0.2277 - accuracy: 0.9112 - val_loss: 0.2610 - val_accuracy: 0.9005\n",
      "Epoch 109/200\n",
      "22000/22000 [==============================] - 1s 62us/sample - loss: 0.2298 - accuracy: 0.9113 - val_loss: 0.2570 - val_accuracy: 0.9002\n",
      "Epoch 110/200\n",
      "22000/22000 [==============================] - 2s 71us/sample - loss: 0.2258 - accuracy: 0.9111 - val_loss: 0.2583 - val_accuracy: 0.9038\n",
      "Epoch 111/200\n",
      "22000/22000 [==============================] - 1s 58us/sample - loss: 0.2273 - accuracy: 0.9124 - val_loss: 0.2633 - val_accuracy: 0.9005\n",
      "Epoch 112/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.2276 - accuracy: 0.9102 - val_loss: 0.2559 - val_accuracy: 0.8993\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2233 - accuracy: 0.9130 - val_loss: 0.2627 - val_accuracy: 0.8995\n",
      "Epoch 114/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2259 - accuracy: 0.9127 - val_loss: 0.2610 - val_accuracy: 0.8993\n",
      "Epoch 115/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.2273 - accuracy: 0.9123 - val_loss: 0.2638 - val_accuracy: 0.8985\n",
      "Epoch 116/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2277 - accuracy: 0.9129 - val_loss: 0.2598 - val_accuracy: 0.9002\n",
      "Epoch 117/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2249 - accuracy: 0.9136 - val_loss: 0.2617 - val_accuracy: 0.9005\n",
      "Epoch 118/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2256 - accuracy: 0.9111 - val_loss: 0.2541 - val_accuracy: 0.9038\n",
      "Epoch 119/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2268 - accuracy: 0.9115 - val_loss: 0.2551 - val_accuracy: 0.9022\n",
      "Epoch 120/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2250 - accuracy: 0.9130 - val_loss: 0.2597 - val_accuracy: 0.9013\n",
      "Epoch 121/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2225 - accuracy: 0.9148 - val_loss: 0.2576 - val_accuracy: 0.9029\n",
      "Epoch 122/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2222 - accuracy: 0.9152 - val_loss: 0.2552 - val_accuracy: 0.9062\n",
      "Epoch 123/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2241 - accuracy: 0.9133 - val_loss: 0.2581 - val_accuracy: 0.9013\n",
      "Epoch 124/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2211 - accuracy: 0.9159 - val_loss: 0.2621 - val_accuracy: 0.9016\n",
      "Epoch 125/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2240 - accuracy: 0.9144 - val_loss: 0.2584 - val_accuracy: 0.9015\n",
      "Epoch 126/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2206 - accuracy: 0.9153 - val_loss: 0.2574 - val_accuracy: 0.9024\n",
      "Epoch 127/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2260 - accuracy: 0.9132 - val_loss: 0.2544 - val_accuracy: 0.9045\n",
      "Epoch 128/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2193 - accuracy: 0.9162 - val_loss: 0.2589 - val_accuracy: 0.9016\n",
      "Epoch 129/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2156 - accuracy: 0.9177 - val_loss: 0.2523 - val_accuracy: 0.9044\n",
      "Epoch 130/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2174 - accuracy: 0.9163 - val_loss: 0.2603 - val_accuracy: 0.9044\n",
      "Epoch 131/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2190 - accuracy: 0.9165 - val_loss: 0.2626 - val_accuracy: 0.9009\n",
      "Epoch 132/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.2198 - accuracy: 0.9165 - val_loss: 0.2590 - val_accuracy: 0.9033\n",
      "Epoch 133/200\n",
      "22000/22000 [==============================] - 1s 56us/sample - loss: 0.2180 - accuracy: 0.9178 - val_loss: 0.2548 - val_accuracy: 0.9027\n",
      "Epoch 134/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2187 - accuracy: 0.9154 - val_loss: 0.2605 - val_accuracy: 0.9024\n",
      "Epoch 135/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2211 - accuracy: 0.9139 - val_loss: 0.2599 - val_accuracy: 0.9035\n",
      "Epoch 136/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2197 - accuracy: 0.9161 - val_loss: 0.2588 - val_accuracy: 0.9005\n",
      "Epoch 137/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2179 - accuracy: 0.9165 - val_loss: 0.2598 - val_accuracy: 0.9018\n",
      "Epoch 138/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.2202 - accuracy: 0.9160 - val_loss: 0.2606 - val_accuracy: 0.9033\n",
      "Epoch 139/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2188 - accuracy: 0.9162 - val_loss: 0.2596 - val_accuracy: 0.9020\n",
      "Epoch 140/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2177 - accuracy: 0.9171 - val_loss: 0.2566 - val_accuracy: 0.9038\n",
      "Epoch 141/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2198 - accuracy: 0.9147 - val_loss: 0.2564 - val_accuracy: 0.9055\n",
      "Epoch 142/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2172 - accuracy: 0.9154 - val_loss: 0.2613 - val_accuracy: 0.9024\n",
      "test:0.900800\n",
      "valid:0.906182\n",
      "train:0.945182\n",
      "acc:0.850289\n",
      "0.8502885780598517\n",
      "Train on 22000 samples, validate on 5500 samples\n",
      "Epoch 1/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.4170 - accuracy: 0.8141 - val_loss: 0.3552 - val_accuracy: 0.8485\n",
      "Epoch 2/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.3727 - accuracy: 0.8457 - val_loss: 0.3340 - val_accuracy: 0.8616\n",
      "Epoch 3/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.3523 - accuracy: 0.8533 - val_loss: 0.3206 - val_accuracy: 0.8673\n",
      "Epoch 4/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.3394 - accuracy: 0.8611 - val_loss: 0.3106 - val_accuracy: 0.8702\n",
      "Epoch 5/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.3339 - accuracy: 0.8642 - val_loss: 0.3059 - val_accuracy: 0.8778\n",
      "Epoch 6/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.3254 - accuracy: 0.8669 - val_loss: 0.3007 - val_accuracy: 0.8751\n",
      "Epoch 7/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.3202 - accuracy: 0.8706 - val_loss: 0.2968 - val_accuracy: 0.8809\n",
      "Epoch 8/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.3171 - accuracy: 0.8726 - val_loss: 0.2904 - val_accuracy: 0.8822\n",
      "Epoch 9/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.3116 - accuracy: 0.8750 - val_loss: 0.2884 - val_accuracy: 0.8820\n",
      "Epoch 10/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.3074 - accuracy: 0.8764 - val_loss: 0.2845 - val_accuracy: 0.8836\n",
      "Epoch 11/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.3035 - accuracy: 0.8795 - val_loss: 0.2818 - val_accuracy: 0.8855\n",
      "Epoch 12/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2983 - accuracy: 0.8826 - val_loss: 0.2807 - val_accuracy: 0.8862\n",
      "Epoch 13/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2969 - accuracy: 0.8829 - val_loss: 0.2791 - val_accuracy: 0.8887\n",
      "Epoch 14/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2969 - accuracy: 0.8824 - val_loss: 0.2738 - val_accuracy: 0.8898\n",
      "Epoch 15/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2953 - accuracy: 0.8838 - val_loss: 0.2740 - val_accuracy: 0.8911\n",
      "Epoch 16/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2930 - accuracy: 0.8852 - val_loss: 0.2727 - val_accuracy: 0.8902\n",
      "Epoch 17/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2877 - accuracy: 0.8852 - val_loss: 0.2705 - val_accuracy: 0.8920\n",
      "Epoch 18/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2891 - accuracy: 0.8853 - val_loss: 0.2661 - val_accuracy: 0.8922\n",
      "Epoch 19/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2883 - accuracy: 0.8857 - val_loss: 0.2690 - val_accuracy: 0.8924\n",
      "Epoch 20/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2846 - accuracy: 0.8862 - val_loss: 0.2676 - val_accuracy: 0.8922\n",
      "Epoch 21/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2803 - accuracy: 0.8891 - val_loss: 0.2654 - val_accuracy: 0.8927\n",
      "Epoch 22/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2804 - accuracy: 0.8888 - val_loss: 0.2662 - val_accuracy: 0.8936\n",
      "Epoch 23/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2735 - accuracy: 0.8947 - val_loss: 0.2656 - val_accuracy: 0.8949\n",
      "Epoch 24/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2755 - accuracy: 0.8909 - val_loss: 0.2647 - val_accuracy: 0.8929\n",
      "Epoch 25/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2763 - accuracy: 0.8929 - val_loss: 0.2641 - val_accuracy: 0.8964\n",
      "Epoch 26/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2717 - accuracy: 0.8935 - val_loss: 0.2618 - val_accuracy: 0.8971\n",
      "Epoch 27/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2730 - accuracy: 0.8937 - val_loss: 0.2613 - val_accuracy: 0.8960\n",
      "Epoch 28/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2734 - accuracy: 0.8899 - val_loss: 0.2587 - val_accuracy: 0.8962\n",
      "Epoch 29/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2683 - accuracy: 0.8953 - val_loss: 0.2596 - val_accuracy: 0.8951\n",
      "Epoch 30/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2672 - accuracy: 0.8972 - val_loss: 0.2587 - val_accuracy: 0.8969\n",
      "Epoch 31/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2666 - accuracy: 0.8982 - val_loss: 0.2594 - val_accuracy: 0.8956\n",
      "Epoch 32/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2643 - accuracy: 0.8976 - val_loss: 0.2570 - val_accuracy: 0.8989\n",
      "Epoch 33/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2624 - accuracy: 0.8974 - val_loss: 0.2562 - val_accuracy: 0.9002\n",
      "Epoch 34/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.2614 - accuracy: 0.8970 - val_loss: 0.2581 - val_accuracy: 0.9002\n",
      "Epoch 35/200\n",
      "22000/22000 [==============================] - 1s 63us/sample - loss: 0.2606 - accuracy: 0.8969 - val_loss: 0.2544 - val_accuracy: 0.9000\n",
      "Epoch 36/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.2606 - accuracy: 0.8990 - val_loss: 0.2548 - val_accuracy: 0.8973\n",
      "Epoch 37/200\n",
      "22000/22000 [==============================] - 1s 56us/sample - loss: 0.2609 - accuracy: 0.8980 - val_loss: 0.2540 - val_accuracy: 0.9000\n",
      "Epoch 38/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2583 - accuracy: 0.8991 - val_loss: 0.2509 - val_accuracy: 0.9018\n",
      "Epoch 39/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2583 - accuracy: 0.8999 - val_loss: 0.2522 - val_accuracy: 0.8989\n",
      "Epoch 40/200\n",
      "22000/22000 [==============================] - 1s 44us/sample - loss: 0.2585 - accuracy: 0.8977 - val_loss: 0.2510 - val_accuracy: 0.9020\n",
      "Epoch 41/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2565 - accuracy: 0.8996 - val_loss: 0.2502 - val_accuracy: 0.8993\n",
      "Epoch 42/200\n",
      "22000/22000 [==============================] - 1s 65us/sample - loss: 0.2552 - accuracy: 0.9009 - val_loss: 0.2510 - val_accuracy: 0.9018\n",
      "Epoch 43/200\n",
      "22000/22000 [==============================] - 2s 77us/sample - loss: 0.2517 - accuracy: 0.9019 - val_loss: 0.2514 - val_accuracy: 0.9013\n",
      "Epoch 44/200\n",
      "22000/22000 [==============================] - 1s 62us/sample - loss: 0.2556 - accuracy: 0.9021 - val_loss: 0.2525 - val_accuracy: 0.9009\n",
      "Epoch 45/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.2514 - accuracy: 0.9026 - val_loss: 0.2532 - val_accuracy: 0.9015\n",
      "Epoch 46/200\n",
      "22000/22000 [==============================] - 1s 58us/sample - loss: 0.2529 - accuracy: 0.9020 - val_loss: 0.2522 - val_accuracy: 0.9004\n",
      "Epoch 47/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.2518 - accuracy: 0.9027 - val_loss: 0.2536 - val_accuracy: 0.9002\n",
      "Epoch 48/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.2477 - accuracy: 0.9041 - val_loss: 0.2476 - val_accuracy: 0.9018\n",
      "Epoch 49/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2491 - accuracy: 0.9038 - val_loss: 0.2481 - val_accuracy: 0.9031\n",
      "Epoch 50/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2481 - accuracy: 0.9039 - val_loss: 0.2483 - val_accuracy: 0.9013\n",
      "Epoch 51/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2513 - accuracy: 0.9031 - val_loss: 0.2468 - val_accuracy: 0.9016\n",
      "Epoch 52/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.2495 - accuracy: 0.9037 - val_loss: 0.2499 - val_accuracy: 0.9022\n",
      "Epoch 53/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2495 - accuracy: 0.9009 - val_loss: 0.2504 - val_accuracy: 0.9018\n",
      "Epoch 54/200\n",
      "22000/22000 [==============================] - 1s 64us/sample - loss: 0.2436 - accuracy: 0.9074 - val_loss: 0.2487 - val_accuracy: 0.9033\n",
      "Epoch 55/200\n",
      "22000/22000 [==============================] - 1s 61us/sample - loss: 0.2450 - accuracy: 0.9037 - val_loss: 0.2478 - val_accuracy: 0.9016\n",
      "Epoch 56/200\n",
      "22000/22000 [==============================] - 1s 59us/sample - loss: 0.2451 - accuracy: 0.9062 - val_loss: 0.2491 - val_accuracy: 0.9031\n",
      "Epoch 57/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2433 - accuracy: 0.9069 - val_loss: 0.2448 - val_accuracy: 0.9038\n",
      "Epoch 58/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.2434 - accuracy: 0.9041 - val_loss: 0.2496 - val_accuracy: 0.9047\n",
      "Epoch 59/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.2406 - accuracy: 0.9062 - val_loss: 0.2464 - val_accuracy: 0.9049\n",
      "Epoch 60/200\n",
      "22000/22000 [==============================] - 1s 58us/sample - loss: 0.2415 - accuracy: 0.9062 - val_loss: 0.2505 - val_accuracy: 0.9027\n",
      "Epoch 61/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.2445 - accuracy: 0.9044 - val_loss: 0.2503 - val_accuracy: 0.9035\n",
      "Epoch 62/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.2427 - accuracy: 0.9062 - val_loss: 0.2536 - val_accuracy: 0.9029\n",
      "Epoch 63/200\n",
      "22000/22000 [==============================] - 1s 63us/sample - loss: 0.2397 - accuracy: 0.9055 - val_loss: 0.2482 - val_accuracy: 0.9042\n",
      "Epoch 64/200\n",
      "22000/22000 [==============================] - 1s 65us/sample - loss: 0.2359 - accuracy: 0.9076 - val_loss: 0.2479 - val_accuracy: 0.9031\n",
      "Epoch 65/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2385 - accuracy: 0.9085 - val_loss: 0.2442 - val_accuracy: 0.9049\n",
      "Epoch 66/200\n",
      "22000/22000 [==============================] - 1s 59us/sample - loss: 0.2363 - accuracy: 0.9099 - val_loss: 0.2438 - val_accuracy: 0.9053\n",
      "Epoch 67/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2400 - accuracy: 0.9074 - val_loss: 0.2431 - val_accuracy: 0.9053\n",
      "Epoch 68/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2374 - accuracy: 0.9068 - val_loss: 0.2463 - val_accuracy: 0.9053\n",
      "Epoch 69/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2370 - accuracy: 0.9089 - val_loss: 0.2471 - val_accuracy: 0.9055\n",
      "Epoch 70/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.2355 - accuracy: 0.9102 - val_loss: 0.2478 - val_accuracy: 0.9038\n",
      "Epoch 71/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2366 - accuracy: 0.9085 - val_loss: 0.2462 - val_accuracy: 0.9069\n",
      "Epoch 72/200\n",
      "22000/22000 [==============================] - 1s 45us/sample - loss: 0.2363 - accuracy: 0.9090 - val_loss: 0.2468 - val_accuracy: 0.9044\n",
      "Epoch 73/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2346 - accuracy: 0.9121 - val_loss: 0.2468 - val_accuracy: 0.9078\n",
      "Epoch 74/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.2350 - accuracy: 0.9080 - val_loss: 0.2485 - val_accuracy: 0.9055\n",
      "Epoch 75/200\n",
      "22000/22000 [==============================] - 1s 68us/sample - loss: 0.2322 - accuracy: 0.9105 - val_loss: 0.2515 - val_accuracy: 0.9051\n",
      "Epoch 76/200\n",
      "22000/22000 [==============================] - 2s 84us/sample - loss: 0.2319 - accuracy: 0.9122 - val_loss: 0.2446 - val_accuracy: 0.9082\n",
      "Epoch 77/200\n",
      "22000/22000 [==============================] - 1s 66us/sample - loss: 0.2325 - accuracy: 0.9103 - val_loss: 0.2430 - val_accuracy: 0.9091\n",
      "Epoch 78/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22000/22000 [==============================] - 1s 58us/sample - loss: 0.2305 - accuracy: 0.9115 - val_loss: 0.2451 - val_accuracy: 0.9067\n",
      "Epoch 79/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.2322 - accuracy: 0.9095 - val_loss: 0.2470 - val_accuracy: 0.9053\n",
      "Epoch 80/200\n",
      "22000/22000 [==============================] - 1s 56us/sample - loss: 0.2307 - accuracy: 0.9131 - val_loss: 0.2492 - val_accuracy: 0.9056\n",
      "Epoch 81/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2340 - accuracy: 0.9101 - val_loss: 0.2423 - val_accuracy: 0.9065\n",
      "Epoch 82/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.2304 - accuracy: 0.9120 - val_loss: 0.2449 - val_accuracy: 0.9073\n",
      "Epoch 83/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2278 - accuracy: 0.9133 - val_loss: 0.2460 - val_accuracy: 0.9065\n",
      "Epoch 84/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.2307 - accuracy: 0.9120 - val_loss: 0.2438 - val_accuracy: 0.9082\n",
      "Epoch 85/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.2289 - accuracy: 0.9130 - val_loss: 0.2422 - val_accuracy: 0.9082\n",
      "Epoch 86/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.2268 - accuracy: 0.9141 - val_loss: 0.2480 - val_accuracy: 0.9053\n",
      "Epoch 87/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.2262 - accuracy: 0.9112 - val_loss: 0.2427 - val_accuracy: 0.9075\n",
      "Epoch 88/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.2298 - accuracy: 0.9117 - val_loss: 0.2428 - val_accuracy: 0.9062\n",
      "Epoch 89/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2281 - accuracy: 0.9119 - val_loss: 0.2436 - val_accuracy: 0.9085\n",
      "Epoch 90/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2287 - accuracy: 0.9111 - val_loss: 0.2445 - val_accuracy: 0.9076\n",
      "Epoch 91/200\n",
      "22000/22000 [==============================] - 1s 61us/sample - loss: 0.2257 - accuracy: 0.9135 - val_loss: 0.2431 - val_accuracy: 0.9044\n",
      "Epoch 92/200\n",
      "22000/22000 [==============================] - 1s 65us/sample - loss: 0.2264 - accuracy: 0.9146 - val_loss: 0.2446 - val_accuracy: 0.9078\n",
      "Epoch 93/200\n",
      "22000/22000 [==============================] - 1s 58us/sample - loss: 0.2245 - accuracy: 0.9139 - val_loss: 0.2420 - val_accuracy: 0.9076\n",
      "Epoch 94/200\n",
      "22000/22000 [==============================] - 1s 56us/sample - loss: 0.2287 - accuracy: 0.9125 - val_loss: 0.2409 - val_accuracy: 0.9071\n",
      "Epoch 95/200\n",
      "22000/22000 [==============================] - 1s 67us/sample - loss: 0.2250 - accuracy: 0.9138 - val_loss: 0.2475 - val_accuracy: 0.9069\n",
      "Epoch 96/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.2247 - accuracy: 0.9148 - val_loss: 0.2428 - val_accuracy: 0.9065\n",
      "Epoch 97/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2249 - accuracy: 0.9136 - val_loss: 0.2485 - val_accuracy: 0.9049\n",
      "test:0.839709\n",
      "valid:0.909091\n",
      "train:0.940409\n",
      "acc:0.885657\n",
      "0.8856573623349149\n",
      "Train on 22000 samples, validate on 5500 samples\n",
      "Epoch 1/200\n",
      "22000/22000 [==============================] - 1s 57us/sample - loss: 0.4546 - accuracy: 0.7970 - val_loss: 0.3736 - val_accuracy: 0.8360\n",
      "Epoch 2/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.3854 - accuracy: 0.8343 - val_loss: 0.3439 - val_accuracy: 0.8576\n",
      "Epoch 3/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.3641 - accuracy: 0.8495 - val_loss: 0.3246 - val_accuracy: 0.8698\n",
      "Epoch 4/200\n",
      "22000/22000 [==============================] - 1s 58us/sample - loss: 0.3479 - accuracy: 0.8582 - val_loss: 0.3129 - val_accuracy: 0.8724\n",
      "Epoch 5/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.3381 - accuracy: 0.8615 - val_loss: 0.3058 - val_accuracy: 0.8749\n",
      "Epoch 6/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.3326 - accuracy: 0.8642 - val_loss: 0.3002 - val_accuracy: 0.8787\n",
      "Epoch 7/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.3213 - accuracy: 0.8707 - val_loss: 0.3010 - val_accuracy: 0.8811\n",
      "Epoch 8/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.3213 - accuracy: 0.8726 - val_loss: 0.2936 - val_accuracy: 0.8825\n",
      "Epoch 9/200\n",
      "22000/22000 [==============================] - 1s 63us/sample - loss: 0.3143 - accuracy: 0.8730 - val_loss: 0.2887 - val_accuracy: 0.8849\n",
      "Epoch 10/200\n",
      "22000/22000 [==============================] - 2s 80us/sample - loss: 0.3062 - accuracy: 0.8765 - val_loss: 0.2897 - val_accuracy: 0.8844\n",
      "Epoch 11/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.3062 - accuracy: 0.8782 - val_loss: 0.2856 - val_accuracy: 0.8860\n",
      "Epoch 12/200\n",
      "22000/22000 [==============================] - 1s 63us/sample - loss: 0.3038 - accuracy: 0.8803 - val_loss: 0.2822 - val_accuracy: 0.8871\n",
      "Epoch 13/200\n",
      "22000/22000 [==============================] - 2s 83us/sample - loss: 0.2988 - accuracy: 0.8820 - val_loss: 0.2816 - val_accuracy: 0.8895\n",
      "Epoch 14/200\n",
      "22000/22000 [==============================] - 2s 83us/sample - loss: 0.2941 - accuracy: 0.8847 - val_loss: 0.2802 - val_accuracy: 0.8864\n",
      "Epoch 15/200\n",
      "22000/22000 [==============================] - 2s 99us/sample - loss: 0.2926 - accuracy: 0.8837 - val_loss: 0.2802 - val_accuracy: 0.8878\n",
      "Epoch 16/200\n",
      "22000/22000 [==============================] - 2s 87us/sample - loss: 0.2903 - accuracy: 0.8865 - val_loss: 0.2763 - val_accuracy: 0.8895\n",
      "Epoch 17/200\n",
      "22000/22000 [==============================] - 2s 82us/sample - loss: 0.2869 - accuracy: 0.8868 - val_loss: 0.2762 - val_accuracy: 0.8907\n",
      "Epoch 18/200\n",
      "22000/22000 [==============================] - 2s 90us/sample - loss: 0.2876 - accuracy: 0.8879 - val_loss: 0.2777 - val_accuracy: 0.8902\n",
      "Epoch 19/200\n",
      "22000/22000 [==============================] - 1s 59us/sample - loss: 0.2878 - accuracy: 0.8852 - val_loss: 0.2728 - val_accuracy: 0.8925\n",
      "Epoch 20/200\n",
      "22000/22000 [==============================] - 1s 60us/sample - loss: 0.2826 - accuracy: 0.8900 - val_loss: 0.2732 - val_accuracy: 0.8913\n",
      "Epoch 21/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2800 - accuracy: 0.8886 - val_loss: 0.2710 - val_accuracy: 0.8918\n",
      "Epoch 22/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.2756 - accuracy: 0.8933 - val_loss: 0.2688 - val_accuracy: 0.8911\n",
      "Epoch 23/200\n",
      "22000/22000 [==============================] - 2s 69us/sample - loss: 0.2734 - accuracy: 0.8932 - val_loss: 0.2695 - val_accuracy: 0.8900\n",
      "Epoch 24/200\n",
      "22000/22000 [==============================] - 1s 60us/sample - loss: 0.2767 - accuracy: 0.8926 - val_loss: 0.2693 - val_accuracy: 0.8913\n",
      "Epoch 25/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.2755 - accuracy: 0.8906 - val_loss: 0.2659 - val_accuracy: 0.8929\n",
      "Epoch 26/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.2727 - accuracy: 0.8942 - val_loss: 0.2657 - val_accuracy: 0.8940\n",
      "Epoch 27/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.2678 - accuracy: 0.8941 - val_loss: 0.2626 - val_accuracy: 0.8938\n",
      "Epoch 28/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2700 - accuracy: 0.8926 - val_loss: 0.2633 - val_accuracy: 0.8949\n",
      "Epoch 29/200\n",
      "22000/22000 [==============================] - 1s 58us/sample - loss: 0.2652 - accuracy: 0.8963 - val_loss: 0.2615 - val_accuracy: 0.8940\n",
      "Epoch 30/200\n",
      "22000/22000 [==============================] - 1s 62us/sample - loss: 0.2667 - accuracy: 0.8975 - val_loss: 0.2621 - val_accuracy: 0.8951\n",
      "Epoch 31/200\n",
      "22000/22000 [==============================] - 1s 61us/sample - loss: 0.2669 - accuracy: 0.8945 - val_loss: 0.2624 - val_accuracy: 0.8935\n",
      "Epoch 32/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2659 - accuracy: 0.8970 - val_loss: 0.2622 - val_accuracy: 0.8940\n",
      "Epoch 33/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2632 - accuracy: 0.8975 - val_loss: 0.2591 - val_accuracy: 0.8956\n",
      "Epoch 34/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2609 - accuracy: 0.8990 - val_loss: 0.2586 - val_accuracy: 0.8973\n",
      "Epoch 35/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2593 - accuracy: 0.9002 - val_loss: 0.2608 - val_accuracy: 0.8951\n",
      "Epoch 36/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2596 - accuracy: 0.8978 - val_loss: 0.2565 - val_accuracy: 0.8976\n",
      "Epoch 37/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2564 - accuracy: 0.8994 - val_loss: 0.2556 - val_accuracy: 0.8998\n",
      "Epoch 38/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2591 - accuracy: 0.8985 - val_loss: 0.2567 - val_accuracy: 0.8964\n",
      "Epoch 39/200\n",
      "22000/22000 [==============================] - 1s 60us/sample - loss: 0.2568 - accuracy: 0.8983 - val_loss: 0.2549 - val_accuracy: 0.8991\n",
      "Epoch 40/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.2510 - accuracy: 0.9031 - val_loss: 0.2549 - val_accuracy: 0.9004\n",
      "Epoch 41/200\n",
      "22000/22000 [==============================] - 1s 66us/sample - loss: 0.2587 - accuracy: 0.8988 - val_loss: 0.2571 - val_accuracy: 0.8940\n",
      "Epoch 42/200\n",
      "22000/22000 [==============================] - 1s 61us/sample - loss: 0.2532 - accuracy: 0.9014 - val_loss: 0.2534 - val_accuracy: 0.8995\n",
      "Epoch 43/200\n",
      "22000/22000 [==============================] - 1s 60us/sample - loss: 0.2531 - accuracy: 0.9035 - val_loss: 0.2533 - val_accuracy: 0.9000\n",
      "Epoch 44/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2485 - accuracy: 0.9035 - val_loss: 0.2510 - val_accuracy: 0.9022\n",
      "Epoch 45/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2478 - accuracy: 0.9040 - val_loss: 0.2512 - val_accuracy: 0.9011\n",
      "Epoch 46/200\n",
      "22000/22000 [==============================] - 1s 58us/sample - loss: 0.2488 - accuracy: 0.9032 - val_loss: 0.2521 - val_accuracy: 0.9000\n",
      "Epoch 47/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2472 - accuracy: 0.9050 - val_loss: 0.2499 - val_accuracy: 0.9015\n",
      "Epoch 48/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2476 - accuracy: 0.9026 - val_loss: 0.2525 - val_accuracy: 0.9004\n",
      "Epoch 49/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2459 - accuracy: 0.9036 - val_loss: 0.2475 - val_accuracy: 0.9036\n",
      "Epoch 50/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2474 - accuracy: 0.9025 - val_loss: 0.2498 - val_accuracy: 0.9024\n",
      "Epoch 51/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.2456 - accuracy: 0.9039 - val_loss: 0.2499 - val_accuracy: 0.9036\n",
      "Epoch 52/200\n",
      "22000/22000 [==============================] - 1s 62us/sample - loss: 0.2475 - accuracy: 0.9038 - val_loss: 0.2479 - val_accuracy: 0.9027\n",
      "Epoch 53/200\n",
      "22000/22000 [==============================] - 1s 63us/sample - loss: 0.2419 - accuracy: 0.9065 - val_loss: 0.2487 - val_accuracy: 0.9011\n",
      "Epoch 54/200\n",
      "22000/22000 [==============================] - 1s 60us/sample - loss: 0.2467 - accuracy: 0.9045 - val_loss: 0.2469 - val_accuracy: 0.9044\n",
      "Epoch 55/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.2380 - accuracy: 0.9087 - val_loss: 0.2528 - val_accuracy: 0.8989\n",
      "Epoch 56/200\n",
      "22000/22000 [==============================] - 1s 59us/sample - loss: 0.2387 - accuracy: 0.9077 - val_loss: 0.2495 - val_accuracy: 0.9029\n",
      "Epoch 57/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2406 - accuracy: 0.9068 - val_loss: 0.2489 - val_accuracy: 0.9027\n",
      "Epoch 58/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.2390 - accuracy: 0.9086 - val_loss: 0.2496 - val_accuracy: 0.9011\n",
      "Epoch 59/200\n",
      "22000/22000 [==============================] - 1s 59us/sample - loss: 0.2355 - accuracy: 0.9088 - val_loss: 0.2490 - val_accuracy: 0.9033\n",
      "Epoch 60/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.2414 - accuracy: 0.9065 - val_loss: 0.2487 - val_accuracy: 0.9015\n",
      "Epoch 61/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2379 - accuracy: 0.9067 - val_loss: 0.2497 - val_accuracy: 0.9016\n",
      "Epoch 62/200\n",
      "22000/22000 [==============================] - 1s 60us/sample - loss: 0.2326 - accuracy: 0.9094 - val_loss: 0.2466 - val_accuracy: 0.9022\n",
      "Epoch 63/200\n",
      "22000/22000 [==============================] - 1s 57us/sample - loss: 0.2361 - accuracy: 0.9083 - val_loss: 0.2460 - val_accuracy: 0.9055\n",
      "Epoch 64/200\n",
      "22000/22000 [==============================] - 2s 80us/sample - loss: 0.2368 - accuracy: 0.9090 - val_loss: 0.2475 - val_accuracy: 0.9035\n",
      "Epoch 65/200\n",
      "22000/22000 [==============================] - 1s 65us/sample - loss: 0.2372 - accuracy: 0.9085 - val_loss: 0.2469 - val_accuracy: 0.9025\n",
      "Epoch 66/200\n",
      "22000/22000 [==============================] - 1s 65us/sample - loss: 0.2347 - accuracy: 0.9085 - val_loss: 0.2473 - val_accuracy: 0.9020\n",
      "Epoch 67/200\n",
      "22000/22000 [==============================] - 1s 65us/sample - loss: 0.2348 - accuracy: 0.9109 - val_loss: 0.2454 - val_accuracy: 0.9042\n",
      "Epoch 68/200\n",
      "22000/22000 [==============================] - 2s 76us/sample - loss: 0.2330 - accuracy: 0.9108 - val_loss: 0.2438 - val_accuracy: 0.9042\n",
      "Epoch 69/200\n",
      "22000/22000 [==============================] - 1s 65us/sample - loss: 0.2303 - accuracy: 0.9111 - val_loss: 0.2476 - val_accuracy: 0.9049\n",
      "Epoch 70/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.2320 - accuracy: 0.9097 - val_loss: 0.2456 - val_accuracy: 0.9035\n",
      "Epoch 71/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.2332 - accuracy: 0.9116 - val_loss: 0.2437 - val_accuracy: 0.9056\n",
      "Epoch 72/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.2312 - accuracy: 0.9119 - val_loss: 0.2413 - val_accuracy: 0.9055\n",
      "Epoch 73/200\n",
      "22000/22000 [==============================] - 1s 56us/sample - loss: 0.2326 - accuracy: 0.9108 - val_loss: 0.2435 - val_accuracy: 0.9033\n",
      "Epoch 74/200\n",
      "22000/22000 [==============================] - 1s 59us/sample - loss: 0.2327 - accuracy: 0.9111 - val_loss: 0.2431 - val_accuracy: 0.9073\n",
      "Epoch 75/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.2296 - accuracy: 0.9112 - val_loss: 0.2406 - val_accuracy: 0.9051\n",
      "Epoch 76/200\n",
      "22000/22000 [==============================] - 1s 58us/sample - loss: 0.2288 - accuracy: 0.9131 - val_loss: 0.2392 - val_accuracy: 0.9082\n",
      "Epoch 77/200\n",
      "22000/22000 [==============================] - 1s 58us/sample - loss: 0.2283 - accuracy: 0.9105 - val_loss: 0.2412 - val_accuracy: 0.9056\n",
      "Epoch 78/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.2263 - accuracy: 0.9132 - val_loss: 0.2410 - val_accuracy: 0.9065\n",
      "Epoch 79/200\n",
      "22000/22000 [==============================] - 2s 70us/sample - loss: 0.2275 - accuracy: 0.9129 - val_loss: 0.2396 - val_accuracy: 0.9082\n",
      "Epoch 80/200\n",
      "22000/22000 [==============================] - 2s 73us/sample - loss: 0.2298 - accuracy: 0.9123 - val_loss: 0.2386 - val_accuracy: 0.9087\n",
      "Epoch 81/200\n",
      "22000/22000 [==============================] - 1s 58us/sample - loss: 0.2308 - accuracy: 0.9112 - val_loss: 0.2398 - val_accuracy: 0.9093\n",
      "Epoch 82/200\n",
      "22000/22000 [==============================] - 1s 57us/sample - loss: 0.2240 - accuracy: 0.9120 - val_loss: 0.2416 - val_accuracy: 0.9096\n",
      "Epoch 83/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.2290 - accuracy: 0.9126 - val_loss: 0.2452 - val_accuracy: 0.9062\n",
      "Epoch 84/200\n",
      "22000/22000 [==============================] - 1s 61us/sample - loss: 0.2252 - accuracy: 0.9147 - val_loss: 0.2417 - val_accuracy: 0.9082\n",
      "Epoch 85/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2269 - accuracy: 0.9120 - val_loss: 0.2440 - val_accuracy: 0.9071\n",
      "Epoch 86/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2270 - accuracy: 0.9139 - val_loss: 0.2377 - val_accuracy: 0.9076\n",
      "Epoch 87/200\n",
      "22000/22000 [==============================] - 1s 56us/sample - loss: 0.2281 - accuracy: 0.9117 - val_loss: 0.2382 - val_accuracy: 0.9073\n",
      "Epoch 88/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22000/22000 [==============================] - 1s 65us/sample - loss: 0.2245 - accuracy: 0.9135 - val_loss: 0.2362 - val_accuracy: 0.9100\n",
      "Epoch 89/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.2243 - accuracy: 0.9154 - val_loss: 0.2380 - val_accuracy: 0.9104\n",
      "Epoch 90/200\n",
      "22000/22000 [==============================] - 1s 60us/sample - loss: 0.2216 - accuracy: 0.9144 - val_loss: 0.2348 - val_accuracy: 0.9080\n",
      "Epoch 91/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.2267 - accuracy: 0.9135 - val_loss: 0.2366 - val_accuracy: 0.9085\n",
      "Epoch 92/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.2219 - accuracy: 0.9137 - val_loss: 0.2333 - val_accuracy: 0.9111\n",
      "Epoch 93/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.2235 - accuracy: 0.9151 - val_loss: 0.2367 - val_accuracy: 0.9084\n",
      "Epoch 94/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2199 - accuracy: 0.9163 - val_loss: 0.2345 - val_accuracy: 0.9085\n",
      "Epoch 95/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.2206 - accuracy: 0.9159 - val_loss: 0.2416 - val_accuracy: 0.9082\n",
      "Epoch 96/200\n",
      "22000/22000 [==============================] - 1s 57us/sample - loss: 0.2209 - accuracy: 0.9157 - val_loss: 0.2352 - val_accuracy: 0.9089\n",
      "Epoch 97/200\n",
      "22000/22000 [==============================] - 1s 56us/sample - loss: 0.2172 - accuracy: 0.9169 - val_loss: 0.2381 - val_accuracy: 0.9076\n",
      "Epoch 98/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2198 - accuracy: 0.9151 - val_loss: 0.2410 - val_accuracy: 0.9093\n",
      "Epoch 99/200\n",
      "22000/22000 [==============================] - 1s 56us/sample - loss: 0.2212 - accuracy: 0.9156 - val_loss: 0.2368 - val_accuracy: 0.9085\n",
      "Epoch 100/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2158 - accuracy: 0.9170 - val_loss: 0.2383 - val_accuracy: 0.9091\n",
      "Epoch 101/200\n",
      "22000/22000 [==============================] - 1s 58us/sample - loss: 0.2218 - accuracy: 0.9160 - val_loss: 0.2371 - val_accuracy: 0.9105\n",
      "Epoch 102/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.2210 - accuracy: 0.9151 - val_loss: 0.2345 - val_accuracy: 0.9115\n",
      "Epoch 103/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2164 - accuracy: 0.9174 - val_loss: 0.2357 - val_accuracy: 0.9069\n",
      "Epoch 104/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2184 - accuracy: 0.9150 - val_loss: 0.2332 - val_accuracy: 0.9105\n",
      "Epoch 105/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.2141 - accuracy: 0.9180 - val_loss: 0.2337 - val_accuracy: 0.9100\n",
      "Epoch 106/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2163 - accuracy: 0.9171 - val_loss: 0.2348 - val_accuracy: 0.9104\n",
      "Epoch 107/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.2176 - accuracy: 0.9174 - val_loss: 0.2349 - val_accuracy: 0.9129\n",
      "Epoch 108/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2158 - accuracy: 0.9171 - val_loss: 0.2346 - val_accuracy: 0.9096\n",
      "Epoch 109/200\n",
      "22000/22000 [==============================] - 1s 58us/sample - loss: 0.2107 - accuracy: 0.9190 - val_loss: 0.2353 - val_accuracy: 0.9084\n",
      "Epoch 110/200\n",
      "22000/22000 [==============================] - 1s 56us/sample - loss: 0.2128 - accuracy: 0.9181 - val_loss: 0.2376 - val_accuracy: 0.9096\n",
      "Epoch 111/200\n",
      "22000/22000 [==============================] - 1s 56us/sample - loss: 0.2162 - accuracy: 0.9164 - val_loss: 0.2373 - val_accuracy: 0.9098\n",
      "Epoch 112/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.2147 - accuracy: 0.9175 - val_loss: 0.2366 - val_accuracy: 0.9091\n",
      "Epoch 113/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.2142 - accuracy: 0.9190 - val_loss: 0.2329 - val_accuracy: 0.9095\n",
      "Epoch 114/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2135 - accuracy: 0.9210 - val_loss: 0.2349 - val_accuracy: 0.9113\n",
      "Epoch 115/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.2130 - accuracy: 0.9184 - val_loss: 0.2341 - val_accuracy: 0.9102\n",
      "Epoch 116/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2091 - accuracy: 0.9198 - val_loss: 0.2383 - val_accuracy: 0.9087\n",
      "Epoch 117/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2118 - accuracy: 0.9194 - val_loss: 0.2358 - val_accuracy: 0.9098\n",
      "Epoch 118/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2143 - accuracy: 0.9173 - val_loss: 0.2312 - val_accuracy: 0.9109\n",
      "Epoch 119/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2098 - accuracy: 0.9200 - val_loss: 0.2357 - val_accuracy: 0.9098\n",
      "Epoch 120/200\n",
      "22000/22000 [==============================] - 1s 61us/sample - loss: 0.2123 - accuracy: 0.9182 - val_loss: 0.2365 - val_accuracy: 0.9118\n",
      "Epoch 121/200\n",
      "22000/22000 [==============================] - 1s 57us/sample - loss: 0.2095 - accuracy: 0.9202 - val_loss: 0.2355 - val_accuracy: 0.9107\n",
      "Epoch 122/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.2108 - accuracy: 0.9197 - val_loss: 0.2386 - val_accuracy: 0.9122\n",
      "Epoch 123/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.2112 - accuracy: 0.9195 - val_loss: 0.2375 - val_accuracy: 0.9118\n",
      "Epoch 124/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2103 - accuracy: 0.9210 - val_loss: 0.2376 - val_accuracy: 0.9133\n",
      "Epoch 125/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.2093 - accuracy: 0.9199 - val_loss: 0.2327 - val_accuracy: 0.9120\n",
      "Epoch 126/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.2114 - accuracy: 0.9197 - val_loss: 0.2362 - val_accuracy: 0.9089\n",
      "Epoch 127/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.2100 - accuracy: 0.9195 - val_loss: 0.2337 - val_accuracy: 0.9107\n",
      "Epoch 128/200\n",
      "22000/22000 [==============================] - 1s 56us/sample - loss: 0.2101 - accuracy: 0.9207 - val_loss: 0.2423 - val_accuracy: 0.9096\n",
      "Epoch 129/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2093 - accuracy: 0.9181 - val_loss: 0.2358 - val_accuracy: 0.9093\n",
      "Epoch 130/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.2122 - accuracy: 0.9194 - val_loss: 0.2350 - val_accuracy: 0.9111\n",
      "Epoch 131/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2082 - accuracy: 0.9198 - val_loss: 0.2352 - val_accuracy: 0.9118\n",
      "Epoch 132/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2080 - accuracy: 0.9222 - val_loss: 0.2311 - val_accuracy: 0.9129\n",
      "Epoch 133/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2123 - accuracy: 0.9178 - val_loss: 0.2359 - val_accuracy: 0.9107\n",
      "Epoch 134/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2068 - accuracy: 0.9205 - val_loss: 0.2342 - val_accuracy: 0.9113\n",
      "Epoch 135/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.2096 - accuracy: 0.9210 - val_loss: 0.2324 - val_accuracy: 0.9125\n",
      "Epoch 136/200\n",
      "22000/22000 [==============================] - 1s 60us/sample - loss: 0.2050 - accuracy: 0.9220 - val_loss: 0.2323 - val_accuracy: 0.9111\n",
      "Epoch 137/200\n",
      "22000/22000 [==============================] - 1s 63us/sample - loss: 0.2070 - accuracy: 0.9230 - val_loss: 0.2330 - val_accuracy: 0.9122\n",
      "Epoch 138/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.2063 - accuracy: 0.9214 - val_loss: 0.2329 - val_accuracy: 0.9100\n",
      "Epoch 139/200\n",
      "22000/22000 [==============================] - 1s 58us/sample - loss: 0.2052 - accuracy: 0.9214 - val_loss: 0.2319 - val_accuracy: 0.9129\n",
      "Epoch 140/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2106 - accuracy: 0.9196 - val_loss: 0.2333 - val_accuracy: 0.9109\n",
      "Epoch 141/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.2066 - accuracy: 0.9208 - val_loss: 0.2346 - val_accuracy: 0.9109\n",
      "Epoch 142/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.2054 - accuracy: 0.9224 - val_loss: 0.2336 - val_accuracy: 0.9113\n",
      "Epoch 143/200\n",
      "22000/22000 [==============================] - 1s 57us/sample - loss: 0.2068 - accuracy: 0.9221 - val_loss: 0.2330 - val_accuracy: 0.9115\n",
      "Epoch 144/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.2034 - accuracy: 0.9221 - val_loss: 0.2308 - val_accuracy: 0.9118\n",
      "test:0.857455\n",
      "valid:0.913273\n",
      "train:0.948091\n",
      "acc:0.848029\n",
      "0.8480292480538952\n"
     ]
    }
   ],
   "source": [
    "#test features from 2 of 8 signals\n",
    "\n",
    "acc_2f={}\n",
    "cols = [ 'LEFT_TA','LEFT_TS','LEFT_BF', 'LEFT_RF',\n",
    "        'RIGHT_TA','RIGHT_TS','RIGHT_BF', 'RIGHT_RF']\n",
    "\n",
    "\n",
    "for p in combinations(cols[:4],2):\n",
    "    ind_temp=feature.columns.str.contains(p[0])| feature.columns.str.contains(p[1])\n",
    "    feature_sc = sc.fit_transform(feature.loc[:,ind_temp])\n",
    "    feature2_sc = sc.transform(feature2.loc[:,ind_temp])\n",
    "    train,valid,test = train_model(model,feature_sc,np.array(y))\n",
    "    acc_rest=test_model(model,feature2_sc,np.array(y2))\n",
    "    acc_2f[p[0]+'_'+p[1]] = [train,valid,test,acc_rest]\n",
    "    print(acc_rest)\n",
    "    \n",
    "for p in combinations(cols[4:],2):\n",
    "    ind_temp=feature.columns.str.contains(p[0])| feature.columns.str.contains(p[1])\n",
    "    feature_sc = sc.fit_transform(feature.loc[:,ind_temp])\n",
    "    feature2_sc = sc.transform(feature2.loc[:,ind_temp])\n",
    "    train,valid,test = train_model(model,feature_sc,np.array(y))\n",
    "    acc_rest=test_model(model,feature2_sc,np.array(y2))\n",
    "    acc_2f[p[0]+'_'+p[1]] = [train,valid,test,acc_rest]\n",
    "    print(acc_rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>valid</th>\n",
       "      <th>test</th>\n",
       "      <th>rest data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LEFT_TA_LEFT_TS</th>\n",
       "      <td>0.912545</td>\n",
       "      <td>0.881273</td>\n",
       "      <td>0.789818</td>\n",
       "      <td>0.782118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LEFT_TA_LEFT_BF</th>\n",
       "      <td>0.931636</td>\n",
       "      <td>0.906909</td>\n",
       "      <td>0.904873</td>\n",
       "      <td>0.864276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LEFT_TA_LEFT_RF</th>\n",
       "      <td>0.915045</td>\n",
       "      <td>0.884545</td>\n",
       "      <td>0.859200</td>\n",
       "      <td>0.898761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LEFT_TS_LEFT_BF</th>\n",
       "      <td>0.933955</td>\n",
       "      <td>0.901636</td>\n",
       "      <td>0.848727</td>\n",
       "      <td>0.824697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LEFT_TS_LEFT_RF</th>\n",
       "      <td>0.933045</td>\n",
       "      <td>0.884182</td>\n",
       "      <td>0.848582</td>\n",
       "      <td>0.856040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LEFT_BF_LEFT_RF</th>\n",
       "      <td>0.927545</td>\n",
       "      <td>0.898909</td>\n",
       "      <td>0.876073</td>\n",
       "      <td>0.868178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RIGHT_TA_RIGHT_TS</th>\n",
       "      <td>0.928909</td>\n",
       "      <td>0.902000</td>\n",
       "      <td>0.865164</td>\n",
       "      <td>0.850987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RIGHT_TA_RIGHT_BF</th>\n",
       "      <td>0.938591</td>\n",
       "      <td>0.906000</td>\n",
       "      <td>0.872582</td>\n",
       "      <td>0.864995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RIGHT_TA_RIGHT_RF</th>\n",
       "      <td>0.928455</td>\n",
       "      <td>0.902545</td>\n",
       "      <td>0.877818</td>\n",
       "      <td>0.857539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RIGHT_TS_RIGHT_BF</th>\n",
       "      <td>0.945182</td>\n",
       "      <td>0.906182</td>\n",
       "      <td>0.900800</td>\n",
       "      <td>0.850289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RIGHT_TS_RIGHT_RF</th>\n",
       "      <td>0.940409</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.839709</td>\n",
       "      <td>0.885657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RIGHT_BF_RIGHT_RF</th>\n",
       "      <td>0.948091</td>\n",
       "      <td>0.913273</td>\n",
       "      <td>0.857455</td>\n",
       "      <td>0.848029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      train     valid      test  rest data\n",
       "LEFT_TA_LEFT_TS    0.912545  0.881273  0.789818   0.782118\n",
       "LEFT_TA_LEFT_BF    0.931636  0.906909  0.904873   0.864276\n",
       "LEFT_TA_LEFT_RF    0.915045  0.884545  0.859200   0.898761\n",
       "LEFT_TS_LEFT_BF    0.933955  0.901636  0.848727   0.824697\n",
       "LEFT_TS_LEFT_RF    0.933045  0.884182  0.848582   0.856040\n",
       "LEFT_BF_LEFT_RF    0.927545  0.898909  0.876073   0.868178\n",
       "RIGHT_TA_RIGHT_TS  0.928909  0.902000  0.865164   0.850987\n",
       "RIGHT_TA_RIGHT_BF  0.938591  0.906000  0.872582   0.864995\n",
       "RIGHT_TA_RIGHT_RF  0.928455  0.902545  0.877818   0.857539\n",
       "RIGHT_TS_RIGHT_BF  0.945182  0.906182  0.900800   0.850289\n",
       "RIGHT_TS_RIGHT_RF  0.940409  0.909091  0.839709   0.885657\n",
       "RIGHT_BF_RIGHT_RF  0.948091  0.913273  0.857455   0.848029"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(acc_2f,index=['train','valid','test','rest data']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on some of rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:0.997041\n",
      "acc:0.994048\n",
      "acc:0.956284\n",
      "acc:0.980276\n",
      "acc:0.991055\n",
      "acc:0.906706\n",
      "acc:0.856749\n",
      "acc:0.966764\n",
      "[0.9970414201183432, 0.9940476190476191, 0.9562841530054644, 0.980276134122288, 0.9910554561717353, 0.9067055393586005, 0.8567493112947658, 0.9667644183773216]\n"
     ]
    }
   ],
   "source": [
    "some_of_rest = ['正常/P940_MSham_B_Walking_trial_6_emg.csv',\n",
    "                '正常/P940_M050_B_Walking_trial_4_emg.csv',\n",
    "                '正常/P812_M100_A_Walking_trial_3_emg.csv',\n",
    "                '正常/P645_M050_A_Walking_trial_3_emg.csv',\n",
    "                '正常/P623_Msham_B_Walking_trial_2_emg.csv',\n",
    "                '正常/P551_M50_B_Walking_trial_6_emg.csv',\n",
    "                'P379_M050_2_OFF_A_FoG_trial_1_emg.csv',\n",
    "                'P551_M050_2_B_FoG_trial_2_emg.csv']\n",
    "#booster = xgb.Booster()\n",
    "#booster.load_model('./model/XGBoost_W256_S64_Left.json')\n",
    "#model = xgb.XGBClassifier()\n",
    "#model._Booster = booster\n",
    "acc = []\n",
    "columns=['LEFT_TA','LEFT_TS','LEFT_BF', 'LEFT_RF']\n",
    "for file in some_of_rest:\n",
    "    path = './data/'+file\n",
    "    feature2,y2 = dp.pipeline_feature(path,width=256,stride=64,scaler=False,\n",
    "                                      threshold_WAMP=threshold_WAMP,\n",
    "                                      threshold_ZC=threshold_ZC,\n",
    "                                      threshold_SSC=threshold_SSC,\n",
    "                                      bins=bins,\n",
    "                                      ranges=HIST_range,\n",
    "                                      show_para=False,\n",
    "                                      filt = 250)\n",
    "    feature2_sc = sc.transform(feature2)\n",
    "    acc += [test_model(model,feature2_sc,y2)]\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9589472691255542"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=model.predict(feature2_sc)\n",
    "metrics.accuracy_score(y2,y_pred>0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_re = feature_sc.reshape((-1,feature.shape[1],1))\n",
    "x_full,x_test,y_full,y_test = train_test_split(feature_re,y_01,test_size=0.2,random_state=123)\n",
    "x_train,x_valid,y_train,y_valid = train_test_split(x_full,y_full,test_size=0.2,random_state=555)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = layers.Input(shape=[feature.shape[1],1])\n",
    "lstm1 = layers.GRU(100)(input_)\n",
    "#lstm2 = layers.LSTM(20)(lstm1)\n",
    "output = layers.Dense(1,activation='sigmoid')(lstm1)\n",
    "model = Model(inputs=[input_],outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21990 samples, validate on 5498 samples\n",
      "Epoch 1/100\n",
      "21990/21990 [==============================] - 55s 3ms/sample - loss: 0.6715 - accuracy: 0.5768 - val_loss: 0.6168 - val_accuracy: 0.6808\n",
      "Epoch 2/100\n",
      "21990/21990 [==============================] - 52s 2ms/sample - loss: 0.5631 - accuracy: 0.7150 - val_loss: 0.5077 - val_accuracy: 0.7552\n",
      "Epoch 3/100\n",
      "21990/21990 [==============================] - 52s 2ms/sample - loss: 0.5141 - accuracy: 0.7546 - val_loss: 0.4896 - val_accuracy: 0.7696\n",
      "Epoch 4/100\n",
      "21990/21990 [==============================] - 51s 2ms/sample - loss: 0.4999 - accuracy: 0.7643 - val_loss: 0.4811 - val_accuracy: 0.7803\n",
      "Epoch 5/100\n",
      "21990/21990 [==============================] - 51s 2ms/sample - loss: 0.4728 - accuracy: 0.7853 - val_loss: 0.4479 - val_accuracy: 0.7968\n",
      "Epoch 6/100\n",
      "21990/21990 [==============================] - 54s 2ms/sample - loss: 0.4521 - accuracy: 0.7983 - val_loss: 0.4376 - val_accuracy: 0.8032\n",
      "Epoch 7/100\n",
      "21990/21990 [==============================] - 54s 2ms/sample - loss: 0.4400 - accuracy: 0.8035 - val_loss: 0.4285 - val_accuracy: 0.8047\n",
      "Epoch 8/100\n",
      "21990/21990 [==============================] - 51s 2ms/sample - loss: 0.4256 - accuracy: 0.8104 - val_loss: 0.4125 - val_accuracy: 0.8139\n",
      "Epoch 9/100\n",
      "21990/21990 [==============================] - 50s 2ms/sample - loss: 0.4153 - accuracy: 0.8158 - val_loss: 0.4076 - val_accuracy: 0.8168\n",
      "Epoch 10/100\n",
      "21990/21990 [==============================] - 50s 2ms/sample - loss: 0.4055 - accuracy: 0.8200 - val_loss: 0.3910 - val_accuracy: 0.8248\n",
      "Epoch 11/100\n",
      "21990/21990 [==============================] - 50s 2ms/sample - loss: 0.3986 - accuracy: 0.8251 - val_loss: 0.3954 - val_accuracy: 0.8239\n",
      "Epoch 12/100\n",
      "21990/21990 [==============================] - 50s 2ms/sample - loss: 0.3899 - accuracy: 0.8274 - val_loss: 0.3834 - val_accuracy: 0.8323\n",
      "Epoch 13/100\n",
      "21990/21990 [==============================] - 57s 3ms/sample - loss: 0.3825 - accuracy: 0.8336 - val_loss: 0.3764 - val_accuracy: 0.8330\n",
      "Epoch 14/100\n",
      "21990/21990 [==============================] - 53s 2ms/sample - loss: 0.3781 - accuracy: 0.8344 - val_loss: 0.3763 - val_accuracy: 0.8341\n",
      "Epoch 15/100\n",
      "21990/21990 [==============================] - 50s 2ms/sample - loss: 0.3769 - accuracy: 0.8356 - val_loss: 0.3824 - val_accuracy: 0.8308\n",
      "Epoch 16/100\n",
      "21990/21990 [==============================] - 51s 2ms/sample - loss: 0.3702 - accuracy: 0.8385 - val_loss: 0.3647 - val_accuracy: 0.8392\n",
      "Epoch 17/100\n",
      "21990/21990 [==============================] - 50s 2ms/sample - loss: 0.3664 - accuracy: 0.8400 - val_loss: 0.3628 - val_accuracy: 0.8412\n",
      "Epoch 18/100\n",
      "21990/21990 [==============================] - 51s 2ms/sample - loss: 0.3602 - accuracy: 0.8447 - val_loss: 0.3623 - val_accuracy: 0.8421\n",
      "Epoch 19/100\n",
      "21990/21990 [==============================] - 55s 3ms/sample - loss: 0.3565 - accuracy: 0.8453 - val_loss: 0.3549 - val_accuracy: 0.8443\n",
      "Epoch 20/100\n",
      "21990/21990 [==============================] - 50s 2ms/sample - loss: 0.3611 - accuracy: 0.8427 - val_loss: 0.3642 - val_accuracy: 0.8430\n",
      "Epoch 21/100\n",
      "21990/21990 [==============================] - 51s 2ms/sample - loss: 0.3535 - accuracy: 0.8477 - val_loss: 0.3479 - val_accuracy: 0.8496\n",
      "Epoch 22/100\n",
      "21990/21990 [==============================] - 50s 2ms/sample - loss: 0.3428 - accuracy: 0.8531 - val_loss: 0.3441 - val_accuracy: 0.8510\n",
      "Epoch 23/100\n",
      "21990/21990 [==============================] - 50s 2ms/sample - loss: 0.3367 - accuracy: 0.8567 - val_loss: 0.3428 - val_accuracy: 0.8521\n",
      "Epoch 24/100\n",
      "21990/21990 [==============================] - 51s 2ms/sample - loss: 0.3370 - accuracy: 0.8578 - val_loss: 0.3387 - val_accuracy: 0.8534\n",
      "Epoch 25/100\n",
      "21990/21990 [==============================] - 55s 2ms/sample - loss: 0.3334 - accuracy: 0.8593 - val_loss: 0.3467 - val_accuracy: 0.8532\n",
      "Epoch 26/100\n",
      "21990/21990 [==============================] - 59s 3ms/sample - loss: 0.3366 - accuracy: 0.8578 - val_loss: 0.3497 - val_accuracy: 0.8485\n",
      "Epoch 27/100\n",
      "21990/21990 [==============================] - 55s 2ms/sample - loss: 0.3239 - accuracy: 0.8637 - val_loss: 0.3408 - val_accuracy: 0.8509\n",
      "Epoch 28/100\n",
      "21990/21990 [==============================] - 57s 3ms/sample - loss: 0.3187 - accuracy: 0.8674 - val_loss: 0.3296 - val_accuracy: 0.8579\n",
      "Epoch 29/100\n",
      "21990/21990 [==============================] - 54s 2ms/sample - loss: 0.3141 - accuracy: 0.8695 - val_loss: 0.3242 - val_accuracy: 0.8607\n",
      "Epoch 30/100\n",
      "21990/21990 [==============================] - 53s 2ms/sample - loss: 0.3147 - accuracy: 0.8709 - val_loss: 0.3199 - val_accuracy: 0.8592\n",
      "Epoch 31/100\n",
      "21990/21990 [==============================] - 55s 2ms/sample - loss: 0.3040 - accuracy: 0.8740 - val_loss: 0.3198 - val_accuracy: 0.8636\n",
      "Epoch 32/100\n",
      "21990/21990 [==============================] - 51s 2ms/sample - loss: 0.2984 - accuracy: 0.8792 - val_loss: 0.3172 - val_accuracy: 0.8647\n",
      "Epoch 33/100\n",
      "21990/21990 [==============================] - 54s 2ms/sample - loss: 0.2944 - accuracy: 0.8793 - val_loss: 0.3056 - val_accuracy: 0.8703\n",
      "Epoch 34/100\n",
      "21990/21990 [==============================] - 58s 3ms/sample - loss: 0.2918 - accuracy: 0.8804 - val_loss: 0.3224 - val_accuracy: 0.8665\n",
      "Epoch 35/100\n",
      "21990/21990 [==============================] - 60s 3ms/sample - loss: 0.2965 - accuracy: 0.8781 - val_loss: 0.3047 - val_accuracy: 0.8685\n",
      "Epoch 36/100\n",
      "21990/21990 [==============================] - 61s 3ms/sample - loss: 0.2858 - accuracy: 0.8834 - val_loss: 0.3056 - val_accuracy: 0.8730\n",
      "Epoch 37/100\n",
      "21990/21990 [==============================] - 70s 3ms/sample - loss: 0.2817 - accuracy: 0.8855 - val_loss: 0.3023 - val_accuracy: 0.8738\n",
      "Epoch 38/100\n",
      "21990/21990 [==============================] - 59s 3ms/sample - loss: 0.2824 - accuracy: 0.8838 - val_loss: 0.2955 - val_accuracy: 0.8750\n",
      "Epoch 39/100\n",
      "21990/21990 [==============================] - 59s 3ms/sample - loss: 0.2764 - accuracy: 0.8876 - val_loss: 0.2927 - val_accuracy: 0.8772\n",
      "Epoch 40/100\n",
      "21990/21990 [==============================] - 58s 3ms/sample - loss: 0.2754 - accuracy: 0.8880 - val_loss: 0.2878 - val_accuracy: 0.8798\n",
      "Epoch 41/100\n",
      "21990/21990 [==============================] - 58s 3ms/sample - loss: 0.2713 - accuracy: 0.8900 - val_loss: 0.2879 - val_accuracy: 0.8809\n",
      "Epoch 42/100\n",
      "21990/21990 [==============================] - 64s 3ms/sample - loss: 0.2708 - accuracy: 0.8917 - val_loss: 0.2857 - val_accuracy: 0.8821\n",
      "Epoch 43/100\n",
      "21990/21990 [==============================] - 61s 3ms/sample - loss: 0.2661 - accuracy: 0.8942 - val_loss: 0.2970 - val_accuracy: 0.8767\n",
      "Epoch 44/100\n",
      "21990/21990 [==============================] - 58s 3ms/sample - loss: 0.2641 - accuracy: 0.8933 - val_loss: 0.2820 - val_accuracy: 0.8863\n",
      "Epoch 45/100\n",
      "21990/21990 [==============================] - 58s 3ms/sample - loss: 0.2623 - accuracy: 0.8945 - val_loss: 0.2780 - val_accuracy: 0.8867\n",
      "Epoch 46/100\n",
      "21990/21990 [==============================] - 60s 3ms/sample - loss: 0.2595 - accuracy: 0.8976 - val_loss: 0.2897 - val_accuracy: 0.8783\n",
      "Epoch 47/100\n",
      "21990/21990 [==============================] - 60s 3ms/sample - loss: 0.2594 - accuracy: 0.8964 - val_loss: 0.2728 - val_accuracy: 0.8916\n",
      "Epoch 48/100\n",
      "21990/21990 [==============================] - 68s 3ms/sample - loss: 0.2608 - accuracy: 0.8952 - val_loss: 0.2785 - val_accuracy: 0.8841\n",
      "Epoch 49/100\n",
      "21990/21990 [==============================] - 59s 3ms/sample - loss: 0.2615 - accuracy: 0.8950 - val_loss: 0.2793 - val_accuracy: 0.8880\n",
      "Epoch 50/100\n",
      "21990/21990 [==============================] - 58s 3ms/sample - loss: 0.2507 - accuracy: 0.9005 - val_loss: 0.2762 - val_accuracy: 0.8854\n",
      "Epoch 51/100\n",
      "21990/21990 [==============================] - 57s 3ms/sample - loss: 0.2523 - accuracy: 0.9002 - val_loss: 0.2679 - val_accuracy: 0.8912\n",
      "Epoch 52/100\n",
      "21990/21990 [==============================] - 59s 3ms/sample - loss: 0.2469 - accuracy: 0.9012 - val_loss: 0.2665 - val_accuracy: 0.8961\n",
      "Epoch 53/100\n",
      "21990/21990 [==============================] - 67s 3ms/sample - loss: 0.2469 - accuracy: 0.9022 - val_loss: 0.2704 - val_accuracy: 0.8892\n",
      "Epoch 54/100\n",
      "21990/21990 [==============================] - 58s 3ms/sample - loss: 0.2519 - accuracy: 0.8998 - val_loss: 0.2953 - val_accuracy: 0.8740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "21990/21990 [==============================] - 59s 3ms/sample - loss: 0.2446 - accuracy: 0.9028 - val_loss: 0.2694 - val_accuracy: 0.8909\n",
      "Epoch 56/100\n",
      "21990/21990 [==============================] - 60s 3ms/sample - loss: 0.2435 - accuracy: 0.9028 - val_loss: 0.2641 - val_accuracy: 0.8927\n",
      "Epoch 57/100\n",
      "21990/21990 [==============================] - 58s 3ms/sample - loss: 0.2359 - accuracy: 0.9075 - val_loss: 0.2672 - val_accuracy: 0.8927\n",
      "Epoch 58/100\n",
      "21990/21990 [==============================] - 58s 3ms/sample - loss: 0.2331 - accuracy: 0.9080 - val_loss: 0.2556 - val_accuracy: 0.8994\n",
      "Epoch 59/100\n",
      "21990/21990 [==============================] - 66s 3ms/sample - loss: 0.2314 - accuracy: 0.9074 - val_loss: 0.2608 - val_accuracy: 0.8920\n",
      "Epoch 60/100\n",
      "21990/21990 [==============================] - 58s 3ms/sample - loss: 0.2337 - accuracy: 0.9083 - val_loss: 0.2617 - val_accuracy: 0.8952\n",
      "Epoch 61/100\n",
      "21990/21990 [==============================] - 58s 3ms/sample - loss: 0.2263 - accuracy: 0.9112 - val_loss: 0.2680 - val_accuracy: 0.8938\n",
      "Epoch 62/100\n",
      "21990/21990 [==============================] - 59s 3ms/sample - loss: 0.2256 - accuracy: 0.9116 - val_loss: 0.2648 - val_accuracy: 0.8912\n",
      "Epoch 63/100\n",
      "21990/21990 [==============================] - 58s 3ms/sample - loss: 0.2272 - accuracy: 0.9104 - val_loss: 0.2523 - val_accuracy: 0.9016\n",
      "Epoch 64/100\n",
      "21990/21990 [==============================] - 68s 3ms/sample - loss: 0.2188 - accuracy: 0.9149 - val_loss: 0.2563 - val_accuracy: 0.8983\n",
      "Epoch 65/100\n",
      "21990/21990 [==============================] - 58s 3ms/sample - loss: 0.2192 - accuracy: 0.9143 - val_loss: 0.2599 - val_accuracy: 0.8958\n",
      "Epoch 66/100\n",
      "21990/21990 [==============================] - 60s 3ms/sample - loss: 0.2175 - accuracy: 0.9144 - val_loss: 0.2565 - val_accuracy: 0.8994\n",
      "Epoch 67/100\n",
      "21990/21990 [==============================] - 63s 3ms/sample - loss: 0.2191 - accuracy: 0.9151 - val_loss: 0.2565 - val_accuracy: 0.9012\n",
      "Epoch 68/100\n",
      "21990/21990 [==============================] - 60s 3ms/sample - loss: 0.2188 - accuracy: 0.9146 - val_loss: 0.2499 - val_accuracy: 0.8976\n",
      "Epoch 69/100\n",
      "21990/21990 [==============================] - 68s 3ms/sample - loss: 0.2161 - accuracy: 0.9147 - val_loss: 0.2448 - val_accuracy: 0.9031\n",
      "Epoch 70/100\n",
      "21990/21990 [==============================] - 68s 3ms/sample - loss: 0.2097 - accuracy: 0.9181 - val_loss: 0.2669 - val_accuracy: 0.8934\n",
      "Epoch 71/100\n",
      "21990/21990 [==============================] - 65s 3ms/sample - loss: 0.2124 - accuracy: 0.9186 - val_loss: 0.2402 - val_accuracy: 0.9041\n",
      "Epoch 72/100\n",
      "21990/21990 [==============================] - 58s 3ms/sample - loss: 0.2059 - accuracy: 0.9209 - val_loss: 0.2535 - val_accuracy: 0.9000\n",
      "Epoch 73/100\n",
      "21990/21990 [==============================] - 63s 3ms/sample - loss: 0.2042 - accuracy: 0.9212 - val_loss: 0.2632 - val_accuracy: 0.8951\n",
      "Epoch 74/100\n",
      "21990/21990 [==============================] - 61s 3ms/sample - loss: 0.2007 - accuracy: 0.9223 - val_loss: 0.2516 - val_accuracy: 0.9018\n",
      "Epoch 75/100\n",
      "21990/21990 [==============================] - 69s 3ms/sample - loss: 0.1959 - accuracy: 0.9240 - val_loss: 0.2480 - val_accuracy: 0.9049\n",
      "Epoch 76/100\n",
      "21990/21990 [==============================] - 54s 2ms/sample - loss: 0.1995 - accuracy: 0.9223 - val_loss: 0.2474 - val_accuracy: 0.9021\n",
      "Epoch 77/100\n",
      "21990/21990 [==============================] - 52s 2ms/sample - loss: 0.1951 - accuracy: 0.9256 - val_loss: 0.2463 - val_accuracy: 0.9012\n",
      "Epoch 78/100\n",
      "21990/21990 [==============================] - 51s 2ms/sample - loss: 0.1940 - accuracy: 0.9255 - val_loss: 0.2395 - val_accuracy: 0.9072\n",
      "Epoch 79/100\n",
      "21990/21990 [==============================] - 53s 2ms/sample - loss: 0.1882 - accuracy: 0.9290 - val_loss: 0.2450 - val_accuracy: 0.9054\n",
      "Epoch 80/100\n",
      "21990/21990 [==============================] - 53s 2ms/sample - loss: 0.1900 - accuracy: 0.9274 - val_loss: 0.2403 - val_accuracy: 0.9049\n",
      "Epoch 81/100\n",
      "21990/21990 [==============================] - 54s 2ms/sample - loss: 0.1843 - accuracy: 0.9307 - val_loss: 0.2582 - val_accuracy: 0.8989\n",
      "Epoch 82/100\n",
      "21990/21990 [==============================] - 51s 2ms/sample - loss: 0.1854 - accuracy: 0.9292 - val_loss: 0.2461 - val_accuracy: 0.9021\n",
      "Epoch 83/100\n",
      "21990/21990 [==============================] - 50s 2ms/sample - loss: 0.1944 - accuracy: 0.9250 - val_loss: 0.2446 - val_accuracy: 0.9016\n",
      "Epoch 84/100\n",
      "21990/21990 [==============================] - 51s 2ms/sample - loss: 0.1830 - accuracy: 0.9312 - val_loss: 0.2420 - val_accuracy: 0.9043\n",
      "Epoch 85/100\n",
      "21990/21990 [==============================] - 49s 2ms/sample - loss: 0.1782 - accuracy: 0.9335 - val_loss: 0.2419 - val_accuracy: 0.9038\n",
      "Epoch 86/100\n",
      "21990/21990 [==============================] - 48s 2ms/sample - loss: 0.1778 - accuracy: 0.9327 - val_loss: 0.2529 - val_accuracy: 0.9072\n",
      "Epoch 87/100\n",
      "21990/21990 [==============================] - 66s 3ms/sample - loss: 0.1777 - accuracy: 0.9332 - val_loss: 0.2586 - val_accuracy: 0.8974\n",
      "Epoch 88/100\n",
      "21990/21990 [==============================] - 51s 2ms/sample - loss: 0.1751 - accuracy: 0.9343 - val_loss: 0.2365 - val_accuracy: 0.9100\n",
      "Epoch 89/100\n",
      "21990/21990 [==============================] - 51s 2ms/sample - loss: 0.1706 - accuracy: 0.9364 - val_loss: 0.2363 - val_accuracy: 0.9056\n",
      "Epoch 90/100\n",
      "21990/21990 [==============================] - 51s 2ms/sample - loss: 0.1769 - accuracy: 0.9331 - val_loss: 0.2393 - val_accuracy: 0.9080\n",
      "Epoch 91/100\n",
      "21990/21990 [==============================] - 51s 2ms/sample - loss: 0.1745 - accuracy: 0.9343 - val_loss: 0.2374 - val_accuracy: 0.9067\n",
      "Epoch 92/100\n",
      "21990/21990 [==============================] - 57s 3ms/sample - loss: 0.1649 - accuracy: 0.9388 - val_loss: 0.2482 - val_accuracy: 0.9078\n",
      "Epoch 93/100\n",
      "21990/21990 [==============================] - 63s 3ms/sample - loss: 0.1690 - accuracy: 0.9366 - val_loss: 0.2429 - val_accuracy: 0.9081\n",
      "Epoch 94/100\n",
      "21990/21990 [==============================] - 56s 3ms/sample - loss: 0.1614 - accuracy: 0.9382 - val_loss: 0.2349 - val_accuracy: 0.9118\n",
      "Epoch 95/100\n",
      "21990/21990 [==============================] - 57s 3ms/sample - loss: 0.1564 - accuracy: 0.9424 - val_loss: 0.2483 - val_accuracy: 0.9078\n",
      "Epoch 96/100\n",
      "21990/21990 [==============================] - 47s 2ms/sample - loss: 0.1538 - accuracy: 0.9428 - val_loss: 0.2466 - val_accuracy: 0.9076\n",
      "Epoch 97/100\n",
      "21990/21990 [==============================] - 47s 2ms/sample - loss: 0.1576 - accuracy: 0.9412 - val_loss: 0.2456 - val_accuracy: 0.9096\n",
      "Epoch 98/100\n",
      "21990/21990 [==============================] - 47s 2ms/sample - loss: 0.1532 - accuracy: 0.9437 - val_loss: 0.2464 - val_accuracy: 0.9081\n",
      "Epoch 99/100\n",
      "21990/21990 [==============================] - 51s 2ms/sample - loss: 0.1459 - accuracy: 0.9456 - val_loss: 0.2576 - val_accuracy: 0.9054\n",
      "Epoch 100/100\n",
      "21990/21990 [==============================] - 48s 2ms/sample - loss: 0.1493 - accuracy: 0.9451 - val_loss: 0.2571 - val_accuracy: 0.9054\n"
     ]
    }
   ],
   "source": [
    "early_stopping = callbacks.EarlyStopping(patience = 20,\n",
    "                                         monitor = 'val_accuracy', \n",
    "                                         restore_best_weights=True)\n",
    "history = model.fit(x_train,y_train,validation_data=[x_valid,y_valid],\n",
    "                    epochs=100,batch_size=500,\n",
    "                   callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature2_re = feature2_sc.reshape((-1,feature.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:0.889541\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8895405669599218"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(model,feature2_re,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
