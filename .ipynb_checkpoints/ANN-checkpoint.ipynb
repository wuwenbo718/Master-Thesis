{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import data_processing as dp\n",
    "from scipy import signal\n",
    "from scipy.stats import skew\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "import os\n",
    "import time\n",
    "import h5py\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for dirname, _, filenames in os.walk('.\\data'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2 = '.\\data\\正常\\G11_Walking_trial_4_emg.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.read_csv('./processed data/featurePcwtf_W256_S64_WS32_DWTLmax_dropna_sameLabel.csv')\n",
    "\n",
    "# read file name of data with various Labels\n",
    "df = pd.read_csv('./useful_data_label.csv',index_col=0) \n",
    "drop = 'P551_M050_2_B_FoG_trial_2_emg.csv'\n",
    "ind_drop = df.columns!=drop\n",
    "# read file name of data with only label 0\n",
    "df2 = pd.read_csv('./unuseful_data_label.csv',index_col=0)\n",
    "# read some of the data with only label 0\n",
    "df3 = pd.read_csv('./data/file_name.txt',header=None)\n",
    "\n",
    "files = np.concatenate([np.array(df.columns),np.array(df3.loc[:,0])])\n",
    "ind = Data.File.isin(files)\n",
    "Data_sel = Data[ind]\n",
    "Data_rest = Data[~ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_col = ['_IEMG','_MAV','_SSI','_VAR','_RMS',\n",
    "               '_WL','_ZC','_SSC','_WAMP','_skew','_Acti','_AR','_HIST','_MDF']\n",
    "\n",
    "feature_all = Data_sel.iloc[:,1:-1]\n",
    "#ind_temp1 = feature_all.columns.str.contains('_mDWT')\n",
    "#ind_temp2 = feature_all.columns.str.contains('_Coe')\n",
    "#ind_temp3 = feature_all.columns.str.contains('_Scale')\n",
    "#ind_temp4 = feature_all.columns.str.contains('_HIST')\n",
    "#ind_temp = ind_temp1|ind_temp2|ind_temp3|ind_temp4\n",
    "#ind_temp = feature_all.columns.str.contains('mDWT')\n",
    "#feature = feature_all.loc[:,~ind_temp]\n",
    "feature = Data_sel.iloc[:,1:-1]\n",
    "#feature = Data_sel.iloc[:,:-2]\n",
    "y = Data_sel.Label\n",
    "feature2_all = Data_rest.iloc[:,1:-1]\n",
    "#feature2 = feature2_all.loc[:,ind_temp]\n",
    "#feature2 = Data_rest.iloc[:,1:-1]\n",
    "#feature2 = Data_rest.iloc[:,:-2]\n",
    "y2 = Data_rest.Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './processed data/data_set_after_window_withoutSC.hdf5'\n",
    "with h5py.File(path,'r') as f:\n",
    "    x = f['cwt_data'][...]\n",
    "    y = f['label2'][...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "imp.reload(dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctypes\n",
    "player = ctypes.windll.kernel32\n",
    "player.Beep(1000,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LEFT_TA_IEMG</th>\n",
       "      <th>LEFT_TS_IEMG</th>\n",
       "      <th>LEFT_BF_IEMG</th>\n",
       "      <th>LEFT_RF_IEMG</th>\n",
       "      <th>RIGHT_TA_IEMG</th>\n",
       "      <th>RIGHT_TS_IEMG</th>\n",
       "      <th>RIGHT_BF_IEMG</th>\n",
       "      <th>RIGHT_RF_IEMG</th>\n",
       "      <th>LEFT_TA_SSI</th>\n",
       "      <th>LEFT_TS_SSI</th>\n",
       "      <th>...</th>\n",
       "      <th>RIGHT_TS_Mean_Scale</th>\n",
       "      <th>RIGHT_TS_Median_Scale</th>\n",
       "      <th>RIGHT_BF_Mean_Coe</th>\n",
       "      <th>RIGHT_BF_Min_Coe</th>\n",
       "      <th>RIGHT_BF_Mean_Scale</th>\n",
       "      <th>RIGHT_BF_Median_Scale</th>\n",
       "      <th>RIGHT_RF_Mean_Coe</th>\n",
       "      <th>RIGHT_RF_Min_Coe</th>\n",
       "      <th>RIGHT_RF_Mean_Scale</th>\n",
       "      <th>RIGHT_RF_Median_Scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>454.0</td>\n",
       "      <td>748.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>1406.0</td>\n",
       "      <td>4458.0</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>887.0</td>\n",
       "      <td>2070.0</td>\n",
       "      <td>1706.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.378038</td>\n",
       "      <td>8.0</td>\n",
       "      <td>24.542059</td>\n",
       "      <td>2.255293</td>\n",
       "      <td>21.602984</td>\n",
       "      <td>22.0</td>\n",
       "      <td>8.149243</td>\n",
       "      <td>2.348719</td>\n",
       "      <td>21.488162</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>476.0</td>\n",
       "      <td>794.0</td>\n",
       "      <td>647.0</td>\n",
       "      <td>1235.0</td>\n",
       "      <td>3225.0</td>\n",
       "      <td>2104.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>2124.0</td>\n",
       "      <td>1884.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.355238</td>\n",
       "      <td>9.0</td>\n",
       "      <td>27.130697</td>\n",
       "      <td>2.353224</td>\n",
       "      <td>21.448208</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.715876</td>\n",
       "      <td>2.236105</td>\n",
       "      <td>21.400280</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>525.0</td>\n",
       "      <td>477.0</td>\n",
       "      <td>731.0</td>\n",
       "      <td>624.0</td>\n",
       "      <td>1090.0</td>\n",
       "      <td>3633.0</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>895.0</td>\n",
       "      <td>2051.0</td>\n",
       "      <td>1905.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.222962</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.276554</td>\n",
       "      <td>2.454869</td>\n",
       "      <td>21.276233</td>\n",
       "      <td>21.0</td>\n",
       "      <td>9.268578</td>\n",
       "      <td>2.117670</td>\n",
       "      <td>21.645772</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>577.0</td>\n",
       "      <td>446.0</td>\n",
       "      <td>699.0</td>\n",
       "      <td>625.0</td>\n",
       "      <td>1108.0</td>\n",
       "      <td>5036.0</td>\n",
       "      <td>1751.0</td>\n",
       "      <td>808.0</td>\n",
       "      <td>2287.0</td>\n",
       "      <td>1660.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.601896</td>\n",
       "      <td>8.0</td>\n",
       "      <td>18.943253</td>\n",
       "      <td>2.585153</td>\n",
       "      <td>21.298372</td>\n",
       "      <td>22.0</td>\n",
       "      <td>8.467463</td>\n",
       "      <td>2.023193</td>\n",
       "      <td>21.997017</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>541.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>759.0</td>\n",
       "      <td>579.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>3126.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>906.0</td>\n",
       "      <td>2159.0</td>\n",
       "      <td>1602.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.475606</td>\n",
       "      <td>10.0</td>\n",
       "      <td>22.510206</td>\n",
       "      <td>2.759928</td>\n",
       "      <td>21.465651</td>\n",
       "      <td>21.0</td>\n",
       "      <td>9.763655</td>\n",
       "      <td>1.920696</td>\n",
       "      <td>21.582086</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74288</th>\n",
       "      <td>1208.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>536.0</td>\n",
       "      <td>736.0</td>\n",
       "      <td>522.0</td>\n",
       "      <td>626.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>15176.0</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.775696</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.333287</td>\n",
       "      <td>2.106539</td>\n",
       "      <td>16.330013</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.456178</td>\n",
       "      <td>1.682207</td>\n",
       "      <td>17.414168</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74289</th>\n",
       "      <td>1240.0</td>\n",
       "      <td>394.0</td>\n",
       "      <td>1108.0</td>\n",
       "      <td>529.0</td>\n",
       "      <td>753.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>626.0</td>\n",
       "      <td>567.0</td>\n",
       "      <td>15334.0</td>\n",
       "      <td>1398.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.015715</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.873222</td>\n",
       "      <td>2.090484</td>\n",
       "      <td>17.329646</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.523884</td>\n",
       "      <td>1.578831</td>\n",
       "      <td>17.987499</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74290</th>\n",
       "      <td>1455.0</td>\n",
       "      <td>407.0</td>\n",
       "      <td>1077.0</td>\n",
       "      <td>521.0</td>\n",
       "      <td>754.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>588.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>19859.0</td>\n",
       "      <td>1449.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.993815</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.367231</td>\n",
       "      <td>1.998784</td>\n",
       "      <td>16.830988</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.380889</td>\n",
       "      <td>1.610062</td>\n",
       "      <td>17.566651</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74291</th>\n",
       "      <td>1483.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>948.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>819.0</td>\n",
       "      <td>547.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>597.0</td>\n",
       "      <td>20093.0</td>\n",
       "      <td>1389.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.605526</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.420711</td>\n",
       "      <td>1.957482</td>\n",
       "      <td>17.253457</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.730140</td>\n",
       "      <td>2.113619</td>\n",
       "      <td>16.993441</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74292</th>\n",
       "      <td>1518.0</td>\n",
       "      <td>408.0</td>\n",
       "      <td>762.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>794.0</td>\n",
       "      <td>557.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>598.0</td>\n",
       "      <td>20040.0</td>\n",
       "      <td>1406.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.096408</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.957175</td>\n",
       "      <td>1.868804</td>\n",
       "      <td>16.279840</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.813554</td>\n",
       "      <td>1.895576</td>\n",
       "      <td>16.089282</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30640 rows × 192 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LEFT_TA_IEMG  LEFT_TS_IEMG  LEFT_BF_IEMG  LEFT_RF_IEMG  RIGHT_TA_IEMG  \\\n",
       "0             540.0         454.0         748.0         620.0         1406.0   \n",
       "1             540.0         476.0         794.0         647.0         1235.0   \n",
       "2             525.0         477.0         731.0         624.0         1090.0   \n",
       "3             577.0         446.0         699.0         625.0         1108.0   \n",
       "4             541.0         432.0         759.0         579.0         1024.0   \n",
       "...             ...           ...           ...           ...            ...   \n",
       "74288        1208.0         405.0        1124.0         536.0          736.0   \n",
       "74289        1240.0         394.0        1108.0         529.0          753.0   \n",
       "74290        1455.0         407.0        1077.0         521.0          754.0   \n",
       "74291        1483.0         401.0         948.0         546.0          819.0   \n",
       "74292        1518.0         408.0         762.0         555.0          794.0   \n",
       "\n",
       "       RIGHT_TS_IEMG  RIGHT_BF_IEMG  RIGHT_RF_IEMG  LEFT_TA_SSI  LEFT_TS_SSI  \\\n",
       "0             4458.0         1992.0          887.0       2070.0       1706.0   \n",
       "1             3225.0         2104.0          975.0       2124.0       1884.0   \n",
       "2             3633.0         1726.0          895.0       2051.0       1905.0   \n",
       "3             5036.0         1751.0          808.0       2287.0       1660.0   \n",
       "4             3126.0         2008.0          906.0       2159.0       1602.0   \n",
       "...              ...            ...            ...          ...          ...   \n",
       "74288          522.0          626.0          546.0      15176.0       1515.0   \n",
       "74289          540.0          626.0          567.0      15334.0       1398.0   \n",
       "74290          549.0          588.0          580.0      19859.0       1449.0   \n",
       "74291          547.0          563.0          597.0      20093.0       1389.0   \n",
       "74292          557.0          531.0          598.0      20040.0       1406.0   \n",
       "\n",
       "       ...  RIGHT_TS_Mean_Scale  RIGHT_TS_Median_Scale  RIGHT_BF_Mean_Coe  \\\n",
       "0      ...            11.378038                    8.0          24.542059   \n",
       "1      ...            12.355238                    9.0          27.130697   \n",
       "2      ...            11.222962                    8.0          20.276554   \n",
       "3      ...            10.601896                    8.0          18.943253   \n",
       "4      ...            12.475606                   10.0          22.510206   \n",
       "...    ...                  ...                    ...                ...   \n",
       "74288  ...            17.775696                   16.0           3.333287   \n",
       "74289  ...            20.015715                   20.0           3.873222   \n",
       "74290  ...            19.993815                   20.0           3.367231   \n",
       "74291  ...            19.605526                   19.0           3.420711   \n",
       "74292  ...            18.096408                   17.0           2.957175   \n",
       "\n",
       "       RIGHT_BF_Min_Coe  RIGHT_BF_Mean_Scale  RIGHT_BF_Median_Scale  \\\n",
       "0              2.255293            21.602984                   22.0   \n",
       "1              2.353224            21.448208                   21.0   \n",
       "2              2.454869            21.276233                   21.0   \n",
       "3              2.585153            21.298372                   22.0   \n",
       "4              2.759928            21.465651                   21.0   \n",
       "...                 ...                  ...                    ...   \n",
       "74288          2.106539            16.330013                   14.0   \n",
       "74289          2.090484            17.329646                   16.0   \n",
       "74290          1.998784            16.830988                   15.0   \n",
       "74291          1.957482            17.253457                   16.0   \n",
       "74292          1.868804            16.279840                   15.0   \n",
       "\n",
       "       RIGHT_RF_Mean_Coe  RIGHT_RF_Min_Coe  RIGHT_RF_Mean_Scale  \\\n",
       "0               8.149243          2.348719            21.488162   \n",
       "1              10.715876          2.236105            21.400280   \n",
       "2               9.268578          2.117670            21.645772   \n",
       "3               8.467463          2.023193            21.997017   \n",
       "4               9.763655          1.920696            21.582086   \n",
       "...                  ...               ...                  ...   \n",
       "74288           2.456178          1.682207            17.414168   \n",
       "74289           2.523884          1.578831            17.987499   \n",
       "74290           2.380889          1.610062            17.566651   \n",
       "74291           2.730140          2.113619            16.993441   \n",
       "74292           2.813554          1.895576            16.089282   \n",
       "\n",
       "       RIGHT_RF_Median_Scale  \n",
       "0                       22.0  \n",
       "1                       21.0  \n",
       "2                       21.0  \n",
       "3                       22.0  \n",
       "4                       21.0  \n",
       "...                      ...  \n",
       "74288                   17.0  \n",
       "74289                   17.0  \n",
       "74290                   17.0  \n",
       "74291                   16.0  \n",
       "74292                   15.0  \n",
       "\n",
       "[30640 rows x 192 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 256\n",
    "threshold_WAMP = 30\n",
    "threshold_ZC = 0\n",
    "threshold_SSC = 1\n",
    "bins=9\n",
    "bound = 70\n",
    "HIST_range = (-bound,bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './processed data/data_set_after_window_S64_withoutSC_allPa.hdf5'\n",
    "with h5py.File(path,'r') as f:\n",
    "    x = f['cwt_data'][...]\n",
    "    y = f['label2'][...]\n",
    "feature = dp.generate_feature(x,threshold_WAMP=threshold_WAMP,\n",
    "                              threshold_ZC=threshold_ZC,\n",
    "                              threshold_SSC=threshold_SSC,\n",
    "                              bins=bins,ranges=HIST_range)\n",
    "#feature2 = dp.generate_feature(x2)\n",
    "player.Beep(1000,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('./processed data/nfeatures_W256_S64_WAMP30.hdf5','r') as f:\n",
    "    feature = f['features'][...]\n",
    "    y = f['labels'][...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature2,y2 = dp.pipeline_feature(path2,width=256,stride=64,\n",
    "                                  scaler=False,\n",
    "                                  threshold_WAMP=threshold_WAMP,\n",
    "                                  threshold_ZC=threshold_ZC,\n",
    "                                  threshold_SSC=threshold_SSC,\n",
    "                                  bins=bins,ranges=HIST_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('./processed data/nfeatures_rest_W256_S64.hdf5','r') as f:\n",
    "    feature2 = f['features'][...]\n",
    "    y2 = f['labels'][...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler(with_mean=True)\n",
    "feature_sc = sc.fit_transform(feature)\n",
    "feature2_sc = sc.transform(feature2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,Model,callbacks,regularizers\n",
    "from sklearn.model_selection import train_test_split,cross_validate\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from imblearn.over_sampling import SMOTE,BorderlineSMOTE,ADASYN,SVMSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,feature,y,binary=True,file=None):\n",
    "    if binary:\n",
    "        ind = ((y==0)|(y==4)|(y==1)|(y==2)|(y==3)|(y==6))\n",
    "        ind1 = ((y==4)|(y==1)|(y==2)|(y==3)|(y==6))\n",
    "        y_01 = y.copy()\n",
    "        y_01[ind1] = 1\n",
    "        cw = None\n",
    "    else:\n",
    "        ind = ((y==1)|(y==2)|(y==6))\n",
    "        #ind = ((y==1)|(y==6))\n",
    "        y_01 = y[ind].copy()\n",
    "        oc = OneHotEncoder()\n",
    "        y_01 = oc.fit_transform(np.array(y_01)[:,np.newaxis]).toarray()\n",
    "        cw = None#{0:5,1:1,2:1}#{0:2,1:1,2:10,3:2}\n",
    "    x_full,x_test,y_full,y_test = train_test_split(np.array(feature)[ind,:],y_01,\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=345,\n",
    "                                                   shuffle=False)\n",
    "    x_train,x_valid,y_train,y_valid = train_test_split(x_full,y_full,\n",
    "                                                       test_size=0.25,\n",
    "                                                       random_state=555,\n",
    "                                                       shuffle=True)\n",
    "    #sm = BorderlineSMOTE(random_state=50,kind='borderline-2')\n",
    "    #x_train,y_train = sm.fit_resample(x_train,y_train)\n",
    "    sc = StandardScaler(with_mean=True)\n",
    "    x_train = sc.fit_transform(x_full)\n",
    "    x_valid = sc.transform(x_valid)\n",
    "    x_test = sc.transform(x_test)\n",
    "    \n",
    "    early_stopping = callbacks.EarlyStopping(patience = 10,\n",
    "                                             monitor = 'val_accuracy', \n",
    "                                             restore_best_weights=True)\n",
    "    history = model.fit(x_train,y_full,validation_data=[x_test,y_test],\n",
    "                        epochs=200,batch_size=32,class_weight=cw,\n",
    "                        callbacks=[early_stopping],\n",
    "                        shuffle=True)\n",
    "    \n",
    "    if binary:\n",
    "        y_pred_t=model.predict(x_test)\n",
    "        test = metrics.accuracy_score(y_test,np.argmax(y_pred_t,axis=1))\n",
    "        #y_pred_v=model.predict(x_valid)\n",
    "        #valid = metrics.accuracy_score(y_valid,np.argmax(y_pred_v,axis=1))\n",
    "        y_pred_ta=model.predict(x_train)\n",
    "        train = metrics.accuracy_score(y_full,np.argmax(y_pred_ta,axis=1))\n",
    "    else:\n",
    "        y_pred_t=model.predict(x_test)\n",
    "        test = metrics.accuracy_score(np.argmax(y_test,axis=1),np.argmax(y_pred_t,axis=1))\n",
    "        #y_pred_v=model.predict(x_valid)\n",
    "        #valid = metrics.accuracy_score(np.argmax(y_valid,axis=1),np.argmax(y_pred_v,axis=1))\n",
    "        y_pred_ta=model.predict(x_train)\n",
    "        train = metrics.accuracy_score(np.argmax(y_full,axis=1),np.argmax(y_pred_ta,axis=1))        \n",
    "        print('train: \\n',metrics.confusion_matrix(np.argmax(y_full,axis=1),np.argmax(y_pred_ta,axis=1)))\n",
    "        #print('valid: \\n',metrics.confusion_matrix(np.argmax(y_valid,axis=1),np.argmax(y_pred_v,axis=1)))\n",
    "        print('test: \\n',metrics.confusion_matrix(np.argmax(y_test,axis=1),np.argmax(y_pred_t,axis=1)))\n",
    "    print('test:%f'%test)\n",
    "    #print('valid:%f'%valid)\n",
    "    print('train:%f'%train)\n",
    "    if file != None:\n",
    "        model.save_model(file)\n",
    "    return train,test,sc\n",
    "\n",
    "def test_model(model,feature,y,sc):\n",
    "    ind = ((y==4)|(y==1)|(y==2)|(y==3)|(y==6))\n",
    "    y_01 = y.copy()\n",
    "    y_01[ind] = 1\n",
    "    y_pred=model.predict(sc.transform(feature))\n",
    "    test = metrics.accuracy_score(y_01,np.argmax(y_pred,axis=1))\n",
    "    print('acc:%f'%test)\n",
    "    return test\n",
    "\n",
    "def sparse_cost_sensitive_loss (y_true,y_pred):\n",
    "    #cost_matrix = tf.constant([[0,1.5,1,1.5],\n",
    "    #              [1,0,1,1],\n",
    "    #              [5,10,0,5],\n",
    "    #              [1.,1.,1,0]])\n",
    "    cost_matrix = tf.constant([[0,20.,1],\n",
    "                  [1,0,1],\n",
    "                  [1.5,2.,0]])\n",
    "    batch_cost_matrix = tf.nn.embedding_lookup(cost_matrix, tf.argmax(y_true,axis=1))\n",
    "    eps = 1e-6\n",
    "    probability = tf.clip_by_value(y_pred, eps, 1-eps)\n",
    "    cost_values = tf.math.log(1-probability)*batch_cost_matrix\n",
    "    loss = tf.reduce_mean(-tf.reduce_sum(cost_values, axis=1))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = ((y==1)|(y==2)|(y==3)|(y==6))\n",
    "#ind = ((y==4)|(y==1)|(y==2)|(y==3)|(y==6))\n",
    "ind_f = [0,1,6,42,46,57,62]\n",
    "#y_01 = y[ind].copy()\n",
    "#y_01[y_01==1]=0\n",
    "#y_01[y_01==2]=1\n",
    "#y_01[y_01==3]=2\n",
    "#y_01[y_01==6]=3\n",
    "y_01 = y[ind].copy()\n",
    "#y_01[ind] = 1\n",
    "oh_ec = OneHotEncoder()\n",
    "y_oh = oh_ec.fit_transform(y_01[:,np.newaxis]).toarray()\n",
    "x_full,x_test,y_full,y_test = train_test_split(feature.loc[ind,:],y_01,test_size=0.2,random_state=123,shuffle=False)\n",
    "x_train,x_valid,y_train,y_valid = train_test_split(x_full,y_full,test_size=0.2,random_state=555,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = layers.Input(shape=feature.shape[1:])\n",
    "l1 = layers.Dense(128,activation='relu',\n",
    "                  #kernel_initializer='lecun_normal',\n",
    "                  #kernel_regularizer = regularizers.l2(0.001),\n",
    "                 )(input_)\n",
    "drop1 = layers.Dropout(0.2)(l1)\n",
    "l2 = layers.Dense(64,activation='relu',\n",
    "                  #kernel_initializer='lecun_normal',\n",
    "                  #kernel_regularizer = regularizers.l2(0.001),\n",
    "                 )(drop1)\n",
    "drop2 = layers.Dropout(0.2)(l2)\n",
    "l3 = layers.Dense(32,activation='relu',\n",
    "                  #kernel_initializer='lecun_normal',\n",
    "                  #kernel_regularizer = regularizers.l2(0.001),\n",
    "                 )(drop2)\n",
    "drop3 = layers.Dropout(0.2)(l3)\n",
    "#l4 = layers.Dense(16,activation='relu')(l3)\n",
    "#drop4 = layers.Dropout(0.2)(l4)\n",
    "output = layers.Dense(3,activation='softmax')(drop3)\n",
    "model = Model(inputs=[input_],outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=sparse_cost_sensitive_loss,optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = callbacks.EarlyStopping(patience = 20,\n",
    "                                         monitor = 'val_accuracy', \n",
    "                                         restore_best_weights=True)\n",
    "history = model.fit(x_train,y_train,validation_data=[x_valid,y_valid],\n",
    "                    epochs=200,batch_size=50,\n",
    "                   callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8527 samples, validate on 2132 samples\n",
      "Epoch 1/200\n",
      "8527/8527 [==============================] - 2s 283us/sample - loss: 0.9630 - accuracy: 0.5344 - val_loss: 18.9821 - val_accuracy: 0.8832\n",
      "Epoch 2/200\n",
      "8527/8527 [==============================] - 1s 79us/sample - loss: 0.7239 - accuracy: 0.6237 - val_loss: 24.5705 - val_accuracy: 0.8865\n",
      "Epoch 3/200\n",
      "8527/8527 [==============================] - 1s 78us/sample - loss: 0.6921 - accuracy: 0.6628 - val_loss: 23.1119 - val_accuracy: 0.8832\n",
      "Epoch 4/200\n",
      "8527/8527 [==============================] - 1s 78us/sample - loss: 0.6033 - accuracy: 0.6999 - val_loss: 24.9802 - val_accuracy: 0.8790\n",
      "Epoch 5/200\n",
      "8527/8527 [==============================] - 1s 76us/sample - loss: 0.5893 - accuracy: 0.7136 - val_loss: 23.6371 - val_accuracy: 0.8813\n",
      "Epoch 6/200\n",
      "8527/8527 [==============================] - 1s 78us/sample - loss: 0.6151 - accuracy: 0.7147 - val_loss: 17.7840 - val_accuracy: 0.8616\n",
      "Epoch 7/200\n",
      "8527/8527 [==============================] - 1s 77us/sample - loss: 0.5714 - accuracy: 0.7233 - val_loss: 20.5631 - val_accuracy: 0.8635\n",
      "Epoch 8/200\n",
      "8527/8527 [==============================] - 1s 80us/sample - loss: 0.5455 - accuracy: 0.7348 - val_loss: 24.9163 - val_accuracy: 0.8748\n",
      "Epoch 9/200\n",
      "8527/8527 [==============================] - 1s 78us/sample - loss: 0.5182 - accuracy: 0.7443 - val_loss: 26.8573 - val_accuracy: 0.8884\n",
      "Epoch 10/200\n",
      "8527/8527 [==============================] - 1s 76us/sample - loss: 0.5061 - accuracy: 0.7548 - val_loss: 26.1709 - val_accuracy: 0.8893\n",
      "Epoch 11/200\n",
      "8527/8527 [==============================] - 1s 78us/sample - loss: 0.4993 - accuracy: 0.7579 - val_loss: 26.6015 - val_accuracy: 0.8846\n",
      "Epoch 12/200\n",
      "8527/8527 [==============================] - 1s 79us/sample - loss: 0.4552 - accuracy: 0.7767 - val_loss: 28.2924 - val_accuracy: 0.8879\n",
      "Epoch 13/200\n",
      "8527/8527 [==============================] - 1s 79us/sample - loss: 0.4509 - accuracy: 0.7807 - val_loss: 27.9405 - val_accuracy: 0.8856\n",
      "Epoch 14/200\n",
      "8527/8527 [==============================] - 1s 78us/sample - loss: 0.4792 - accuracy: 0.7880 - val_loss: 26.6158 - val_accuracy: 0.8823\n",
      "Epoch 15/200\n",
      "8527/8527 [==============================] - 1s 78us/sample - loss: 0.4637 - accuracy: 0.7766 - val_loss: 26.7802 - val_accuracy: 0.8870\n",
      "Epoch 16/200\n",
      "8527/8527 [==============================] - 1s 76us/sample - loss: 0.4559 - accuracy: 0.7828 - val_loss: 26.0379 - val_accuracy: 0.8738\n",
      "Epoch 17/200\n",
      "8527/8527 [==============================] - 1s 81us/sample - loss: 0.4125 - accuracy: 0.7993 - val_loss: 26.7222 - val_accuracy: 0.8813\n",
      "Epoch 18/200\n",
      "8527/8527 [==============================] - 1s 81us/sample - loss: 0.3900 - accuracy: 0.8083 - val_loss: 27.3029 - val_accuracy: 0.8818\n",
      "Epoch 19/200\n",
      "8527/8527 [==============================] - 1s 81us/sample - loss: 0.3975 - accuracy: 0.8076 - val_loss: 26.1139 - val_accuracy: 0.8738\n",
      "Epoch 20/200\n",
      "8527/8527 [==============================] - 1s 82us/sample - loss: 0.3914 - accuracy: 0.8095 - val_loss: 25.5313 - val_accuracy: 0.8818\n",
      "train: \n",
      " [[1878    1  258]\n",
      " [ 975 2111  363]\n",
      " [  86   12 2843]]\n",
      "test: \n",
      " [[   0  233    0]\n",
      " [   1 1896    2]\n",
      " [   0    0    0]]\n",
      "test:0.889306\n",
      "train:0.801220\n"
     ]
    }
   ],
   "source": [
    "#sc = StandardScaler(with_mean=True)\n",
    "#feature_sc = sc.fit_transform(feature)\n",
    "#feature2_sc = sc.transform(feature2)\n",
    "#pca = PCA(n_components=160,copy=True)\n",
    "#feature_pca = pca.fit_transform(feature)\n",
    "#feature2_pca = pca.transform(feature2)\n",
    "train,test,sc = train_model(model,feature,np.array(y),False)\n",
    "#rest = test_model(model,feature2,np.array(y2),sc)\n",
    "#acc = [train,valid,test,rest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:0.960744\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9607438016528925"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(model,feature2,np.array(y2),sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    19934\n",
       "2     5348\n",
       "6     2941\n",
       "1     2370\n",
       "3       47\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_model(model,feature2_sc,np.array(y2))\n",
    "ind = ((y==1)|(y==2)|(y==6))\n",
    "y_01 = y[ind].copy()\n",
    "oc = OneHotEncoder()\n",
    "y_01 = oc.fit_transform(np.array(y_01)[:,np.newaxis]).toarray()\n",
    "pred=model.predict(feature_sc[ind,:])\n",
    "np.argmax(pred,axis=1)\n",
    "np.argmax(y_01,axis=1)\n",
    "metrics.confusion_matrix(np.argmax(y_01,axis=1),np.argmax(pred,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acc_ann = pd.DataFrame(acc,columns=['dnn1'],index=['train','valid','test','rest data'])\n",
    "#acc_ann_com=pd.concat([acc_ann_com,acc_ann.T])\n",
    "#acc_ann.loc['drop_mDWT',:]=[train,valid,test,rest]\n",
    "acc_ann_com.loc['dnn2',:]=acc\n",
    "acc_ann_com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test feature from Left or Right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = layers.Input(shape=feature.loc[:,ind_temp].shape[1:])\n",
    "l1 = layers.Dense(128,activation='elu')(input_)\n",
    "drop1 = layers.Dropout(0.2)(l1)\n",
    "l2 = layers.Dense(64,activation='elu')(drop1)\n",
    "drop2 = layers.Dropout(0.2)(l2)\n",
    "#l3 = layers.Dense(32,activation='elu')(drop2)\n",
    "#drop3 = layers.Dropout(0.2)(l3)\n",
    "#l4 = layers.Dense(16,activation='selu')(l3)\n",
    "#drop4 = layers.Dropout(0.2)(l4)\n",
    "output = layers.Dense(1,activation='sigmoid')(drop2)\n",
    "model = Model(inputs=[input_],outputs=[output])\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc={}\n",
    "cols = ['LEFT','RIGHT']\n",
    "\n",
    "#sc = StandardScaler(with_mean=True)\n",
    "\n",
    "for col in cols:\n",
    "    ind_temp=feature.columns.str.contains(col)\n",
    "    #feature_sc = sc.fit_transform(feature.loc[:,ind_temp])\n",
    "    #feature2_sc = sc.transform(feature2.loc[:,ind_temp])\n",
    "    train,valid,test,sc = train_model(model,np.array(feature.loc[:,ind_temp]),np.array(y))\n",
    "    \n",
    "    acc_rest=test_model(model,np.array(feature2.loc[:,ind_temp]),np.array(y2),sc)\n",
    "    acc[col] = [train,valid,test,acc_rest]\n",
    "    print(acc_rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_lr=pd.DataFrame(acc,index=['train','valid','test','rest data'])#.to_csv('./results/acc_lr_ann.csv')\n",
    "#acc_com=pd.concat([acc_ann_com.drop(['dnn','dnn1'],'index'),acc_lr.T])\n",
    "acc_com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test features from 2 of 8 signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test features from 2 of 8 signals\n",
    "\n",
    "acc_2f={}\n",
    "cols = [ 'LEFT_TA','LEFT_TS','LEFT_BF', 'LEFT_RF',\n",
    "        'RIGHT_TA','RIGHT_TS','RIGHT_BF', 'RIGHT_RF']\n",
    "\n",
    "\n",
    "for p in combinations(cols[:4],2):\n",
    "    ind_temp=feature.columns.str.contains(p[0])| feature.columns.str.contains(p[1])\n",
    "    #feature_sc = sc.fit_transform(feature.loc[:,ind_temp])\n",
    "    #feature2_sc = sc.transform(feature2.loc[:,ind_temp])\n",
    "    train,valid,test,sc = train_model(model,np.array(feature.loc[:,ind_temp]),np.array(y))\n",
    "    acc_rest=test_model(model,np.array(feature2.loc[:,ind_temp]),np.array(y2),sc)\n",
    "    acc_2f[p[0]+'_'+p[1]] = [train,valid,test,acc_rest]\n",
    "    print(acc_rest)\n",
    "    \n",
    "for p in combinations(cols[4:],2):\n",
    "    ind_temp=feature.columns.str.contains(p[0])| feature.columns.str.contains(p[1])\n",
    "    #feature_sc = sc.fit_transform(feature.loc[:,ind_temp])\n",
    "    #feature2_sc = sc.transform(feature2.loc[:,ind_temp])\n",
    "    train,valid,test,sc = train_model(model,np.array(feature.loc[:,ind_temp]),np.array(y))\n",
    "    acc_rest=test_model(model,np.array(feature2.loc[:,ind_temp]),np.array(y2),sc)\n",
    "    acc_2f[p[0]+'_'+p[1]] = [train,valid,test,acc_rest]\n",
    "    print(acc_rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acc_2f_ann = pd.DataFrame(acc_2f,index=['train','valid','test','rest data']).T\n",
    "#acc_com = pd.concat([acc_com,acc_2f_ann])\n",
    "acc_com.to_csv('./results/dropna/acc_com_ann.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(acc_2f,index=['train','valid','test','rest data']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on some of rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_of_rest = ['正常/P940_MSham_B_Walking_trial_6_emg.csv',\n",
    "                '正常/P940_M050_B_Walking_trial_4_emg.csv',\n",
    "                '正常/P812_M100_A_Walking_trial_3_emg.csv',\n",
    "                '正常/P645_M050_A_Walking_trial_3_emg.csv',\n",
    "                '正常/P623_Msham_B_Walking_trial_2_emg.csv',\n",
    "                '正常/P551_M50_B_Walking_trial_6_emg.csv',\n",
    "                'P379_M050_2_OFF_A_FoG_trial_1_emg.csv',\n",
    "                'P551_M050_2_B_FoG_trial_2_emg.csv']\n",
    "#booster = xgb.Booster()\n",
    "#booster.load_model('./model/XGBoost_W256_S64_Left.json')\n",
    "#model = xgb.XGBClassifier()\n",
    "#model._Booster = booster\n",
    "acc = []\n",
    "columns=['LEFT_TA','LEFT_TS','LEFT_BF', 'LEFT_RF']\n",
    "for file in some_of_rest:\n",
    "    path = './data/'+file\n",
    "    feature2,y2 = dp.pipeline_feature(path,width=256,stride=64,scaler=False,\n",
    "                                      threshold_WAMP=threshold_WAMP,\n",
    "                                      threshold_ZC=threshold_ZC,\n",
    "                                      threshold_SSC=threshold_SSC,\n",
    "                                      bins=bins,\n",
    "                                      ranges=HIST_range,\n",
    "                                      show_para=False,\n",
    "                                      filt = 250)\n",
    "    feature2_sc = sc.transform(feature2)\n",
    "    acc += [test_model(model,feature2_sc,y2)]\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(feature2_sc)\n",
    "metrics.accuracy_score(y2,y_pred>0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_re = feature_sc.reshape((-1,feature.shape[1],1))\n",
    "x_full,x_test,y_full,y_test = train_test_split(np.array(feature_re),np.array(y_01),test_size=0.2,random_state=123)\n",
    "x_train,x_valid,y_train,y_valid = train_test_split(x_full,y_full,test_size=0.2,random_state=555)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = layers.Input(shape=[feature.shape[1],1])\n",
    "lstm1 = layers.GRU(100)(input_)\n",
    "#lstm2 = layers.LSTM(20)(lstm1)\n",
    "output = layers.Dense(1,activation='sigmoid')(lstm1)\n",
    "model = Model(inputs=[input_],outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "early_stopping = callbacks.EarlyStopping(patience = 20,\n",
    "                                         monitor = 'val_accuracy', \n",
    "                                         restore_best_weights=True)\n",
    "history = model.fit(x_train,y_train,validation_data=[x_valid,y_valid],\n",
    "                    epochs=100,batch_size=500,\n",
    "                   callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature2_re = feature2_sc.reshape((-1,feature.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(model,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_matrix=np.array([[0,1,1,1],\n",
    "                  [1,0,1,1],\n",
    "                  [10,100,0,10],\n",
    "                  [1.,1.,1,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.constant(cost_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.00e+00, 2.00e+00, 1.10e+02, 2.00e+00],\n",
       "       [2.00e+00, 3.00e+00, 2.00e+01, 2.00e+00],\n",
       "       [1.10e+02, 2.00e+01, 1.02e+04, 1.10e+02],\n",
       "       [2.00e+00, 2.00e+00, 1.10e+02, 3.00e+00]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(t@tf.transpose(t)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1567100, shape=(4, 4), dtype=float64, numpy=\n",
       "array([[  0.,   1.,  10.,   1.],\n",
       "       [  1.,   0., 100.,   1.],\n",
       "       [  1.,   1.,   0.,   1.],\n",
       "       [  1.,   1.,  10.,   0.]])>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.transpose(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
