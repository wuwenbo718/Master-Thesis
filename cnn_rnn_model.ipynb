{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.config import Config\n",
    "from lib.data_set import Dataset\n",
    "from lib.model import NNModel\n",
    "from lib import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctypes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras import layers as KL\n",
    "from tensorflow.keras import models as KM\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File name read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file name of data with various Labels\n",
    "df = pd.read_csv('./useful_data_label.csv',index_col=0) \n",
    "# read file name of data with only label 0\n",
    "df2 = pd.read_csv('./unuseful_data_label.csv',index_col=0)\n",
    "# read some of the data with only label 0\n",
    "df3 = pd.read_csv('./data/file_name.txt',header=None)\n",
    "player = ctypes.windll.kernel32\n",
    "\n",
    "ind = df2.iloc[1].isna()\n",
    "files = np.concatenate([np.array(df.columns),np.array('normal/'+df2.columns[ind])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Override the base class of Config and Features for RNN_CNN Model\n",
    "class RCNN_Config(Config):\n",
    "    \n",
    "    NAME = 'RNN_CNN'\n",
    "    NUM_CLASSES = 2\n",
    "    EPOCHS = 500\n",
    "    BATCH_SIZE = 32\n",
    "    COST_SENSITIVE = False\n",
    "    CLASS_WEIGHTS = None\n",
    "    TEST_FILES = files[[6,30,31,32,33,34,35]]\n",
    "    \n",
    "    FN_LP = 300\n",
    "    FN_HP = None\n",
    "    FN_IR = False\n",
    "    DETREND_LAMBDA = 50\n",
    "\n",
    "    DROP_WITH_ZSCORE = None\n",
    "    \n",
    "class Rect_dataset(Dataset):\n",
    "    \n",
    "    def __init__(self,config):\n",
    "        super(Rect_dataset,self).__init__(config)\n",
    "        self.n_env = config.N_ENV\n",
    "    \n",
    "    def rectify_data(self):\n",
    "        \n",
    "        self.Xr = utils.rectify_emg_moving_average(self.X,self.n_env)\n",
    "        self.Xr2 = utils.rectify_emg_moving_average(self.X2,self.n_env)\n",
    "        self.Xr3 = utils.rectify_emg_moving_average(self.X3,self.n_env)\n",
    "    \n",
    "    @property\n",
    "    def train_set(self):\n",
    "        return self.Xr,self.Y,self.F\n",
    "    \n",
    "    @property\n",
    "    def valid_set(self):\n",
    "        return self.Xr2,self.Y2,self.F2\n",
    "    \n",
    "    @property\n",
    "    def test_set(self):\n",
    "        return self.Xr3,self.Y3,self.F3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BATCH_SIZE                     32\n",
      "CHANNELS                       ['LEFT_TA', 'LEFT_TS', 'LEFT_BF', 'LEFT_RF', 'RIGHT_TA', 'RIGHT_TS', 'RIGHT_BF', 'RIGHT_RF']\n",
      "CLASS_WEIGHTS                  None\n",
      "COST_SENSITIVE                 False\n",
      "DETREND_LAMBDA                 50\n",
      "DROP_WITH_ZSCORE               None\n",
      "EPOCHS                         500\n",
      "FN_HP                          None\n",
      "FN_IR                          False\n",
      "FN_LP                          300\n",
      "NAME                           RNN_CNN\n",
      "NUM_CLASSES                    2\n",
      "N_ENV                          20\n",
      "RECT                           False\n",
      "REMOVE_FREQS                   True\n",
      "SAME_LABEL                     True\n",
      "SAVE                           False\n",
      "SCALE                          True\n",
      "SHUFFLE                        True\n",
      "STEP_SIZE                      512\n",
      "TEST_FILES                     ['G08_FoG_1_trial_1_emg.csv' 'normal/G09_Walking_trial_2_emg.csv'\n",
      " 'normal/G09_Walking_trial_4_emg.csv' 'normal/G09_Walking_trial_6_emg.csv'\n",
      " 'normal/G11_Walking_trial_2_emg.csv' 'normal/G11_Walking_trial_4_emg.csv'\n",
      " 'normal/P231_M050_A_Walking_trial_2_emg.csv']\n",
      "TRAIN_SET_RATIO                0.8\n",
      "WINDOW_SIZE                    1024\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate CWT-CNN configuration\n",
    "config = RCNN_Config()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Rect_dataset(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip\n",
      "skip\n",
      "3/174: G06_FoG_trial_1_emg.csv\n",
      "4/174: G06_FoG_trial_2_emg.csv\n",
      "5/174: G06_FoG_trial_3_emg.csv\n",
      "6/174: G07_Freezing_Trial1_trial_1_emg.csv\n",
      "7/174: G08_FoG_1_trial_1_emg.csv\n",
      "8/174: G08_FoG_2_trial_1_emg.csv\n",
      "9/174: G11_FoG_trial_1_emg.csv\n",
      "10/174: G11_FoG_trial_2_emg.csv\n",
      "11/174: P379_M050_2_OFF_A_FoG_trial_1_emg.csv\n",
      "12/174: P379_M050_2_OFF_A_FoG_trial_2_emg.csv\n",
      "13/174: P379_M050_2_OFF_A_FoG_trial_3_emg.csv\n",
      "14/174: P379_M050_2_OFF_B_FoG_trial_1_emg.csv\n",
      "15/174: P379_M050_2_OFF_B_FoG_trial_2_emg.csv\n",
      "16/174: P379_M050_2_OFF_B_FoG_trial_3_emg.csv\n",
      "17/174: P551_M050_2_A_FoG_trial_1_emg.csv\n",
      "18/174: P551_M050_2_B_FoG_trial_1_emg.csv\n",
      "19/174: P551_M050_2_B_FoG_trial_2_emg.csv\n",
      "20/174: P812_M050_2_B_FoG_trial_1_emg.csv\n",
      "21/174: P812_M050_2_B_FoG_trial_2_emg.csv\n",
      "22/174: normal/G02_Walking_trial_1_emg.csv\n",
      "23/174: normal/G03_Walking_trial_1_emg.csv\n",
      "24/174: normal/G03_Walking_trial_2_emg.csv\n",
      "25/174: normal/G05_Walking_struct_fixed_trial_1_emg.csv\n",
      "26/174: normal/G05_Walking_struct_fixed_trial_2_emg.csv\n",
      "27/174: normal/G05_Walking_struct_fixed_trial_3_emg.csv\n",
      "28/174: normal/G09_FoG_trial_1_emg.csv\n",
      "29/174: normal/G09_FoG_trial_2_emg.csv\n",
      "30/174: normal/G09_FoG_trial_3_emg.csv\n",
      "31/174: normal/G09_Walking_trial_2_emg.csv\n",
      "32/174: normal/G09_Walking_trial_4_emg.csv\n",
      "33/174: normal/G09_Walking_trial_6_emg.csv\n",
      "34/174: normal/G11_Walking_trial_2_emg.csv\n",
      "35/174: normal/G11_Walking_trial_4_emg.csv\n",
      "36/174: normal/P231_M050_A_Walking_trial_2_emg.csv\n",
      "37/174: normal/P231_M050_A_Walking_trial_4_emg.csv\n",
      "38/174: normal/P231_M050_A_Walking_trial_6_emg.csv\n",
      "39/174: normal/P231_M050_B_Walking_trial_2_emg.csv\n",
      "40/174: normal/P231_M050_B_Walking_trial_4_emg.csv\n",
      "41/174: normal/P231_M050_B_Walking_trial_6_emg.csv\n",
      "42/174: normal/P231_M100_2_A_FoG_trial_3_emg.csv\n",
      "43/174: normal/P231_M100_2_A_Walking_trial_4_emg.csv\n",
      "44/174: normal/P231_M100_2_A_Walking_trial_6_emg.csv\n",
      "45/174: normal/P231_M100_ON_A_Walking_trial_2_emg.csv\n",
      "46/174: normal/P231_M100_ON_A_Walking_trial_4_emg.csv\n",
      "47/174: normal/P231_M100_ON_A_Walking_trial_6_emg.csv\n",
      "48/174: normal/P231_Msham_A_Walking_trial_2_emg.csv\n",
      "49/174: normal/P231_Msham_A_Walking_trial_6_emg.csv\n",
      "50/174: normal/P231_Msham_B_Walking_trial_2_emg.csv\n",
      "51/174: normal/P351_M050_2_A_FoG_trial_1_emg.csv\n",
      "52/174: normal/P351_M050_2_A_FoG_trial_2_emg.csv\n",
      "53/174: normal/P351_M050_2_A_FoG_trial_3_emg.csv\n",
      "54/174: normal/P351_M050_2_A_Walking_trial_2_emg.csv\n",
      "55/174: normal/P351_M050_2_A_Walking_trial_4_emg.csv\n",
      "56/174: normal/P351_M050_2_A_Walking_trial_6_emg.csv\n",
      "57/174: normal/P351_M050_2_B_FoG_trial_1_emg.csv\n",
      "58/174: normal/P351_M050_2_B_FoG_trial_2_emg.csv\n",
      "59/174: normal/P351_M050_2_B_FoG_trial_3_emg.csv\n",
      "60/174: normal/P351_M050_2_B_Walking_trial_2_emg.csv\n",
      "61/174: normal/P351_M050_2_B_Walking_trial_4_emg.csv\n",
      "62/174: normal/P351_M050_2_B_Walking_trial_6_emg.csv\n",
      "63/174: normal/P351_M050_A_FoG_trial_1_emg.csv\n",
      "64/174: normal/P351_M050_A_FoG_trial_2_emg.csv\n",
      "65/174: normal/P351_M050_A_FoG_trial_3_emg.csv\n",
      "66/174: normal/P351_M050_A_Walking_trial_2_emg.csv\n",
      "67/174: normal/P351_M050_A_Walking_trial_4_emg.csv\n",
      "68/174: normal/P351_M050_B_FoG_trial_1_emg.csv\n",
      "69/174: normal/P351_M050_B_FoG_trial_2_emg.csv\n",
      "70/174: normal/P351_M050_B_FoG_trial_3_emg.csv\n",
      "71/174: normal/P351_M050_B_Walking_trial_2_emg.csv\n",
      "72/174: normal/P351_M050_B_Walking_trial_4_emg.csv\n",
      "73/174: normal/P351_M050_B_Walking_trial_6_emg.csv\n",
      "74/174: normal/P351_Msham_A_FoG_trial_1_emg.csv\n",
      "75/174: normal/P351_Msham_A_FoG_trial_2_emg.csv\n",
      "76/174: normal/P351_Msham_A_FoG_trial_3_emg.csv\n",
      "77/174: normal/P351_Msham_A_Walking_trial_2_emg.csv\n",
      "78/174: normal/P351_Msham_A_Walking_trial_4_emg.csv\n",
      "79/174: normal/P351_Msham_A_Walking_trial_6_emg.csv\n",
      "80/174: normal/P351_Msham_B_FoG_trial_1_emg.csv\n",
      "81/174: normal/P351_Msham_B_FoG_trial_2_emg.csv\n",
      "82/174: normal/P351_Msham_B_FoG_trial_3_emg.csv\n",
      "83/174: normal/P351_Msham_B_Walking_trial_2_emg.csv\n",
      "84/174: normal/P351_Msham_B_Walking_trial_4_emg.csv\n",
      "85/174: normal/P351_Msham_B_Walking_trial_6_emg.csv\n",
      "86/174: normal/P379_M050_A_Walking_trial_2_emg.csv\n",
      "87/174: normal/P379_M050_A_Walking_trial_3_emg.csv\n",
      "88/174: normal/P379_M050_B_Walking_trial_2_emg.csv\n",
      "89/174: normal/P379_Msham_B_Walking_trial_6_emg.csv\n",
      "90/174: normal/P533_M050_A_Walking_trial_1_emg.csv\n",
      "91/174: normal/P533_M050_A_Walking_trial_2_emg.csv\n",
      "92/174: normal/P533_M050_B_Walking_trial_2_emg.csv\n",
      "93/174: normal/P533_M050_B_Walking_trial_3_emg.csv\n",
      "94/174: normal/P533_M100_A_Walking_trial_2_emg.csv\n",
      "95/174: normal/P533_M100_B_Walking_trial_4_emg.csv\n",
      "96/174: normal/P551_M50_B_Walking_trial_6_emg.csv\n",
      "97/174: normal/P623_M050_2_A_Walking_trial_2_emg.csv\n",
      "98/174: normal/P623_M050_2_A_Walking_trial_4_emg.csv\n",
      "skip\n",
      "100/174: normal/P623_M050_2_B_Walking_trial_2_emg.csv\n",
      "101/174: normal/P623_M050_2_B_Walking_trial_6_emg.csv\n",
      "102/174: normal/P623_M050_A_Walking_trial_4_emg.csv\n",
      "103/174: normal/P623_M100_A_Walking_trial_4_emg.csv\n",
      "104/174: normal/P623_M100_B_Walking_trial_4_emg.csv\n",
      "105/174: normal/P623_Msham_A_Walking_trial_4_emg.csv\n",
      "106/174: normal/P623_Msham_A_Walking_trial_6_emg.csv\n",
      "107/174: normal/P623_Msham_B_Walking_trial_2_emg.csv\n",
      "108/174: normal/P623_Msham_B_Walking_trial_4_emg.csv\n",
      "109/174: normal/P645_M050_A_Walking_trial_2_emg.csv\n",
      "110/174: normal/P645_M050_A_Walking_trial_3_emg.csv\n",
      "111/174: normal/P645_M050_B_Walking_trial_2_emg.csv\n",
      "112/174: normal/P645_M050_B_Walking_trial_3_emg.csv\n",
      "113/174: normal/P812_M050_2_A_FoG_trial_1_emg.csv\n",
      "114/174: normal/P812_M050_2_A_FoG_trial_3_emg.csv\n",
      "115/174: normal/P812_M050_2_A_Walking_trial_2_emg.csv\n",
      "116/174: normal/P812_M050_2_A_Walking_trial_3_emg.csv\n",
      "117/174: normal/P812_M050_2_B_Walking_1_trial_4_emg.csv\n",
      "118/174: normal/P812_M050_A_FoG_trial_1_emg.csv\n",
      "119/174: normal/P812_M050_A_FoG_trial_2_emg.csv\n",
      "120/174: normal/P812_M050_A_FoG_trial_3_emg.csv\n",
      "121/174: normal/P812_M050_A_Walking_trial_1_emg.csv\n",
      "122/174: normal/P812_M050_A_Walking_trial_2_emg.csv\n",
      "123/174: normal/P812_M050_B_FoG_trial_1_emg.csv\n",
      "124/174: normal/P812_M050_B_FoG_trial_2_emg.csv\n",
      "125/174: normal/P812_M050_B_FoG_trial_3_emg.csv\n",
      "126/174: normal/P812_M050_B_Walking_trial_1_emg.csv\n",
      "127/174: normal/P812_M050_B_Walking_trial_2_emg.csv\n",
      "128/174: normal/P812_M100_A_FoG_trial_1_emg.csv\n",
      "129/174: normal/P812_M100_A_Walking_trial_3_emg.csv\n",
      "130/174: normal/P812_M100_B_FoG_trial_1_emg.csv\n",
      "131/174: normal/P812_M100_B_FoG_trial_3_emg.csv\n",
      "132/174: normal/P812_M100_B_Walking2_trial_1_emg.csv\n",
      "133/174: normal/P812_M100_B_Walking2_trial_2_emg.csv\n",
      "134/174: normal/P876_M100_B_FoG_trial_1_emg.csv\n",
      "135/174: normal/P876_M100_B_FoG_trial_2_emg.csv\n",
      "136/174: normal/P876_M100_B_FoG_trial_3_emg.csv\n",
      "137/174: normal/P876_M100_B_Walking_trial_4_emg.csv\n",
      "138/174: normal/P876_M100_B_Walking_trial_6_emg.csv\n",
      "139/174: normal/P940_M050_2_A_FoG_trial_3_emg.csv\n",
      "140/174: normal/P940_M050_2_A_FoG_trial_4_emg.csv\n",
      "141/174: normal/P940_M050_2_A_Walking_trial_2_emg.csv\n",
      "142/174: normal/P940_M050_2_B_FoG_trial_1_emg.csv\n",
      "143/174: normal/P940_M050_2_B_Walking_trial_2_emg.csv\n",
      "144/174: normal/P940_M050_2_B_Walking_trial_4_emg.csv\n",
      "145/174: normal/P940_M050_2_B_Walking_trial_6_emg.csv\n",
      "146/174: normal/P940_M050_A_FoG_trial_2_emg.csv\n",
      "147/174: normal/P940_M050_A_FoG_trial_3_emg.csv\n",
      "148/174: normal/P940_M050_A_Walking_trial_2_emg.csv\n",
      "149/174: normal/P940_M050_A_Walking_trial_4_emg.csv\n",
      "150/174: normal/P940_M050_A_Walking_trial_6_emg.csv\n",
      "151/174: normal/P940_M050_B_FoG_trial_1_emg.csv\n",
      "152/174: normal/P940_M050_B_FoG_trial_2_emg.csv\n",
      "153/174: normal/P940_M050_B_FoG_trial_3_emg.csv\n",
      "154/174: normal/P940_M050_B_Walking_trial_2_emg.csv\n",
      "155/174: normal/P940_M050_B_Walking_trial_4_emg.csv\n",
      "156/174: normal/P940_M050_B_Walking_trial_6_emg.csv\n",
      "157/174: normal/P940_M100_A_FoG_trial_1_emg.csv\n",
      "158/174: normal/P940_M100_A_FoG_trial_2_emg.csv\n",
      "159/174: normal/P940_M100_A_FoG_trial_3_emg.csv\n",
      "160/174: normal/P940_M100_A_Walking_trial_2_emg.csv\n",
      "161/174: normal/P940_M100_A_Walking_trial_4_emg.csv\n",
      "162/174: normal/P940_M100_A_Walking_trial_6_emg.csv\n",
      "163/174: normal/P940_M100_B_FoG_trial_2_emg.csv\n",
      "164/174: normal/P940_M100_B_FoG_trial_3_emg.csv\n",
      "165/174: normal/P940_M100_B_Walking_2_trial_2_emg.csv\n",
      "166/174: normal/P940_M100_B_Walking_2_trial_6_emg.csv\n",
      "167/174: normal/P940_MSham_A_FoG_trial_1_emg.csv\n",
      "168/174: normal/P940_MSham_A_FoG_trial_3_emg.csv\n",
      "169/174: normal/P940_MSham_A_Walking_trial_2_emg.csv\n",
      "170/174: normal/P940_MSham_A_Walking_trial_4_emg.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/174: normal/P940_MSham_A_Walking_trial_6_emg.csv\n",
      "172/174: normal/P940_MSham_B_Walking_trial_2_emg.csv\n",
      "173/174: normal/P940_MSham_B_Walking_trial_4_emg.csv\n",
      "174/174: normal/P940_MSham_B_Walking_trial_6_emg.csv\n"
     ]
    }
   ],
   "source": [
    "# Load data from files\n",
    "data.load_data(files)\n",
    "\n",
    "# Rectify the data to get envelope\n",
    "data.rectify_data()\n",
    "\n",
    "X_train,Y_train,F1 = data.train_set\n",
    "X_valid,Y_valid,F2 = data.valid_set\n",
    "X_test, Y_test, F3 = data.test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Override base class of SimpleMode for RNN_CNN\n",
    "class RNN_CNN_Model(NNModel):\n",
    "    \n",
    "    def build(self,config):\n",
    "        self.input_shape = [config.WINDOW_SIZE, len(config.CHANNELS)]\n",
    "        kernel_size=3\n",
    "        reg=keras.regularizers.l2(1e-4)\n",
    "        drop_rate = 0.\n",
    "        kernel_initializer = 'glorot_normal'\n",
    "        mo = 0.8\n",
    "        st = 1\n",
    "        axis = 2\n",
    "        model = KM.Sequential()\n",
    "        model.add(KL.InputLayer(input_shape=self.input_shape))\n",
    "\n",
    "        model.add(KL.Bidirectional(KL.LSTM(32,return_sequences=True,\n",
    "                                                   recurrent_regularizer=reg)))\n",
    "\n",
    "        model.add(KL.Conv1D(filters=32, kernel_size=kernel_size,strides=st,\n",
    "                                padding='same',\n",
    "                                kernel_regularizer=reg,\n",
    "                               ))\n",
    "        model.add(KL.BatchNormalization(momentum=mo))\n",
    "\n",
    "        model.add(KL.LeakyReLU(0.1))\n",
    "        model.add(KL.MaxPooling1D(2))\n",
    "        model.add(KL.Dropout(drop_rate))\n",
    "        model.add(KL.Conv1D(filters=16, kernel_size=kernel_size,strides=st,\n",
    "                                padding='same',\n",
    "                                kernel_regularizer=reg,\n",
    "                               ))\n",
    "        model.add(KL.BatchNormalization(momentum=mo))\n",
    "\n",
    "        model.add(KL.LeakyReLU(0.1))\n",
    "        model.add(KL.MaxPooling1D(2))\n",
    "        model.add(KL.Dropout(drop_rate))\n",
    "        model.add(KL.Conv1D(filters=8, kernel_size=kernel_size,strides=st,\n",
    "                                padding='same',\n",
    "                                kernel_regularizer=reg,\n",
    "                               ))\n",
    "        model.add(KL.BatchNormalization(momentum=mo))\n",
    "\n",
    "        model.add(KL.LeakyReLU(0.1))\n",
    "        model.add(KL.MaxPooling1D(2))\n",
    "        model.add(KL.Dropout(drop_rate))\n",
    "        model.add(KL.Conv1D(filters=4, kernel_size=kernel_size,strides=st,\n",
    "                                padding='same',\n",
    "                                kernel_regularizer=reg,\n",
    "                               ))\n",
    "        model.add(KL.BatchNormalization(momentum=mo))\n",
    "\n",
    "        model.add(KL.LeakyReLU(0.1))\n",
    "        model.add(KL.MaxPooling1D(2))\n",
    "\n",
    "        model.add(KL.GlobalAveragePooling1D())\n",
    "        model.add(KL.Dropout(drop_rate))\n",
    "        model.add(KL.Dense(config.NUM_CLASSES,activation='softmax',kernel_regularizer=reg))\n",
    "        \n",
    "        model.summary()\n",
    "        if config.COST_SENSITIVE:\n",
    "            self.cost_matrix = config.COST_MATRIX\n",
    "            model.compile(loss=self.sparse_cost_sensitive_loss, optimizer=\"adam\", metrics=['accuracy'])\n",
    "            print('Using cost sensitive with cost matrix:\\n',np.array(self.cost_matrix))\n",
    "        else:\n",
    "            model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "            if config.CLASS_WEIGHTS != None:\n",
    "                print('Using categorical crossentropy with class weights:\\n',config.CLASS_WEIGHTS)\n",
    "            else:\n",
    "                print('Using categorical crossentropy without class weights.')\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def sparse_cost_sensitive_loss (self,y_true,y_pred):\n",
    "        cost_matrix = self.cost_matrix\n",
    "        batch_cost_matrix = tf.nn.embedding_lookup(cost_matrix, tf.argmax(y_true,axis=1))\n",
    "        eps = 1e-6\n",
    "        probability = tf.clip_by_value(y_pred, eps, 1-eps)\n",
    "        cost_values = tf.math.log(1-probability)*batch_cost_matrix\n",
    "        loss = tf.reduce_mean(-tf.reduce_sum(cost_values, axis=1))\n",
    "        return loss\n",
    "    \n",
    "    def model_metrics(self,data,label):\n",
    "        pred = self.keras_model.predict(data)\n",
    "        acc = metrics.accuracy_score(np.argmax(label,axis=1),np.argmax(pred,axis=1))\n",
    "        cm = metrics.confusion_matrix(np.argmax(label,axis=1),np.argmax(pred,axis=1))\n",
    "        f1 = metrics.f1_score(np.argmax(label,axis=1),np.argmax(pred,axis=1),average='macro')\n",
    "        return acc,cm,f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data split and processing for model\n",
    "class_id = [1,2,6]\n",
    "binary = False\n",
    "x_train,y_train,x_valid,y_valid,x_test,y_test,oh = utils.data_split_oh((X_train,X_valid,X_test),\n",
    "                                                                    (Y_train,Y_valid,Y_test),\n",
    "                                                                    class_id,\n",
    "                                                                    binary,\n",
    "                                                                    random_state = 555)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional (Bidirectional (None, 1024, 64)          10496     \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 1024, 32)          6176      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 1024, 32)          128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 1024, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 512, 32)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 512, 16)           1552      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512, 16)           64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 512, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 256, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 256, 8)            392       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256, 8)            32        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 256, 8)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 128, 8)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128, 8)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 128, 4)            100       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128, 4)            16        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 128, 4)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 64, 4)             0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 15        \n",
      "=================================================================\n",
      "Total params: 18,971\n",
      "Trainable params: 18,851\n",
      "Non-trainable params: 120\n",
      "_________________________________________________________________\n",
      "Using categorical crossentropy without class weights.\n"
     ]
    }
   ],
   "source": [
    "config.COST_MATRIX = tf.constant([[0,1.],\n",
    "              [10,0]])\n",
    "\n",
    "if binary:\n",
    "    config.COST_SENSITIVE = True\n",
    "    config.NUM_CLASSES = 2\n",
    "else:\n",
    "    config.COST_SENSITIVE = False\n",
    "    config.NUM_CLASSES = len(class_id)\n",
    "\n",
    "rcnn_model = RNN_CNN_Model('RNN_CNN',config,'./model/RNN_CNN/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 0.\n",
      "\n",
      "Checkpoint Path: ./model/RNN_CNN/rnn_cnn20211104T2142\\RNN_CNN_rnn_cnn_{epoch:04d}.h5\n",
      "Epoch 1/500\n",
      "14/14 [==============================] - 15s 654ms/step - loss: 1.0277 - accuracy: 0.5094 - val_loss: 0.9846 - val_accuracy: 0.6507\n",
      "Epoch 2/500\n",
      "14/14 [==============================] - 7s 527ms/step - loss: 0.9282 - accuracy: 0.5661 - val_loss: 0.8506 - val_accuracy: 0.7055\n",
      "Epoch 3/500\n",
      "14/14 [==============================] - 7s 504ms/step - loss: 0.8644 - accuracy: 0.6495 - val_loss: 0.7682 - val_accuracy: 0.7123\n",
      "Epoch 4/500\n",
      "14/14 [==============================] - 7s 540ms/step - loss: 0.8238 - accuracy: 0.6793 - val_loss: 0.7591 - val_accuracy: 0.7740\n",
      "Epoch 5/500\n",
      "14/14 [==============================] - 7s 509ms/step - loss: 0.7646 - accuracy: 0.7631 - val_loss: 0.6865 - val_accuracy: 0.7603\n",
      "Epoch 6/500\n",
      "14/14 [==============================] - 7s 503ms/step - loss: 0.7543 - accuracy: 0.7150 - val_loss: 0.6811 - val_accuracy: 0.7671\n",
      "Epoch 7/500\n",
      "14/14 [==============================] - 7s 504ms/step - loss: 0.7260 - accuracy: 0.7243 - val_loss: 0.6984 - val_accuracy: 0.7945\n",
      "Epoch 8/500\n",
      "14/14 [==============================] - 7s 536ms/step - loss: 0.7012 - accuracy: 0.7513 - val_loss: 0.6424 - val_accuracy: 0.7808\n",
      "Epoch 9/500\n",
      "14/14 [==============================] - 8s 555ms/step - loss: 0.6847 - accuracy: 0.7420 - val_loss: 0.6220 - val_accuracy: 0.8082\n",
      "Epoch 10/500\n",
      "14/14 [==============================] - 9s 613ms/step - loss: 0.6665 - accuracy: 0.7769 - val_loss: 0.5912 - val_accuracy: 0.7329\n",
      "Epoch 11/500\n",
      "14/14 [==============================] - 10s 713ms/step - loss: 0.6742 - accuracy: 0.7217 - val_loss: 0.6405 - val_accuracy: 0.8425\n",
      "Epoch 12/500\n",
      "14/14 [==============================] - 10s 699ms/step - loss: 0.6594 - accuracy: 0.7459 - val_loss: 0.5942 - val_accuracy: 0.8288\n",
      "Epoch 13/500\n",
      "14/14 [==============================] - 9s 664ms/step - loss: 0.6405 - accuracy: 0.7541 - val_loss: 0.5651 - val_accuracy: 0.7740\n",
      "Epoch 14/500\n",
      "14/14 [==============================] - 9s 637ms/step - loss: 0.6289 - accuracy: 0.7575 - val_loss: 0.5580 - val_accuracy: 0.7740\n",
      "Epoch 15/500\n",
      "14/14 [==============================] - 11s 742ms/step - loss: 0.6095 - accuracy: 0.7510 - val_loss: 0.5918 - val_accuracy: 0.8151\n",
      "Epoch 16/500\n",
      "14/14 [==============================] - 8s 588ms/step - loss: 0.5943 - accuracy: 0.7700 - val_loss: 0.5227 - val_accuracy: 0.8014\n",
      "Epoch 17/500\n",
      "14/14 [==============================] - 10s 729ms/step - loss: 0.5884 - accuracy: 0.7767 - val_loss: 0.5291 - val_accuracy: 0.8425\n",
      "Epoch 18/500\n",
      "14/14 [==============================] - 10s 702ms/step - loss: 0.5875 - accuracy: 0.7629 - val_loss: 0.5269 - val_accuracy: 0.8151\n",
      "Epoch 19/500\n",
      "14/14 [==============================] - 10s 677ms/step - loss: 0.5654 - accuracy: 0.7796 - val_loss: 0.5139 - val_accuracy: 0.8014\n",
      "Epoch 20/500\n",
      "14/14 [==============================] - 9s 662ms/step - loss: 0.5556 - accuracy: 0.7935 - val_loss: 0.5258 - val_accuracy: 0.8425\n",
      "Epoch 21/500\n",
      "14/14 [==============================] - 10s 735ms/step - loss: 0.5568 - accuracy: 0.7686 - val_loss: 0.5137 - val_accuracy: 0.7740\n",
      "Epoch 22/500\n",
      "14/14 [==============================] - 9s 683ms/step - loss: 0.5429 - accuracy: 0.7584 - val_loss: 0.4817 - val_accuracy: 0.8219\n",
      "Epoch 23/500\n",
      "14/14 [==============================] - 10s 695ms/step - loss: 0.5455 - accuracy: 0.7705 - val_loss: 0.4912 - val_accuracy: 0.8562\n",
      "Epoch 24/500\n",
      "14/14 [==============================] - 9s 654ms/step - loss: 0.5148 - accuracy: 0.8209 - val_loss: 0.4883 - val_accuracy: 0.8356\n",
      "Epoch 25/500\n",
      "14/14 [==============================] - 9s 641ms/step - loss: 0.5090 - accuracy: 0.7891 - val_loss: 0.5326 - val_accuracy: 0.8562\n",
      "Epoch 26/500\n",
      "14/14 [==============================] - 9s 631ms/step - loss: 0.5008 - accuracy: 0.8237 - val_loss: 0.4641 - val_accuracy: 0.8493\n",
      "Epoch 27/500\n",
      "14/14 [==============================] - 10s 693ms/step - loss: 0.4955 - accuracy: 0.8273 - val_loss: 0.4823 - val_accuracy: 0.8288\n",
      "Epoch 28/500\n",
      "14/14 [==============================] - 9s 634ms/step - loss: 0.4989 - accuracy: 0.8100 - val_loss: 0.4600 - val_accuracy: 0.8630\n",
      "Epoch 29/500\n",
      "14/14 [==============================] - 10s 713ms/step - loss: 0.4578 - accuracy: 0.8753 - val_loss: 0.4744 - val_accuracy: 0.8493\n",
      "Epoch 30/500\n",
      "14/14 [==============================] - 10s 724ms/step - loss: 0.4643 - accuracy: 0.8709 - val_loss: 0.4532 - val_accuracy: 0.8219\n",
      "Epoch 31/500\n",
      "14/14 [==============================] - 9s 671ms/step - loss: 0.4449 - accuracy: 0.8886 - val_loss: 0.4473 - val_accuracy: 0.8493\n",
      "Epoch 32/500\n",
      "14/14 [==============================] - 9s 677ms/step - loss: 0.4520 - accuracy: 0.8796 - val_loss: 0.4755 - val_accuracy: 0.8562\n",
      "Epoch 33/500\n",
      "14/14 [==============================] - 14s 1s/step - loss: 0.4617 - accuracy: 0.8773 - val_loss: 0.4511 - val_accuracy: 0.8562\n",
      "Epoch 34/500\n",
      "14/14 [==============================] - 10s 737ms/step - loss: 0.4465 - accuracy: 0.8837 - val_loss: 0.4400 - val_accuracy: 0.8699\n",
      "Epoch 35/500\n",
      "14/14 [==============================] - 9s 656ms/step - loss: 0.4017 - accuracy: 0.9001 - val_loss: 0.4392 - val_accuracy: 0.8562\n",
      "Epoch 36/500\n",
      "14/14 [==============================] - 9s 681ms/step - loss: 0.4201 - accuracy: 0.9046 - val_loss: 0.4378 - val_accuracy: 0.8562\n",
      "Epoch 37/500\n",
      "14/14 [==============================] - 9s 646ms/step - loss: 0.4333 - accuracy: 0.8891 - val_loss: 0.4695 - val_accuracy: 0.8836\n",
      "Epoch 38/500\n",
      "14/14 [==============================] - 8s 603ms/step - loss: 0.3942 - accuracy: 0.9213 - val_loss: 0.4336 - val_accuracy: 0.8767\n",
      "Epoch 39/500\n",
      "14/14 [==============================] - 10s 682ms/step - loss: 0.3970 - accuracy: 0.9213 - val_loss: 0.4255 - val_accuracy: 0.8630\n",
      "Epoch 40/500\n",
      "14/14 [==============================] - 9s 666ms/step - loss: 0.3744 - accuracy: 0.9381 - val_loss: 0.4312 - val_accuracy: 0.8767\n",
      "Epoch 41/500\n",
      "14/14 [==============================] - 9s 642ms/step - loss: 0.3597 - accuracy: 0.9371 - val_loss: 0.4215 - val_accuracy: 0.8767\n",
      "Epoch 42/500\n",
      "14/14 [==============================] - 10s 703ms/step - loss: 0.3705 - accuracy: 0.9548 - val_loss: 0.4407 - val_accuracy: 0.8425\n",
      "Epoch 43/500\n",
      "14/14 [==============================] - 10s 698ms/step - loss: 0.3884 - accuracy: 0.9134 - val_loss: 0.4552 - val_accuracy: 0.8767\n",
      "Epoch 44/500\n",
      "14/14 [==============================] - 10s 714ms/step - loss: 0.3592 - accuracy: 0.9405 - val_loss: 0.4163 - val_accuracy: 0.8767\n",
      "Epoch 45/500\n",
      "14/14 [==============================] - 9s 638ms/step - loss: 0.3516 - accuracy: 0.9404 - val_loss: 0.4037 - val_accuracy: 0.8630\n",
      "Epoch 46/500\n",
      "14/14 [==============================] - 9s 616ms/step - loss: 0.3245 - accuracy: 0.9651 - val_loss: 0.3998 - val_accuracy: 0.8562\n",
      "Epoch 47/500\n",
      "14/14 [==============================] - 9s 633ms/step - loss: 0.3281 - accuracy: 0.9430 - val_loss: 0.3938 - val_accuracy: 0.8699\n",
      "Epoch 48/500\n",
      "14/14 [==============================] - 9s 671ms/step - loss: 0.3255 - accuracy: 0.9437 - val_loss: 0.4126 - val_accuracy: 0.8630\n",
      "Epoch 49/500\n",
      "14/14 [==============================] - 9s 654ms/step - loss: 0.3034 - accuracy: 0.9493 - val_loss: 0.3923 - val_accuracy: 0.8836\n",
      "Epoch 50/500\n",
      "14/14 [==============================] - 8s 604ms/step - loss: 0.3011 - accuracy: 0.9523 - val_loss: 0.3803 - val_accuracy: 0.8836\n",
      "Epoch 51/500\n",
      "14/14 [==============================] - 10s 717ms/step - loss: 0.2847 - accuracy: 0.9725 - val_loss: 0.3868 - val_accuracy: 0.8699\n",
      "Epoch 52/500\n",
      "14/14 [==============================] - 9s 671ms/step - loss: 0.2837 - accuracy: 0.9617 - val_loss: 0.4346 - val_accuracy: 0.8356\n",
      "Epoch 53/500\n",
      "14/14 [==============================] - 8s 577ms/step - loss: 0.2878 - accuracy: 0.9473 - val_loss: 0.4020 - val_accuracy: 0.8767\n",
      "Epoch 54/500\n",
      "14/14 [==============================] - 8s 574ms/step - loss: 0.2907 - accuracy: 0.9587 - val_loss: 0.3910 - val_accuracy: 0.8630\n",
      "Epoch 55/500\n",
      "14/14 [==============================] - 8s 588ms/step - loss: 0.3054 - accuracy: 0.9327 - val_loss: 0.3601 - val_accuracy: 0.8767\n",
      "Epoch 56/500\n",
      "14/14 [==============================] - 8s 575ms/step - loss: 0.2501 - accuracy: 0.9677 - val_loss: 0.3742 - val_accuracy: 0.8767\n",
      "Epoch 57/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 8s 581ms/step - loss: 0.2424 - accuracy: 0.9851 - val_loss: 0.3707 - val_accuracy: 0.8630\n",
      "Epoch 58/500\n",
      "14/14 [==============================] - 8s 589ms/step - loss: 0.2205 - accuracy: 0.9818 - val_loss: 0.3724 - val_accuracy: 0.8767\n",
      "Epoch 59/500\n",
      "14/14 [==============================] - 9s 622ms/step - loss: 0.2185 - accuracy: 0.9843 - val_loss: 0.3815 - val_accuracy: 0.8836\n",
      "Epoch 60/500\n",
      "14/14 [==============================] - 8s 602ms/step - loss: 0.2079 - accuracy: 0.9824 - val_loss: 0.3757 - val_accuracy: 0.8699\n",
      "Epoch 61/500\n",
      "14/14 [==============================] - 7s 535ms/step - loss: 0.2299 - accuracy: 0.9786 - val_loss: 0.3563 - val_accuracy: 0.8973\n",
      "Epoch 62/500\n",
      "14/14 [==============================] - 9s 614ms/step - loss: 0.2056 - accuracy: 0.9785 - val_loss: 0.4124 - val_accuracy: 0.8356\n",
      "Epoch 63/500\n",
      "14/14 [==============================] - 8s 546ms/step - loss: 0.2059 - accuracy: 0.9852 - val_loss: 0.4113 - val_accuracy: 0.8836\n",
      "Epoch 64/500\n",
      "14/14 [==============================] - 8s 584ms/step - loss: 0.1974 - accuracy: 0.9787 - val_loss: 0.3627 - val_accuracy: 0.8904\n",
      "Epoch 65/500\n",
      "14/14 [==============================] - 9s 667ms/step - loss: 0.2139 - accuracy: 0.9692 - val_loss: 0.3462 - val_accuracy: 0.8973\n",
      "Epoch 66/500\n",
      "14/14 [==============================] - 7s 527ms/step - loss: 0.1948 - accuracy: 0.9855 - val_loss: 0.3447 - val_accuracy: 0.8767\n",
      "Epoch 67/500\n",
      "14/14 [==============================] - 8s 607ms/step - loss: 0.1854 - accuracy: 0.9839 - val_loss: 0.3472 - val_accuracy: 0.8699\n",
      "Epoch 68/500\n",
      "14/14 [==============================] - 9s 684ms/step - loss: 0.1922 - accuracy: 0.9852 - val_loss: 0.3591 - val_accuracy: 0.8904\n",
      "Epoch 69/500\n",
      "14/14 [==============================] - 8s 599ms/step - loss: 0.2026 - accuracy: 0.9836 - val_loss: 0.4121 - val_accuracy: 0.8630\n",
      "Epoch 70/500\n",
      "14/14 [==============================] - 8s 601ms/step - loss: 0.2277 - accuracy: 0.9549 - val_loss: 0.9619 - val_accuracy: 0.7397\n",
      "Epoch 71/500\n",
      "14/14 [==============================] - 9s 625ms/step - loss: 0.2687 - accuracy: 0.9263 - val_loss: 0.4402 - val_accuracy: 0.8151\n",
      "Epoch 72/500\n",
      "14/14 [==============================] - 10s 696ms/step - loss: 0.1981 - accuracy: 0.9666 - val_loss: 0.4173 - val_accuracy: 0.8630\n",
      "Epoch 73/500\n",
      "14/14 [==============================] - 8s 584ms/step - loss: 0.2089 - accuracy: 0.9685 - val_loss: 0.4318 - val_accuracy: 0.8562\n",
      "Epoch 74/500\n",
      "14/14 [==============================] - 8s 606ms/step - loss: 0.1923 - accuracy: 0.9715 - val_loss: 0.3930 - val_accuracy: 0.8630\n",
      "Epoch 75/500\n",
      "14/14 [==============================] - 9s 640ms/step - loss: 0.1740 - accuracy: 0.9854 - val_loss: 0.3646 - val_accuracy: 0.8767\n",
      "Epoch 76/500\n",
      "14/14 [==============================] - 10s 758ms/step - loss: 0.1481 - accuracy: 0.9972 - val_loss: 0.3687 - val_accuracy: 0.8904\n",
      "Epoch 77/500\n",
      "14/14 [==============================] - 10s 696ms/step - loss: 0.1446 - accuracy: 0.9928 - val_loss: 0.3688 - val_accuracy: 0.8767\n",
      "Epoch 78/500\n",
      "14/14 [==============================] - 9s 653ms/step - loss: 0.1284 - accuracy: 0.9956 - val_loss: 0.3696 - val_accuracy: 0.8699\n",
      "Epoch 79/500\n",
      "14/14 [==============================] - 9s 617ms/step - loss: 0.1282 - accuracy: 0.9978 - val_loss: 0.3510 - val_accuracy: 0.8767\n",
      "Epoch 80/500\n",
      "14/14 [==============================] - 9s 660ms/step - loss: 0.1305 - accuracy: 0.9884 - val_loss: 0.3683 - val_accuracy: 0.8630\n",
      "Epoch 81/500\n",
      "14/14 [==============================] - 8s 577ms/step - loss: 0.1217 - accuracy: 0.9948 - val_loss: 0.3913 - val_accuracy: 0.8836\n",
      "Epoch 82/500\n",
      "14/14 [==============================] - 8s 599ms/step - loss: 0.1269 - accuracy: 0.9833 - val_loss: 0.3274 - val_accuracy: 0.8973\n",
      "Epoch 83/500\n",
      "14/14 [==============================] - 9s 645ms/step - loss: 0.1580 - accuracy: 0.9792 - val_loss: 0.3766 - val_accuracy: 0.8630\n",
      "Epoch 84/500\n",
      "14/14 [==============================] - 8s 589ms/step - loss: 0.1291 - accuracy: 0.9893 - val_loss: 0.3998 - val_accuracy: 0.8493\n",
      "Epoch 85/500\n",
      "14/14 [==============================] - 8s 561ms/step - loss: 0.1371 - accuracy: 0.9801 - val_loss: 0.4458 - val_accuracy: 0.8630\n",
      "Epoch 86/500\n",
      "14/14 [==============================] - 9s 624ms/step - loss: 0.1653 - accuracy: 0.9671 - val_loss: 0.3696 - val_accuracy: 0.8767\n",
      "Epoch 87/500\n",
      "14/14 [==============================] - 9s 627ms/step - loss: 0.1593 - accuracy: 0.9777 - val_loss: 0.4200 - val_accuracy: 0.8699\n",
      "Epoch 88/500\n",
      "14/14 [==============================] - 9s 617ms/step - loss: 0.1309 - accuracy: 0.9873 - val_loss: 0.3947 - val_accuracy: 0.8767\n",
      "Epoch 89/500\n",
      "14/14 [==============================] - 10s 693ms/step - loss: 0.1401 - accuracy: 0.9871 - val_loss: 0.3868 - val_accuracy: 0.8767\n",
      "Epoch 90/500\n",
      "14/14 [==============================] - 8s 565ms/step - loss: 0.1024 - accuracy: 0.9982 - val_loss: 0.3592 - val_accuracy: 0.8836\n",
      "Epoch 91/500\n",
      "14/14 [==============================] - 9s 628ms/step - loss: 0.0875 - accuracy: 0.9924 - val_loss: 0.3711 - val_accuracy: 0.8767\n",
      "Epoch 92/500\n",
      "14/14 [==============================] - 8s 593ms/step - loss: 0.0814 - accuracy: 0.9982 - val_loss: 0.3601 - val_accuracy: 0.8562\n",
      "Epoch 93/500\n",
      "14/14 [==============================] - 9s 642ms/step - loss: 0.0790 - accuracy: 0.9962 - val_loss: 0.3577 - val_accuracy: 0.8904\n",
      "Epoch 94/500\n",
      "14/14 [==============================] - 9s 620ms/step - loss: 0.0779 - accuracy: 0.9987 - val_loss: 0.3593 - val_accuracy: 0.8836\n",
      "Epoch 95/500\n",
      "14/14 [==============================] - 8s 596ms/step - loss: 0.0842 - accuracy: 0.9941 - val_loss: 0.3650 - val_accuracy: 0.8699\n",
      "Epoch 96/500\n",
      "14/14 [==============================] - 8s 597ms/step - loss: 0.0677 - accuracy: 0.9990 - val_loss: 0.3805 - val_accuracy: 0.8767\n",
      "Epoch 97/500\n",
      "14/14 [==============================] - 8s 593ms/step - loss: 0.0888 - accuracy: 0.9949 - val_loss: 0.4279 - val_accuracy: 0.8699\n",
      "Epoch 98/500\n",
      "14/14 [==============================] - 7s 525ms/step - loss: 0.0843 - accuracy: 0.9884 - val_loss: 0.4079 - val_accuracy: 0.8767\n",
      "Epoch 99/500\n",
      "14/14 [==============================] - 7s 534ms/step - loss: 0.0971 - accuracy: 0.9971 - val_loss: 0.3807 - val_accuracy: 0.8836\n",
      "Epoch 100/500\n",
      "14/14 [==============================] - 7s 516ms/step - loss: 0.0757 - accuracy: 0.9978 - val_loss: 0.3761 - val_accuracy: 0.8630\n",
      "Epoch 101/500\n",
      "14/14 [==============================] - 8s 561ms/step - loss: 0.0824 - accuracy: 0.9994 - val_loss: 0.3466 - val_accuracy: 0.8904\n",
      "Epoch 102/500\n",
      "14/14 [==============================] - 9s 633ms/step - loss: 0.0699 - accuracy: 0.9991 - val_loss: 0.3501 - val_accuracy: 0.8904\n"
     ]
    }
   ],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(patience = 20,\n",
    "                                             monitor = 'val_loss', \n",
    "                                             #baseline = 0.9,\n",
    "                                             restore_best_weights=True)\n",
    "rcnn_model.train((x_train,y_train),(x_valid,y_valid),config.EPOCHS,config.BATCH_SIZE,[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_train: 0.984018\n",
      "f1_train: 0.979078\n",
      "confusion_matrix:\n",
      " [[ 83   0   2]\n",
      " [  0 246   0]\n",
      " [  2   3 102]]\n",
      "acc_valid: 0.897260\n",
      "f1_valid: 0.810269\n",
      "confusion_matrix:\n",
      " [[ 9  6  4]\n",
      " [ 1 92  2]\n",
      " [ 1  1 30]]\n",
      "acc_test: 0.778523\n",
      "f1_test: 0.757871\n",
      "confusion_matrix:\n",
      " [[22 12  1]\n",
      " [ 6 47  0]\n",
      " [12  2 47]]\n"
     ]
    }
   ],
   "source": [
    "acc_train,cm_train,f1_train = rcnn_model.model_metrics(x_train,y_train)\n",
    "acc_valid,cm_valid,f1_valid = rcnn_model.model_metrics(x_valid,y_valid)\n",
    "acc_test,cm_test,f1_test = rcnn_model.model_metrics(x_test,y_test)\n",
    "print('acc_train: %f\\nf1_train: %f\\nconfusion_matrix:\\n'%(acc_train,f1_train),cm_train)\n",
    "print('acc_valid: %f\\nf1_valid: %f\\nconfusion_matrix:\\n'%(acc_valid,f1_valid),cm_valid)\n",
    "print('acc_test: %f\\nf1_test: %f\\nconfusion_matrix:\\n'%(acc_test,f1_test),cm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
