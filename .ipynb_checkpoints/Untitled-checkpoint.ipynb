{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import data_processing as dp\n",
    "from scipy import signal\n",
    "from scipy.stats import skew\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "import os\n",
    "import time\n",
    "import h5py\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file name of data with various Labels\n",
    "df = pd.read_csv('./useful_data_label.csv',index_col=0) \n",
    "# read file name of data with only label 0\n",
    "df2 = pd.read_csv('./unuseful_data_label.csv',index_col=0)\n",
    "# read some of the data with only label 0\n",
    "df3 = pd.read_csv('./data/file_name.txt',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/21: G04_FoG_trial_1_emg.csv\n",
      "2/21: G04_FoG_trial_2_emg.csv\n",
      "3/21: G06_FoG_trial_1_emg.csv\n",
      "4/21: G06_FoG_trial_2_emg.csv\n",
      "5/21: G06_FoG_trial_3_emg.csv\n",
      "6/21: G07_Freezing_Trial1_trial_1_emg.csv\n",
      "7/21: G08_FoG_1_trial_1_emg.csv\n",
      "8/21: G08_FoG_2_trial_1_emg.csv\n",
      "9/21: G11_FoG_trial_1_emg.csv\n",
      "10/21: G11_FoG_trial_2_emg.csv\n",
      "11/21: P379_M050_2_OFF_A_FoG_trial_1_emg.csv\n",
      "12/21: P379_M050_2_OFF_A_FoG_trial_2_emg.csv\n",
      "13/21: P379_M050_2_OFF_A_FoG_trial_3_emg.csv\n",
      "14/21: P379_M050_2_OFF_B_FoG_trial_1_emg.csv\n",
      "15/21: P379_M050_2_OFF_B_FoG_trial_2_emg.csv\n",
      "16/21: P379_M050_2_OFF_B_FoG_trial_3_emg.csv\n",
      "17/21: P551_M050_2_A_FoG_trial_1_emg.csv\n",
      "18/21: P551_M050_2_B_FoG_trial_1_emg.csv\n",
      "19/21: P551_M050_2_B_FoG_trial_2_emg.csv\n",
      "20/21: P812_M050_2_B_FoG_trial_1_emg.csv\n",
      "21/21: P812_M050_2_B_FoG_trial_2_emg.csv\n",
      "Duration: 61.547411\n"
     ]
    }
   ],
   "source": [
    "# read the data and labels of df2 or df3\n",
    "sc = StandardScaler()\n",
    "#sc = MinMaxScaler()\n",
    "ind = df2.iloc[1].isna()\n",
    "#files = np.concatenate([np.array(df.columns),np.array('正常/'+df2.columns[ind])])\n",
    "files = np.array(df.columns)\n",
    "N = len(files)\n",
    "#sc = StandardScaler(with_mean=False)\n",
    "width = 256\n",
    "stride = 32\n",
    "start = time.time()\n",
    "i = 0\n",
    "X = []\n",
    "Y = []\n",
    "X2 = []\n",
    "Y2 = []\n",
    "F = []\n",
    "F2 = []\n",
    "for file in files:\n",
    "    #if file in np.array(df3.loc[:,0]):\n",
    "    #    continue\n",
    "    i += 1\n",
    "    emg_data = pd.read_csv('./data/'+file)\n",
    "    #emg_data.iloc[:,3:] = \n",
    "    emg_data = emg_data.dropna().reset_index(drop=True)\n",
    "    #emg_data.iloc[:,3:]=normalize(emg_data.iloc[:,3:])\n",
    "    #emg_data.iloc[:,3:] = sc.fit_transform(emg_data.iloc[:,3:])\n",
    "    fn = 20\n",
    "    wn=2*fn/1000\n",
    "    fn1 = 350\n",
    "    wn1 = 2*fn1/1000\n",
    "    #b, a = signal.butter(4, [wn,wn1], 'bandpass')\n",
    "    b, a = signal.butter(4, [wn], 'highpass')\n",
    "    #for j in ['LEFT_TA','LEFT_TS','LEFT_BF','LEFT_RF','RIGHT_TA','RIGHT_TS','RIGHT_BF','RIGHT_RF']:\n",
    "        #emg_data.loc[:,j] = signal.filtfilt(b, a, emg_data.loc[:,j])\n",
    "    x,y = dp.generate_window_slide_data(emg_data,width=width,\n",
    "                                        stride=stride,\n",
    "                                        scaler=True,\n",
    "                                        same_label=True)\n",
    "    #x=np.abs(x)\n",
    "    #x=dp.lowpass_filter(x,300)\n",
    "    ind1 = []\n",
    "    ind2 = []\n",
    "    l = len(y)\n",
    "    for j in set(y):\n",
    "        ind = np.where(y == j)[0].tolist()\n",
    "        l_t = len(ind)\n",
    "        ind1 += ind[:int(l_t*0.8)]\n",
    "        ind2 += ind[int(l_t*0.8):]\n",
    "        #l_t = len(label[ind])\n",
    "        #feature1 += feature[ind][:int(l_t*0.8)].tolist()\n",
    "        #label1 += label[ind][:int(l_t*0.8)].tolist()\n",
    "        #feature2 += feature[ind][int(l_t*0.8):].tolist()\n",
    "        #label2 += label[ind][int(l_t*0.8):].tolist()\n",
    "    l1 = len(ind1)\n",
    "    l2 = len(ind2)\n",
    "\n",
    "    fi = [file]*len(x)\n",
    "    X += x[ind1].tolist()\n",
    "    Y += y[ind1].tolist()\n",
    "    F += fi\n",
    "    X2 += x[ind2].tolist()\n",
    "    Y2 += y[ind2].tolist()\n",
    "    F2 += fi\n",
    "    print('%d/%d: '%(i,N)+file)\n",
    "    \n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "X2 = np.array(X2)\n",
    "Y2 = np.array(Y2)\n",
    "end = time.time()\n",
    "duration = end-start\n",
    "print('Duration: %f'%(duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,Model,callbacks,regularizers,models\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.model_selection import train_test_split,cross_validate\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import OneHotEncoder,normalize,MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE,BorderlineSMOTE,ADASYN,SVMSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,feature,y,binary=True,file=None):\n",
    "    if binary:\n",
    "        ind = ((y==0)|(y==1)|(y==2)|(y==6))\n",
    "        #ind1 = ((y==4)|(y==1)|(y==2)|(y==3)|(y==6))\n",
    "        y_01 = y[ind].copy()\n",
    "        ind1 = ((y_01==1)|(y_01==2)|(y_01==6))\n",
    "        y_01[ind1] = 1\n",
    "        oc = OneHotEncoder()\n",
    "        y_01 = oc.fit_transform(np.array(y_01)[:,np.newaxis]).toarray()\n",
    "        cw = None#{0:1,1:5}\n",
    "    else:\n",
    "        ind = ((y==1)|(y==2)|(y==6))\n",
    "        #ind = ((y==1)|(y==6))\n",
    "        y_01 = y[ind].copy()\n",
    "        oc = OneHotEncoder()\n",
    "        y_01 = oc.fit_transform(np.array(y_01)[:,np.newaxis]).toarray()\n",
    "        cw = None#{0:5,1:1,2:1}#{0:2,1:1,2:10,3:2}\n",
    "    x_full,x_test,y_full,y_test = train_test_split(np.array(feature)[ind,:],y_01,\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=123,\n",
    "                                                   shuffle=True)\n",
    "    x_train,x_valid,y_train,y_valid = train_test_split(x_full,y_full,\n",
    "                                                       test_size=0.25,\n",
    "                                                       random_state=555,\n",
    "                                                       shuffle=True)\n",
    "    \n",
    "    #sm = BorderlineSMOTE(random_state=50,kind='borderline-2')\n",
    "    #sm = SMOTE(random_state=50)\n",
    "    #print(y_full.shape)\n",
    "    #x_full,y_full = sm.fit_resample(x_full,y_full)\n",
    "    #print(y_full_n.shape)\n",
    "    sc = StandardScaler(with_mean=True)\n",
    "    #sc = MinMaxScaler()\n",
    "    #x_train = sc.fit_transform(x_full)\n",
    "    pca = PCA(n_components=100)\n",
    "    #x_train = pca.fit_transform(x_train)\n",
    "    #x_valid = sc.transform(x_valid)\n",
    "    #x_test = sc.transform(x_test)\n",
    "    #x_test = pca.transform(x_test)\n",
    "    x_train = x_full\n",
    "    \n",
    "    early_stopping = callbacks.EarlyStopping(patience = 20,\n",
    "                                             monitor = 'val_loss', \n",
    "                                             restore_best_weights=True)\n",
    "    history = model.fit(x_train,y_full,validation_data=[x_test,y_test],\n",
    "                        epochs=100,batch_size=32,class_weight=cw,\n",
    "                        callbacks=[early_stopping],\n",
    "                        shuffle=True)\n",
    "    \n",
    "    if binary:\n",
    "        y_pred_t=model.predict(x_test)\n",
    "        test = metrics.accuracy_score(np.argmax(y_test,axis=1),np.argmax(y_pred_t,axis=1))\n",
    "        #test = metrics.accuracy_score(y_test,y_pred_t>0.5)\n",
    "        \n",
    "        #y_pred_v=model.predict(x_valid)\n",
    "        #valid = metrics.accuracy_score(y_valid,np.argmax(y_pred_v,axis=1))\n",
    "        y_pred_ta=model.predict(x_train)\n",
    "        train = metrics.accuracy_score(np.argmax(y_full,axis=1),np.argmax(y_pred_ta,axis=1))\n",
    "        #train = metrics.accuracy_score(y_full,y_pred_ta>0.5)\n",
    "        \n",
    "        print('train: \\n',metrics.confusion_matrix(np.argmax(y_full,axis=1),np.argmax(y_pred_ta,axis=1)))\n",
    "        #print('valid: \\n',metrics.confusion_matrix(np.argmax(y_valid,axis=1),np.argmax(y_pred_v,axis=1)))\n",
    "        print('test: \\n',metrics.confusion_matrix(np.argmax(y_test,axis=1),np.argmax(y_pred_t,axis=1)))\n",
    "        \n",
    "        #print('train: \\n',metrics.confusion_matrix(y_full,y_pred_ta>0.5))\n",
    "        #print('test: \\n',metrics.confusion_matrix(y_test,y_pred_t>0.5))\n",
    "\n",
    "    else:\n",
    "        y_pred_t=model.predict(x_test)\n",
    "        test = metrics.accuracy_score(np.argmax(y_test,axis=1),np.argmax(y_pred_t,axis=1))\n",
    "        #y_pred_v=model.predict(x_valid)\n",
    "        #valid = metrics.accuracy_score(np.argmax(y_valid,axis=1),np.argmax(y_pred_v,axis=1))\n",
    "        y_pred_ta=model.predict(x_train)\n",
    "        train = metrics.accuracy_score(np.argmax(y_full,axis=1),np.argmax(y_pred_ta,axis=1))        \n",
    "        print('train: \\n',metrics.confusion_matrix(np.argmax(y_full,axis=1),np.argmax(y_pred_ta,axis=1)))\n",
    "        #print('valid: \\n',metrics.confusion_matrix(np.argmax(y_valid,axis=1),np.argmax(y_pred_v,axis=1)))\n",
    "        print('test: \\n',metrics.confusion_matrix(np.argmax(y_test,axis=1),np.argmax(y_pred_t,axis=1)))\n",
    "    print('test:%f'%test)\n",
    "    #print('valid:%f'%valid)\n",
    "    print('train:%f'%train)\n",
    "    if file != None:\n",
    "        model.save_model(file)\n",
    "    return train,test,sc,pca\n",
    "\n",
    "def test_model(model,feature,y,binary=True):\n",
    "    if binary:\n",
    "        ind = ((y==0)|(y==1)|(y==2)|(y==3)|(y==4)|(y==6))\n",
    "        #ind1 = ((y==4)|(y==1)|(y==2)|(y==3)|(y==6))\n",
    "        y_01 = y[ind].copy()\n",
    "        ind1 = ((y_01==1)|(y_01==2)|(y_01==6))\n",
    "        y_01[ind1] = 1\n",
    "        oc = OneHotEncoder()\n",
    "        y_01 = oc.fit_transform(np.array(y_01)[:,np.newaxis]).toarray()\n",
    "        cw = None#{0:1,1:5}\n",
    "    else:\n",
    "        ind = ((y==1)|(y==2)|(y==6))\n",
    "        #ind = ((y==1)|(y==6))\n",
    "        y_01 = y[ind].copy()\n",
    "        oc = OneHotEncoder()\n",
    "        y_01 = oc.fit_transform(np.array(y_01)[:,np.newaxis]).toarray()\n",
    "        cw = None#{0:5,1:1,2:1}#{0:2,1:1,2:10,3:2}\n",
    "\n",
    "    #print(y_01)\n",
    "    #feature=sc.transform(feature[ind])\n",
    "    feature = feature[ind]\n",
    "    #feature=pca.transform(feature)\n",
    "    y_pred=model.predict(feature)\n",
    "    test = metrics.accuracy_score(np.argmax(y_01,axis=1),np.argmax(y_pred,axis=1))\n",
    "    #test = metrics.accuracy_score(y_01,y_pred>0.5)\n",
    "    \n",
    "    print('acc:%f'%test)\n",
    "    print(metrics.confusion_matrix(np.argmax(y_01,axis=1),np.argmax(y_pred,axis=1)))\n",
    "    #print(metrics.confusion_matrix(y_01,y_pred>0.5))\n",
    "    return test\n",
    "\n",
    "def sparse_cost_sensitive_loss (y_true,y_pred):\n",
    "    #cost_matrix = tf.constant([[0,1.,1,1.],\n",
    "    #              [2,0,5,5],\n",
    "    #              [1,1,0,1],\n",
    "    #              [1.,2.,1,0]])\n",
    "    cost_matrix = tf.constant([[0,2.,2],\n",
    "                  [1,0,1],\n",
    "                  [1.0,1.,0]])\n",
    "    #cost_matrix = tf.constant([[0,1.],\n",
    "    #              [5.,0]])\n",
    "    batch_cost_matrix = tf.nn.embedding_lookup(cost_matrix, tf.argmax(y_true,axis=1))\n",
    "    eps = 1e-6\n",
    "    probability = tf.clip_by_value(y_pred, eps, 1-eps)\n",
    "    cost_values = tf.math.log(1-probability)*batch_cost_matrix\n",
    "    loss = tf.reduce_mean(-tf.reduce_sum(cost_values, axis=1))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'num_steps': 256,\n",
    "        'channels': 8,\n",
    "        'conv_activation': 'relu',\n",
    "        'dropout_rate': 0.2,\n",
    "        'wavelet_mother': 'db7',\n",
    "        'wavelet_levels': 2,\n",
    "        'wavelet_trainable': True,\n",
    "        'use_mini_batch': False,\n",
    "        'sliding_window': 10,\n",
    "        'activation_function': 'tanh',\n",
    "        'moving_avg_window': 100,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"low_pass_0/Identity:0\", shape=(None, 128, 1), dtype=float32)\n",
      "Tensor(\"low_pass_1/Identity:0\", shape=(None, 128, 1), dtype=float32)\n",
      "Critic model:\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 256, 8)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "envelope (Lambda)               (None, 256, 8)       0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 2048)         0           envelope[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 1025)         0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1025)         0           flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1025)         0           lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 1025)         0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "high_pass_0 (Conv1D)            (None, 128, 1)       112         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "high_pass_1 (Conv1D)            (None, 128, 1)       112         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "low_pass_1 (Conv1D)             (None, 128, 1)       112         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "fft_abs (Reshape)               (None, 1025, 1)      0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 1025, 1)      0           lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 384, 1)       0           high_pass_0[0][0]                \n",
      "                                                                 high_pass_1[0][0]                \n",
      "                                                                 low_pass_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "raw_conv_1 (Conv1D)             (None, 128, 16)      400         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "fft_conv_1 (Conv1D)             (None, 513, 16)      64          fft_abs[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "fft_env_conv_1 (Conv1D)         (None, 513, 16)      64          reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "wavelet_conv_1 (Conv1D)         (None, 192, 16)      64          concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 128, 16)      0           raw_conv_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 513, 16)      0           fft_conv_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 513, 16)      0           fft_env_conv_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 192, 16)      0           wavelet_conv_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128, 16)      0           leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 513, 16)      0           leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 513, 16)      0           leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 192, 16)      0           leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "raw_conv_2 (Conv1D)             (None, 64, 32)       1568        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "fft_conv_2 (Conv1D)             (None, 257, 32)      1568        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fft_env_conv_2 (Conv1D)         (None, 257, 32)      1568        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "wavelet_conv_2 (Conv1D)         (None, 96, 32)       1568        dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 64, 32)       128         raw_conv_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 257, 32)      128         fft_conv_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 257, 32)      128         fft_env_conv_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 96, 32)       128         wavelet_conv_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 64, 32)       0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 257, 32)      0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 257, 32)      0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 96, 32)       0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64, 32)       0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 257, 32)      0           leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 257, 32)      0           leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 96, 32)       0           leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "raw_conv_3 (Conv1D)             (None, 32, 64)       6208        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fft_conv_3 (Conv1D)             (None, 129, 64)      6208        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fft_env_conv_3 (Conv1D)         (None, 129, 64)      6208        dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "wavelet_conv_3 (Conv1D)         (None, 48, 64)       6208        dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 64)       256         raw_conv_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 129, 64)      256         fft_conv_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 129, 64)      256         fft_env_conv_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 48, 64)       256         wavelet_conv_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 32, 64)       0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 129, 64)      0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 129, 64)      0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 48, 64)       0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32, 64)       0           leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 129, 64)      0           leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 129, 64)      0           leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 48, 64)       0           leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "raw_conv_4 (Conv1D)             (None, 16, 32)       6176        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fft_conv_4 (Conv1D)             (None, 65, 64)       12352       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fft_env_conv_4 (Conv1D)         (None, 65, 64)       12352       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "wavelet_conv_4 (Conv1D)         (None, 24, 32)       6176        dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 16, 32)       128         raw_conv_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 65, 64)       256         fft_conv_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 65, 64)       256         fft_env_conv_4[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 24, 32)       128         wavelet_conv_4[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 16, 32)       0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 65, 64)       0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 65, 64)       0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 24, 32)       0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 16, 32)       0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 65, 64)       0           leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 65, 64)       0           leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 24, 32)       0           leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 512)          0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 4160)         0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 4160)         0           dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 768)          0           dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 9600)         0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "                                                                 flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 3)            28803       concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 100,195\n",
      "Trainable params: 99,043\n",
      "Non-trainable params: 1,152\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cric = discriminator.Discriminator(args,training=True)\n",
    "cric.model.compile(loss = 'categorical_crossentropy' ,optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13626 samples, validate on 3407 samples\n",
      "Epoch 1/100\n",
      "13626/13626 [==============================] - 82s 6ms/sample - loss: 0.9692 - accuracy: 0.6098 - val_loss: 0.7000 - val_accuracy: 0.7194\n",
      "Epoch 2/100\n",
      "13626/13626 [==============================] - 56s 4ms/sample - loss: 0.7243 - accuracy: 0.7088 - val_loss: 0.6496 - val_accuracy: 0.7191\n",
      "Epoch 3/100\n",
      "13626/13626 [==============================] - 54s 4ms/sample - loss: 0.6343 - accuracy: 0.7464 - val_loss: 0.4830 - val_accuracy: 0.8075\n",
      "Epoch 4/100\n",
      "13626/13626 [==============================] - 56s 4ms/sample - loss: 0.5543 - accuracy: 0.7768 - val_loss: 0.4381 - val_accuracy: 0.8245\n",
      "Epoch 5/100\n",
      "13626/13626 [==============================] - 55s 4ms/sample - loss: 0.4824 - accuracy: 0.8106 - val_loss: 0.3632 - val_accuracy: 0.8647\n",
      "Epoch 6/100\n",
      "13626/13626 [==============================] - 58s 4ms/sample - loss: 0.4187 - accuracy: 0.8369 - val_loss: 0.3472 - val_accuracy: 0.8673\n",
      "Epoch 7/100\n",
      "13626/13626 [==============================] - 59s 4ms/sample - loss: 0.3852 - accuracy: 0.8470 - val_loss: 0.3361 - val_accuracy: 0.8667\n",
      "Epoch 8/100\n",
      "13626/13626 [==============================] - 56s 4ms/sample - loss: 0.3633 - accuracy: 0.8556 - val_loss: 0.3637 - val_accuracy: 0.8638\n",
      "Epoch 9/100\n",
      "13626/13626 [==============================] - 55s 4ms/sample - loss: 0.3386 - accuracy: 0.8668 - val_loss: 0.2750 - val_accuracy: 0.8982\n",
      "Epoch 10/100\n",
      "13626/13626 [==============================] - 54s 4ms/sample - loss: 0.3144 - accuracy: 0.8785 - val_loss: 0.2547 - val_accuracy: 0.9043\n",
      "Epoch 11/100\n",
      "13626/13626 [==============================] - 55s 4ms/sample - loss: 0.2956 - accuracy: 0.8863 - val_loss: 0.2000 - val_accuracy: 0.9304\n",
      "Epoch 12/100\n",
      "13626/13626 [==============================] - 60s 4ms/sample - loss: 0.2752 - accuracy: 0.8920 - val_loss: 0.2262 - val_accuracy: 0.9158\n",
      "Epoch 13/100\n",
      "13626/13626 [==============================] - 55s 4ms/sample - loss: 0.2632 - accuracy: 0.8968 - val_loss: 0.2137 - val_accuracy: 0.9196\n",
      "Epoch 14/100\n",
      "13626/13626 [==============================] - 54s 4ms/sample - loss: 0.2494 - accuracy: 0.9003 - val_loss: 0.1942 - val_accuracy: 0.9266\n",
      "Epoch 15/100\n",
      "13626/13626 [==============================] - 56s 4ms/sample - loss: 0.2305 - accuracy: 0.9099 - val_loss: 0.1873 - val_accuracy: 0.9328\n",
      "Epoch 16/100\n",
      "13626/13626 [==============================] - 63s 5ms/sample - loss: 0.2296 - accuracy: 0.9115 - val_loss: 0.1473 - val_accuracy: 0.9486\n",
      "Epoch 17/100\n",
      "13626/13626 [==============================] - 66s 5ms/sample - loss: 0.2183 - accuracy: 0.9141 - val_loss: 0.1718 - val_accuracy: 0.9343\n",
      "Epoch 18/100\n",
      "13626/13626 [==============================] - 71s 5ms/sample - loss: 0.2053 - accuracy: 0.9224 - val_loss: 0.1683 - val_accuracy: 0.9360\n",
      "Epoch 19/100\n",
      "13626/13626 [==============================] - 63s 5ms/sample - loss: 0.1973 - accuracy: 0.9240 - val_loss: 0.2097 - val_accuracy: 0.9158\n",
      "Epoch 20/100\n",
      "13626/13626 [==============================] - 65s 5ms/sample - loss: 0.1930 - accuracy: 0.9271 - val_loss: 0.1529 - val_accuracy: 0.9428\n",
      "Epoch 21/100\n",
      "13626/13626 [==============================] - 63s 5ms/sample - loss: 0.1765 - accuracy: 0.9328 - val_loss: 0.1793 - val_accuracy: 0.9325\n",
      "Epoch 22/100\n",
      "13626/13626 [==============================] - 64s 5ms/sample - loss: 0.1762 - accuracy: 0.9336 - val_loss: 0.1559 - val_accuracy: 0.9395\n",
      "Epoch 23/100\n",
      "13626/13626 [==============================] - 73s 5ms/sample - loss: 0.1755 - accuracy: 0.9342 - val_loss: 0.1108 - val_accuracy: 0.9636\n",
      "Epoch 24/100\n",
      "13626/13626 [==============================] - 78s 6ms/sample - loss: 0.1727 - accuracy: 0.9336 - val_loss: 0.1234 - val_accuracy: 0.9583\n",
      "Epoch 25/100\n",
      "13626/13626 [==============================] - 76s 6ms/sample - loss: 0.1586 - accuracy: 0.9394 - val_loss: 0.1128 - val_accuracy: 0.9589\n",
      "Epoch 26/100\n",
      "13626/13626 [==============================] - 74s 5ms/sample - loss: 0.1609 - accuracy: 0.9364 - val_loss: 0.1126 - val_accuracy: 0.9583\n",
      "Epoch 27/100\n",
      "13626/13626 [==============================] - 84s 6ms/sample - loss: 0.1510 - accuracy: 0.9428 - val_loss: 0.1171 - val_accuracy: 0.9595\n",
      "Epoch 28/100\n",
      "13626/13626 [==============================] - 74s 5ms/sample - loss: 0.1555 - accuracy: 0.9403 - val_loss: 0.1295 - val_accuracy: 0.9539\n",
      "Epoch 29/100\n",
      "13626/13626 [==============================] - 75s 5ms/sample - loss: 0.1549 - accuracy: 0.9408 - val_loss: 0.1405 - val_accuracy: 0.9460\n",
      "Epoch 30/100\n",
      "13626/13626 [==============================] - 74s 5ms/sample - loss: 0.1420 - accuracy: 0.9466 - val_loss: 0.1282 - val_accuracy: 0.9548\n",
      "Epoch 31/100\n",
      "13626/13626 [==============================] - 80s 6ms/sample - loss: 0.1402 - accuracy: 0.9463 - val_loss: 0.1328 - val_accuracy: 0.9516\n",
      "Epoch 32/100\n",
      "13626/13626 [==============================] - 80s 6ms/sample - loss: 0.1440 - accuracy: 0.9455 - val_loss: 0.1060 - val_accuracy: 0.9607\n",
      "Epoch 33/100\n",
      "13626/13626 [==============================] - 75s 5ms/sample - loss: 0.1407 - accuracy: 0.9480 - val_loss: 0.1227 - val_accuracy: 0.9551\n",
      "Epoch 34/100\n",
      "13626/13626 [==============================] - 74s 5ms/sample - loss: 0.1362 - accuracy: 0.9468 - val_loss: 0.1048 - val_accuracy: 0.9592\n",
      "Epoch 35/100\n",
      "13626/13626 [==============================] - 75s 6ms/sample - loss: 0.1261 - accuracy: 0.9518 - val_loss: 0.0936 - val_accuracy: 0.9668\n",
      "Epoch 36/100\n",
      "13626/13626 [==============================] - 71s 5ms/sample - loss: 0.1357 - accuracy: 0.9486 - val_loss: 0.0973 - val_accuracy: 0.9668\n",
      "Epoch 37/100\n",
      "13626/13626 [==============================] - 63s 5ms/sample - loss: 0.1248 - accuracy: 0.9530 - val_loss: 0.0995 - val_accuracy: 0.9651\n",
      "Epoch 38/100\n",
      "13626/13626 [==============================] - 63s 5ms/sample - loss: 0.1173 - accuracy: 0.9561 - val_loss: 0.1146 - val_accuracy: 0.9557\n",
      "Epoch 39/100\n",
      "13626/13626 [==============================] - 63s 5ms/sample - loss: 0.1227 - accuracy: 0.9533 - val_loss: 0.0824 - val_accuracy: 0.9686\n",
      "Epoch 40/100\n",
      "13626/13626 [==============================] - 65s 5ms/sample - loss: 0.1211 - accuracy: 0.9555 - val_loss: 0.1306 - val_accuracy: 0.9513\n",
      "Epoch 41/100\n",
      "13626/13626 [==============================] - 72s 5ms/sample - loss: 0.1091 - accuracy: 0.9574 - val_loss: 0.1100 - val_accuracy: 0.9633\n",
      "Epoch 42/100\n",
      "13626/13626 [==============================] - 64s 5ms/sample - loss: 0.1184 - accuracy: 0.9568 - val_loss: 0.0844 - val_accuracy: 0.9712\n",
      "Epoch 43/100\n",
      "13626/13626 [==============================] - 63s 5ms/sample - loss: 0.1081 - accuracy: 0.9599 - val_loss: 0.0829 - val_accuracy: 0.9692\n",
      "Epoch 44/100\n",
      "13626/13626 [==============================] - 64s 5ms/sample - loss: 0.1167 - accuracy: 0.9565 - val_loss: 0.0703 - val_accuracy: 0.9748\n",
      "Epoch 45/100\n",
      "13626/13626 [==============================] - 63s 5ms/sample - loss: 0.1105 - accuracy: 0.9566 - val_loss: 0.0788 - val_accuracy: 0.9712\n",
      "Epoch 46/100\n",
      "13626/13626 [==============================] - 72s 5ms/sample - loss: 0.0955 - accuracy: 0.9654 - val_loss: 0.1008 - val_accuracy: 0.9621\n",
      "Epoch 47/100\n",
      "13626/13626 [==============================] - 66s 5ms/sample - loss: 0.1106 - accuracy: 0.9592 - val_loss: 0.0724 - val_accuracy: 0.9733\n",
      "Epoch 48/100\n",
      "13626/13626 [==============================] - 63s 5ms/sample - loss: 0.1051 - accuracy: 0.9588 - val_loss: 0.0975 - val_accuracy: 0.9648\n",
      "Epoch 49/100\n",
      "13626/13626 [==============================] - 63s 5ms/sample - loss: 0.1047 - accuracy: 0.9613 - val_loss: 0.0967 - val_accuracy: 0.9636\n",
      "Epoch 50/100\n",
      "13626/13626 [==============================] - 65s 5ms/sample - loss: 0.0904 - accuracy: 0.9671 - val_loss: 0.1039 - val_accuracy: 0.9615\n",
      "Epoch 51/100\n",
      "13626/13626 [==============================] - 71s 5ms/sample - loss: 0.0993 - accuracy: 0.9627 - val_loss: 0.0655 - val_accuracy: 0.9768\n",
      "Epoch 52/100\n",
      "13626/13626 [==============================] - 63s 5ms/sample - loss: 0.1064 - accuracy: 0.9598 - val_loss: 0.0926 - val_accuracy: 0.9692\n",
      "Epoch 53/100\n",
      "13626/13626 [==============================] - 63s 5ms/sample - loss: 0.1074 - accuracy: 0.9626 - val_loss: 0.0691 - val_accuracy: 0.9783\n",
      "Epoch 54/100\n",
      "13626/13626 [==============================] - 65s 5ms/sample - loss: 0.1000 - accuracy: 0.9645 - val_loss: 0.0647 - val_accuracy: 0.9783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "13626/13626 [==============================] - 68s 5ms/sample - loss: 0.0917 - accuracy: 0.9656 - val_loss: 0.0664 - val_accuracy: 0.9774\n",
      "Epoch 56/100\n",
      "13626/13626 [==============================] - 73s 5ms/sample - loss: 0.1015 - accuracy: 0.9634 - val_loss: 0.1184 - val_accuracy: 0.9592\n",
      "Epoch 57/100\n",
      "13626/13626 [==============================] - 55s 4ms/sample - loss: 0.0904 - accuracy: 0.9655 - val_loss: 0.0540 - val_accuracy: 0.9812\n",
      "Epoch 58/100\n",
      "13626/13626 [==============================] - 55s 4ms/sample - loss: 0.1051 - accuracy: 0.9614 - val_loss: 0.1182 - val_accuracy: 0.9560\n",
      "Epoch 59/100\n",
      "13626/13626 [==============================] - 55s 4ms/sample - loss: 0.0986 - accuracy: 0.9644 - val_loss: 0.0690 - val_accuracy: 0.9759\n",
      "Epoch 60/100\n",
      "13626/13626 [==============================] - 55s 4ms/sample - loss: 0.0892 - accuracy: 0.9689 - val_loss: 0.1208 - val_accuracy: 0.9566\n",
      "Epoch 61/100\n",
      "13626/13626 [==============================] - 58s 4ms/sample - loss: 0.0875 - accuracy: 0.9670 - val_loss: 0.0555 - val_accuracy: 0.9812\n",
      "Epoch 62/100\n",
      "13626/13626 [==============================] - 56s 4ms/sample - loss: 0.0927 - accuracy: 0.9636 - val_loss: 0.0777 - val_accuracy: 0.9721\n",
      "Epoch 63/100\n",
      "13626/13626 [==============================] - 55s 4ms/sample - loss: 0.0889 - accuracy: 0.9687 - val_loss: 0.0803 - val_accuracy: 0.9701\n",
      "Epoch 64/100\n",
      "13626/13626 [==============================] - 54s 4ms/sample - loss: 0.0965 - accuracy: 0.9658 - val_loss: 0.0608 - val_accuracy: 0.9771\n",
      "Epoch 65/100\n",
      "13626/13626 [==============================] - 55s 4ms/sample - loss: 0.0898 - accuracy: 0.9662 - val_loss: 0.0808 - val_accuracy: 0.9692\n",
      "Epoch 66/100\n",
      "13626/13626 [==============================] - 54s 4ms/sample - loss: 0.0843 - accuracy: 0.9679 - val_loss: 0.0773 - val_accuracy: 0.9683\n",
      "Epoch 67/100\n",
      "13626/13626 [==============================] - 60s 4ms/sample - loss: 0.0921 - accuracy: 0.9670 - val_loss: 0.1063 - val_accuracy: 0.9601\n",
      "Epoch 68/100\n",
      "13626/13626 [==============================] - 54s 4ms/sample - loss: 0.0893 - accuracy: 0.9669 - val_loss: 0.0586 - val_accuracy: 0.9789\n",
      "Epoch 69/100\n",
      "13626/13626 [==============================] - 54s 4ms/sample - loss: 0.0873 - accuracy: 0.9687 - val_loss: 0.0659 - val_accuracy: 0.9753\n",
      "Epoch 70/100\n",
      "13626/13626 [==============================] - 58s 4ms/sample - loss: 0.0828 - accuracy: 0.9712 - val_loss: 0.0716 - val_accuracy: 0.9742\n",
      "Epoch 71/100\n",
      "13626/13626 [==============================] - 56s 4ms/sample - loss: 0.0783 - accuracy: 0.9742 - val_loss: 0.1170 - val_accuracy: 0.9574\n",
      "Epoch 72/100\n",
      "13626/13626 [==============================] - 55s 4ms/sample - loss: 0.0773 - accuracy: 0.9717 - val_loss: 0.0727 - val_accuracy: 0.9748\n",
      "Epoch 73/100\n",
      "13626/13626 [==============================] - 60s 4ms/sample - loss: 0.0814 - accuracy: 0.9706 - val_loss: 0.0641 - val_accuracy: 0.9762\n",
      "Epoch 74/100\n",
      "13626/13626 [==============================] - 54s 4ms/sample - loss: 0.0812 - accuracy: 0.9699 - val_loss: 0.0678 - val_accuracy: 0.9765\n",
      "Epoch 75/100\n",
      "13626/13626 [==============================] - 54s 4ms/sample - loss: 0.0803 - accuracy: 0.9712 - val_loss: 0.0572 - val_accuracy: 0.9780\n",
      "Epoch 76/100\n",
      "13626/13626 [==============================] - 54s 4ms/sample - loss: 0.0744 - accuracy: 0.9732 - val_loss: 0.0684 - val_accuracy: 0.9762\n",
      "Epoch 77/100\n",
      "13626/13626 [==============================] - 54s 4ms/sample - loss: 0.0782 - accuracy: 0.9715 - val_loss: 0.0648 - val_accuracy: 0.9777\n",
      "Epoch 78/100\n",
      "13626/13626 [==============================] - 54s 4ms/sample - loss: 0.0811 - accuracy: 0.9718 - val_loss: 0.0942 - val_accuracy: 0.9665\n",
      "Epoch 79/100\n",
      "13626/13626 [==============================] - 60s 4ms/sample - loss: 0.0825 - accuracy: 0.9702 - val_loss: 0.0527 - val_accuracy: 0.9812\n",
      "Epoch 80/100\n",
      "13626/13626 [==============================] - 56s 4ms/sample - loss: 0.0764 - accuracy: 0.9720 - val_loss: 0.0574 - val_accuracy: 0.9792\n",
      "Epoch 81/100\n",
      "13626/13626 [==============================] - 55s 4ms/sample - loss: 0.0781 - accuracy: 0.9728 - val_loss: 0.0569 - val_accuracy: 0.9806\n",
      "Epoch 82/100\n",
      "13626/13626 [==============================] - 55s 4ms/sample - loss: 0.0813 - accuracy: 0.9706 - val_loss: 0.0483 - val_accuracy: 0.9824\n",
      "Epoch 83/100\n",
      "13626/13626 [==============================] - 54s 4ms/sample - loss: 0.0736 - accuracy: 0.9723 - val_loss: 0.0497 - val_accuracy: 0.9818\n",
      "Epoch 84/100\n",
      "13626/13626 [==============================] - 55s 4ms/sample - loss: 0.0782 - accuracy: 0.9720 - val_loss: 0.0529 - val_accuracy: 0.9809\n",
      "Epoch 85/100\n",
      "13626/13626 [==============================] - 60s 4ms/sample - loss: 0.0785 - accuracy: 0.9707 - val_loss: 0.0438 - val_accuracy: 0.9844\n",
      "Epoch 86/100\n",
      "13626/13626 [==============================] - 54s 4ms/sample - loss: 0.0804 - accuracy: 0.9698 - val_loss: 0.0672 - val_accuracy: 0.9768\n",
      "Epoch 87/100\n",
      "13626/13626 [==============================] - 55s 4ms/sample - loss: 0.0818 - accuracy: 0.9700 - val_loss: 0.0600 - val_accuracy: 0.9774\n",
      "Epoch 88/100\n",
      "13626/13626 [==============================] - 55s 4ms/sample - loss: 0.0666 - accuracy: 0.9756 - val_loss: 0.0522 - val_accuracy: 0.9818\n",
      "Epoch 89/100\n",
      "13626/13626 [==============================] - 55s 4ms/sample - loss: 0.0757 - accuracy: 0.9725 - val_loss: 0.0450 - val_accuracy: 0.9844\n",
      "Epoch 90/100\n",
      "13626/13626 [==============================] - 58s 4ms/sample - loss: 0.0683 - accuracy: 0.9737 - val_loss: 0.0730 - val_accuracy: 0.9745\n",
      "Epoch 91/100\n",
      "13626/13626 [==============================] - 60s 4ms/sample - loss: 0.0749 - accuracy: 0.9729 - val_loss: 0.0800 - val_accuracy: 0.9718\n",
      "Epoch 92/100\n",
      "13626/13626 [==============================] - 55s 4ms/sample - loss: 0.0783 - accuracy: 0.9732 - val_loss: 0.0906 - val_accuracy: 0.9695\n",
      "Epoch 93/100\n",
      "13626/13626 [==============================] - 55s 4ms/sample - loss: 0.0756 - accuracy: 0.9723 - val_loss: 0.0516 - val_accuracy: 0.9839\n",
      "Epoch 94/100\n",
      "13626/13626 [==============================] - 54s 4ms/sample - loss: 0.0756 - accuracy: 0.9720 - val_loss: 0.0733 - val_accuracy: 0.9774\n",
      "Epoch 95/100\n",
      "13626/13626 [==============================] - 55s 4ms/sample - loss: 0.0728 - accuracy: 0.9744 - val_loss: 0.0456 - val_accuracy: 0.9871\n",
      "Epoch 96/100\n",
      "13626/13626 [==============================] - 63s 5ms/sample - loss: 0.0655 - accuracy: 0.9770 - val_loss: 0.0633 - val_accuracy: 0.9771\n",
      "Epoch 97/100\n",
      "13626/13626 [==============================] - 61s 4ms/sample - loss: 0.0758 - accuracy: 0.9731 - val_loss: 0.0566 - val_accuracy: 0.9812\n",
      "Epoch 98/100\n",
      "13626/13626 [==============================] - 63s 5ms/sample - loss: 0.0714 - accuracy: 0.9748 - val_loss: 0.0516 - val_accuracy: 0.9824\n",
      "Epoch 99/100\n",
      "13626/13626 [==============================] - 59s 4ms/sample - loss: 0.0638 - accuracy: 0.9756 - val_loss: 0.0712 - val_accuracy: 0.9745\n",
      "Epoch 100/100\n",
      "13626/13626 [==============================] - 55s 4ms/sample - loss: 0.0663 - accuracy: 0.9772 - val_loss: 0.0492 - val_accuracy: 0.9833\n",
      "train: \n",
      " [[3059    0    0]\n",
      " [   0 6839    0]\n",
      " [   1    1 3726]]\n",
      "test: \n",
      " [[ 720   16    0]\n",
      " [  10 1682    1]\n",
      " [  19   11  948]]\n",
      "test:0.983270\n",
      "train:0.999853\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9998532217818875,\n",
       " 0.9832697387731142,\n",
       " StandardScaler(),\n",
       " PCA(n_components=100))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(cric.model,X,Y,binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:0.700445\n",
      "[[ 394  397  161]\n",
      " [ 239 1822   81]\n",
      " [ 170  232  777]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7004446524689913"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(cric.model,X2,Y2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
