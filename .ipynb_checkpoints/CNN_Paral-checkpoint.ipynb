{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.config import Config\n",
    "from lib.data_set import Dataset\n",
    "from lib.model import NNModel\n",
    "from lib import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctypes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pywt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras import layers as KL\n",
    "from tensorflow.keras import models as KM\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File name read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file name of data with various Labels\n",
    "df = pd.read_csv('./useful_data_label.csv',index_col=0) \n",
    "# read file name of data with only label 0\n",
    "df2 = pd.read_csv('./unuseful_data_label.csv',index_col=0)\n",
    "# read some of the data with only label 0\n",
    "df3 = pd.read_csv('./data/file_name.txt',header=None)\n",
    "# player = ctypes.windll.kernel32\n",
    "\n",
    "ind = df2.iloc[1].isna()\n",
    "files = np.concatenate([np.array(df.columns),np.array('normal/'+df2.columns[ind])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuraion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Override the base class of Config and Features for CWT-CNN Model\n",
    "class CNNPa_Config(Config):\n",
    "    NAME = 'CNN_Paral'\n",
    "    NUM_CLASSES = 2\n",
    "    EPOCHS = 300\n",
    "    BATCH_SIZE = 32\n",
    "    CLASS_WEIGHTS = None\n",
    "    FN_LP = 300\n",
    "    DETREND_LAMBDA = 50\n",
    "    TEST_FILES = files[[6,30,31,32,33,34,35]]\n",
    "    \n",
    "    DWT_WAVELET = 'haar'\n",
    "    DWT_LEVELS = 5\n",
    "    KERNEL_SIZE  = 3\n",
    "    DROPOUT_RATE = 0.2\n",
    "    DWT_TRAINABLE = False\n",
    "    MOVING_AVG_WINDOW = 50\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BATCH_SIZE                     32\n",
      "CHANNELS                       ['LEFT_TA', 'LEFT_TS', 'LEFT_BF', 'LEFT_RF', 'RIGHT_TA', 'RIGHT_TS', 'RIGHT_BF', 'RIGHT_RF']\n",
      "CLASS_WEIGHTS                  None\n",
      "DETREND_LAMBDA                 50\n",
      "DROPOUT_RATE                   0.2\n",
      "DROP_WITH_ZSCORE               None\n",
      "DWT_LEVELS                     5\n",
      "DWT_TRAINABLE                  False\n",
      "DWT_WAVELET                    haar\n",
      "EPOCHS                         300\n",
      "FN_HP                          None\n",
      "FN_IR                          False\n",
      "FN_LP                          300\n",
      "KERNEL_SIZE                    3\n",
      "MOVING_AVG_WINDOW              50\n",
      "NAME                           CNN_Paral\n",
      "NUM_CLASSES                    2\n",
      "N_ENV                          20\n",
      "RECT                           False\n",
      "REMOVE_FREQS                   True\n",
      "SAME_LABEL                     True\n",
      "SAVE                           False\n",
      "SCALE                          True\n",
      "SHUFFLE                        True\n",
      "STEP_SIZE                      512\n",
      "TEST_FILES                     ['G08_FoG_1_trial_1_emg.csv' 'normal/G09_Walking_trial_2_emg.csv'\n",
      " 'normal/G09_Walking_trial_4_emg.csv' 'normal/G09_Walking_trial_6_emg.csv'\n",
      " 'normal/G11_Walking_trial_2_emg.csv' 'normal/G11_Walking_trial_4_emg.csv'\n",
      " 'normal/P231_M050_A_Walking_trial_2_emg.csv']\n",
      "TRAIN_SET_RATIO                0.8\n",
      "WINDOW_SIZE                    1024\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate CWT-CNN configuration\n",
    "config = CNNPa_Config()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip\n",
      "skip\n",
      "3/174: G06_FoG_trial_1_emg.csv\n",
      "4/174: G06_FoG_trial_2_emg.csv\n",
      "5/174: G06_FoG_trial_3_emg.csv\n",
      "6/174: G07_Freezing_Trial1_trial_1_emg.csv\n",
      "7/174: G08_FoG_1_trial_1_emg.csv\n",
      "8/174: G08_FoG_2_trial_1_emg.csv\n",
      "9/174: G11_FoG_trial_1_emg.csv\n",
      "10/174: G11_FoG_trial_2_emg.csv\n",
      "11/174: P379_M050_2_OFF_A_FoG_trial_1_emg.csv\n",
      "12/174: P379_M050_2_OFF_A_FoG_trial_2_emg.csv\n",
      "13/174: P379_M050_2_OFF_A_FoG_trial_3_emg.csv\n",
      "14/174: P379_M050_2_OFF_B_FoG_trial_1_emg.csv\n",
      "15/174: P379_M050_2_OFF_B_FoG_trial_2_emg.csv\n",
      "16/174: P379_M050_2_OFF_B_FoG_trial_3_emg.csv\n",
      "17/174: P551_M050_2_A_FoG_trial_1_emg.csv\n",
      "18/174: P551_M050_2_B_FoG_trial_1_emg.csv\n",
      "19/174: P551_M050_2_B_FoG_trial_2_emg.csv\n",
      "20/174: P812_M050_2_B_FoG_trial_1_emg.csv\n",
      "21/174: P812_M050_2_B_FoG_trial_2_emg.csv\n",
      "22/174: normal/G02_Walking_trial_1_emg.csv\n",
      "23/174: normal/G03_Walking_trial_1_emg.csv\n",
      "24/174: normal/G03_Walking_trial_2_emg.csv\n",
      "25/174: normal/G05_Walking_struct_fixed_trial_1_emg.csv\n",
      "26/174: normal/G05_Walking_struct_fixed_trial_2_emg.csv\n",
      "27/174: normal/G05_Walking_struct_fixed_trial_3_emg.csv\n",
      "28/174: normal/G09_FoG_trial_1_emg.csv\n",
      "29/174: normal/G09_FoG_trial_2_emg.csv\n",
      "30/174: normal/G09_FoG_trial_3_emg.csv\n",
      "31/174: normal/G09_Walking_trial_2_emg.csv\n",
      "32/174: normal/G09_Walking_trial_4_emg.csv\n",
      "33/174: normal/G09_Walking_trial_6_emg.csv\n",
      "34/174: normal/G11_Walking_trial_2_emg.csv\n",
      "35/174: normal/G11_Walking_trial_4_emg.csv\n",
      "36/174: normal/P231_M050_A_Walking_trial_2_emg.csv\n",
      "37/174: normal/P231_M050_A_Walking_trial_4_emg.csv\n",
      "38/174: normal/P231_M050_A_Walking_trial_6_emg.csv\n",
      "39/174: normal/P231_M050_B_Walking_trial_2_emg.csv\n",
      "40/174: normal/P231_M050_B_Walking_trial_4_emg.csv\n",
      "41/174: normal/P231_M050_B_Walking_trial_6_emg.csv\n",
      "42/174: normal/P231_M100_2_A_FoG_trial_3_emg.csv\n",
      "43/174: normal/P231_M100_2_A_Walking_trial_4_emg.csv\n",
      "44/174: normal/P231_M100_2_A_Walking_trial_6_emg.csv\n",
      "45/174: normal/P231_M100_ON_A_Walking_trial_2_emg.csv\n",
      "46/174: normal/P231_M100_ON_A_Walking_trial_4_emg.csv\n",
      "47/174: normal/P231_M100_ON_A_Walking_trial_6_emg.csv\n",
      "48/174: normal/P231_Msham_A_Walking_trial_2_emg.csv\n",
      "49/174: normal/P231_Msham_A_Walking_trial_6_emg.csv\n",
      "50/174: normal/P231_Msham_B_Walking_trial_2_emg.csv\n",
      "51/174: normal/P351_M050_2_A_FoG_trial_1_emg.csv\n",
      "52/174: normal/P351_M050_2_A_FoG_trial_2_emg.csv\n",
      "53/174: normal/P351_M050_2_A_FoG_trial_3_emg.csv\n",
      "54/174: normal/P351_M050_2_A_Walking_trial_2_emg.csv\n",
      "55/174: normal/P351_M050_2_A_Walking_trial_4_emg.csv\n",
      "56/174: normal/P351_M050_2_A_Walking_trial_6_emg.csv\n",
      "57/174: normal/P351_M050_2_B_FoG_trial_1_emg.csv\n",
      "58/174: normal/P351_M050_2_B_FoG_trial_2_emg.csv\n",
      "59/174: normal/P351_M050_2_B_FoG_trial_3_emg.csv\n",
      "60/174: normal/P351_M050_2_B_Walking_trial_2_emg.csv\n",
      "61/174: normal/P351_M050_2_B_Walking_trial_4_emg.csv\n",
      "62/174: normal/P351_M050_2_B_Walking_trial_6_emg.csv\n",
      "63/174: normal/P351_M050_A_FoG_trial_1_emg.csv\n",
      "64/174: normal/P351_M050_A_FoG_trial_2_emg.csv\n",
      "65/174: normal/P351_M050_A_FoG_trial_3_emg.csv\n",
      "66/174: normal/P351_M050_A_Walking_trial_2_emg.csv\n",
      "67/174: normal/P351_M050_A_Walking_trial_4_emg.csv\n",
      "68/174: normal/P351_M050_B_FoG_trial_1_emg.csv\n",
      "69/174: normal/P351_M050_B_FoG_trial_2_emg.csv\n",
      "70/174: normal/P351_M050_B_FoG_trial_3_emg.csv\n",
      "71/174: normal/P351_M050_B_Walking_trial_2_emg.csv\n",
      "72/174: normal/P351_M050_B_Walking_trial_4_emg.csv\n",
      "73/174: normal/P351_M050_B_Walking_trial_6_emg.csv\n",
      "74/174: normal/P351_Msham_A_FoG_trial_1_emg.csv\n",
      "75/174: normal/P351_Msham_A_FoG_trial_2_emg.csv\n",
      "76/174: normal/P351_Msham_A_FoG_trial_3_emg.csv\n",
      "77/174: normal/P351_Msham_A_Walking_trial_2_emg.csv\n",
      "78/174: normal/P351_Msham_A_Walking_trial_4_emg.csv\n",
      "79/174: normal/P351_Msham_A_Walking_trial_6_emg.csv\n",
      "80/174: normal/P351_Msham_B_FoG_trial_1_emg.csv\n",
      "81/174: normal/P351_Msham_B_FoG_trial_2_emg.csv\n",
      "82/174: normal/P351_Msham_B_FoG_trial_3_emg.csv\n",
      "83/174: normal/P351_Msham_B_Walking_trial_2_emg.csv\n",
      "84/174: normal/P351_Msham_B_Walking_trial_4_emg.csv\n",
      "85/174: normal/P351_Msham_B_Walking_trial_6_emg.csv\n",
      "86/174: normal/P379_M050_A_Walking_trial_2_emg.csv\n",
      "87/174: normal/P379_M050_A_Walking_trial_3_emg.csv\n",
      "88/174: normal/P379_M050_B_Walking_trial_2_emg.csv\n",
      "89/174: normal/P379_Msham_B_Walking_trial_6_emg.csv\n",
      "90/174: normal/P533_M050_A_Walking_trial_1_emg.csv\n",
      "91/174: normal/P533_M050_A_Walking_trial_2_emg.csv\n",
      "92/174: normal/P533_M050_B_Walking_trial_2_emg.csv\n",
      "93/174: normal/P533_M050_B_Walking_trial_3_emg.csv\n",
      "94/174: normal/P533_M100_A_Walking_trial_2_emg.csv\n",
      "95/174: normal/P533_M100_B_Walking_trial_4_emg.csv\n",
      "96/174: normal/P551_M50_B_Walking_trial_6_emg.csv\n",
      "97/174: normal/P623_M050_2_A_Walking_trial_2_emg.csv\n",
      "98/174: normal/P623_M050_2_A_Walking_trial_4_emg.csv\n",
      "skip\n",
      "100/174: normal/P623_M050_2_B_Walking_trial_2_emg.csv\n",
      "101/174: normal/P623_M050_2_B_Walking_trial_6_emg.csv\n",
      "102/174: normal/P623_M050_A_Walking_trial_4_emg.csv\n",
      "103/174: normal/P623_M100_A_Walking_trial_4_emg.csv\n",
      "104/174: normal/P623_M100_B_Walking_trial_4_emg.csv\n",
      "105/174: normal/P623_Msham_A_Walking_trial_4_emg.csv\n",
      "106/174: normal/P623_Msham_A_Walking_trial_6_emg.csv\n",
      "107/174: normal/P623_Msham_B_Walking_trial_2_emg.csv\n",
      "108/174: normal/P623_Msham_B_Walking_trial_4_emg.csv\n",
      "109/174: normal/P645_M050_A_Walking_trial_2_emg.csv\n",
      "110/174: normal/P645_M050_A_Walking_trial_3_emg.csv\n",
      "111/174: normal/P645_M050_B_Walking_trial_2_emg.csv\n",
      "112/174: normal/P645_M050_B_Walking_trial_3_emg.csv\n",
      "113/174: normal/P812_M050_2_A_FoG_trial_1_emg.csv\n",
      "114/174: normal/P812_M050_2_A_FoG_trial_3_emg.csv\n",
      "115/174: normal/P812_M050_2_A_Walking_trial_2_emg.csv\n",
      "116/174: normal/P812_M050_2_A_Walking_trial_3_emg.csv\n",
      "117/174: normal/P812_M050_2_B_Walking_1_trial_4_emg.csv\n",
      "118/174: normal/P812_M050_A_FoG_trial_1_emg.csv\n",
      "119/174: normal/P812_M050_A_FoG_trial_2_emg.csv\n",
      "120/174: normal/P812_M050_A_FoG_trial_3_emg.csv\n",
      "121/174: normal/P812_M050_A_Walking_trial_1_emg.csv\n",
      "122/174: normal/P812_M050_A_Walking_trial_2_emg.csv\n",
      "123/174: normal/P812_M050_B_FoG_trial_1_emg.csv\n",
      "124/174: normal/P812_M050_B_FoG_trial_2_emg.csv\n",
      "125/174: normal/P812_M050_B_FoG_trial_3_emg.csv\n",
      "126/174: normal/P812_M050_B_Walking_trial_1_emg.csv\n",
      "127/174: normal/P812_M050_B_Walking_trial_2_emg.csv\n",
      "128/174: normal/P812_M100_A_FoG_trial_1_emg.csv\n",
      "129/174: normal/P812_M100_A_Walking_trial_3_emg.csv\n",
      "130/174: normal/P812_M100_B_FoG_trial_1_emg.csv\n",
      "131/174: normal/P812_M100_B_FoG_trial_3_emg.csv\n",
      "132/174: normal/P812_M100_B_Walking2_trial_1_emg.csv\n",
      "133/174: normal/P812_M100_B_Walking2_trial_2_emg.csv\n",
      "134/174: normal/P876_M100_B_FoG_trial_1_emg.csv\n",
      "135/174: normal/P876_M100_B_FoG_trial_2_emg.csv\n",
      "136/174: normal/P876_M100_B_FoG_trial_3_emg.csv\n",
      "137/174: normal/P876_M100_B_Walking_trial_4_emg.csv\n",
      "138/174: normal/P876_M100_B_Walking_trial_6_emg.csv\n",
      "139/174: normal/P940_M050_2_A_FoG_trial_3_emg.csv\n",
      "140/174: normal/P940_M050_2_A_FoG_trial_4_emg.csv\n",
      "141/174: normal/P940_M050_2_A_Walking_trial_2_emg.csv\n",
      "142/174: normal/P940_M050_2_B_FoG_trial_1_emg.csv\n",
      "143/174: normal/P940_M050_2_B_Walking_trial_2_emg.csv\n",
      "144/174: normal/P940_M050_2_B_Walking_trial_4_emg.csv\n",
      "145/174: normal/P940_M050_2_B_Walking_trial_6_emg.csv\n",
      "146/174: normal/P940_M050_A_FoG_trial_2_emg.csv\n",
      "147/174: normal/P940_M050_A_FoG_trial_3_emg.csv\n",
      "148/174: normal/P940_M050_A_Walking_trial_2_emg.csv\n",
      "149/174: normal/P940_M050_A_Walking_trial_4_emg.csv\n",
      "150/174: normal/P940_M050_A_Walking_trial_6_emg.csv\n",
      "151/174: normal/P940_M050_B_FoG_trial_1_emg.csv\n",
      "152/174: normal/P940_M050_B_FoG_trial_2_emg.csv\n",
      "153/174: normal/P940_M050_B_FoG_trial_3_emg.csv\n",
      "154/174: normal/P940_M050_B_Walking_trial_2_emg.csv\n",
      "155/174: normal/P940_M050_B_Walking_trial_4_emg.csv\n",
      "156/174: normal/P940_M050_B_Walking_trial_6_emg.csv\n",
      "157/174: normal/P940_M100_A_FoG_trial_1_emg.csv\n",
      "158/174: normal/P940_M100_A_FoG_trial_2_emg.csv\n",
      "159/174: normal/P940_M100_A_FoG_trial_3_emg.csv\n",
      "160/174: normal/P940_M100_A_Walking_trial_2_emg.csv\n",
      "161/174: normal/P940_M100_A_Walking_trial_4_emg.csv\n",
      "162/174: normal/P940_M100_A_Walking_trial_6_emg.csv\n",
      "163/174: normal/P940_M100_B_FoG_trial_2_emg.csv\n",
      "164/174: normal/P940_M100_B_FoG_trial_3_emg.csv\n",
      "165/174: normal/P940_M100_B_Walking_2_trial_2_emg.csv\n",
      "166/174: normal/P940_M100_B_Walking_2_trial_6_emg.csv\n",
      "167/174: normal/P940_MSham_A_FoG_trial_1_emg.csv\n",
      "168/174: normal/P940_MSham_A_FoG_trial_3_emg.csv\n",
      "169/174: normal/P940_MSham_A_Walking_trial_2_emg.csv\n",
      "170/174: normal/P940_MSham_A_Walking_trial_4_emg.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/174: normal/P940_MSham_A_Walking_trial_6_emg.csv\n",
      "172/174: normal/P940_MSham_B_Walking_trial_2_emg.csv\n",
      "173/174: normal/P940_MSham_B_Walking_trial_4_emg.csv\n",
      "174/174: normal/P940_MSham_B_Walking_trial_6_emg.csv\n"
     ]
    }
   ],
   "source": [
    "# Load data from files\n",
    "data.load_data(files)\n",
    "\n",
    "X_train,Y_train,_ = data.train_set\n",
    "X_valid,Y_valid,_ = data.valid_set\n",
    "X_test, Y_test, _ = data.test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Override base class of SimpleMode for CNNPa\n",
    "class CNNPa_Model(NNModel):\n",
    "        \n",
    "    def make_wavelet_expansion(self, input_tensor):\n",
    "        #input_tensor = Reshape((input_tensor.shape[-1],1))(input_tensor)\n",
    "        print(input_tensor.shape)\n",
    "        low_pass, high_pass  = pywt.Wavelet(self.wavelet_mother).filter_bank[:2]\n",
    "        low_pass_filter = np.array(low_pass)\n",
    "        high_pass_filter = np.array(high_pass)\n",
    "        n_levels = self.wavelet_levels\n",
    "        trainable=self.wavelet_trainable\n",
    "        \n",
    "        wv_kwargs = {\n",
    "            \"filters\":1,\n",
    "            \"kernel_size\":len(low_pass),\n",
    "            \"strides\":2, \n",
    "            \"use_bias\":False, \n",
    "            \"padding\":\"same\", \n",
    "            \"trainable\":trainable,\n",
    "        }\n",
    "\n",
    "        approximation_coefficients = []\n",
    "        detail_coefficients = []\n",
    "\n",
    "        last_approximant = input_tensor\n",
    "        last_approximant = K.reshape(last_approximant,(-1,last_approximant.shape[-2],last_approximant.shape[-1],1))\n",
    "        for i in range(n_levels):\n",
    "            lpf = low_pass_filter\n",
    "            hpf = high_pass_filter\n",
    "            #print(lpf.reshape((-1, int(self.channels))).shape)\n",
    "            for j in range(self.channels):\n",
    "                if j == 0:\n",
    "                    a_n = KL.Conv1D(\n",
    "                        kernel_initializer=keras.initializers.Constant(lpf.reshape((-1, 1))),\n",
    "                        name=\"low_pass_{}.{}\".format(i,j),\n",
    "                        **wv_kwargs\n",
    "                    )(last_approximant[:,:,j,:])\n",
    "                    d_n = KL.Conv1D(\n",
    "                        kernel_initializer=keras.initializers.Constant(hpf.reshape((-1, 1))),\n",
    "                        name=\"high_pass_{}.{}\".format(i,j),\n",
    "                        **wv_kwargs,\n",
    "                    )(last_approximant[:,:,j,:])\n",
    "                else:\n",
    "                #print(a_n)\n",
    "                    temp_a = KL.Conv1D(\n",
    "                        kernel_initializer=keras.initializers.Constant(lpf.reshape((-1, 1))),\n",
    "                        name=\"low_pass_{}.{}\".format(i,j),\n",
    "                        **wv_kwargs\n",
    "                    )(last_approximant[:,:,j,:])\n",
    "                    a_n = K.concatenate([a_n,temp_a],axis=2)\n",
    "                    temp_d = KL.Conv1D(\n",
    "                        kernel_initializer=keras.initializers.Constant(hpf.reshape((-1, 1))),\n",
    "                        name=\"high_pass_{}.{}\".format(i,j),\n",
    "                        **wv_kwargs,\n",
    "                    )(last_approximant[:,:,j,:])\n",
    "                    d_n = K.concatenate([d_n,temp_d],axis=2)\n",
    "            detail_coefficients.append(d_n)\n",
    "            approximation_coefficients.append(a_n)\n",
    "            last_approximant = a_n\n",
    "            last_approximant = K.reshape(last_approximant,(-1,last_approximant.shape[-2],last_approximant.shape[-1],1))\n",
    "\n",
    "        return approximation_coefficients, detail_coefficients\n",
    "    \n",
    "    def envelopes(self, args):\n",
    "        \"\"\"Reparameterization trick by sampling fr an isotropic unit Gaussian.\n",
    "\n",
    "        # Arguments\n",
    "            args (tensor): mean and log of variance of Q(z|X)\n",
    "\n",
    "        # Returns\n",
    "            z (tensor): sampled latent vector\n",
    "        \"\"\"\n",
    "        input_ = args\n",
    "        abs_envelope = K.abs(input_)\n",
    "        envelope = tf.signal.frame(\n",
    "            abs_envelope,\n",
    "            self.moving_avg_window,\n",
    "            1,#steps\n",
    "            pad_end=True,\n",
    "            pad_value=0,\n",
    "            axis=1,\n",
    "            name='envelope_moving_average'\n",
    "        )\n",
    "        #print(envelope.shape)\n",
    "        #envelope_reshaped = K.reshape(envelope,(-1,self.window_size,self.moving_avg_window))\n",
    "        envelope_mean = K.mean(envelope, axis=2, keepdims=True)\n",
    "        #print(envelope_mean.shape)\n",
    "        envelope_mean = K.reshape(envelope_mean,(-1,self.window_size,self.channels))\n",
    "        return envelope_mean\n",
    "    \n",
    "    def rfft_layer(self,data):\n",
    "        #data=Reshape((data.shape[1],data.shape[2],1))(data)\n",
    "        n = data.shape[2]\n",
    "        #print(data.shape)\n",
    "        for i in range(n):\n",
    "            if i == 0:\n",
    "                fft = K.abs(tf.signal.rfft(data[:,:,i]))\n",
    "                fft = K.reshape(fft,(-1,fft.shape[1],1))\n",
    "            else:\n",
    "                temp = K.abs(tf.signal.rfft(data[:,:,i]))\n",
    "                temp = K.reshape(temp,(-1,temp.shape[1],1))\n",
    "                fft = K.concatenate([fft,temp],axis=2)\n",
    "        #print(fft.shape)\n",
    "        return fft\n",
    "    \n",
    "    def build(self,config):\n",
    "        \n",
    "        self.kernel_size = config.KERNEL_SIZE\n",
    "        self.dropout_rate = config.DROPOUT_RATE  # Dropout rate\n",
    "        # Define parameters for wavelet decomposition\n",
    "        self.wavelet_mother = config.DWT_WAVELET \n",
    "        self.wavelet_levels = config.DWT_LEVELS  \n",
    "        self.wavelet_trainable= config.DWT_TRAINABLE\n",
    "\n",
    "        self.moving_avg_window = config.MOVING_AVG_WINDOW\n",
    "        self.classes_num = config.NUM_CLASSES\n",
    "        \n",
    "        self.window_size = config.WINDOW_SIZE\n",
    "        self.channels = len(config.CHANNELS)\n",
    "        \n",
    "        self.input_shape = (self.window_size,self.channels)\n",
    "        \n",
    "        input_ = KL.Input(shape=self.input_shape)\n",
    "        \n",
    "        #CNN on raw signal\n",
    "        \n",
    "        kernels=[16,32,64,32,16]\n",
    "        cnn_name=['raw_conv_1','raw_conv_2','raw_conv_3','raw_conv_4','raw_conv_5']\n",
    "        fft_name=['fft_conv_1','fft_conv_2','fft_conv_3','fft_conv_4','fft_conv_5']\n",
    "        envelope_name=['envelope_conv_1','envelope_conv_2','envelope_conv_3','envelope_conv_4','envelope_conv_5']\n",
    "        wavelet_name=['wavelet_cnn_1','wavelet_conv_2','wavelet_conv_3','wavelet_conv_4','wavelet_conv_5']\n",
    "    \n",
    "        cnn_1 = input_\n",
    "        for i,(k,n) in enumerate(zip(kernels,cnn_name)):\n",
    "            cnn_1 = KL.Conv1D(k, kernel_size=self.kernel_size, strides=1, padding=\"same\", name=n)(cnn_1)\n",
    "            if i!=0:\n",
    "                cnn_1 = KL.BatchNormalization(momentum=0.8)(cnn_1)\n",
    "            cnn_1 = KL.Activation(config.ACTI)(cnn_1)\n",
    "            # cnn_1 = KL.BatchNormalization(momentum=0.8)(cnn_1)\n",
    "            cnn_1 = KL.MaxPooling1D(2)(cnn_1)\n",
    "            cnn_1 = KL.Dropout(self.dropout_rate)(cnn_1)\n",
    "\n",
    "        cnn_5 = KL.GlobalAveragePooling1D()(cnn_1)\n",
    "        \n",
    "        #CNN on FFT of raw signal\n",
    "        \n",
    "        fft = KL.Lambda(self.rfft_layer,name='rfft')(input_)\n",
    "        fft_cnn_1 = fft\n",
    "        for i,(k,n) in enumerate(zip(kernels,fft_name)):\n",
    "            fft_cnn_1 = KL.Conv1D(k, kernel_size=self.kernel_size, strides=1, padding=\"same\", name=n)(fft_cnn_1)\n",
    "            if i!=0:\n",
    "                fft_cnn_1 = KL.BatchNormalization(momentum=0.8)(fft_cnn_1)\n",
    "            fft_cnn_1 = KL.Activation(config.ACTI)(fft_cnn_1)\n",
    "            # fft_cnn_1 = KL.BatchNormalization(momentum=0.8)(fft_cnn_1)\n",
    "            fft_cnn_1 = KL.MaxPooling1D(2)(fft_cnn_1)\n",
    "            fft_cnn_1 = KL.Dropout(self.dropout_rate)(fft_cnn_1)\n",
    "        \n",
    "#         fft_cnn_5 = KL.Flatten()(fft_cnn_5)\n",
    "        fft_cnn_5 = KL.GlobalAveragePooling1D()(fft_cnn_1)\n",
    "                \n",
    "        #CNN on FFT of envelope\n",
    "        envelope_window = KL.Lambda(self.envelopes, output_shape=(self.input_shape[0],self.input_shape[1]), name='envelope')(input_)\n",
    "        envelope_cnn_1 = envelope_window\n",
    "        for i,(k,n) in enumerate(zip(kernels,envelope_name)):\n",
    "            envelope_cnn_1 = KL.Conv1D(k, kernel_size=self.kernel_size, strides=1, padding=\"same\", name=n)(envelope_cnn_1)\n",
    "            if i!=0:\n",
    "                envelope_cnn_1 = KL.BatchNormalization(momentum=0.8)(envelope_cnn_1)\n",
    "            envelope_cnn_1 = KL.Activation(config.ACTI)(envelope_cnn_1)\n",
    "            # envelope_cnn_1 = KL.BatchNormalization(momentum=0.8)(envelope_cnn_1)\n",
    "            envelope_cnn_1 = KL.MaxPooling1D(2)(envelope_cnn_1)\n",
    "            envelope_cnn_1 = KL.Dropout(self.dropout_rate)(envelope_cnn_1)\n",
    "            \n",
    "#         envelope_cnn_5 = KL.Flatten()(envelope_cnn_5)\n",
    "        envelope_cnn_5 = KL.GlobalAveragePooling1D()(envelope_cnn_1)\n",
    "        \n",
    "        # Wavelet Expansion\n",
    "        approx_stack, detail_stack = self.make_wavelet_expansion(input_)\n",
    "        features_list = []\n",
    "        features_list.extend(detail_stack)\n",
    "        features_list.append(approx_stack[-1])\n",
    "        wavelet_concatenate = KL.Concatenate(axis=1,name='wavelet_concat')(features_list)\n",
    "        wavelet_concatenate = K.abs(wavelet_concatenate)\n",
    "        \n",
    "        wavelet_cnn_1 = wavelet_concatenate\n",
    "        \n",
    "        for i,(k,n) in enumerate(zip(kernels,wavelet_name)):\n",
    "            wavelet_cnn_1 = KL.Conv1D(k, kernel_size=self.kernel_size, strides=1, padding=\"same\", name=n)(wavelet_cnn_1)\n",
    "            if i!=0:\n",
    "                wavelet_cnn_1 = KL.BatchNormalization(momentum=0.8)(wavelet_cnn_1)\n",
    "            wavelet_cnn_1 = KL.Activation(config.ACTI)(wavelet_cnn_1)\n",
    "            # wavelet_cnn_1 = KL.BatchNormalization(momentum=0.8)(wavelet_cnn_1)\n",
    "            wavelet_cnn_1 = KL.MaxPooling1D(2)(wavelet_cnn_1)\n",
    "            wavelet_cnn_1 = KL.Dropout(self.dropout_rate)(wavelet_cnn_1)\n",
    "        \n",
    "#         wavelet_cnn_5 = KL.Flatten()(wavelet_cnn_5)\n",
    "        wavelet_cnn_5 = KL.GlobalAveragePooling1D()(wavelet_cnn_1)\n",
    "        \n",
    "        concatenate = KL.Concatenate()([cnn_5,envelope_cnn_5,fft_cnn_5,wavelet_cnn_5])\n",
    "\n",
    "        dropout = KL.Dropout(self.dropout_rate)(concatenate)\n",
    "        mlp = KL.Dense(self.classes_num,activation='softmax')(dropout)\n",
    "                \n",
    "        model = KM.Model(input_, mlp)\n",
    "        \n",
    "#         model.summary()\n",
    "        \n",
    "        if config.COST_SENSITIVE:\n",
    "            self.cost_matrix = config.COST_MATRIX\n",
    "            model.compile(loss=self.sparse_cost_sensitive_loss, optimizer=\"adam\", metrics=['accuracy'])\n",
    "            print('Using cost sensitive with cost matrix:\\n',np.array(self.cost_matrix))\n",
    "        else:\n",
    "            model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "            if config.CLASS_WEIGHTS != None:\n",
    "                print('Using categorical crossentropy with class weights:\\n',config.CLASS_WEIGHTS)\n",
    "            else:\n",
    "                print('Using categorical crossentropy without class weights.')\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def sparse_cost_sensitive_loss (self,y_true,y_pred):\n",
    "        cost_matrix = self.cost_matrix\n",
    "        batch_cost_matrix = tf.nn.embedding_lookup(cost_matrix, tf.argmax(y_true,axis=1))\n",
    "        eps = 1e-6\n",
    "        probability = tf.clip_by_value(y_pred, eps, 1-eps)\n",
    "        cost_values = tf.math.log(1-probability)*batch_cost_matrix\n",
    "        loss = tf.reduce_mean(-tf.reduce_sum(cost_values, axis=1))\n",
    "        return loss\n",
    "    \n",
    "    def model_metrics(self,data,label):\n",
    "        pred = self.keras_model.predict(data)\n",
    "        acc = metrics.accuracy_score(np.argmax(label,axis=1),np.argmax(pred,axis=1))\n",
    "        cm = metrics.confusion_matrix(np.argmax(label,axis=1),np.argmax(pred,axis=1))\n",
    "        f1 = metrics.f1_score(np.argmax(label,axis=1),np.argmax(pred,axis=1),average='macro')\n",
    "        return acc,cm,f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data split and processing for model\n",
    "class_id = [1,2,6]\n",
    "binary = True\n",
    "x_train,y_train,x_valid,y_valid,x_test,y_test,oh = utils.data_split_oh((X_train,X_valid,X_test),\n",
    "                                                                       (Y_train,Y_valid,Y_test),\n",
    "                                                                        class_id,\n",
    "                                                                       binary,\n",
    "                                                                       random_state = 555)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1024, 8)\n",
      "Using categorical crossentropy without class weights.\n"
     ]
    }
   ],
   "source": [
    "config.COST_MATRIX = tf.constant([[0,1.],\n",
    "              [10,0]])\n",
    "\n",
    "config.DWT_WAVELET = 'haar'\n",
    "config.DWT_LEVELS = 5\n",
    "config.KERNEL_SIZE  = 3\n",
    "config.DROPOUT_RATE = 0.2\n",
    "config.DWT_TRAINABLE = False\n",
    "config.MOVING_AVG_WINDOW = 50\n",
    "config.EPOCHS=500\n",
    "config.ACTI=KL.LeakyReLU(alpha=0.2)\n",
    "\n",
    "if binary:\n",
    "    config.COST_SENSITIVE = True\n",
    "    config.NUM_CLASSES = 2\n",
    "else:\n",
    "    config.COST_SENSITIVE = False\n",
    "    config.NUM_CLASSES = len(class_id)\n",
    "\n",
    "# Generate CWT_CNN Model\n",
    "cnnpa_model = CNNPa_Model('CNNPa',config,'./model/CNNPa/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 0.\n",
      "\n",
      "Checkpoint Path: ./model/CNNPa/cnn_paral20211104T2129\\CNNPa_cnn_paral_{epoch:04d}.h5\n",
      "Epoch 1/500\n",
      "14/14 [==============================] - 20s 555ms/step - loss: 1.0326 - accuracy: 0.5274 - val_loss: 1.2807 - val_accuracy: 0.3356\n",
      "Epoch 2/500\n",
      "14/14 [==============================] - 4s 305ms/step - loss: 0.7828 - accuracy: 0.6896 - val_loss: 0.9786 - val_accuracy: 0.5342\n",
      "Epoch 3/500\n",
      "14/14 [==============================] - 4s 291ms/step - loss: 0.6484 - accuracy: 0.7341 - val_loss: 0.9066 - val_accuracy: 0.5822\n",
      "Epoch 4/500\n",
      "14/14 [==============================] - 4s 314ms/step - loss: 0.6273 - accuracy: 0.7453 - val_loss: 0.8437 - val_accuracy: 0.6370\n",
      "Epoch 5/500\n",
      "14/14 [==============================] - 5s 353ms/step - loss: 0.6411 - accuracy: 0.7263 - val_loss: 0.6935 - val_accuracy: 0.7397\n",
      "Epoch 6/500\n",
      "14/14 [==============================] - 4s 298ms/step - loss: 0.5743 - accuracy: 0.7678 - val_loss: 0.6456 - val_accuracy: 0.7877\n",
      "Epoch 7/500\n",
      "14/14 [==============================] - 4s 319ms/step - loss: 0.5267 - accuracy: 0.8000 - val_loss: 0.6085 - val_accuracy: 0.7945\n",
      "Epoch 8/500\n",
      "14/14 [==============================] - 4s 326ms/step - loss: 0.5292 - accuracy: 0.7721 - val_loss: 0.5514 - val_accuracy: 0.8082\n",
      "Epoch 9/500\n",
      "14/14 [==============================] - 5s 335ms/step - loss: 0.4847 - accuracy: 0.7960 - val_loss: 0.5505 - val_accuracy: 0.7877\n",
      "Epoch 10/500\n",
      "14/14 [==============================] - 4s 315ms/step - loss: 0.4112 - accuracy: 0.8368 - val_loss: 0.4949 - val_accuracy: 0.8425\n",
      "Epoch 11/500\n",
      "14/14 [==============================] - 4s 288ms/step - loss: 0.4622 - accuracy: 0.7928 - val_loss: 0.4746 - val_accuracy: 0.8288\n",
      "Epoch 12/500\n",
      "14/14 [==============================] - 4s 286ms/step - loss: 0.4484 - accuracy: 0.8266 - val_loss: 0.4229 - val_accuracy: 0.8356\n",
      "Epoch 13/500\n",
      "14/14 [==============================] - 4s 284ms/step - loss: 0.4053 - accuracy: 0.8260 - val_loss: 0.4321 - val_accuracy: 0.8356\n",
      "Epoch 14/500\n",
      "14/14 [==============================] - 4s 296ms/step - loss: 0.4072 - accuracy: 0.8338 - val_loss: 0.3877 - val_accuracy: 0.8493\n",
      "Epoch 15/500\n",
      "14/14 [==============================] - 4s 292ms/step - loss: 0.4172 - accuracy: 0.8102 - val_loss: 0.4088 - val_accuracy: 0.8493\n",
      "Epoch 16/500\n",
      "14/14 [==============================] - 4s 290ms/step - loss: 0.3699 - accuracy: 0.8324 - val_loss: 0.4093 - val_accuracy: 0.8493\n",
      "Epoch 17/500\n",
      "14/14 [==============================] - 4s 295ms/step - loss: 0.4040 - accuracy: 0.8369 - val_loss: 0.3814 - val_accuracy: 0.8630\n",
      "Epoch 18/500\n",
      "14/14 [==============================] - 4s 291ms/step - loss: 0.4081 - accuracy: 0.8228 - val_loss: 0.4230 - val_accuracy: 0.8425\n",
      "Epoch 19/500\n",
      "14/14 [==============================] - 4s 289ms/step - loss: 0.3632 - accuracy: 0.8473 - val_loss: 0.3868 - val_accuracy: 0.8562\n",
      "Epoch 20/500\n",
      "14/14 [==============================] - 4s 283ms/step - loss: 0.3934 - accuracy: 0.8238 - val_loss: 0.3798 - val_accuracy: 0.8699\n",
      "Epoch 21/500\n",
      "14/14 [==============================] - 4s 287ms/step - loss: 0.3646 - accuracy: 0.8517 - val_loss: 0.3675 - val_accuracy: 0.8699\n",
      "Epoch 22/500\n",
      "14/14 [==============================] - 4s 286ms/step - loss: 0.3147 - accuracy: 0.8953 - val_loss: 0.3789 - val_accuracy: 0.8562\n",
      "Epoch 23/500\n",
      "14/14 [==============================] - 4s 287ms/step - loss: 0.2990 - accuracy: 0.9013 - val_loss: 0.4031 - val_accuracy: 0.8288\n",
      "Epoch 24/500\n",
      "14/14 [==============================] - 4s 286ms/step - loss: 0.2960 - accuracy: 0.8958 - val_loss: 0.3668 - val_accuracy: 0.8630\n",
      "Epoch 25/500\n",
      "14/14 [==============================] - 4s 285ms/step - loss: 0.3039 - accuracy: 0.8852 - val_loss: 0.3839 - val_accuracy: 0.8562\n",
      "Epoch 26/500\n",
      "14/14 [==============================] - 4s 292ms/step - loss: 0.2956 - accuracy: 0.8931 - val_loss: 0.3717 - val_accuracy: 0.8630\n",
      "Epoch 27/500\n",
      "14/14 [==============================] - 4s 281ms/step - loss: 0.2740 - accuracy: 0.8928 - val_loss: 0.3677 - val_accuracy: 0.8699\n",
      "Epoch 28/500\n",
      "14/14 [==============================] - 4s 283ms/step - loss: 0.2801 - accuracy: 0.9014 - val_loss: 0.4489 - val_accuracy: 0.8219\n",
      "Epoch 29/500\n",
      "14/14 [==============================] - 4s 325ms/step - loss: 0.2812 - accuracy: 0.8935 - val_loss: 0.3975 - val_accuracy: 0.8493\n",
      "Epoch 30/500\n",
      "14/14 [==============================] - 5s 366ms/step - loss: 0.2564 - accuracy: 0.9182 - val_loss: 0.4212 - val_accuracy: 0.8562\n",
      "Epoch 31/500\n",
      "14/14 [==============================] - 5s 366ms/step - loss: 0.2725 - accuracy: 0.8745 - val_loss: 0.3677 - val_accuracy: 0.8699\n",
      "Epoch 32/500\n",
      "14/14 [==============================] - 5s 340ms/step - loss: 0.2441 - accuracy: 0.9205 - val_loss: 0.3877 - val_accuracy: 0.8630\n",
      "Epoch 33/500\n",
      "14/14 [==============================] - 4s 321ms/step - loss: 0.2191 - accuracy: 0.9372 - val_loss: 0.4862 - val_accuracy: 0.8219\n",
      "Epoch 34/500\n",
      "14/14 [==============================] - 5s 336ms/step - loss: 0.2420 - accuracy: 0.9299 - val_loss: 0.4043 - val_accuracy: 0.8630\n"
     ]
    }
   ],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(patience = 20,\n",
    "                                             monitor = 'val_loss', \n",
    "                                             #baseline = 0.9,\n",
    "                                             restore_best_weights=True)\n",
    "cnnpa_model.train((x_train,y_train),(x_valid,y_valid),config.EPOCHS,config.BATCH_SIZE,[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_train: 0.922374\n",
      "f1_train: 0.894036\n",
      "confusion_matrix:\n",
      " [[ 63   5  17]\n",
      " [  6 235   5]\n",
      " [  1   0 106]]\n",
      "acc_valid: 0.863014\n",
      "f1_valid: 0.763199\n",
      "confusion_matrix:\n",
      " [[ 8  5  6]\n",
      " [ 5 86  4]\n",
      " [ 0  0 32]]\n",
      "acc_test: 0.738255\n",
      "f1_test: 0.722282\n",
      "confusion_matrix:\n",
      " [[22 13  0]\n",
      " [12 41  0]\n",
      " [14  0 47]]\n"
     ]
    }
   ],
   "source": [
    "acc_train,cm_train,f1_train = cnnpa_model.model_metrics(x_train,y_train)\n",
    "acc_valid,cm_valid,f1_valid = cnnpa_model.model_metrics(x_valid,y_valid)\n",
    "acc_test,cm_test,f1_test = cnnpa_model.model_metrics(x_test,y_test)\n",
    "print('acc_train: %f\\nf1_train: %f\\nconfusion_matrix:\\n'%(acc_train,f1_train),cm_train)\n",
    "print('acc_valid: %f\\nf1_valid: %f\\nconfusion_matrix:\\n'%(acc_valid,f1_valid),cm_valid)\n",
    "print('acc_test: %f\\nf1_test: %f\\nconfusion_matrix:\\n'%(acc_test,f1_test),cm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
