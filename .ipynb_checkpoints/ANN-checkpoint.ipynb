{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import data_processing as dp\n",
    "from scipy import signal\n",
    "from scipy.stats import skew\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "import os\n",
    "import time\n",
    "import h5py\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\data\\G04_FoG_trial_1_emg.csv\n",
      ".\\data\\G04_FoG_trial_2_emg.csv\n",
      ".\\data\\G06_FoG_trial_1_emg.csv\n",
      ".\\data\\G06_FoG_trial_2_emg.csv\n",
      ".\\data\\G06_FoG_trial_3_emg.csv\n",
      ".\\data\\G07_Freezing_Trial1_trial_1_emg.csv\n",
      ".\\data\\G08_FoG_1_trial_1_emg.csv\n",
      ".\\data\\G08_FoG_2_trial_1_emg.csv\n",
      ".\\data\\G11_FoG_trial_1_emg.csv\n",
      ".\\data\\G11_FoG_trial_2_emg.csv\n",
      ".\\data\\P379_M050_2_OFF_A_FoG_trial_1_emg.csv\n",
      ".\\data\\P379_M050_2_OFF_A_FoG_trial_2_emg.csv\n",
      ".\\data\\P379_M050_2_OFF_A_FoG_trial_3_emg.csv\n",
      ".\\data\\P379_M050_2_OFF_B_FoG_trial_1_emg.csv\n",
      ".\\data\\P379_M050_2_OFF_B_FoG_trial_2_emg.csv\n",
      ".\\data\\P379_M050_2_OFF_B_FoG_trial_3_emg.csv\n",
      ".\\data\\P551_M050_2_A_FoG_trial_1_emg.csv\n",
      ".\\data\\P551_M050_2_B_FoG_trial_1_emg.csv\n",
      ".\\data\\P551_M050_2_B_FoG_trial_2_emg.csv\n",
      ".\\data\\P812_M050_2_B_FoG_trial_1_emg.csv\n",
      ".\\data\\P812_M050_2_B_FoG_trial_2_emg.csv\n",
      ".\\data\\其他\\labels.txt\n",
      ".\\data\\其他\\P812_M050_2_B_FoG_trial1_annotation.csv\n",
      ".\\data\\其他\\P812_M050_2_B_FoG_trials.mat\n",
      ".\\data\\其他\\P812_M050_2_B_FoG_trial_1_out_left_foot.csv\n",
      ".\\data\\其他\\P812_M050_2_B_FoG_trial_1_out_lower_left_foot.csv\n",
      ".\\data\\其他\\P812_M050_2_B_FoG_trial_1_out_lower_right_foot.csv\n",
      ".\\data\\其他\\P812_M050_2_B_FoG_trial_1_out_right_foot.csv\n",
      ".\\data\\其他\\P812_M050_2_B_FoG_trial_2_out_left_foot.csv\n",
      ".\\data\\其他\\P812_M050_2_B_FoG_trial_2_out_lower_left_foot.csv\n",
      ".\\data\\其他\\P812_M050_2_B_FoG_trial_2_out_lower_right_foot.csv\n",
      ".\\data\\其他\\P812_M050_2_B_FoG_trial_2_out_right_foot.csv\n",
      ".\\data\\其他\\P812_M50_2_B_FoG_trial2_annotation.csv\n",
      ".\\data\\正常\\G02_Walking_trial_1_emg.csv\n",
      ".\\data\\正常\\G03_Walking_trial_1_emg.csv\n",
      ".\\data\\正常\\G03_Walking_trial_2_emg.csv\n",
      ".\\data\\正常\\G05_Walking_struct_fixed_trial_1_emg.csv\n",
      ".\\data\\正常\\G05_Walking_struct_fixed_trial_2_emg.csv\n",
      ".\\data\\正常\\G05_Walking_struct_fixed_trial_3_emg.csv\n",
      ".\\data\\正常\\G09_FoG_trial_1_emg.csv\n",
      ".\\data\\正常\\G09_FoG_trial_2_emg.csv\n",
      ".\\data\\正常\\G09_FoG_trial_3_emg.csv\n",
      ".\\data\\正常\\G09_Walking_trial_2_emg.csv\n",
      ".\\data\\正常\\G09_Walking_trial_4_emg.csv\n",
      ".\\data\\正常\\G09_Walking_trial_6_emg.csv\n",
      ".\\data\\正常\\G11_Walking_trial_2_emg.csv\n",
      ".\\data\\正常\\G11_Walking_trial_4_emg.csv\n"
     ]
    }
   ],
   "source": [
    "for dirname, _, filenames in os.walk('.\\data'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2 = '.\\data\\正常\\G11_Walking_trial_4_emg.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.read_csv('./processed data/dataframe_W256_S64.csv')\n",
    "\n",
    "# read file name of data with various Labels\n",
    "df = pd.read_csv('./useful_data_label.csv',index_col=0) \n",
    "drop = 'P551_M050_2_B_FoG_trial_2_emg.csv'\n",
    "ind_drop = df.columns!=drop\n",
    "# read file name of data with only label 0\n",
    "df2 = pd.read_csv('./unuseful_data_label.csv',index_col=0)\n",
    "# read some of the data with only label 0\n",
    "df3 = pd.read_csv('./data/file_name.txt',header=None)\n",
    "\n",
    "files = np.concatenate([np.array(df.columns),np.array(df3.loc[:,0])])\n",
    "ind = Data.File.isin(files)\n",
    "Data_sel = Data[ind]\n",
    "Data_rest = Data[~ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_col = ['_IEMG','_MAV','_SSI','_VAR','_RMS',\n",
    "               '_WL','_ZC','_SSC','_WAMP','_skew','_Acti','_AR','_HIST','_MDF']\n",
    "\n",
    "feature_all = Data_sel.iloc[:,1:-1]\n",
    "ind_temp1 = feature_all.columns.str.contains('MAV')\n",
    "ind_temp2 = feature_all.columns.str.contains('RMS')\n",
    "ind_temp3 = feature_all.columns.str.contains('VAR')\n",
    "ind_temp = ind_temp1|ind_temp2|ind_temp3\n",
    "feature = feature_all.loc[:,~ind_temp]\n",
    "y = Data_sel.iloc[:,0]\n",
    "feature2_all = Data_rest.iloc[:,1:-1]\n",
    "feature2 = feature2_all.loc[:,~ind_temp]\n",
    "y2 = Data_rest.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './processed data/data_set_after_window_withoutSC.hdf5'\n",
    "with h5py.File(path,'r') as f:\n",
    "    x = f['cwt_data'][...]\n",
    "    y = f['label2'][...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data_processing' from 'E:\\\\Document\\\\jupyter\\\\Master Thesis\\\\data_processing.py'>"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imp\n",
    "imp.reload(dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ctypes\n",
    "player = ctypes.windll.kernel32\n",
    "player.Beep(1000,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 256\n",
    "threshold_WAMP = 30\n",
    "threshold_ZC = 0\n",
    "threshold_SSC = 1\n",
    "bins=9\n",
    "bound = 70\n",
    "HIST_range = (-bound,bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold_WAMP:30.0, threshold_ZC:0.0, threshold_SSC:1.0,bins:9,ranges:(-70,70)\n",
      "IEMG,MAV,SSI,VAR,RMS,WL,ZC,SSC,WAMP,skew,Acti,AR,HIST\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = './processed data/data_set_after_window_S64_withoutSC_allPa.hdf5'\n",
    "with h5py.File(path,'r') as f:\n",
    "    x = f['cwt_data'][...]\n",
    "    y = f['label2'][...]\n",
    "feature = dp.generate_feature(x,threshold_WAMP=threshold_WAMP,\n",
    "                              threshold_ZC=threshold_ZC,\n",
    "                              threshold_SSC=threshold_SSC,\n",
    "                              bins=bins,ranges=HIST_range)\n",
    "#feature2 = dp.generate_feature(x2)\n",
    "player.Beep(1000,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'h5py' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ee592dd2b42c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./processed data/nfeatures_W256_S64_WAMP30.hdf5'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mfeature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'features'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'labels'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'h5py' is not defined"
     ]
    }
   ],
   "source": [
    "with h5py.File('./processed data/nfeatures_W256_S64_WAMP30.hdf5','r') as f:\n",
    "    feature = f['features'][...]\n",
    "    y = f['labels'][...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature2,y2 = dp.pipeline_feature(path2,width=256,stride=64,\n",
    "                                  scaler=False,\n",
    "                                  threshold_WAMP=threshold_WAMP,\n",
    "                                  threshold_ZC=threshold_ZC,\n",
    "                                  threshold_SSC=threshold_SSC,\n",
    "                                  bins=bins,ranges=HIST_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('./processed data/nfeatures_rest_W256_S64.hdf5','r') as f:\n",
    "    feature2 = f['features'][...]\n",
    "    y2 = f['labels'][...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler(with_mean=True)\n",
    "feature_sc = sc.fit_transform(feature)\n",
    "feature2_sc = sc.transform(feature2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers,Model,callbacks\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(feature,y,file=None):\n",
    "    ind = ((y==4)|(y==1)|(y==2)|(y==3)|(y==6))\n",
    "    y_01 = y.copy()\n",
    "    y_01[ind] = 1\n",
    "    x_full,x_test,y_full,y_test = train_test_split(feature,y_01,\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=123,\n",
    "                                                   shuffle=False)\n",
    "    x_train,x_valid,y_train,y_valid = train_test_split(x_full,y_full,\n",
    "                                                       test_size=0.2,\n",
    "                                                       random_state=555,\n",
    "                                                       shuffle=True)\n",
    "    input_ = layers.Input(shape=feature.shape[1:])\n",
    "    l1 = layers.Dense(128,activation='elu')(input_)\n",
    "    drop1 = layers.Dropout(0.2)(l1)\n",
    "    l2 = layers.Dense(64,activation='elu')(drop1)\n",
    "    drop2 = layers.Dropout(0.2)(l2)\n",
    "    l3 = layers.Dense(32,activation='elu')(drop2)\n",
    "    drop3 = layers.Dropout(0.2)(l3)\n",
    "    l4 = layers.Dense(16,activation='elu')(drop3)\n",
    "    drop4 = layers.Dropout(0.2)(l4)\n",
    "    output = layers.Dense(1,activation='sigmoid')(drop4)\n",
    "    model = Model(inputs=[input_],outputs=[output])\n",
    "    \n",
    "    early_stopping = callbacks.EarlyStopping(patience = 20,\n",
    "                                             monitor = 'val_accuracy', \n",
    "                                             restore_best_weights=True)\n",
    "    history = model.fit(x_train,y_train,validation_data=[x_valid,y_valid],\n",
    "                        epochs=200,batch_size=50,\n",
    "                        callbacks=[early_stopping])\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    \n",
    "    y_pred_t=model.predict(x_test)\n",
    "    test = metrics.accuracy_score(y_test,y_pred_t>0.5)\n",
    "    y_pred_v=model.predict(x_valid)\n",
    "    valid = metrics.accuracy_score(y_valid,y_pred_v>0.5)\n",
    "    y_pred_ta=model.predict(x_train)\n",
    "    train = metrics.accuracy_score(y_train,y_pred_ta>0.5)\n",
    "    print('test:%f'%test)\n",
    "    print('valid:%f'%valid)\n",
    "    print('train:%f'%train)\n",
    "    if file != None:\n",
    "        model.save_model(file)\n",
    "    return train,valid,test,model\n",
    "\n",
    "def test_model(model,feature,y):\n",
    "    ind = ((y==4)|(y==1)|(y==2)|(y==3)|(y==6))\n",
    "    y_01 = y.copy()\n",
    "    y_01[ind] = 1\n",
    "    y_pred=model.predict(feature)\n",
    "    test = metrics.accuracy_score(y_01,y_pred>0.5)\n",
    "    print('acc:%f'%test)\n",
    "    return test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ind = ((y==1)|(y==2)|(y==3)|(y==6))\n",
    "ind = ((y==4)|(y==1)|(y==2)|(y==3)|(y==6))\n",
    "ind_f = [0,1,6,42,46,57,62]\n",
    "#y_01 = y[ind].copy()\n",
    "#y_01[y_01==1]=0\n",
    "#y_01[y_01==2]=1\n",
    "#y_01[y_01==3]=2\n",
    "#y_01[y_01==6]=3\n",
    "y_01 = y.copy()\n",
    "y_01[ind] = 1\n",
    "oh_ec = OneHotEncoder()\n",
    "y_oh = oh_ec.fit_transform(y_01[:,np.newaxis]).toarray()\n",
    "x_full,x_test,y_full,y_test = train_test_split(feature_sc,y_01,test_size=0.2,random_state=123,shuffle=False)\n",
    "x_train,x_valid,y_train,y_valid = train_test_split(x_full,y_full,test_size=0.2,random_state=555,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = layers.Input(shape=feature_sc.shape[1:])\n",
    "l1 = layers.Dense(128,activation='elu')(input_)\n",
    "drop1 = layers.Dropout(0.2)(l1)\n",
    "l2 = layers.Dense(64,activation='elu')(drop1)\n",
    "drop2 = layers.Dropout(0.2)(l2)\n",
    "l3 = layers.Dense(32,activation='elu')(drop2)\n",
    "drop3 = layers.Dropout(0.2)(l3)\n",
    "l4 = layers.Dense(16,activation='elu')(drop3)\n",
    "drop4 = layers.Dropout(0.2)(l4)\n",
    "output = layers.Dense(1,activation='sigmoid')(drop4)\n",
    "model = Model(inputs=[input_],outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = callbacks.EarlyStopping(patience = 20,\n",
    "                                         monitor = 'val_accuracy', \n",
    "                                         restore_best_weights=True)\n",
    "history = model.fit(x_train,y_train,validation_data=[x_valid,y_valid],\n",
    "                    epochs=200,batch_size=50,\n",
    "                   callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22000 samples, validate on 5500 samples\n",
      "Epoch 1/200\n",
      "22000/22000 [==============================] - 2s 81us/sample - loss: 0.3253 - accuracy: 0.8672 - val_loss: 0.2081 - val_accuracy: 0.9209\n",
      "Epoch 2/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2399 - accuracy: 0.9108 - val_loss: 0.1831 - val_accuracy: 0.9316\n",
      "Epoch 3/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.2167 - accuracy: 0.9188 - val_loss: 0.1717 - val_accuracy: 0.9336\n",
      "Epoch 4/200\n",
      "22000/22000 [==============================] - 1s 67us/sample - loss: 0.1985 - accuracy: 0.9273 - val_loss: 0.1679 - val_accuracy: 0.9375\n",
      "Epoch 5/200\n",
      "22000/22000 [==============================] - 2s 86us/sample - loss: 0.1856 - accuracy: 0.9334 - val_loss: 0.1559 - val_accuracy: 0.9413\n",
      "Epoch 6/200\n",
      "22000/22000 [==============================] - 2s 68us/sample - loss: 0.1728 - accuracy: 0.9350 - val_loss: 0.1627 - val_accuracy: 0.9404\n",
      "Epoch 7/200\n",
      "22000/22000 [==============================] - 1s 58us/sample - loss: 0.1666 - accuracy: 0.9391 - val_loss: 0.1486 - val_accuracy: 0.9440\n",
      "Epoch 8/200\n",
      "22000/22000 [==============================] - 1s 57us/sample - loss: 0.1555 - accuracy: 0.9435 - val_loss: 0.1466 - val_accuracy: 0.9451\n",
      "Epoch 9/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.1505 - accuracy: 0.9435 - val_loss: 0.1401 - val_accuracy: 0.9462\n",
      "Epoch 10/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.1442 - accuracy: 0.9477 - val_loss: 0.1450 - val_accuracy: 0.9435\n",
      "Epoch 11/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.1369 - accuracy: 0.9511 - val_loss: 0.1380 - val_accuracy: 0.9491\n",
      "Epoch 12/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.1336 - accuracy: 0.9513 - val_loss: 0.1344 - val_accuracy: 0.9524\n",
      "Epoch 13/200\n",
      "22000/22000 [==============================] - 1s 56us/sample - loss: 0.1284 - accuracy: 0.9542 - val_loss: 0.1281 - val_accuracy: 0.9525\n",
      "Epoch 14/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.1249 - accuracy: 0.9557 - val_loss: 0.1339 - val_accuracy: 0.9500\n",
      "Epoch 15/200\n",
      "22000/22000 [==============================] - 1s 58us/sample - loss: 0.1198 - accuracy: 0.9581 - val_loss: 0.1283 - val_accuracy: 0.9540\n",
      "Epoch 16/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.1169 - accuracy: 0.9583 - val_loss: 0.1293 - val_accuracy: 0.9513\n",
      "Epoch 17/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.1119 - accuracy: 0.9594 - val_loss: 0.1199 - val_accuracy: 0.9553\n",
      "Epoch 18/200\n",
      "22000/22000 [==============================] - 1s 56us/sample - loss: 0.1086 - accuracy: 0.9614 - val_loss: 0.1227 - val_accuracy: 0.9553\n",
      "Epoch 19/200\n",
      "22000/22000 [==============================] - 1s 62us/sample - loss: 0.1081 - accuracy: 0.9613 - val_loss: 0.1202 - val_accuracy: 0.9567\n",
      "Epoch 20/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.1040 - accuracy: 0.9622 - val_loss: 0.1178 - val_accuracy: 0.9575\n",
      "Epoch 21/200\n",
      "22000/22000 [==============================] - 1s 56us/sample - loss: 0.0962 - accuracy: 0.9659 - val_loss: 0.1137 - val_accuracy: 0.9595\n",
      "Epoch 22/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.0950 - accuracy: 0.9670 - val_loss: 0.1165 - val_accuracy: 0.9605\n",
      "Epoch 23/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.0925 - accuracy: 0.9661 - val_loss: 0.1184 - val_accuracy: 0.9580\n",
      "Epoch 24/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.0904 - accuracy: 0.9680 - val_loss: 0.1110 - val_accuracy: 0.9602\n",
      "Epoch 25/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.0886 - accuracy: 0.9675 - val_loss: 0.1085 - val_accuracy: 0.9618\n",
      "Epoch 26/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.0838 - accuracy: 0.9689 - val_loss: 0.1153 - val_accuracy: 0.9605\n",
      "Epoch 27/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.0812 - accuracy: 0.9712 - val_loss: 0.1129 - val_accuracy: 0.9624\n",
      "Epoch 28/200\n",
      "22000/22000 [==============================] - 1s 56us/sample - loss: 0.0826 - accuracy: 0.9696 - val_loss: 0.1071 - val_accuracy: 0.9636\n",
      "Epoch 29/200\n",
      "22000/22000 [==============================] - 1s 59us/sample - loss: 0.0793 - accuracy: 0.9724 - val_loss: 0.1104 - val_accuracy: 0.9618\n",
      "Epoch 30/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.0767 - accuracy: 0.9722 - val_loss: 0.1080 - val_accuracy: 0.9611\n",
      "Epoch 31/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.0699 - accuracy: 0.9745 - val_loss: 0.1107 - val_accuracy: 0.9611\n",
      "Epoch 32/200\n",
      "22000/22000 [==============================] - 1s 59us/sample - loss: 0.0745 - accuracy: 0.9731 - val_loss: 0.1040 - val_accuracy: 0.9642\n",
      "Epoch 33/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.0733 - accuracy: 0.9740 - val_loss: 0.1062 - val_accuracy: 0.9631\n",
      "Epoch 34/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.0679 - accuracy: 0.9749 - val_loss: 0.1067 - val_accuracy: 0.9645\n",
      "Epoch 35/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.0697 - accuracy: 0.9757 - val_loss: 0.1167 - val_accuracy: 0.9604\n",
      "Epoch 36/200\n",
      "22000/22000 [==============================] - 1s 61us/sample - loss: 0.0704 - accuracy: 0.9756 - val_loss: 0.1054 - val_accuracy: 0.9647\n",
      "Epoch 37/200\n",
      "22000/22000 [==============================] - 2s 75us/sample - loss: 0.0616 - accuracy: 0.9777 - val_loss: 0.1062 - val_accuracy: 0.9655\n",
      "Epoch 38/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.0664 - accuracy: 0.9763 - val_loss: 0.1044 - val_accuracy: 0.9676\n",
      "Epoch 39/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.0615 - accuracy: 0.9782 - val_loss: 0.0943 - val_accuracy: 0.9673\n",
      "Epoch 40/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.0941 - val_accuracy: 0.9689\n",
      "Epoch 41/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.0634 - accuracy: 0.9765 - val_loss: 0.1002 - val_accuracy: 0.9671\n",
      "Epoch 42/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.0596 - accuracy: 0.9796 - val_loss: 0.1016 - val_accuracy: 0.9691\n",
      "Epoch 43/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.0588 - accuracy: 0.9794 - val_loss: 0.0991 - val_accuracy: 0.9680\n",
      "Epoch 44/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.0562 - accuracy: 0.9805 - val_loss: 0.1020 - val_accuracy: 0.9664\n",
      "Epoch 45/200\n",
      "22000/22000 [==============================] - 1s 57us/sample - loss: 0.0556 - accuracy: 0.9796 - val_loss: 0.0952 - val_accuracy: 0.9698\n",
      "Epoch 46/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.0556 - accuracy: 0.9806 - val_loss: 0.1047 - val_accuracy: 0.9675\n",
      "Epoch 47/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.0537 - accuracy: 0.9814 - val_loss: 0.0993 - val_accuracy: 0.9675\n",
      "Epoch 48/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.0520 - accuracy: 0.9810 - val_loss: 0.1041 - val_accuracy: 0.9651\n",
      "Epoch 49/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.0523 - accuracy: 0.9804 - val_loss: 0.0963 - val_accuracy: 0.9691\n",
      "Epoch 50/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.0525 - accuracy: 0.9811 - val_loss: 0.0916 - val_accuracy: 0.9718\n",
      "Epoch 51/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.0480 - accuracy: 0.9819 - val_loss: 0.0960 - val_accuracy: 0.9704\n",
      "Epoch 52/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.0476 - accuracy: 0.9826 - val_loss: 0.0964 - val_accuracy: 0.9716\n",
      "Epoch 53/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.0455 - accuracy: 0.9829 - val_loss: 0.0955 - val_accuracy: 0.9705\n",
      "Epoch 54/200\n",
      "22000/22000 [==============================] - 1s 60us/sample - loss: 0.0463 - accuracy: 0.9846 - val_loss: 0.0892 - val_accuracy: 0.9700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.0470 - accuracy: 0.9831 - val_loss: 0.0987 - val_accuracy: 0.9711\n",
      "Epoch 56/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.0454 - accuracy: 0.9846 - val_loss: 0.1004 - val_accuracy: 0.9695\n",
      "Epoch 57/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.0421 - accuracy: 0.9840 - val_loss: 0.0979 - val_accuracy: 0.9684\n",
      "Epoch 58/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.0417 - accuracy: 0.9856 - val_loss: 0.0990 - val_accuracy: 0.9693\n",
      "Epoch 59/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.0447 - accuracy: 0.9842 - val_loss: 0.0931 - val_accuracy: 0.9727\n",
      "Epoch 60/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.0440 - accuracy: 0.9837 - val_loss: 0.0964 - val_accuracy: 0.9711\n",
      "Epoch 61/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.0411 - accuracy: 0.9854 - val_loss: 0.1010 - val_accuracy: 0.9685\n",
      "Epoch 62/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.0390 - accuracy: 0.9864 - val_loss: 0.1019 - val_accuracy: 0.9707\n",
      "Epoch 63/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.0439 - accuracy: 0.9838 - val_loss: 0.0981 - val_accuracy: 0.9696\n",
      "Epoch 64/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.0402 - accuracy: 0.9861 - val_loss: 0.1021 - val_accuracy: 0.9716\n",
      "Epoch 65/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.0371 - accuracy: 0.9869 - val_loss: 0.0982 - val_accuracy: 0.9711\n",
      "Epoch 66/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.0380 - accuracy: 0.9863 - val_loss: 0.0916 - val_accuracy: 0.9725\n",
      "Epoch 67/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.0376 - accuracy: 0.9860 - val_loss: 0.1004 - val_accuracy: 0.9711\n",
      "Epoch 68/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.0376 - accuracy: 0.9867 - val_loss: 0.1024 - val_accuracy: 0.9722\n",
      "Epoch 69/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.0365 - accuracy: 0.9873 - val_loss: 0.0992 - val_accuracy: 0.9727\n",
      "Epoch 70/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.0343 - accuracy: 0.9875 - val_loss: 0.0971 - val_accuracy: 0.9742\n",
      "Epoch 71/200\n",
      "22000/22000 [==============================] - 1s 56us/sample - loss: 0.0361 - accuracy: 0.9877 - val_loss: 0.1017 - val_accuracy: 0.9716\n",
      "Epoch 72/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.0346 - accuracy: 0.9878 - val_loss: 0.1003 - val_accuracy: 0.9709\n",
      "Epoch 73/200\n",
      "22000/22000 [==============================] - 1s 56us/sample - loss: 0.0379 - accuracy: 0.9857 - val_loss: 0.1024 - val_accuracy: 0.9716\n",
      "Epoch 74/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.0340 - accuracy: 0.9878 - val_loss: 0.1305 - val_accuracy: 0.9678\n",
      "Epoch 75/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.0328 - accuracy: 0.9883 - val_loss: 0.0962 - val_accuracy: 0.9729\n",
      "Epoch 76/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.0316 - accuracy: 0.9886 - val_loss: 0.1243 - val_accuracy: 0.9716\n",
      "Epoch 77/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.0315 - accuracy: 0.9891 - val_loss: 0.0965 - val_accuracy: 0.9720\n",
      "Epoch 78/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.0324 - accuracy: 0.9879 - val_loss: 0.0973 - val_accuracy: 0.9709\n",
      "Epoch 79/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.0346 - accuracy: 0.9880 - val_loss: 0.0942 - val_accuracy: 0.9722\n",
      "Epoch 80/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.0311 - accuracy: 0.9885 - val_loss: 0.1078 - val_accuracy: 0.9722\n",
      "Epoch 81/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.0319 - accuracy: 0.9879 - val_loss: 0.0868 - val_accuracy: 0.9756\n",
      "Epoch 82/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.0303 - accuracy: 0.9889 - val_loss: 0.1028 - val_accuracy: 0.9729\n",
      "Epoch 83/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.0292 - accuracy: 0.9900 - val_loss: 0.1100 - val_accuracy: 0.9715\n",
      "Epoch 84/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.0284 - accuracy: 0.9901 - val_loss: 0.1131 - val_accuracy: 0.9740\n",
      "Epoch 85/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.0319 - accuracy: 0.9893 - val_loss: 0.0932 - val_accuracy: 0.9751\n",
      "Epoch 86/200\n",
      "22000/22000 [==============================] - 1s 59us/sample - loss: 0.0309 - accuracy: 0.9885 - val_loss: 0.0911 - val_accuracy: 0.9727\n",
      "Epoch 87/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.0354 - accuracy: 0.9875 - val_loss: 0.0936 - val_accuracy: 0.9718\n",
      "Epoch 88/200\n",
      "22000/22000 [==============================] - 1s 60us/sample - loss: 0.0306 - accuracy: 0.9894 - val_loss: 0.0983 - val_accuracy: 0.9740\n",
      "Epoch 89/200\n",
      "22000/22000 [==============================] - 1s 65us/sample - loss: 0.0289 - accuracy: 0.9902 - val_loss: 0.1005 - val_accuracy: 0.9740\n",
      "Epoch 90/200\n",
      "22000/22000 [==============================] - 1s 56us/sample - loss: 0.0275 - accuracy: 0.9900 - val_loss: 0.0909 - val_accuracy: 0.9745\n",
      "Epoch 91/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.0285 - accuracy: 0.9896 - val_loss: 0.1105 - val_accuracy: 0.9696\n",
      "Epoch 92/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.0310 - accuracy: 0.9894 - val_loss: 0.0971 - val_accuracy: 0.9724\n",
      "Epoch 93/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.0256 - accuracy: 0.9913 - val_loss: 0.0908 - val_accuracy: 0.9755\n",
      "Epoch 94/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.0289 - accuracy: 0.9907 - val_loss: 0.1049 - val_accuracy: 0.9709\n",
      "Epoch 95/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.0283 - accuracy: 0.9900 - val_loss: 0.1034 - val_accuracy: 0.9733\n",
      "Epoch 96/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.0277 - accuracy: 0.9900 - val_loss: 0.0946 - val_accuracy: 0.9740\n",
      "Epoch 97/200\n",
      "22000/22000 [==============================] - 1s 59us/sample - loss: 0.0274 - accuracy: 0.9905 - val_loss: 0.1077 - val_accuracy: 0.9733\n",
      "Epoch 98/200\n",
      "22000/22000 [==============================] - 1s 59us/sample - loss: 0.0281 - accuracy: 0.9901 - val_loss: 0.1012 - val_accuracy: 0.9735\n",
      "Epoch 99/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.0268 - accuracy: 0.9901 - val_loss: 0.0962 - val_accuracy: 0.9765\n",
      "Epoch 100/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.0258 - accuracy: 0.9906 - val_loss: 0.1060 - val_accuracy: 0.9760\n",
      "Epoch 101/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.0271 - accuracy: 0.9906 - val_loss: 0.0951 - val_accuracy: 0.9753\n",
      "Epoch 102/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.0281 - accuracy: 0.9909 - val_loss: 0.0864 - val_accuracy: 0.9762\n",
      "Epoch 103/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.0282 - accuracy: 0.9900 - val_loss: 0.0901 - val_accuracy: 0.9755\n",
      "Epoch 104/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.0256 - accuracy: 0.9914 - val_loss: 0.0867 - val_accuracy: 0.9762\n",
      "Epoch 105/200\n",
      "22000/22000 [==============================] - 1s 63us/sample - loss: 0.0269 - accuracy: 0.9907 - val_loss: 0.1015 - val_accuracy: 0.9751\n",
      "Epoch 106/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.0262 - accuracy: 0.9909 - val_loss: 0.0899 - val_accuracy: 0.9751\n",
      "Epoch 107/200\n",
      "22000/22000 [==============================] - 1s 60us/sample - loss: 0.0237 - accuracy: 0.9907 - val_loss: 0.0909 - val_accuracy: 0.9756\n",
      "Epoch 108/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.0249 - accuracy: 0.9917 - val_loss: 0.0974 - val_accuracy: 0.9740\n",
      "Epoch 109/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.0251 - accuracy: 0.9912 - val_loss: 0.0939 - val_accuracy: 0.9755\n",
      "Epoch 110/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.0237 - accuracy: 0.9918 - val_loss: 0.0954 - val_accuracy: 0.9744\n",
      "Epoch 111/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.0253 - accuracy: 0.9911 - val_loss: 0.0980 - val_accuracy: 0.9769\n",
      "Epoch 112/200\n",
      "22000/22000 [==============================] - 1s 56us/sample - loss: 0.0249 - accuracy: 0.9915 - val_loss: 0.1048 - val_accuracy: 0.9736\n",
      "Epoch 113/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.0234 - accuracy: 0.9921 - val_loss: 0.1058 - val_accuracy: 0.9760\n",
      "Epoch 114/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.0247 - accuracy: 0.9915 - val_loss: 0.0907 - val_accuracy: 0.9762\n",
      "Epoch 115/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.0243 - accuracy: 0.9920 - val_loss: 0.0936 - val_accuracy: 0.9755\n",
      "Epoch 116/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.0217 - accuracy: 0.9929 - val_loss: 0.1015 - val_accuracy: 0.9740\n",
      "Epoch 117/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.0246 - accuracy: 0.9912 - val_loss: 0.0966 - val_accuracy: 0.9756\n",
      "Epoch 118/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.0243 - accuracy: 0.9920 - val_loss: 0.0972 - val_accuracy: 0.9756\n",
      "Epoch 119/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.0204 - accuracy: 0.9929 - val_loss: 0.0997 - val_accuracy: 0.9744\n",
      "Epoch 120/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.0231 - accuracy: 0.9921 - val_loss: 0.1017 - val_accuracy: 0.9747\n",
      "Epoch 121/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.0228 - accuracy: 0.9924 - val_loss: 0.1035 - val_accuracy: 0.9753\n",
      "Epoch 122/200\n",
      "22000/22000 [==============================] - 1s 57us/sample - loss: 0.0214 - accuracy: 0.9922 - val_loss: 0.1016 - val_accuracy: 0.9744\n",
      "Epoch 123/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.0184 - accuracy: 0.9939 - val_loss: 0.1150 - val_accuracy: 0.9762\n",
      "Epoch 124/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.0216 - accuracy: 0.9924 - val_loss: 0.1052 - val_accuracy: 0.9753\n",
      "Epoch 125/200\n",
      "22000/22000 [==============================] - 1s 58us/sample - loss: 0.0215 - accuracy: 0.9925 - val_loss: 0.0962 - val_accuracy: 0.9747\n",
      "Epoch 126/200\n",
      "22000/22000 [==============================] - 1s 56us/sample - loss: 0.0211 - accuracy: 0.9931 - val_loss: 0.0955 - val_accuracy: 0.9747\n",
      "Epoch 127/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.0221 - accuracy: 0.9920 - val_loss: 0.0957 - val_accuracy: 0.9740\n",
      "Epoch 128/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.0230 - accuracy: 0.9926 - val_loss: 0.1069 - val_accuracy: 0.9765\n",
      "Epoch 129/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.0206 - accuracy: 0.9922 - val_loss: 0.0945 - val_accuracy: 0.9764\n",
      "Epoch 130/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.0199 - accuracy: 0.9934 - val_loss: 0.0995 - val_accuracy: 0.9745\n",
      "Epoch 131/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.0201 - accuracy: 0.9930 - val_loss: 0.1164 - val_accuracy: 0.9764\n",
      "test:0.946036\n",
      "valid:0.976909\n",
      "train:0.999455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9994545454545455, 0.976909090909091, 0.9460363636363637)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = StandardScaler(with_mean=True)\n",
    "feature_sc = sc.fit_transform(feature)\n",
    "feature2_sc = sc.transform(feature2)\n",
    "train_model(model,feature_sc,np.array(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:0.961448\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9614476143529074"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(model,feature2_sc,np.array(y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9988181818181818,\n",
       " 0.9772727272727273,\n",
       " 0.9345454545454546,\n",
       " 0.9541356008790848]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0.9988181818181818, 0.9772727272727273, 0.9345454545454546, 0.9541356008790848]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test feature from Left or Right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22000 samples, validate on 5500 samples\n",
      "Epoch 1/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2241 - accuracy: 0.9136 - val_loss: 0.2032 - val_accuracy: 0.9209\n",
      "Epoch 2/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2155 - accuracy: 0.9158 - val_loss: 0.2035 - val_accuracy: 0.9209\n",
      "Epoch 3/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.2134 - accuracy: 0.9179 - val_loss: 0.1939 - val_accuracy: 0.9265\n",
      "Epoch 4/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.2123 - accuracy: 0.9189 - val_loss: 0.1922 - val_accuracy: 0.9251\n",
      "Epoch 5/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2100 - accuracy: 0.9196 - val_loss: 0.1929 - val_accuracy: 0.9229\n",
      "Epoch 6/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2049 - accuracy: 0.9211 - val_loss: 0.1937 - val_accuracy: 0.9236\n",
      "Epoch 7/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2021 - accuracy: 0.9231 - val_loss: 0.1897 - val_accuracy: 0.9235\n",
      "Epoch 8/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.2034 - accuracy: 0.9211 - val_loss: 0.1887 - val_accuracy: 0.9265\n",
      "Epoch 9/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.2010 - accuracy: 0.9213 - val_loss: 0.1895 - val_accuracy: 0.9264\n",
      "Epoch 10/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.1949 - accuracy: 0.9254 - val_loss: 0.1854 - val_accuracy: 0.9264\n",
      "Epoch 11/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.1940 - accuracy: 0.9249 - val_loss: 0.1966 - val_accuracy: 0.9224\n",
      "Epoch 12/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1942 - accuracy: 0.9247 - val_loss: 0.1853 - val_accuracy: 0.9287\n",
      "Epoch 13/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.1928 - accuracy: 0.9260 - val_loss: 0.1863 - val_accuracy: 0.9285\n",
      "Epoch 14/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.1884 - accuracy: 0.9277 - val_loss: 0.1777 - val_accuracy: 0.9318\n",
      "Epoch 15/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.1854 - accuracy: 0.9284 - val_loss: 0.1801 - val_accuracy: 0.9302\n",
      "Epoch 16/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.1842 - accuracy: 0.9302 - val_loss: 0.1810 - val_accuracy: 0.9311\n",
      "Epoch 17/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.1793 - accuracy: 0.9302 - val_loss: 0.1767 - val_accuracy: 0.9315\n",
      "Epoch 18/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.1816 - accuracy: 0.9295 - val_loss: 0.1745 - val_accuracy: 0.9347\n",
      "Epoch 19/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.1767 - accuracy: 0.9312 - val_loss: 0.1763 - val_accuracy: 0.9322\n",
      "Epoch 20/200\n",
      "22000/22000 [==============================] - 1s 56us/sample - loss: 0.1739 - accuracy: 0.9340 - val_loss: 0.1787 - val_accuracy: 0.9325\n",
      "Epoch 21/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.1774 - accuracy: 0.9333 - val_loss: 0.1797 - val_accuracy: 0.9340\n",
      "Epoch 22/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1734 - accuracy: 0.9341 - val_loss: 0.1711 - val_accuracy: 0.9329\n",
      "Epoch 23/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.1725 - accuracy: 0.9345 - val_loss: 0.1727 - val_accuracy: 0.9356\n",
      "Epoch 24/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1684 - accuracy: 0.9377 - val_loss: 0.1714 - val_accuracy: 0.9347\n",
      "Epoch 25/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.1699 - accuracy: 0.9362 - val_loss: 0.1689 - val_accuracy: 0.9347\n",
      "Epoch 26/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.1634 - accuracy: 0.9367 - val_loss: 0.1674 - val_accuracy: 0.9375\n",
      "Epoch 27/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.1651 - accuracy: 0.9361 - val_loss: 0.1737 - val_accuracy: 0.9342\n",
      "Epoch 28/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.1614 - accuracy: 0.9400 - val_loss: 0.1685 - val_accuracy: 0.9349\n",
      "Epoch 29/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.1612 - accuracy: 0.9375 - val_loss: 0.1688 - val_accuracy: 0.9342\n",
      "Epoch 30/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.1631 - accuracy: 0.9377 - val_loss: 0.1690 - val_accuracy: 0.9347\n",
      "Epoch 31/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1604 - accuracy: 0.9391 - val_loss: 0.1657 - val_accuracy: 0.9376\n",
      "Epoch 32/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.1558 - accuracy: 0.9409 - val_loss: 0.1682 - val_accuracy: 0.9369\n",
      "Epoch 33/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.1547 - accuracy: 0.9411 - val_loss: 0.1704 - val_accuracy: 0.9345\n",
      "Epoch 34/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1520 - accuracy: 0.9430 - val_loss: 0.1690 - val_accuracy: 0.9362\n",
      "Epoch 35/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.1551 - accuracy: 0.9420 - val_loss: 0.1684 - val_accuracy: 0.9396\n",
      "Epoch 36/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1529 - accuracy: 0.9440 - val_loss: 0.1624 - val_accuracy: 0.9385\n",
      "Epoch 37/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.1500 - accuracy: 0.9435 - val_loss: 0.1688 - val_accuracy: 0.9369\n",
      "Epoch 38/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1488 - accuracy: 0.9434 - val_loss: 0.1666 - val_accuracy: 0.9382\n",
      "Epoch 39/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.1490 - accuracy: 0.9435 - val_loss: 0.1574 - val_accuracy: 0.9400\n",
      "Epoch 40/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.1480 - accuracy: 0.9445 - val_loss: 0.1649 - val_accuracy: 0.9395\n",
      "Epoch 41/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1462 - accuracy: 0.9458 - val_loss: 0.1551 - val_accuracy: 0.9435\n",
      "Epoch 42/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1475 - accuracy: 0.9432 - val_loss: 0.1596 - val_accuracy: 0.9371\n",
      "Epoch 43/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1396 - accuracy: 0.9465 - val_loss: 0.1587 - val_accuracy: 0.9395\n",
      "Epoch 44/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.1471 - accuracy: 0.9460 - val_loss: 0.1603 - val_accuracy: 0.9404\n",
      "Epoch 45/200\n",
      "22000/22000 [==============================] - 1s 59us/sample - loss: 0.1453 - accuracy: 0.9446 - val_loss: 0.1607 - val_accuracy: 0.9411\n",
      "Epoch 46/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.1404 - accuracy: 0.9470 - val_loss: 0.1636 - val_accuracy: 0.9416\n",
      "Epoch 47/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.1420 - accuracy: 0.9471 - val_loss: 0.1536 - val_accuracy: 0.9405\n",
      "Epoch 48/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.1427 - accuracy: 0.9461 - val_loss: 0.1554 - val_accuracy: 0.9415\n",
      "Epoch 49/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.1396 - accuracy: 0.9467 - val_loss: 0.1567 - val_accuracy: 0.9400\n",
      "Epoch 50/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1383 - accuracy: 0.9479 - val_loss: 0.1562 - val_accuracy: 0.9404\n",
      "Epoch 51/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.1372 - accuracy: 0.9490 - val_loss: 0.1530 - val_accuracy: 0.9427\n",
      "Epoch 52/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.1334 - accuracy: 0.9510 - val_loss: 0.1676 - val_accuracy: 0.9420\n",
      "Epoch 53/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.1338 - accuracy: 0.9495 - val_loss: 0.1666 - val_accuracy: 0.9411\n",
      "Epoch 54/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1304 - accuracy: 0.9516 - val_loss: 0.1532 - val_accuracy: 0.9425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.1317 - accuracy: 0.9516 - val_loss: 0.1511 - val_accuracy: 0.9425\n",
      "Epoch 56/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.1310 - accuracy: 0.9508 - val_loss: 0.1519 - val_accuracy: 0.9425\n",
      "Epoch 57/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.1302 - accuracy: 0.9520 - val_loss: 0.1557 - val_accuracy: 0.9427\n",
      "Epoch 58/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.1304 - accuracy: 0.9522 - val_loss: 0.1572 - val_accuracy: 0.9429\n",
      "Epoch 59/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.1307 - accuracy: 0.9510 - val_loss: 0.1539 - val_accuracy: 0.9398\n",
      "Epoch 60/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.1269 - accuracy: 0.9529 - val_loss: 0.1518 - val_accuracy: 0.9445\n",
      "Epoch 61/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.1259 - accuracy: 0.9534 - val_loss: 0.1551 - val_accuracy: 0.9418\n",
      "Epoch 62/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.1307 - accuracy: 0.9514 - val_loss: 0.1533 - val_accuracy: 0.9427\n",
      "Epoch 63/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1241 - accuracy: 0.9533 - val_loss: 0.1551 - val_accuracy: 0.9436\n",
      "Epoch 64/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.1241 - accuracy: 0.9542 - val_loss: 0.1579 - val_accuracy: 0.9438\n",
      "Epoch 65/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.1264 - accuracy: 0.9522 - val_loss: 0.1540 - val_accuracy: 0.9433\n",
      "Epoch 66/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.1266 - accuracy: 0.9522 - val_loss: 0.1567 - val_accuracy: 0.9438\n",
      "Epoch 67/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.1239 - accuracy: 0.9546 - val_loss: 0.1584 - val_accuracy: 0.9456\n",
      "Epoch 68/200\n",
      "22000/22000 [==============================] - 2s 73us/sample - loss: 0.1221 - accuracy: 0.9548 - val_loss: 0.1518 - val_accuracy: 0.9433\n",
      "Epoch 69/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.1241 - accuracy: 0.9541 - val_loss: 0.1531 - val_accuracy: 0.9429\n",
      "Epoch 70/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.1199 - accuracy: 0.9545 - val_loss: 0.1526 - val_accuracy: 0.9447\n",
      "Epoch 71/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.1187 - accuracy: 0.9562 - val_loss: 0.1530 - val_accuracy: 0.9438\n",
      "Epoch 72/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.1195 - accuracy: 0.9557 - val_loss: 0.1557 - val_accuracy: 0.9415\n",
      "Epoch 73/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1191 - accuracy: 0.9565 - val_loss: 0.1513 - val_accuracy: 0.9445\n",
      "Epoch 74/200\n",
      "22000/22000 [==============================] - 1s 58us/sample - loss: 0.1195 - accuracy: 0.9561 - val_loss: 0.1512 - val_accuracy: 0.9424\n",
      "Epoch 75/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.1167 - accuracy: 0.9570 - val_loss: 0.1534 - val_accuracy: 0.9449\n",
      "Epoch 76/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.1169 - accuracy: 0.9569 - val_loss: 0.1553 - val_accuracy: 0.9427\n",
      "Epoch 77/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1188 - accuracy: 0.9548 - val_loss: 0.1511 - val_accuracy: 0.9436\n",
      "Epoch 78/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.1119 - accuracy: 0.9587 - val_loss: 0.1632 - val_accuracy: 0.9436\n",
      "Epoch 79/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.1149 - accuracy: 0.9584 - val_loss: 0.1473 - val_accuracy: 0.9458\n",
      "Epoch 80/200\n",
      "22000/22000 [==============================] - 1s 61us/sample - loss: 0.1191 - accuracy: 0.9545 - val_loss: 0.1536 - val_accuracy: 0.9456\n",
      "Epoch 81/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.1154 - accuracy: 0.9573 - val_loss: 0.1510 - val_accuracy: 0.9453\n",
      "Epoch 82/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.1149 - accuracy: 0.9557 - val_loss: 0.1490 - val_accuracy: 0.9442\n",
      "Epoch 83/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.1106 - accuracy: 0.9589 - val_loss: 0.1523 - val_accuracy: 0.9478\n",
      "Epoch 84/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.1172 - accuracy: 0.9567 - val_loss: 0.1458 - val_accuracy: 0.9482\n",
      "Epoch 85/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.1097 - accuracy: 0.9591 - val_loss: 0.1489 - val_accuracy: 0.9435\n",
      "Epoch 86/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.1132 - accuracy: 0.9578 - val_loss: 0.1515 - val_accuracy: 0.9467\n",
      "Epoch 87/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1136 - accuracy: 0.9575 - val_loss: 0.1470 - val_accuracy: 0.9453\n",
      "Epoch 88/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.1113 - accuracy: 0.9586 - val_loss: 0.1443 - val_accuracy: 0.9449\n",
      "Epoch 89/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.1092 - accuracy: 0.9611 - val_loss: 0.1494 - val_accuracy: 0.9453\n",
      "Epoch 90/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.1111 - accuracy: 0.9590 - val_loss: 0.1515 - val_accuracy: 0.9449\n",
      "Epoch 91/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.1104 - accuracy: 0.9606 - val_loss: 0.1459 - val_accuracy: 0.9478\n",
      "Epoch 92/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.1072 - accuracy: 0.9608 - val_loss: 0.1438 - val_accuracy: 0.9469\n",
      "Epoch 93/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1093 - accuracy: 0.9591 - val_loss: 0.1473 - val_accuracy: 0.9495\n",
      "Epoch 94/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.1074 - accuracy: 0.9620 - val_loss: 0.1371 - val_accuracy: 0.9496\n",
      "Epoch 95/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.1047 - accuracy: 0.9632 - val_loss: 0.1486 - val_accuracy: 0.9476\n",
      "Epoch 96/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.1056 - accuracy: 0.9610 - val_loss: 0.1519 - val_accuracy: 0.9473\n",
      "Epoch 97/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.1055 - accuracy: 0.9611 - val_loss: 0.1491 - val_accuracy: 0.9455\n",
      "Epoch 98/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.1060 - accuracy: 0.9610 - val_loss: 0.1464 - val_accuracy: 0.9471\n",
      "Epoch 99/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.1088 - accuracy: 0.9600 - val_loss: 0.1437 - val_accuracy: 0.9504\n",
      "Epoch 100/200\n",
      "22000/22000 [==============================] - 1s 56us/sample - loss: 0.1015 - accuracy: 0.9640 - val_loss: 0.1425 - val_accuracy: 0.9502\n",
      "Epoch 101/200\n",
      "22000/22000 [==============================] - 1s 56us/sample - loss: 0.1043 - accuracy: 0.9617 - val_loss: 0.1426 - val_accuracy: 0.9515\n",
      "Epoch 102/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.1034 - accuracy: 0.9625 - val_loss: 0.1465 - val_accuracy: 0.9478\n",
      "Epoch 103/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.0981 - accuracy: 0.9650 - val_loss: 0.1508 - val_accuracy: 0.9476\n",
      "Epoch 104/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.1016 - accuracy: 0.9625 - val_loss: 0.1416 - val_accuracy: 0.9513\n",
      "Epoch 105/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.1027 - accuracy: 0.9622 - val_loss: 0.1398 - val_accuracy: 0.9509\n",
      "Epoch 106/200\n",
      "22000/22000 [==============================] - 1s 56us/sample - loss: 0.1015 - accuracy: 0.9621 - val_loss: 0.1451 - val_accuracy: 0.9507\n",
      "Epoch 107/200\n",
      "22000/22000 [==============================] - 1s 60us/sample - loss: 0.1010 - accuracy: 0.9635 - val_loss: 0.1468 - val_accuracy: 0.9491\n",
      "Epoch 108/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.1034 - accuracy: 0.9634 - val_loss: 0.1441 - val_accuracy: 0.9505\n",
      "Epoch 109/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1005 - accuracy: 0.9637 - val_loss: 0.1443 - val_accuracy: 0.9484\n",
      "Epoch 110/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.0973 - accuracy: 0.9643 - val_loss: 0.1532 - val_accuracy: 0.9480\n",
      "Epoch 111/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.0996 - accuracy: 0.9648 - val_loss: 0.1495 - val_accuracy: 0.9487\n",
      "Epoch 112/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.1007 - accuracy: 0.9637 - val_loss: 0.1411 - val_accuracy: 0.9531\n",
      "Epoch 113/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.0992 - accuracy: 0.9640 - val_loss: 0.1392 - val_accuracy: 0.9482\n",
      "Epoch 114/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.0982 - accuracy: 0.9649 - val_loss: 0.1438 - val_accuracy: 0.9505\n",
      "Epoch 115/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.0999 - accuracy: 0.9635 - val_loss: 0.1439 - val_accuracy: 0.9495\n",
      "Epoch 116/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.0994 - accuracy: 0.9645 - val_loss: 0.1468 - val_accuracy: 0.9493\n",
      "Epoch 117/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.0962 - accuracy: 0.9635 - val_loss: 0.1426 - val_accuracy: 0.9536\n",
      "Epoch 118/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1025 - accuracy: 0.9630 - val_loss: 0.1405 - val_accuracy: 0.9516\n",
      "Epoch 119/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.0978 - accuracy: 0.9640 - val_loss: 0.1411 - val_accuracy: 0.9496\n",
      "Epoch 120/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.0935 - accuracy: 0.9652 - val_loss: 0.1529 - val_accuracy: 0.9469\n",
      "Epoch 121/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.0972 - accuracy: 0.9641 - val_loss: 0.1449 - val_accuracy: 0.9496\n",
      "Epoch 122/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.0961 - accuracy: 0.9660 - val_loss: 0.1503 - val_accuracy: 0.9495\n",
      "Epoch 123/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.0966 - accuracy: 0.9647 - val_loss: 0.1392 - val_accuracy: 0.9502\n",
      "Epoch 124/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.0921 - accuracy: 0.9668 - val_loss: 0.1497 - val_accuracy: 0.9495\n",
      "Epoch 125/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.0932 - accuracy: 0.9656 - val_loss: 0.1474 - val_accuracy: 0.9498\n",
      "Epoch 126/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.0943 - accuracy: 0.9652 - val_loss: 0.1409 - val_accuracy: 0.9491\n",
      "Epoch 127/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.0927 - accuracy: 0.9676 - val_loss: 0.1399 - val_accuracy: 0.9509\n",
      "Epoch 128/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.0914 - accuracy: 0.9677 - val_loss: 0.1444 - val_accuracy: 0.9520\n",
      "Epoch 129/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.0943 - accuracy: 0.9655 - val_loss: 0.1484 - val_accuracy: 0.9507\n",
      "Epoch 130/200\n",
      "22000/22000 [==============================] - 1s 62us/sample - loss: 0.0958 - accuracy: 0.9646 - val_loss: 0.1436 - val_accuracy: 0.9511\n",
      "Epoch 131/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.0912 - accuracy: 0.9667 - val_loss: 0.1522 - val_accuracy: 0.9487\n",
      "Epoch 132/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.0932 - accuracy: 0.9660 - val_loss: 0.1386 - val_accuracy: 0.9505\n",
      "Epoch 133/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.0882 - accuracy: 0.9680 - val_loss: 0.1467 - val_accuracy: 0.9513\n",
      "Epoch 134/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.0935 - accuracy: 0.9681 - val_loss: 0.1373 - val_accuracy: 0.9511\n",
      "Epoch 135/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.0939 - accuracy: 0.9652 - val_loss: 0.1367 - val_accuracy: 0.9513\n",
      "Epoch 136/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.0924 - accuracy: 0.9670 - val_loss: 0.1401 - val_accuracy: 0.9544\n",
      "Epoch 137/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.0910 - accuracy: 0.9680 - val_loss: 0.1417 - val_accuracy: 0.9509\n",
      "Epoch 138/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.0912 - accuracy: 0.9684 - val_loss: 0.1365 - val_accuracy: 0.9505\n",
      "Epoch 139/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.0916 - accuracy: 0.9663 - val_loss: 0.1392 - val_accuracy: 0.9531\n",
      "Epoch 140/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.0893 - accuracy: 0.9683 - val_loss: 0.1424 - val_accuracy: 0.9507\n",
      "Epoch 141/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.0880 - accuracy: 0.9676 - val_loss: 0.1407 - val_accuracy: 0.9531\n",
      "Epoch 142/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.0859 - accuracy: 0.9694 - val_loss: 0.1394 - val_accuracy: 0.9533\n",
      "Epoch 143/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.0936 - accuracy: 0.9655 - val_loss: 0.1411 - val_accuracy: 0.9520\n",
      "Epoch 144/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.0883 - accuracy: 0.9681 - val_loss: 0.1478 - val_accuracy: 0.9518\n",
      "Epoch 145/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.0856 - accuracy: 0.9695 - val_loss: 0.1435 - val_accuracy: 0.9507\n",
      "Epoch 146/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.0892 - accuracy: 0.9671 - val_loss: 0.1459 - val_accuracy: 0.9518\n",
      "Epoch 147/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.0856 - accuracy: 0.9696 - val_loss: 0.1465 - val_accuracy: 0.9513\n",
      "Epoch 148/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.0836 - accuracy: 0.9701 - val_loss: 0.1485 - val_accuracy: 0.9509\n",
      "Epoch 149/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.0877 - accuracy: 0.9674 - val_loss: 0.1406 - val_accuracy: 0.9524\n",
      "Epoch 150/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.0850 - accuracy: 0.9704 - val_loss: 0.1599 - val_accuracy: 0.9495\n",
      "Epoch 151/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.0883 - accuracy: 0.9683 - val_loss: 0.1389 - val_accuracy: 0.9524\n",
      "Epoch 152/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.0882 - accuracy: 0.9689 - val_loss: 0.1425 - val_accuracy: 0.9524\n",
      "Epoch 153/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.0845 - accuracy: 0.9699 - val_loss: 0.1453 - val_accuracy: 0.9520\n",
      "Epoch 154/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.0834 - accuracy: 0.9693 - val_loss: 0.1485 - val_accuracy: 0.9511\n",
      "Epoch 155/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.0860 - accuracy: 0.9688 - val_loss: 0.1367 - val_accuracy: 0.9524\n",
      "Epoch 156/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.0831 - accuracy: 0.9683 - val_loss: 0.1384 - val_accuracy: 0.9507\n",
      "test:0.920873\n",
      "valid:0.954364\n",
      "train:0.987864\n",
      "acc:0.927044\n",
      "0.9270441801712983\n",
      "Train on 22000 samples, validate on 5500 samples\n",
      "Epoch 1/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.4070 - accuracy: 0.8361 - val_loss: 0.3151 - val_accuracy: 0.8738\n",
      "Epoch 2/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.3278 - accuracy: 0.8688 - val_loss: 0.2922 - val_accuracy: 0.8847\n",
      "Epoch 3/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.3066 - accuracy: 0.8782 - val_loss: 0.2708 - val_accuracy: 0.8925\n",
      "Epoch 4/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2874 - accuracy: 0.8865 - val_loss: 0.2577 - val_accuracy: 0.8969\n",
      "Epoch 5/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2727 - accuracy: 0.8928 - val_loss: 0.2481 - val_accuracy: 0.9005\n",
      "Epoch 6/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2587 - accuracy: 0.8990 - val_loss: 0.2474 - val_accuracy: 0.9015\n",
      "Epoch 7/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.2526 - accuracy: 0.9009 - val_loss: 0.2319 - val_accuracy: 0.9053\n",
      "Epoch 8/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2442 - accuracy: 0.9047 - val_loss: 0.2319 - val_accuracy: 0.9069\n",
      "Epoch 9/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2350 - accuracy: 0.9090 - val_loss: 0.2206 - val_accuracy: 0.9104\n",
      "Epoch 10/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2316 - accuracy: 0.9091 - val_loss: 0.2224 - val_accuracy: 0.9124\n",
      "Epoch 11/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.2224 - accuracy: 0.9142 - val_loss: 0.2122 - val_accuracy: 0.9156\n",
      "Epoch 12/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2186 - accuracy: 0.9155 - val_loss: 0.2088 - val_accuracy: 0.9175\n",
      "Epoch 13/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2131 - accuracy: 0.9184 - val_loss: 0.2019 - val_accuracy: 0.9198\n",
      "Epoch 14/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2040 - accuracy: 0.9208 - val_loss: 0.2021 - val_accuracy: 0.9191\n",
      "Epoch 15/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2016 - accuracy: 0.9224 - val_loss: 0.1963 - val_accuracy: 0.9236\n",
      "Epoch 16/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.2013 - accuracy: 0.9217 - val_loss: 0.1989 - val_accuracy: 0.9209\n",
      "Epoch 17/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1952 - accuracy: 0.9252 - val_loss: 0.1913 - val_accuracy: 0.9229\n",
      "Epoch 18/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.1933 - accuracy: 0.9270 - val_loss: 0.1918 - val_accuracy: 0.9224\n",
      "Epoch 19/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1880 - accuracy: 0.9264 - val_loss: 0.1876 - val_accuracy: 0.9249\n",
      "Epoch 20/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.1852 - accuracy: 0.9280 - val_loss: 0.1888 - val_accuracy: 0.9256\n",
      "Epoch 21/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.1818 - accuracy: 0.9283 - val_loss: 0.1858 - val_accuracy: 0.9287\n",
      "Epoch 22/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.1763 - accuracy: 0.9339 - val_loss: 0.1847 - val_accuracy: 0.9267\n",
      "Epoch 23/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1738 - accuracy: 0.9342 - val_loss: 0.1833 - val_accuracy: 0.9298\n",
      "Epoch 24/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.1743 - accuracy: 0.9342 - val_loss: 0.1877 - val_accuracy: 0.9269\n",
      "Epoch 25/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.1708 - accuracy: 0.9343 - val_loss: 0.1754 - val_accuracy: 0.9291\n",
      "Epoch 26/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.1720 - accuracy: 0.9345 - val_loss: 0.1805 - val_accuracy: 0.9293\n",
      "Epoch 27/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1691 - accuracy: 0.9352 - val_loss: 0.1762 - val_accuracy: 0.9305\n",
      "Epoch 28/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.1686 - accuracy: 0.9365 - val_loss: 0.1771 - val_accuracy: 0.9295\n",
      "Epoch 29/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.1674 - accuracy: 0.9361 - val_loss: 0.1831 - val_accuracy: 0.9307\n",
      "Epoch 30/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1619 - accuracy: 0.9365 - val_loss: 0.1812 - val_accuracy: 0.9307\n",
      "Epoch 31/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.1603 - accuracy: 0.9389 - val_loss: 0.1751 - val_accuracy: 0.9320\n",
      "Epoch 32/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1518 - accuracy: 0.9424 - val_loss: 0.1768 - val_accuracy: 0.9320\n",
      "Epoch 33/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1562 - accuracy: 0.9409 - val_loss: 0.1711 - val_accuracy: 0.9327\n",
      "Epoch 34/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1527 - accuracy: 0.9415 - val_loss: 0.1761 - val_accuracy: 0.9307\n",
      "Epoch 35/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1526 - accuracy: 0.9433 - val_loss: 0.1728 - val_accuracy: 0.9338\n",
      "Epoch 36/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1482 - accuracy: 0.9432 - val_loss: 0.1728 - val_accuracy: 0.9325\n",
      "Epoch 37/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1496 - accuracy: 0.9449 - val_loss: 0.1729 - val_accuracy: 0.9344\n",
      "Epoch 38/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.1461 - accuracy: 0.9438 - val_loss: 0.1719 - val_accuracy: 0.9331\n",
      "Epoch 39/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1431 - accuracy: 0.9470 - val_loss: 0.1659 - val_accuracy: 0.9364\n",
      "Epoch 40/200\n",
      "22000/22000 [==============================] - 1s 57us/sample - loss: 0.1449 - accuracy: 0.9460 - val_loss: 0.1706 - val_accuracy: 0.9331\n",
      "Epoch 41/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.1422 - accuracy: 0.9461 - val_loss: 0.1723 - val_accuracy: 0.9358\n",
      "Epoch 42/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1396 - accuracy: 0.9480 - val_loss: 0.1687 - val_accuracy: 0.9382\n",
      "Epoch 43/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.1387 - accuracy: 0.9473 - val_loss: 0.1657 - val_accuracy: 0.9378\n",
      "Epoch 44/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1412 - accuracy: 0.9469 - val_loss: 0.1701 - val_accuracy: 0.9371\n",
      "Epoch 45/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.1384 - accuracy: 0.9476 - val_loss: 0.1620 - val_accuracy: 0.9393\n",
      "Epoch 46/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1383 - accuracy: 0.9472 - val_loss: 0.1621 - val_accuracy: 0.9373\n",
      "Epoch 47/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.1372 - accuracy: 0.9478 - val_loss: 0.1660 - val_accuracy: 0.9362\n",
      "Epoch 48/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.1353 - accuracy: 0.9491 - val_loss: 0.1659 - val_accuracy: 0.9353\n",
      "Epoch 49/200\n",
      "22000/22000 [==============================] - 1s 52us/sample - loss: 0.1348 - accuracy: 0.9500 - val_loss: 0.1664 - val_accuracy: 0.9380\n",
      "Epoch 50/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.1338 - accuracy: 0.9500 - val_loss: 0.1664 - val_accuracy: 0.9396\n",
      "Epoch 51/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.1331 - accuracy: 0.9513 - val_loss: 0.1629 - val_accuracy: 0.9402\n",
      "Epoch 52/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.1309 - accuracy: 0.9495 - val_loss: 0.1639 - val_accuracy: 0.9382\n",
      "Epoch 53/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.1291 - accuracy: 0.9521 - val_loss: 0.1582 - val_accuracy: 0.9385\n",
      "Epoch 54/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.1257 - accuracy: 0.9518 - val_loss: 0.1593 - val_accuracy: 0.9413\n",
      "Epoch 55/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.1271 - accuracy: 0.9524 - val_loss: 0.1604 - val_accuracy: 0.9415\n",
      "Epoch 56/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.1254 - accuracy: 0.9543 - val_loss: 0.1609 - val_accuracy: 0.9435\n",
      "Epoch 57/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1303 - accuracy: 0.9501 - val_loss: 0.1584 - val_accuracy: 0.9416\n",
      "Epoch 58/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.1258 - accuracy: 0.9525 - val_loss: 0.1549 - val_accuracy: 0.9405\n",
      "Epoch 59/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1250 - accuracy: 0.9538 - val_loss: 0.1574 - val_accuracy: 0.9422\n",
      "Epoch 60/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22000/22000 [==============================] - 1s 56us/sample - loss: 0.1238 - accuracy: 0.9542 - val_loss: 0.1590 - val_accuracy: 0.9411\n",
      "Epoch 61/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.1191 - accuracy: 0.9545 - val_loss: 0.1567 - val_accuracy: 0.9404\n",
      "Epoch 62/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1213 - accuracy: 0.9537 - val_loss: 0.1562 - val_accuracy: 0.9438\n",
      "Epoch 63/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.1230 - accuracy: 0.9544 - val_loss: 0.1583 - val_accuracy: 0.9435\n",
      "Epoch 64/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1226 - accuracy: 0.9545 - val_loss: 0.1564 - val_accuracy: 0.9420\n",
      "Epoch 65/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.1193 - accuracy: 0.9552 - val_loss: 0.1604 - val_accuracy: 0.9438\n",
      "Epoch 66/200\n",
      "22000/22000 [==============================] - 1s 62us/sample - loss: 0.1166 - accuracy: 0.9558 - val_loss: 0.1680 - val_accuracy: 0.9438\n",
      "Epoch 67/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.1195 - accuracy: 0.9546 - val_loss: 0.1707 - val_accuracy: 0.9433\n",
      "Epoch 68/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.1211 - accuracy: 0.9547 - val_loss: 0.1571 - val_accuracy: 0.9438\n",
      "Epoch 69/200\n",
      "22000/22000 [==============================] - 1s 56us/sample - loss: 0.1197 - accuracy: 0.9551 - val_loss: 0.1604 - val_accuracy: 0.9420\n",
      "Epoch 70/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.1122 - accuracy: 0.9584 - val_loss: 0.1548 - val_accuracy: 0.9451\n",
      "Epoch 71/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.1121 - accuracy: 0.9598 - val_loss: 0.1554 - val_accuracy: 0.9431\n",
      "Epoch 72/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.1100 - accuracy: 0.9591 - val_loss: 0.1536 - val_accuracy: 0.9444\n",
      "Epoch 73/200\n",
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.1159 - accuracy: 0.9558 - val_loss: 0.1547 - val_accuracy: 0.9427\n",
      "Epoch 74/200\n",
      "22000/22000 [==============================] - 1s 53us/sample - loss: 0.1119 - accuracy: 0.9585 - val_loss: 0.1585 - val_accuracy: 0.9442\n",
      "Epoch 75/200\n",
      "22000/22000 [==============================] - 1s 59us/sample - loss: 0.1098 - accuracy: 0.9594 - val_loss: 0.1613 - val_accuracy: 0.9460\n",
      "Epoch 76/200\n",
      "22000/22000 [==============================] - 1s 58us/sample - loss: 0.1106 - accuracy: 0.9591 - val_loss: 0.1645 - val_accuracy: 0.9433\n",
      "Epoch 77/200\n",
      "22000/22000 [==============================] - 1s 65us/sample - loss: 0.1100 - accuracy: 0.9594 - val_loss: 0.1622 - val_accuracy: 0.9460\n",
      "Epoch 78/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.1109 - accuracy: 0.9598 - val_loss: 0.1586 - val_accuracy: 0.9427\n",
      "Epoch 79/200\n",
      "22000/22000 [==============================] - 1s 55us/sample - loss: 0.1100 - accuracy: 0.9588 - val_loss: 0.1631 - val_accuracy: 0.9445\n",
      "Epoch 80/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.1088 - accuracy: 0.9608 - val_loss: 0.1535 - val_accuracy: 0.9464\n",
      "Epoch 81/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.1070 - accuracy: 0.9611 - val_loss: 0.1590 - val_accuracy: 0.9453\n",
      "Epoch 82/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.1069 - accuracy: 0.9601 - val_loss: 0.1581 - val_accuracy: 0.9444\n",
      "Epoch 83/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1094 - accuracy: 0.9590 - val_loss: 0.1586 - val_accuracy: 0.9431\n",
      "Epoch 84/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.1103 - accuracy: 0.9603 - val_loss: 0.1574 - val_accuracy: 0.9435\n",
      "Epoch 85/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.1053 - accuracy: 0.9603 - val_loss: 0.1560 - val_accuracy: 0.9442\n",
      "Epoch 86/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1056 - accuracy: 0.9622 - val_loss: 0.1560 - val_accuracy: 0.9413\n",
      "Epoch 87/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1046 - accuracy: 0.9608 - val_loss: 0.1545 - val_accuracy: 0.9464\n",
      "Epoch 88/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1085 - accuracy: 0.9619 - val_loss: 0.1653 - val_accuracy: 0.9433\n",
      "Epoch 89/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.1065 - accuracy: 0.9601 - val_loss: 0.1580 - val_accuracy: 0.9445\n",
      "Epoch 90/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1048 - accuracy: 0.9617 - val_loss: 0.1637 - val_accuracy: 0.9407\n",
      "Epoch 91/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.0981 - accuracy: 0.9641 - val_loss: 0.1528 - val_accuracy: 0.9465\n",
      "Epoch 92/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1064 - accuracy: 0.9613 - val_loss: 0.1511 - val_accuracy: 0.9464\n",
      "Epoch 93/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1007 - accuracy: 0.9634 - val_loss: 0.1528 - val_accuracy: 0.9455\n",
      "Epoch 94/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1015 - accuracy: 0.9632 - val_loss: 0.1536 - val_accuracy: 0.9471\n",
      "Epoch 95/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1032 - accuracy: 0.9633 - val_loss: 0.1500 - val_accuracy: 0.9478\n",
      "Epoch 96/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1083 - accuracy: 0.9605 - val_loss: 0.1476 - val_accuracy: 0.9484\n",
      "Epoch 97/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1003 - accuracy: 0.9640 - val_loss: 0.1538 - val_accuracy: 0.9511\n",
      "Epoch 98/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1012 - accuracy: 0.9626 - val_loss: 0.1488 - val_accuracy: 0.9482\n",
      "Epoch 99/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.1027 - accuracy: 0.9613 - val_loss: 0.1531 - val_accuracy: 0.9480\n",
      "Epoch 100/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.0981 - accuracy: 0.9636 - val_loss: 0.1520 - val_accuracy: 0.9469\n",
      "Epoch 101/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.0972 - accuracy: 0.9634 - val_loss: 0.1530 - val_accuracy: 0.9467\n",
      "Epoch 102/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.0963 - accuracy: 0.9645 - val_loss: 0.1621 - val_accuracy: 0.9449\n",
      "Epoch 103/200\n",
      "22000/22000 [==============================] - 1s 54us/sample - loss: 0.0962 - accuracy: 0.9639 - val_loss: 0.1615 - val_accuracy: 0.9471\n",
      "Epoch 104/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.0990 - accuracy: 0.9641 - val_loss: 0.1521 - val_accuracy: 0.9471\n",
      "Epoch 105/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.0969 - accuracy: 0.9644 - val_loss: 0.1550 - val_accuracy: 0.9480\n",
      "Epoch 106/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.0978 - accuracy: 0.9654 - val_loss: 0.1561 - val_accuracy: 0.9485\n",
      "Epoch 107/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.0945 - accuracy: 0.9654 - val_loss: 0.1574 - val_accuracy: 0.9480\n",
      "Epoch 108/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.0999 - accuracy: 0.9648 - val_loss: 0.1529 - val_accuracy: 0.9496\n",
      "Epoch 109/200\n",
      "22000/22000 [==============================] - 1s 51us/sample - loss: 0.1014 - accuracy: 0.9632 - val_loss: 0.1472 - val_accuracy: 0.9487\n",
      "Epoch 110/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.0933 - accuracy: 0.9658 - val_loss: 0.1602 - val_accuracy: 0.9495\n",
      "Epoch 111/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.0933 - accuracy: 0.9669 - val_loss: 0.1488 - val_accuracy: 0.9465\n",
      "Epoch 112/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.0934 - accuracy: 0.9660 - val_loss: 0.1501 - val_accuracy: 0.9464\n",
      "Epoch 113/200\n",
      "22000/22000 [==============================] - 1s 50us/sample - loss: 0.0950 - accuracy: 0.9642 - val_loss: 0.1500 - val_accuracy: 0.9476\n",
      "Epoch 114/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22000/22000 [==============================] - 1s 47us/sample - loss: 0.0924 - accuracy: 0.9668 - val_loss: 0.1500 - val_accuracy: 0.9476\n",
      "Epoch 115/200\n",
      "22000/22000 [==============================] - 1s 49us/sample - loss: 0.0942 - accuracy: 0.9660 - val_loss: 0.1520 - val_accuracy: 0.9475\n",
      "Epoch 116/200\n",
      "22000/22000 [==============================] - 1s 48us/sample - loss: 0.0953 - accuracy: 0.9652 - val_loss: 0.1493 - val_accuracy: 0.9484\n",
      "Epoch 117/200\n",
      "22000/22000 [==============================] - 1s 46us/sample - loss: 0.0963 - accuracy: 0.9645 - val_loss: 0.1421 - val_accuracy: 0.9496\n",
      "test:0.904291\n",
      "valid:0.951091\n",
      "train:0.986136\n",
      "acc:0.894982\n",
      "0.8949822334504077\n"
     ]
    }
   ],
   "source": [
    "acc={}\n",
    "cols = ['LEFT','RIGHT']\n",
    "\n",
    "sc = StandardScaler(with_mean=True)\n",
    "\n",
    "for col in cols:\n",
    "    ind_temp=feature.columns.str.contains(col)\n",
    "    feature_sc = sc.fit_transform(feature.loc[:,ind_temp])\n",
    "    feature2_sc = sc.transform(feature2.loc[:,ind_temp])\n",
    "    train,valid,test = train_model(model,feature_sc,np.array(y))\n",
    "    \n",
    "    acc_rest=test_model(model,feature2_sc,np.array(y2))\n",
    "    acc[col] = [train,valid,test,acc_rest]\n",
    "    print(acc_rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LEFT</th>\n",
       "      <th>RIGHT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.987864</td>\n",
       "      <td>0.986136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid</th>\n",
       "      <td>0.954364</td>\n",
       "      <td>0.951091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.920873</td>\n",
       "      <td>0.904291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rest data</th>\n",
       "      <td>0.927044</td>\n",
       "      <td>0.894982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               LEFT     RIGHT\n",
       "train      0.987864  0.986136\n",
       "valid      0.954364  0.951091\n",
       "test       0.920873  0.904291\n",
       "rest data  0.927044  0.894982"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(acc,index=['train','valid','test','rest data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test features from 2 of 8 signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-d5383c83696d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mfeature_sc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mind_temp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mfeature2_sc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mind_temp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mind_temp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0macc_rest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeature2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mind_temp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0macc_2f\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0macc_rest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-53-d0919d80e212>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, feature, y, file)\u001b[0m\n\u001b[0;32m     28\u001b[0m     history = model.fit(x_train,y_train,validation_data=[x_valid,y_valid],\n\u001b[0;32m     29\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m                         callbacks=[early_stopping])\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    703\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unrecognized keyword arguments: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 705\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assert_compile_was_called\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    706\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_call_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fit'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2872\u001b[0m     \u001b[1;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2873\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2874\u001b[1;33m       raise RuntimeError('You must compile your model before '\n\u001b[0m\u001b[0;32m   2875\u001b[0m                          \u001b[1;34m'training/testing. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2876\u001b[0m                          'Use `model.compile(optimizer, loss)`.')\n",
      "\u001b[1;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "#test features from 2 of 8 signals\n",
    "\n",
    "acc_2f={}\n",
    "cols = [ 'LEFT_TA','LEFT_TS','LEFT_BF', 'LEFT_RF',\n",
    "        'RIGHT_TA','RIGHT_TS','RIGHT_BF', 'RIGHT_RF']\n",
    "\n",
    "\n",
    "for p in combinations(cols[:4],2):\n",
    "    ind_temp=feature.columns.str.contains(p[0])| feature.columns.str.contains(p[1])\n",
    "    feature_sc = sc.fit_transform(feature.loc[:,ind_temp])\n",
    "    feature2_sc = sc.transform(feature2.loc[:,ind_temp])\n",
    "    train,valid,test = train_model(model,feature.loc[:,ind_temp],y)\n",
    "    acc_rest=test_model(model,feature2.loc[:,ind_temp],y2)\n",
    "    acc_2f[p[0]+'_'+p[1]] = [train,valid,test,acc_rest]\n",
    "    print(acc_rest)\n",
    "    \n",
    "for p in combinations(cols[4:],2):\n",
    "    ind_temp=feature.columns.str.contains(p[0])| feature.columns.str.contains(p[1])\n",
    "    feature_sc = sc.fit_transform(feature.loc[:,ind_temp])\n",
    "    feature2_sc = sc.transform(feature2.loc[:,ind_temp])\n",
    "    train,valid,test = train_model(model,feature.loc[:,ind_temp],y)\n",
    "    acc_rest=test_model(model,feature2.loc[:,ind_temp],y2)\n",
    "    acc_2f[p[0]+'_'+p[1]] = [train,valid,test,acc_rest]\n",
    "    print(acc_rest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on some of rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:0.997041\n",
      "acc:0.994048\n",
      "acc:0.956284\n",
      "acc:0.980276\n",
      "acc:0.991055\n",
      "acc:0.906706\n",
      "acc:0.856749\n",
      "acc:0.966764\n",
      "[0.9970414201183432, 0.9940476190476191, 0.9562841530054644, 0.980276134122288, 0.9910554561717353, 0.9067055393586005, 0.8567493112947658, 0.9667644183773216]\n"
     ]
    }
   ],
   "source": [
    "some_of_rest = ['正常/P940_MSham_B_Walking_trial_6_emg.csv',\n",
    "                '正常/P940_M050_B_Walking_trial_4_emg.csv',\n",
    "                '正常/P812_M100_A_Walking_trial_3_emg.csv',\n",
    "                '正常/P645_M050_A_Walking_trial_3_emg.csv',\n",
    "                '正常/P623_Msham_B_Walking_trial_2_emg.csv',\n",
    "                '正常/P551_M50_B_Walking_trial_6_emg.csv',\n",
    "                'P379_M050_2_OFF_A_FoG_trial_1_emg.csv',\n",
    "                'P551_M050_2_B_FoG_trial_2_emg.csv']\n",
    "#booster = xgb.Booster()\n",
    "#booster.load_model('./model/XGBoost_W256_S64_Left.json')\n",
    "#model = xgb.XGBClassifier()\n",
    "#model._Booster = booster\n",
    "acc = []\n",
    "columns=['LEFT_TA','LEFT_TS','LEFT_BF', 'LEFT_RF']\n",
    "for file in some_of_rest:\n",
    "    path = './data/'+file\n",
    "    feature2,y2 = dp.pipeline_feature(path,width=256,stride=64,scaler=False,\n",
    "                                      threshold_WAMP=threshold_WAMP,\n",
    "                                      threshold_ZC=threshold_ZC,\n",
    "                                      threshold_SSC=threshold_SSC,\n",
    "                                      bins=bins,\n",
    "                                      ranges=HIST_range,\n",
    "                                      show_para=False,\n",
    "                                      filt = 250)\n",
    "    feature2_sc = sc.transform(feature2)\n",
    "    acc += [test_model(model,feature2_sc,y2)]\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9589472691255542"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=model.predict(feature2_sc)\n",
    "metrics.accuracy_score(y2,y_pred>0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_re = feature_sc.reshape((-1,feature.shape[1],1))\n",
    "x_full,x_test,y_full,y_test = train_test_split(feature_re,y_01,test_size=0.2,random_state=123)\n",
    "x_train,x_valid,y_train,y_valid = train_test_split(x_full,y_full,test_size=0.2,random_state=555)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = layers.Input(shape=[feature.shape[1],1])\n",
    "lstm1 = layers.GRU(100)(input_)\n",
    "#lstm2 = layers.LSTM(20)(lstm1)\n",
    "output = layers.Dense(1,activation='sigmoid')(lstm1)\n",
    "model = Model(inputs=[input_],outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21990 samples, validate on 5498 samples\n",
      "Epoch 1/100\n",
      "21990/21990 [==============================] - 55s 3ms/sample - loss: 0.6715 - accuracy: 0.5768 - val_loss: 0.6168 - val_accuracy: 0.6808\n",
      "Epoch 2/100\n",
      "21990/21990 [==============================] - 52s 2ms/sample - loss: 0.5631 - accuracy: 0.7150 - val_loss: 0.5077 - val_accuracy: 0.7552\n",
      "Epoch 3/100\n",
      "21990/21990 [==============================] - 52s 2ms/sample - loss: 0.5141 - accuracy: 0.7546 - val_loss: 0.4896 - val_accuracy: 0.7696\n",
      "Epoch 4/100\n",
      "21990/21990 [==============================] - 51s 2ms/sample - loss: 0.4999 - accuracy: 0.7643 - val_loss: 0.4811 - val_accuracy: 0.7803\n",
      "Epoch 5/100\n",
      "21990/21990 [==============================] - 51s 2ms/sample - loss: 0.4728 - accuracy: 0.7853 - val_loss: 0.4479 - val_accuracy: 0.7968\n",
      "Epoch 6/100\n",
      "21990/21990 [==============================] - 54s 2ms/sample - loss: 0.4521 - accuracy: 0.7983 - val_loss: 0.4376 - val_accuracy: 0.8032\n",
      "Epoch 7/100\n",
      "21990/21990 [==============================] - 54s 2ms/sample - loss: 0.4400 - accuracy: 0.8035 - val_loss: 0.4285 - val_accuracy: 0.8047\n",
      "Epoch 8/100\n",
      "21990/21990 [==============================] - 51s 2ms/sample - loss: 0.4256 - accuracy: 0.8104 - val_loss: 0.4125 - val_accuracy: 0.8139\n",
      "Epoch 9/100\n",
      "21990/21990 [==============================] - 50s 2ms/sample - loss: 0.4153 - accuracy: 0.8158 - val_loss: 0.4076 - val_accuracy: 0.8168\n",
      "Epoch 10/100\n",
      "21990/21990 [==============================] - 50s 2ms/sample - loss: 0.4055 - accuracy: 0.8200 - val_loss: 0.3910 - val_accuracy: 0.8248\n",
      "Epoch 11/100\n",
      "21990/21990 [==============================] - 50s 2ms/sample - loss: 0.3986 - accuracy: 0.8251 - val_loss: 0.3954 - val_accuracy: 0.8239\n",
      "Epoch 12/100\n",
      "21990/21990 [==============================] - 50s 2ms/sample - loss: 0.3899 - accuracy: 0.8274 - val_loss: 0.3834 - val_accuracy: 0.8323\n",
      "Epoch 13/100\n",
      "21990/21990 [==============================] - 57s 3ms/sample - loss: 0.3825 - accuracy: 0.8336 - val_loss: 0.3764 - val_accuracy: 0.8330\n",
      "Epoch 14/100\n",
      "21990/21990 [==============================] - 53s 2ms/sample - loss: 0.3781 - accuracy: 0.8344 - val_loss: 0.3763 - val_accuracy: 0.8341\n",
      "Epoch 15/100\n",
      "21990/21990 [==============================] - 50s 2ms/sample - loss: 0.3769 - accuracy: 0.8356 - val_loss: 0.3824 - val_accuracy: 0.8308\n",
      "Epoch 16/100\n",
      "21990/21990 [==============================] - 51s 2ms/sample - loss: 0.3702 - accuracy: 0.8385 - val_loss: 0.3647 - val_accuracy: 0.8392\n",
      "Epoch 17/100\n",
      "21990/21990 [==============================] - 50s 2ms/sample - loss: 0.3664 - accuracy: 0.8400 - val_loss: 0.3628 - val_accuracy: 0.8412\n",
      "Epoch 18/100\n",
      "21990/21990 [==============================] - 51s 2ms/sample - loss: 0.3602 - accuracy: 0.8447 - val_loss: 0.3623 - val_accuracy: 0.8421\n",
      "Epoch 19/100\n",
      "21990/21990 [==============================] - 55s 3ms/sample - loss: 0.3565 - accuracy: 0.8453 - val_loss: 0.3549 - val_accuracy: 0.8443\n",
      "Epoch 20/100\n",
      "21990/21990 [==============================] - 50s 2ms/sample - loss: 0.3611 - accuracy: 0.8427 - val_loss: 0.3642 - val_accuracy: 0.8430\n",
      "Epoch 21/100\n",
      "21990/21990 [==============================] - 51s 2ms/sample - loss: 0.3535 - accuracy: 0.8477 - val_loss: 0.3479 - val_accuracy: 0.8496\n",
      "Epoch 22/100\n",
      "21990/21990 [==============================] - 50s 2ms/sample - loss: 0.3428 - accuracy: 0.8531 - val_loss: 0.3441 - val_accuracy: 0.8510\n",
      "Epoch 23/100\n",
      "21990/21990 [==============================] - 50s 2ms/sample - loss: 0.3367 - accuracy: 0.8567 - val_loss: 0.3428 - val_accuracy: 0.8521\n",
      "Epoch 24/100\n",
      "21990/21990 [==============================] - 51s 2ms/sample - loss: 0.3370 - accuracy: 0.8578 - val_loss: 0.3387 - val_accuracy: 0.8534\n",
      "Epoch 25/100\n",
      "21990/21990 [==============================] - 55s 2ms/sample - loss: 0.3334 - accuracy: 0.8593 - val_loss: 0.3467 - val_accuracy: 0.8532\n",
      "Epoch 26/100\n",
      "21990/21990 [==============================] - 59s 3ms/sample - loss: 0.3366 - accuracy: 0.8578 - val_loss: 0.3497 - val_accuracy: 0.8485\n",
      "Epoch 27/100\n",
      "21990/21990 [==============================] - 55s 2ms/sample - loss: 0.3239 - accuracy: 0.8637 - val_loss: 0.3408 - val_accuracy: 0.8509\n",
      "Epoch 28/100\n",
      "21990/21990 [==============================] - 57s 3ms/sample - loss: 0.3187 - accuracy: 0.8674 - val_loss: 0.3296 - val_accuracy: 0.8579\n",
      "Epoch 29/100\n",
      "21990/21990 [==============================] - 54s 2ms/sample - loss: 0.3141 - accuracy: 0.8695 - val_loss: 0.3242 - val_accuracy: 0.8607\n",
      "Epoch 30/100\n",
      "21990/21990 [==============================] - 53s 2ms/sample - loss: 0.3147 - accuracy: 0.8709 - val_loss: 0.3199 - val_accuracy: 0.8592\n",
      "Epoch 31/100\n",
      "21990/21990 [==============================] - 55s 2ms/sample - loss: 0.3040 - accuracy: 0.8740 - val_loss: 0.3198 - val_accuracy: 0.8636\n",
      "Epoch 32/100\n",
      "21990/21990 [==============================] - 51s 2ms/sample - loss: 0.2984 - accuracy: 0.8792 - val_loss: 0.3172 - val_accuracy: 0.8647\n",
      "Epoch 33/100\n",
      "21990/21990 [==============================] - 54s 2ms/sample - loss: 0.2944 - accuracy: 0.8793 - val_loss: 0.3056 - val_accuracy: 0.8703\n",
      "Epoch 34/100\n",
      "21990/21990 [==============================] - 58s 3ms/sample - loss: 0.2918 - accuracy: 0.8804 - val_loss: 0.3224 - val_accuracy: 0.8665\n",
      "Epoch 35/100\n",
      "21990/21990 [==============================] - 60s 3ms/sample - loss: 0.2965 - accuracy: 0.8781 - val_loss: 0.3047 - val_accuracy: 0.8685\n",
      "Epoch 36/100\n",
      "21990/21990 [==============================] - 61s 3ms/sample - loss: 0.2858 - accuracy: 0.8834 - val_loss: 0.3056 - val_accuracy: 0.8730\n",
      "Epoch 37/100\n",
      "21990/21990 [==============================] - 70s 3ms/sample - loss: 0.2817 - accuracy: 0.8855 - val_loss: 0.3023 - val_accuracy: 0.8738\n",
      "Epoch 38/100\n",
      "21990/21990 [==============================] - 59s 3ms/sample - loss: 0.2824 - accuracy: 0.8838 - val_loss: 0.2955 - val_accuracy: 0.8750\n",
      "Epoch 39/100\n",
      "21990/21990 [==============================] - 59s 3ms/sample - loss: 0.2764 - accuracy: 0.8876 - val_loss: 0.2927 - val_accuracy: 0.8772\n",
      "Epoch 40/100\n",
      "21990/21990 [==============================] - 58s 3ms/sample - loss: 0.2754 - accuracy: 0.8880 - val_loss: 0.2878 - val_accuracy: 0.8798\n",
      "Epoch 41/100\n",
      "21990/21990 [==============================] - 58s 3ms/sample - loss: 0.2713 - accuracy: 0.8900 - val_loss: 0.2879 - val_accuracy: 0.8809\n",
      "Epoch 42/100\n",
      "21990/21990 [==============================] - 64s 3ms/sample - loss: 0.2708 - accuracy: 0.8917 - val_loss: 0.2857 - val_accuracy: 0.8821\n",
      "Epoch 43/100\n",
      "21990/21990 [==============================] - 61s 3ms/sample - loss: 0.2661 - accuracy: 0.8942 - val_loss: 0.2970 - val_accuracy: 0.8767\n",
      "Epoch 44/100\n",
      "21990/21990 [==============================] - 58s 3ms/sample - loss: 0.2641 - accuracy: 0.8933 - val_loss: 0.2820 - val_accuracy: 0.8863\n",
      "Epoch 45/100\n",
      "21990/21990 [==============================] - 58s 3ms/sample - loss: 0.2623 - accuracy: 0.8945 - val_loss: 0.2780 - val_accuracy: 0.8867\n",
      "Epoch 46/100\n",
      "21990/21990 [==============================] - 60s 3ms/sample - loss: 0.2595 - accuracy: 0.8976 - val_loss: 0.2897 - val_accuracy: 0.8783\n",
      "Epoch 47/100\n",
      "21990/21990 [==============================] - 60s 3ms/sample - loss: 0.2594 - accuracy: 0.8964 - val_loss: 0.2728 - val_accuracy: 0.8916\n",
      "Epoch 48/100\n",
      "21990/21990 [==============================] - 68s 3ms/sample - loss: 0.2608 - accuracy: 0.8952 - val_loss: 0.2785 - val_accuracy: 0.8841\n",
      "Epoch 49/100\n",
      "21990/21990 [==============================] - 59s 3ms/sample - loss: 0.2615 - accuracy: 0.8950 - val_loss: 0.2793 - val_accuracy: 0.8880\n",
      "Epoch 50/100\n",
      "21990/21990 [==============================] - 58s 3ms/sample - loss: 0.2507 - accuracy: 0.9005 - val_loss: 0.2762 - val_accuracy: 0.8854\n",
      "Epoch 51/100\n",
      "21990/21990 [==============================] - 57s 3ms/sample - loss: 0.2523 - accuracy: 0.9002 - val_loss: 0.2679 - val_accuracy: 0.8912\n",
      "Epoch 52/100\n",
      "21990/21990 [==============================] - 59s 3ms/sample - loss: 0.2469 - accuracy: 0.9012 - val_loss: 0.2665 - val_accuracy: 0.8961\n",
      "Epoch 53/100\n",
      "21990/21990 [==============================] - 67s 3ms/sample - loss: 0.2469 - accuracy: 0.9022 - val_loss: 0.2704 - val_accuracy: 0.8892\n",
      "Epoch 54/100\n",
      "21990/21990 [==============================] - 58s 3ms/sample - loss: 0.2519 - accuracy: 0.8998 - val_loss: 0.2953 - val_accuracy: 0.8740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "21990/21990 [==============================] - 59s 3ms/sample - loss: 0.2446 - accuracy: 0.9028 - val_loss: 0.2694 - val_accuracy: 0.8909\n",
      "Epoch 56/100\n",
      "21990/21990 [==============================] - 60s 3ms/sample - loss: 0.2435 - accuracy: 0.9028 - val_loss: 0.2641 - val_accuracy: 0.8927\n",
      "Epoch 57/100\n",
      "21990/21990 [==============================] - 58s 3ms/sample - loss: 0.2359 - accuracy: 0.9075 - val_loss: 0.2672 - val_accuracy: 0.8927\n",
      "Epoch 58/100\n",
      "21990/21990 [==============================] - 58s 3ms/sample - loss: 0.2331 - accuracy: 0.9080 - val_loss: 0.2556 - val_accuracy: 0.8994\n",
      "Epoch 59/100\n",
      "21990/21990 [==============================] - 66s 3ms/sample - loss: 0.2314 - accuracy: 0.9074 - val_loss: 0.2608 - val_accuracy: 0.8920\n",
      "Epoch 60/100\n",
      "21990/21990 [==============================] - 58s 3ms/sample - loss: 0.2337 - accuracy: 0.9083 - val_loss: 0.2617 - val_accuracy: 0.8952\n",
      "Epoch 61/100\n",
      "21990/21990 [==============================] - 58s 3ms/sample - loss: 0.2263 - accuracy: 0.9112 - val_loss: 0.2680 - val_accuracy: 0.8938\n",
      "Epoch 62/100\n",
      "21990/21990 [==============================] - 59s 3ms/sample - loss: 0.2256 - accuracy: 0.9116 - val_loss: 0.2648 - val_accuracy: 0.8912\n",
      "Epoch 63/100\n",
      "21990/21990 [==============================] - 58s 3ms/sample - loss: 0.2272 - accuracy: 0.9104 - val_loss: 0.2523 - val_accuracy: 0.9016\n",
      "Epoch 64/100\n",
      "21990/21990 [==============================] - 68s 3ms/sample - loss: 0.2188 - accuracy: 0.9149 - val_loss: 0.2563 - val_accuracy: 0.8983\n",
      "Epoch 65/100\n",
      "21990/21990 [==============================] - 58s 3ms/sample - loss: 0.2192 - accuracy: 0.9143 - val_loss: 0.2599 - val_accuracy: 0.8958\n",
      "Epoch 66/100\n",
      "21990/21990 [==============================] - 60s 3ms/sample - loss: 0.2175 - accuracy: 0.9144 - val_loss: 0.2565 - val_accuracy: 0.8994\n",
      "Epoch 67/100\n",
      "21990/21990 [==============================] - 63s 3ms/sample - loss: 0.2191 - accuracy: 0.9151 - val_loss: 0.2565 - val_accuracy: 0.9012\n",
      "Epoch 68/100\n",
      "21990/21990 [==============================] - 60s 3ms/sample - loss: 0.2188 - accuracy: 0.9146 - val_loss: 0.2499 - val_accuracy: 0.8976\n",
      "Epoch 69/100\n",
      "21990/21990 [==============================] - 68s 3ms/sample - loss: 0.2161 - accuracy: 0.9147 - val_loss: 0.2448 - val_accuracy: 0.9031\n",
      "Epoch 70/100\n",
      "21990/21990 [==============================] - 68s 3ms/sample - loss: 0.2097 - accuracy: 0.9181 - val_loss: 0.2669 - val_accuracy: 0.8934\n",
      "Epoch 71/100\n",
      "21990/21990 [==============================] - 65s 3ms/sample - loss: 0.2124 - accuracy: 0.9186 - val_loss: 0.2402 - val_accuracy: 0.9041\n",
      "Epoch 72/100\n",
      "21990/21990 [==============================] - 58s 3ms/sample - loss: 0.2059 - accuracy: 0.9209 - val_loss: 0.2535 - val_accuracy: 0.9000\n",
      "Epoch 73/100\n",
      "21990/21990 [==============================] - 63s 3ms/sample - loss: 0.2042 - accuracy: 0.9212 - val_loss: 0.2632 - val_accuracy: 0.8951\n",
      "Epoch 74/100\n",
      "21990/21990 [==============================] - 61s 3ms/sample - loss: 0.2007 - accuracy: 0.9223 - val_loss: 0.2516 - val_accuracy: 0.9018\n",
      "Epoch 75/100\n",
      "21990/21990 [==============================] - 69s 3ms/sample - loss: 0.1959 - accuracy: 0.9240 - val_loss: 0.2480 - val_accuracy: 0.9049\n",
      "Epoch 76/100\n",
      "21990/21990 [==============================] - 54s 2ms/sample - loss: 0.1995 - accuracy: 0.9223 - val_loss: 0.2474 - val_accuracy: 0.9021\n",
      "Epoch 77/100\n",
      "21990/21990 [==============================] - 52s 2ms/sample - loss: 0.1951 - accuracy: 0.9256 - val_loss: 0.2463 - val_accuracy: 0.9012\n",
      "Epoch 78/100\n",
      "21990/21990 [==============================] - 51s 2ms/sample - loss: 0.1940 - accuracy: 0.9255 - val_loss: 0.2395 - val_accuracy: 0.9072\n",
      "Epoch 79/100\n",
      "21990/21990 [==============================] - 53s 2ms/sample - loss: 0.1882 - accuracy: 0.9290 - val_loss: 0.2450 - val_accuracy: 0.9054\n",
      "Epoch 80/100\n",
      "21990/21990 [==============================] - 53s 2ms/sample - loss: 0.1900 - accuracy: 0.9274 - val_loss: 0.2403 - val_accuracy: 0.9049\n",
      "Epoch 81/100\n",
      "21990/21990 [==============================] - 54s 2ms/sample - loss: 0.1843 - accuracy: 0.9307 - val_loss: 0.2582 - val_accuracy: 0.8989\n",
      "Epoch 82/100\n",
      "21990/21990 [==============================] - 51s 2ms/sample - loss: 0.1854 - accuracy: 0.9292 - val_loss: 0.2461 - val_accuracy: 0.9021\n",
      "Epoch 83/100\n",
      "21990/21990 [==============================] - 50s 2ms/sample - loss: 0.1944 - accuracy: 0.9250 - val_loss: 0.2446 - val_accuracy: 0.9016\n",
      "Epoch 84/100\n",
      "21990/21990 [==============================] - 51s 2ms/sample - loss: 0.1830 - accuracy: 0.9312 - val_loss: 0.2420 - val_accuracy: 0.9043\n",
      "Epoch 85/100\n",
      "21990/21990 [==============================] - 49s 2ms/sample - loss: 0.1782 - accuracy: 0.9335 - val_loss: 0.2419 - val_accuracy: 0.9038\n",
      "Epoch 86/100\n",
      "21990/21990 [==============================] - 48s 2ms/sample - loss: 0.1778 - accuracy: 0.9327 - val_loss: 0.2529 - val_accuracy: 0.9072\n",
      "Epoch 87/100\n",
      "21990/21990 [==============================] - 66s 3ms/sample - loss: 0.1777 - accuracy: 0.9332 - val_loss: 0.2586 - val_accuracy: 0.8974\n",
      "Epoch 88/100\n",
      "21990/21990 [==============================] - 51s 2ms/sample - loss: 0.1751 - accuracy: 0.9343 - val_loss: 0.2365 - val_accuracy: 0.9100\n",
      "Epoch 89/100\n",
      "21990/21990 [==============================] - 51s 2ms/sample - loss: 0.1706 - accuracy: 0.9364 - val_loss: 0.2363 - val_accuracy: 0.9056\n",
      "Epoch 90/100\n",
      "21990/21990 [==============================] - 51s 2ms/sample - loss: 0.1769 - accuracy: 0.9331 - val_loss: 0.2393 - val_accuracy: 0.9080\n",
      "Epoch 91/100\n",
      "21990/21990 [==============================] - 51s 2ms/sample - loss: 0.1745 - accuracy: 0.9343 - val_loss: 0.2374 - val_accuracy: 0.9067\n",
      "Epoch 92/100\n",
      "21990/21990 [==============================] - 57s 3ms/sample - loss: 0.1649 - accuracy: 0.9388 - val_loss: 0.2482 - val_accuracy: 0.9078\n",
      "Epoch 93/100\n",
      "21990/21990 [==============================] - 63s 3ms/sample - loss: 0.1690 - accuracy: 0.9366 - val_loss: 0.2429 - val_accuracy: 0.9081\n",
      "Epoch 94/100\n",
      "21990/21990 [==============================] - 56s 3ms/sample - loss: 0.1614 - accuracy: 0.9382 - val_loss: 0.2349 - val_accuracy: 0.9118\n",
      "Epoch 95/100\n",
      "21990/21990 [==============================] - 57s 3ms/sample - loss: 0.1564 - accuracy: 0.9424 - val_loss: 0.2483 - val_accuracy: 0.9078\n",
      "Epoch 96/100\n",
      "21990/21990 [==============================] - 47s 2ms/sample - loss: 0.1538 - accuracy: 0.9428 - val_loss: 0.2466 - val_accuracy: 0.9076\n",
      "Epoch 97/100\n",
      "21990/21990 [==============================] - 47s 2ms/sample - loss: 0.1576 - accuracy: 0.9412 - val_loss: 0.2456 - val_accuracy: 0.9096\n",
      "Epoch 98/100\n",
      "21990/21990 [==============================] - 47s 2ms/sample - loss: 0.1532 - accuracy: 0.9437 - val_loss: 0.2464 - val_accuracy: 0.9081\n",
      "Epoch 99/100\n",
      "21990/21990 [==============================] - 51s 2ms/sample - loss: 0.1459 - accuracy: 0.9456 - val_loss: 0.2576 - val_accuracy: 0.9054\n",
      "Epoch 100/100\n",
      "21990/21990 [==============================] - 48s 2ms/sample - loss: 0.1493 - accuracy: 0.9451 - val_loss: 0.2571 - val_accuracy: 0.9054\n"
     ]
    }
   ],
   "source": [
    "early_stopping = callbacks.EarlyStopping(patience = 20,\n",
    "                                         monitor = 'val_accuracy', \n",
    "                                         restore_best_weights=True)\n",
    "history = model.fit(x_train,y_train,validation_data=[x_valid,y_valid],\n",
    "                    epochs=100,batch_size=500,\n",
    "                   callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature2_re = feature2_sc.reshape((-1,feature.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:0.889541\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8895405669599218"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(model,feature2_re,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
